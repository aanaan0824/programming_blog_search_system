<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-atom-one-light" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<p></p>
<div class="toc">
<h3>文章目录</h3>
<ul><li><a href="#1commonpy_2">1.模块解析(common.py)</a></li><li><ul><li><ul><li><a href="#01_Focus_4">01. Focus模块</a></li><li><a href="#02_CONV_29">02. CONV模块</a></li><li><a href="#03Bottleneck_64">03.Bottleneck模块：</a></li><li><a href="#04C3_97">04.C3模块</a></li><li><a href="#05SPP_130">05.SPP模块</a></li></ul>
</li></ul>
</li><li><a href="#2yolov5CBAM_157">2.为yolov5添加CBAM注意力机制</a></li><li><ul><li><ul><li><a href="#01CBAM_158">01.CBAM机制</a></li><li><a href="#02_163">02.具体步骤</a></li><li><ul><li><ul><li><a href="#yolov5lyolov5lyamlC3CBAMC3_164">①.以yolov5l结构为例（其实只是深度和宽度因子不同），修改yolov5l.yaml，将C3模块修改为添加注意力机制后的模块CBAMC3，参数不变即可。</a></li><li><a href="#commonpyCBAMC3_165">②.在common.py中添加CBAMC3模块</a></li><li><a href="#yolopy_228">③.修改yolo.py，添加额外的判断语句</a></li></ul>
</li></ul>
</li></ul>
</li></ul>
</li></ul>
</div>
<br/> 最近在进行yolov5的二次开发，软件开发完毕后才想着对框架进行一些整理和进一步学习，以下将记录一些我的学习记录。
<p></p>
<h1><a id="1commonpy_2"></a>1.模块解析(common.py)</h1>
<p> </p>
<h3><a id="01_Focus_4"></a>01. Focus模块</h3>
<p><strong>作用</strong>：下采样<br/> <strong>输入</strong>：data( 3×640×640 彩色图片)<br/> Focus模块的作用是对图片进行切片，类似于下采样，先将图片变为320×320×12的特征图，再经过3×3的卷积操作，输出通道32，最终变为320×320×32的特征图，是一般卷积计算量的4倍，如此做下采样将无信息丢失。<br/> <strong>输出</strong>：32×320×320特征图<br/> <strong>结构图片描述</strong>：<br/> <img alt="结构图" src="https://img-blog.csdnimg.cn/620cbefbdca74e9c9d58725608c59043.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_15,color_FFFFFF,t_70,g_se,x_16"/><br/> 图示切分过程,channels变为4倍<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/4fb9a46f032b4a3f95e271d010d74c5a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_11,color_FFFFFF,t_70,g_se,x_16"/></p>
<p><strong>代码实现</strong>:</p>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Focus</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Focus wh information into c-space</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, kernel, stride, padding, groups</span>
        <span class="token comment"># c1输入,c2输出,s为步长,k为卷积核大小</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Focus<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1 <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> p<span class="token punctuation">,</span> g<span class="token punctuation">,</span> act<span class="token punctuation">)</span>  <span class="token comment"># 输入channel数量变为4倍</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)</span>
    	<span class="token comment"># 进行切分,再进行concat</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre>
<p> </p>
<h3><a id="02_CONV_29"></a>02. CONV模块</h3>
<ol><li>作者在这个基本卷积模块中封装了三个功能，包括卷积(Conv2d)、BN以及Activate函数(在新版yolov5中，作者采用了SiLU函数作为激活函数)，同时autopad(k, p)实现了自动计算padding的效果。</li><li>总的来说Conv实现了将输入特征经过卷积层，激活函数，归一化层，得到输出层。</li></ol>
<p><strong>输出</strong>：输入大小的一半<br/> <strong>结构图片描述</strong>：<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/d8554343599242639d17389bf7b4670c.png"/></p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/b4bdd308117b4a81aeef180c7e794c3e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_17,color_FFFFFF,t_70,g_se,x_16"/></p>
<p><strong>代码实现</strong>：</p>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Conv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Standard convolution</span>
    <span class="token comment"># ch_in, ch_out, kernel, stride, padding, groups</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    	<span class="token comment"># k为卷积核大小，s为步长</span>
    	<span class="token comment"># g即group,当g=1时，相当于普通卷积,当g&gt;1时,进行分组卷积。</span>
    	<span class="token comment"># 分组卷积相对与普通卷积减少了参数量，提高训练效率</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Conv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> autopad<span class="token punctuation">(</span>k<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>g<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c2<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>Hardswish<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> act <span class="token keyword">is</span> <span class="token boolean">True</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>act <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>act<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">fuseforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p> </p>
<h3><a id="03Bottleneck_64"></a>03.Bottleneck模块：</h3>
<ol><li>先将channel 数减小再扩大（默认减小到一半），具体做法是先进行1×1卷积将channel减小一半，再通过3×3卷积将通道数加倍，并获取特征（共使用两个标准卷积模块），其输入与输出的通道数是不发生改变的。</li><li>shortcut参数控制是否进行残差连接（使用ResNet）。</li><li>在yolov5的backbone中的Bottleneck都默认使shortcut为True，在head中的Bottleneck都不使用shortcut。</li><li>与ResNet对应的，使用add而非concat进行特征融合，使得融合后的特征数不变。</li></ol>
<p><strong>结构图片描述</strong>：<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/f5d497b8883348ac8fa1547b6d04d9ce.png"/></p>
<p><strong>代码实现</strong>：</p>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Bottleneck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Standard bottleneck</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, shortcut, groups, expansion</span>
        <span class="token comment"># 特别参数</span>
        <span class="token comment"># shortcut：是否给bottleneck结构部添加shortcut连接，添加后即为ResNet模块；</span>
        <span class="token comment"># e，即expansion。bottleneck结构中的瓶颈部分的通道膨胀率，默认使用0.5即变为输入的1/2</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> g<span class="token operator">=</span>g<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add <span class="token operator">=</span> shortcut <span class="token keyword">and</span> c1 <span class="token operator">==</span> c2

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>add <span class="token keyword">else</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p> </p>
<h3><a id="04C3_97"></a>04.C3模块</h3>
<ol><li>在新版yolov5中,作者将BottleneckCSP(瓶颈层)模块转变为了C3模块，其结构作用基本相同均为CSP架构，只是在修正单元的选择上有所不同，其包含了3个标准卷积层以及多个Bottleneck模块（数量由配置文件.yaml的n和depth_multiple参数乘积决定）</li><li>从下图可以看出，C3相对于BottleneckCSP模块不同的是，经历过残差输出后的Conv模块被去掉了，concat后的标准卷积模块中的激活函数也由LeakyRelu变为了SiLU（同上）。</li><li>该模块是对残差特征进行学习的主要模块,其结构分为两支,一支使用了上述指定多个Bottleneck堆叠和3个标准卷积层，另一支仅经过一个基本卷积模块，最后将两支进行concat操作。</li></ol>
<p><strong>结构图片描述</strong>：<br/>  <br/> <em>C3模块：</em><br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/3ddad075d6ce4669bf17a19989b3b78d.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_22,color_FFFFFF,t_70,g_se,x_16"/><br/> <em>BottleNeckCSP模块：</em><br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/ed623ac0a5594fa7a8dea81e0eca33c8.png"/></p>
<p><strong>代码实现</strong>：</p>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">C3</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># CSP Bottleneck with 3 convolutions</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, number, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>C3<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv3 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># act=FReLU(c2)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>Bottleneck<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv3<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p> </p>
<h3><a id="05SPP_130"></a>05.SPP模块</h3>
<ol><li>SPP是空间金字塔池化的简称，其先通过一个标准卷积模块将输入通道减半，然后分别做kernel-size为5，9，13的maxpooling（对于不同的核大小，padding是自适应的）。</li><li>对三次最大池化的结果与未进行池化操作的数据进行concat，最终合并后channel数是原来的2倍。</li></ol>
<p><strong>结构图片描述</strong>：<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/9562da0499e34a72bab21c5983002e6f.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_18,color_FFFFFF,t_70,g_se,x_16"/></p>
<p><strong>代码实现：</strong></p>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">SPP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Spatial pyramid pooling layer used in YOLOv3-SPP</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SPP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> c1 <span class="token operator">//</span> <span class="token number">2</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_ <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>x<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span>x <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> k<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>m<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>m<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p> <br/>  <br/>  </p>
<h1><a id="2yolov5CBAM_157"></a>2.为yolov5添加CBAM注意力机制</h1>
<h3><a id="01CBAM_158"></a>01.CBAM机制</h3>
<p><img alt="CBAM结构图片描述" src="https://img-blog.csdnimg.cn/9f132e920ebe45098c3cabe91634e475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA5bm85YS_5Zut5oC75Zut6ZW_,size_25,color_FFFFFF,t_70,g_se,x_16"/><br/> 采用CBAM混合域注意力机制，同时对通道注意力和空间注意力进行评价打分。CBAM 包含2个子模块，Channel Attention Module（CAM）和Spartial Attention Module （SAM） 分别实现通道和空间的Attention。<br/> 此处参考1. <a href="https://zhuanlan.zhihu.com/p/37601161">注意力机制参考链接</a><br/>     2. <a href="https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247484531&amp;idx=1&amp;sn=625065862b28608428acb21da3330717&amp;chksm=9f80bee5a8f737f399f0f564883337154dd8ca3ad5c246c85a86a88b0ac8ede7bf59ffc04554&amp;token=897871599&amp;lang=zh_CN#rd">CBAM参考链接</a></p>
<h3><a id="02_163"></a>02.具体步骤</h3>
<h5><a id="yolov5lyolov5lyamlC3CBAMC3_164"></a>①.以yolov5l结构为例（其实只是深度和宽度因子不同），修改yolov5l.yaml，将C3模块修改为添加注意力机制后的模块CBAMC3，参数不变即可。</h5>
<h5><a id="commonpyCBAMC3_165"></a>②.在common.py中添加CBAMC3模块</h5>
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">ChannelAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChannelAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>f1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>f2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token comment"># 写法二,亦可使用顺序容器</span>
        <span class="token comment"># self.sharedMLP = nn.Sequential(</span>
        <span class="token comment"># nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False), nn.ReLU(),</span>
        <span class="token comment"># nn.Conv2d(in_planes // rotio, in_planes, 1, bias=False))</span>

        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> self<span class="token punctuation">.</span>f2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        max_out <span class="token operator">=</span> self<span class="token punctuation">.</span>f2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>avg_out <span class="token operator">+</span> max_out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> out<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">SpatialAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SpatialAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">assert</span> kernel_size <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'kernel size must be 3 or 7'</span>
        padding <span class="token operator">=</span> <span class="token number">3</span> <span class="token keyword">if</span> kernel_size <span class="token operator">==</span> <span class="token number">7</span> <span class="token keyword">else</span> <span class="token number">1</span>

        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        max_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>avg_out<span class="token punctuation">,</span> max_out<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> out<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">CBAMC3</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># CSP Bottleneck with 3 convolutions</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, number, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CBAMC3<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv3 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>Bottleneck<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>channel_attention <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span>c2<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>spatial_attention <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span>

        <span class="token comment"># self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
   		<span class="token comment"># 将最后的标准卷积模块改为了注意力机制提取特征</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>spatial_attention<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>channel_attention<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv3<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h5><a id="yolopy_228"></a>③.修改yolo.py，添加额外的判断语句</h5>
<pre><code class="prism language-python"><span class="token keyword">if</span> m <span class="token keyword">in</span> <span class="token punctuation">[</span>Conv<span class="token punctuation">,</span> GhostConv<span class="token punctuation">,</span> Bottleneck<span class="token punctuation">,</span> GhostBottleneck<span class="token punctuation">,</span> SPP<span class="token punctuation">,</span> DWConv<span class="token punctuation">,</span> MixConv2d<span class="token punctuation">,</span> Focus<span class="token punctuation">,</span> CrossConv<span class="token punctuation">,</span> BottleneckCSP<span class="token punctuation">,</span>
              C3<span class="token punctuation">,</span> C3TR<span class="token punctuation">,</span> CBAMC3<span class="token punctuation">]</span><span class="token punctuation">:</span>
         c1<span class="token punctuation">,</span> c2 <span class="token operator">=</span> ch<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">,</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
         <span class="token keyword">if</span> c2 <span class="token operator">!=</span> no<span class="token punctuation">:</span>  <span class="token comment"># if not output</span>
             c2 <span class="token operator">=</span> make_divisible<span class="token punctuation">(</span>c2 <span class="token operator">*</span> gw<span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>

         args <span class="token operator">=</span> <span class="token punctuation">[</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
         <span class="token keyword">if</span> m <span class="token keyword">in</span> <span class="token punctuation">[</span>BottleneckCSP<span class="token punctuation">,</span> C3<span class="token punctuation">,</span> C3TR<span class="token punctuation">,</span> CBAMC3<span class="token punctuation">]</span><span class="token punctuation">:</span>
             args<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span>  <span class="token comment"># number of repeats</span>
             n <span class="token operator">=</span> <span class="token number">1</span>
     <span class="token keyword">elif</span> m <span class="token keyword">is</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">:</span>
         args <span class="token operator">=</span> <span class="token punctuation">[</span>ch<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">]</span>
     <span class="token keyword">elif</span> m <span class="token keyword">is</span> Concat<span class="token punctuation">:</span>
         c2 <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">[</span>ch<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> f<span class="token punctuation">]</span><span class="token punctuation">)</span>
     <span class="token keyword">elif</span> m <span class="token keyword">is</span> Detect<span class="token punctuation">:</span>
         args<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>ch<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> f<span class="token punctuation">]</span><span class="token punctuation">)</span>
         <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># number of anchors</span>
             args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span>
     <span class="token keyword">elif</span> m <span class="token keyword">is</span> Contract<span class="token punctuation">:</span>
         c2 <span class="token operator">=</span> ch<span class="token punctuation">[</span>f<span class="token punctuation">]</span> <span class="token operator">*</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span>
     <span class="token keyword">elif</span> m <span class="token keyword">is</span> Expand<span class="token punctuation">:</span>
         c2 <span class="token operator">=</span> ch<span class="token punctuation">[</span>f<span class="token punctuation">]</span> <span class="token operator">//</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span>
     <span class="token keyword">else</span><span class="token punctuation">:</span>
         c2 <span class="token operator">=</span> ch<span class="token punctuation">[</span>f<span class="token punctuation">]</span>
</code></pre>
<p>至此，在训练模型时调用我们修改后的yolov5l.yaml，即可在验证注意力机制在yolov5模型上的有效性。</p>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>