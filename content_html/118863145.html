<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-atom-one-dark" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<p></p>
<div class="toc">
<h3>相机模型、相机标定及基于yolov5的单目测距实现</h3>
<ul><li><ul><li><a href="#1__1">1 前言</a></li><li><a href="#2__3">2 相机模型及单目测距原理</a></li><li><a href="#3__11">3 相机参数标定</a></li><li><ul><li><a href="#31__12">3.1 内参矩阵</a></li><li><a href="#32__16">3.2 内参标定</a></li><li><a href="#33__24">3.3 外参矩阵</a></li></ul>
</li><li><a href="#4_yolov5_37">4 基于yolov5的单目测距实现</a></li></ul>
</li></ul>
</div>
<p></p>
<h2><a id="1__1"></a>1 前言</h2>
<p>在摄像头成像过程中，物体反射的光线通过摄像头的凸透镜打在成像器件上，形成一张图片。这是一个三维物体转换为二维图像的过程。在这个过程中，丢失了物体的深度信息，所以单目摄像头很难测距。但是，我们可以通过一个强假设，来简单计算物体的距离，即假设物体是处于地面上。具体意思下面再详细说。</p>
<h2><a id="2__3"></a>2 相机模型及单目测距原理</h2>
<p>相机模型可以简单看成一个凸透镜成像的模型。下图中，XcYcZc是相机坐标系，其原点为光心O，是相机凸透镜的中心点。x-o1-y坐标系是图像坐标系。<br/> <img alt="图片从b站up主（uid:109364003）视频中截图的" src="https://img-blog.csdnimg.cn/20210717221125720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNjkwODY0,size_16,color_FFFFFF,t_70"/><br/> 图片从b站up主（uid:109364003）的视频中截图的。</p>
<p>图中有一个车辆，且车辆在地面上，其接地点Q必定在地面上。那么Q点的深度便可以求解出来。具体求解步骤懒得打公式了，就截图了。在单目测距过程中，实际物体上的Q点在成像的图片上对应Q’点，Q’点距离o1点沿y轴的距离为o1p’。这个距离o1p’除以y轴像素焦距fy (单位为pixel) ，再求arctan即可得到角度b’。然后按图中步骤很容易理解了。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/2021071722250718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNjkwODY0,size_16,color_FFFFFF,t_70"/><br/> 在按图中步骤求解深度OD时，如果相机高度H、相机光轴与水平线的夹角a没有准确测量的话，会对测距精准度造成较大影响。所以用于自动驾驶时，随着车身抖动，测距精度会很低。如果路面不是水平的，而是具有曲率的，那该方法也将失效。</p>
<h2><a id="3__11"></a>3 相机参数标定</h2>
<h3><a id="31__12"></a>3.1 内参矩阵</h3>
<p>相机内参指得是相机内部参数，主要有相机的x轴和y轴焦距、图像的成像中心的偏移量。相机坐标系和图像坐标系下物体坐标可按照下式转换。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/20210717224756149.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNjkwODY0,size_16,color_FFFFFF,t_70"/><br/> 式中，u和v是图像坐标系中点的x轴和y轴像素坐标，其原点是图像的左上角顶点，x轴朝右、y轴朝下是正方向。Zc是在相机坐标系下的Z轴坐标，也即2中的深度OD。fx和fy分别是x轴和y轴像素焦距 (单位为pixel)。cx和cy是图像的中心点o1（相机坐标系的光心在图像上成像的点）的像素坐标（以图像左上角顶点作为原点）。</p>
<h3><a id="32__16"></a>3.2 内参标定</h3>
<p>可以采用matlab的相机标定工具箱来进行摄像头的内参标定，matlab自带的这个工具箱是采用张正友棋盘格标定方法。我们需要准备一组20张左右的棋盘格照片。棋盘格图可以在此<a href="https://github.com/KinkangLiu/Monocular_Distance_Detect/blob/main/checkerboard.pdf">下载</a>。</p>
<p>打开matlab-&gt;App-&gt;图像处理和计算机视觉-&gt;Camera Calibration，打开后界面如下。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/img_convert/f76c1127e9e2c01ff360ab8371890079.png"/><br/> 直接点击Add Image一张张添加图片即可。弹窗提示输入棋盘格尺寸时，输入25mm（我提供的棋盘格单个方格的边长为25mm）。添加完20张图片左右后，点击Calibration按钮，再点击Export Camera Parameters，选择导出到工作空间，则在malatb工作空间出现标定结果。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/img_convert/26ff1135d6eddfcd139da1c40f13a020.png"/><br/> 如上图所示，标定结果变量为cameraParams，其中的IntrinsicMatrix即为我们所需要的内参矩阵。该矩阵转置后便是3.1中所描述的内参矩阵。</p>
<h3><a id="33__24"></a>3.3 外参矩阵</h3>
<p>外参矩阵描述的是相机坐标系与世界坐标系之间的转换关系。</p>
<p>在智能车上，世界坐标系可以设为：智能车质心作为原点，车辆车头朝向为Xw正方向，车辆右侧为Yw正方向，车辆垂直向上作为Zw正方向。</p>
<p>相机坐标系的原点为凸透镜的光心，垂直于相机凸透镜向外的方向为Zc正方向，相机右侧为Xc正方向，相机上侧为Yc正方向。</p>
<p>两个坐标系之间的转换主要包括绕三个轴的旋转、沿着三个轴的平移<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/img_convert/688e50832f7a1c56722f13305f91a4df.png"/><br/> 需要确定好绕各轴的旋转顺序，先旋转的在右边，后旋转的再左乘上去，如下式是依次绕x，y，z轴旋转。总的旋转矩阵R = Rz<em>Ry</em>Rx。<br/> <img alt="请添加图片描述" src="https://img-blog.csdnimg.cn/img_convert/2e5a666a41d301d97ede226d295deae4.png"/><br/> 外参矩阵由旋转矩阵和平移矩阵构成，如下式。旋转矩阵为R，平移矩阵为T。通过下式可以将世界坐标系的坐标转换为相机坐标系下的坐标。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/img_convert/f417ac5d91565d0324241956fee7510d.png"/></p>
<h2><a id="4_yolov5_37"></a>4 基于yolov5的单目测距实现</h2>
<p>全部程序可以在这<a href="https://github.com/KinkangLiu/Monocular_Distance_Detect">下载</a>。该文件夹下，estimate_distance.py为主程序。该程序中有一个DistanceEstimation类，该类的主要成员函数有camera_parameters（）、object_point_world_position（）、distance（）、Detect（）。在Detect函数中调用yolov5检测得到目标框后，便可以提取目标框的底边的中点作为2中所述的测距所需的Q’点。然后按照2中所述原理，便可以求得到Q点的Xw和Yw坐标。取Xw和Yw的坐标的平方和，再开根号便得到了目标的直线距离。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/img_convert/754c61f9f1c1e999d9a72654a6f2db65.png"/></p>
<p>由于本人水平有限，如有错误之处，希望不吝赐教！</p>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>