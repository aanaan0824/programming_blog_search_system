<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="htmledit_views" id="content_views">
<p>【就看这一篇就行】RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [256]] is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).</p>
<p>针对网上搜到的以下办法均无效的情况：<br/> 1）找到网络模型中的 inplace 操作，将inplace=True改成 inplace=False，例如torch.nn.ReLU(inplace=False)<br/> 2）将代码中的“a+=b”之类的操作改为“c = a + b”<br/> 3）将loss.backward()函数内的参数retain_graph值设置为True, loss.backward(retain_graph=True)，如果retain_graph设置为False，计算过程中的中间变量使用完即被释放掉。</p>
<p><span style="background-color:#fe2c24;">↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑以上方案无效↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑</span></p>
<p><span style="background-color:#ffd900;">↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓正确解决方案如下↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓</span></p>
<hr/>
<h1>1、问题描述：</h1>
<p><img alt="" height="921" src="image\320e9e131a5c4794adbcad29a3cde798.png" width="1200"/></p>
<p> 提示在 loss.backward()报错</p>
<p><span style="background-color:#a5a5a5;">RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [256]] is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).</span></p>
<h1>2、问题分析</h1>
<p>在用PyTorch进行分布式训练时，遇到以上错误。</p>
<p><span style="color:#fe2c24;"><span style="background-color:#0d0016;">日志的大概意思是用于梯度计算的变量通过</span><code><span style="background-color:#0d0016;">inplace</span></code><span style="background-color:#0d0016;">操作被修改。网上的一些解决方法基本是检查模型定义中是否有</span><code><span style="background-color:#0d0016;">inplace=True</span></code><span style="background-color:#0d0016;"> 设置以及</span><code><span style="background-color:#0d0016;">+=</span></code><span style="background-color:#0d0016;">操作符。但是这两种方案都不能解决遇到的问题。</span></span></p>
<p>经过一些调试发现，只有当某些特定情况下才会触发此报错。下面结合一个对比学习的例子（并不是完整的脚本）来简单描述：</p>
<pre><code class="language-python">import torch
import torch.nn as nn

from torchvision.models import resnet50

def main():
    model = resnet50(num_classes=256).cuda()
    model = nn.parallel.DistributedDataParallel(model, 
                                                device_ids=[args.local_rank], 
                                                find_unused_parameters=True)
    criterion = nn.MSELoss()
    
    optimizer = torch.optim.SGD(model.parameters(),
                                lr=0.001,
                                momentum=0.99,
                                weight_decay=1e-4)

    for i in range(10):
        input0 = torch.randn((4, 3, 224, 224), dtype=torch.float32).cuda()
        input2 = torch.randn((4, 3, 224, 224), dtype=torch.float32).cuda()

        out1 = model(input0)
        out2 = model(input1)

        loss = criterion(out1, out2)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

if __name__ == '__main__':
    main()</code></pre>
<p>经过调试发现，当使用<code>nn.DataParallel</code>并行训练或者单卡训练均可正常运行；另外如果将两次模型调用集成到model中，即通过<code>out1, out2 = model(input0, input1)</code> 的方式在分布式训练下也不会报错。</p>
<p>由此可以猜测：<strong>在分布式训练中，如果对同一模型进行多次调用</strong>则会触发以上报错，即</p>
<blockquote>
<p><code>nn.parallel.DistributedDataParallel</code>方法封装的模型，<code>forword()</code>函数和<code>backward()</code>函数必须交替执行，如果执行多个（次）<code>forward()</code>然后执行一次<code>backward()</code>则会报错。</p>
</blockquote>
<p>那么解决此问题的入手点则可以聚焦到<code>nn.parallel.DistributedDataParallel</code>接口上。 通过查询PyTorch官方文档发现此接口下的两个参数：</p>
<pre><code class="language-python">- find_unused_parameters: 如果模型的输出有不需要进行反向传播的，此参数需要设置为True；
若你的代码运行后卡住不动，基本上就是该参数的问题。

- broadcast_buffers: 该参数默认为True，设置为True时，在模型执行forward之前，gpu0会把
buffer中的参数值全部覆盖到别的gpu上。

</code></pre>
<p>问题基本可以定位出来了，即<code>broadcast_buffers=True</code>导致参数被覆盖修改。</p>
<h1>3、解决办法</h1>
<pre><code class="language-python"># 在该出错文件上找到被调用的DistributedDataParallel()，将broadcast_buffers设置为False
model = nn.parallel.DistributedDataParallel(model, 
                                             device_ids=[args.local_rank], 
                                             broadcast_buffers=False,
                                             find_unused_parameters=True)</code></pre>
<p></p>
<p>RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [2048]] is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).</p>
</div>
</div>