<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-atom-one-dark" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<p></p>
<div class="toc">
<h3>文章目录</h3>
<ul><li><a href="#_6">一、两种模式</a></li><li><a href="#_14">二、功能</a></li><li><ul><li><a href="#1_modeltrain_16">1. model.train()</a></li><li><a href="#2_modeleval_23">2. model.eval()</a></li><li><ul><li><a href="#_modeleval__30">为什么测试时要用 model.eval() ？</a></li></ul>
</li><li><a href="#3__42">3. 总结与对比</a></li></ul>
</li><li><a href="#Dropout__55">三、Dropout 简介</a></li><li><a href="#_77">参考链接</a></li></ul>
</div>
<p></p>
<hr/>
<h1><a id="_6"></a>一、两种模式</h1>
<p>pytorch可以给我们提供两种方式来切换训练和评估(推断)的模式，分别是：<code>model.train()</code> 和 <code>model.eval()</code>。</p>
<p>一般用法是：在训练开始之前写上 model.trian() ，在测试时写上 model.eval() 。</p>
<hr/>
<h1><a id="_14"></a>二、功能</h1>
<h2><a id="1_modeltrain_16"></a>1. model.train()</h2>
<p>在使用 pytorch 构建神经网络的时候，训练过程中会在程序上方添加一句model.train()，作用是 <strong>启用 batch normalization 和 dropout</strong> 。</p>
<p>如果模型中有BN层（Batch Normalization）和 Dropout ，需要在 <strong>训练时</strong> 添加 model.train()。</p>
<p>model.train() 是保证 BN 层能够用到 <strong>每一批数据</strong> 的均值和方差。对于 Dropout，model.train() 是 <strong>随机取一部分</strong> 网络连接来训练更新参数。</p>
<h2><a id="2_modeleval_23"></a>2. model.eval()</h2>
<p>model.eval()的作用是 <strong>不启用 Batch Normalization 和 Dropout</strong>。</p>
<p>如果模型中有 BN 层（Batch Normalization）和 Dropout，在 <strong>测试时</strong> 添加 model.eval()。</p>
<p>model.eval() 是保证 BN 层能够用 <strong>全部训练数据</strong> 的均值和方差，即测试过程中要保证 BN 层的均值和方差不变。对于 Dropout，model.eval() 是利用到了 <strong>所有</strong> 网络连接，即不进行随机舍弃神经元。</p>
<h3><a id="_modeleval__30"></a>为什么测试时要用 model.eval() ？</h3>
<p>训练完 train 样本后，生成的模型 model 要用来测试样本了。在 model(test) 之前，需要加上model.eval()，否则的话，有输入数据，即使不训练，它也会改变权值。这是 model 中含有 BN 层和 Dropout 所带来的的性质。</p>
<p>eval() 时，pytorch 会自动把 BN 和 DropOut 固定住，不会取平均，而是用训练好的值。<br/> 不然的话，一旦 test 的 batch_size 过小，很容易就会被 BN 层导致生成图片颜色失真极大。<br/> eval() 在非训练的时候是需要加的，没有这句代码，一些网络层的值会发生变动，不会固定，你神经网络每一次生成的结果也是不固定的，生成质量可能好也可能不好。</p>
<p>也就是说，测试过程中使用model.eval()，这时神经网络会 <strong>沿用 batch normalization 的值</strong>，而并 <strong>不使用 dropout</strong>。</p>
<h2><a id="3__42"></a>3. 总结与对比</h2>
<p>如果模型中有 BN 层(Batch Normalization）和 Dropout，需要在训练时添加 model.train()，在测试时添加 model.eval()。</p>
<p>其中 model.train() 是保证 BN 层用每一批数据的均值和方差，而 model.eval() 是保证 BN 用全部训练数据的均值和方差；</p>
<p>而对于 Dropout，model.train() 是随机取一部分网络连接来训练更新参数，而 model.eval() 是利用到了所有网络连接。</p>
<hr/>
<h1><a id="Dropout__55"></a>三、Dropout 简介</h1>
<p>dropout 常常用于抑制过拟合。</p>
<p>设置Dropout时，torch.nn.Dropout(0.5)，这里的 0.5 是指该层（layer）的神经元在每次迭代训练时会随机有 50% 的可能性被丢弃（失活），不参与训练。也就是将上一层数据减少一半传播。</p>
<hr/>
<h1><a id="_77"></a>参考链接</h1>
<ol><li><a href="https://www.yisu.com/zixun/518049.html">PyTorch中train()方法的作用是什么</a></li><li><a href="https://blog.csdn.net/qq_37791134/article/details/108122202">【pytorch】model.train()和model.evel()的用法</a></li><li><a href="https://www.jianshu.com/p/822d9ae0169d">pytorch中net.eval() 和net.train()的使用</a></li><li><a href="https://www.cnblogs.com/luckyplj/p/13424561.html">Pytorch学习笔记11----model.train()与model.eval()的用法、Dropout原理、relu,sigmiod,tanh激活函数、nn.Linear浅析、输出整个tensor的方法</a></li><li>好文：<a href="https://zhuanlan.zhihu.com/p/357075502">Pytorch：model.train()和model.eval()用法和区别，以及model.eval()和torch.no_grad()的区别</a></li></ol>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>