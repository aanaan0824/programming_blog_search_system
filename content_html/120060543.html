<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-atom-one-dark" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<h1><a id="_0"></a>深度学习</h1>
<font color="#999AAA"> 基础知识和各种网络结构实战 ... </font>
<hr color="#000000" size='1"'/>
<p></p>
<div class="toc">
<h3>狂肝两万字带你用pytorch搞深度学习！！！</h3>
<ul><li><a href="#_0">深度学习</a></li><li><a href="#_14">前言</a></li><li><a href="#Tensor_23">一、基本数据：Tensor</a></li><li><ul><li><a href="#11_Tensor_26">1.1 Tensor的创建</a></li><li><a href="#12_torchFloatTensor_29">1.2 torch.FloatTensor</a></li><li><a href="#13_torchIntTensor_43">1.3 torch.IntTensor</a></li><li><a href="#14_torchrandn_61">1.4 torch.randn</a></li><li><a href="#15_torchrange_73">1.5 torch.range</a></li><li><a href="#16_torchzerosonesempty_84">1.6 torch.zeros/ones/empty</a></li></ul>
</li><li><a href="#Tensor_100">二、Tensor的运算</a></li><li><ul><li><a href="#21_torchabs_101">2.1 torch.abs</a></li><li><a href="#22_torchadd_123">2.2 torch.add</a></li><li><a href="#23_torchclamp_165">2.3 torch.clamp</a></li><li><a href="#24_torchdiv_183">2.4 torch.div</a></li><li><a href="#25_torchpow_209">2.5 torch.pow</a></li><li><a href="#26_torchmm_226">2.6 torch.mm</a></li><li><a href="#27_torchmv_250">2.7 torch.mv</a></li></ul>
</li><li><a href="#torchnn_272">三、神经网络工具箱torch.nn</a></li><li><ul><li><a href="#31_nnModule_274">3.1 nn.Module类</a></li><li><a href="#32__305">3.2 搭建简易神经网络</a></li></ul>
</li><li><a href="#torch_387">四、torch实现一个完整的神经网络</a></li><li><ul><li><a href="#41_torchautogradVariable_388">4.1 torch.autograd和Variable</a></li><li><a href="#42__542">4.2 自定义传播函数</a></li><li><a href="#43_PyTorch__torchnn_587">4.3 PyTorch 之 torch.nn</a></li><li><ul><li><a href="#431_torchnnSequential_588">4.3.1 torch.nn.Sequential</a></li><li><a href="#432_torchnnLinear_611">4.3.2 torch.nn.Linear</a></li><li><a href="#433_torchnnReLU_613">4.3.3 torch.nn.ReLU</a></li><li><a href="#434_torchnnMSELoss_615">4.3.4 torch.nn.MSELoss</a></li><li><a href="#434_torchnnL1Loss_627">4.3.4 torch.nn.L1Loss</a></li><li><a href="#435_torchnnCrossEntropyLoss_639">4.3.5 torch.nn.CrossEntropyLoss</a></li><li><a href="#435__651">4.3.5 使用损失函数的神经网络</a></li></ul>
</li><li><a href="#44_PyTorch__torchoptim_695">4.4 PyTorch 之 torch.optim</a></li></ul>
</li><li><a href="#_743">五、搭建神经网络实现手写数据集</a></li><li><ul><li><a href="#51_torchvision_744">5.1 torchvision</a></li><li><ul><li><a href="#511_torchvisiondatasets_754">5.1.1 torchvision.datasets</a></li><li><a href="#512_torchvisionmodels_767">5.1.2 torchvision.models</a></li><li><a href="#513_torchtransforms_796">5.1.3 torch.transforms</a></li><li><ul><li><a href="#5131_torchvisiontransformsResize_798">5.1.3.1 torchvision.transforms.Resize</a></li><li><a href="#5132_torchvisiontransformsScale_800">5.1.3.2 torchvision.transforms.Scale</a></li><li><a href="#5133_torchvisiontransformsCenterCrop_802">5.1.3.3 torchvision.transforms.CenterCrop</a></li><li><a href="#5134_torchvisiontransformsRandomCrop_804">5.1.3.4 torchvision.transforms.RandomCrop</a></li><li><a href="#5135_torchvisiontransformsRandomHorizontalFlip_806">5.1.3.5 torchvision.transforms.RandomHorizontalFlip</a></li><li><a href="#5136_torchvisiontransformsRandomVerticalFlip_808">5.1.3.6 torchvision.transforms.RandomVerticalFlip</a></li><li><a href="#5137_torchvisiontransformsToTensor_810">5.1.3.7 torchvision.transforms.ToTensor</a></li><li><a href="#5138_torchvisiontransformsToPILImage_812">5.1.3.8 torchvision.transforms.ToPILImage:</a></li></ul>
</li><li><a href="#514_torchutils_826">5.1.4 torch.utils</a></li></ul>
</li><li><a href="#52__859">5.2 模型搭建和参数优化</a></li><li><ul><li><a href="#521_torchnnConv2d_891">5.2.1 torch.nn.Conv2d</a></li><li><a href="#522_torchnnMaxPool2d_895">5.2.2 torch.nn.MaxPool2d</a></li><li><a href="#523_torchnnDropout_899">5.2.3 torch.nn.Dropout</a></li></ul>
</li><li><a href="#53__902">5.3 参数优化</a></li><li><ul><li><a href="#531__911">5.3.1 模型训练</a></li></ul>
</li><li><a href="#54__944">5.4 模型验证</a></li><li><a href="#55__966">5.5 完整代码</a></li></ul>
</li><li><a href="#_1102">六、结语</a></li></ul>
</div>
<p></p>
<h1><a id="_14"></a>前言</h1>
<font color="#999AAA"> </font> 学习深度学习一个好的框架十分的重要，现在主流的就是Pytorch和tf，今天让我们一起来学习pytorch 
<hr color="#000000" size='1"'/>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/25238d12cb8641b8bc38171559ab41e9.jpg#pic_center"/></p>
<h1><a id="Tensor_23"></a>一、基本数据：Tensor</h1>
<p>Tensor，即张量，是PyTorch中的基本操作对象，可以看做是包含单一数据类型元素的多维矩阵。从使用角度来看，Tensor与NumPy的ndarrays非常类似，相互之间也可以自由转换，只不过Tensor还支持GPU的加速。<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/85d160a859334f14bebdcc8c21eff18e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQ0MtTWFj,size_20,color_FFFFFF,t_70,g_se,x_16"/></p>
<h2><a id="11_Tensor_26"></a>1.1 Tensor的创建</h2>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/9e2b11f3791a432eaf86169f5446bcf2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQ0MtTWFj,size_20,color_FFFFFF,t_70,g_se,x_16"/></p>
<h2><a id="12_torchFloatTensor_29"></a>1.2 torch.FloatTensor</h2>
<p>torch.FloatTensor用于生成数据类型为浮点型的Tensor，传递给torch.FloatTensor的参数可以是列表，也可以是一个维度值。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a<span class="token punctuation">,</span>b
</code></pre>
<p>得到的结果是：</p>
<pre><code class="prism language-py"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0561e-38</span><span class="token punctuation">,</span> <span class="token number">1.0102e-38</span><span class="token punctuation">,</span> <span class="token number">9.6429e-39</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token number">8.4490e-39</span><span class="token punctuation">,</span> <span class="token number">9.6429e-39</span><span class="token punctuation">,</span> <span class="token number">9.1837e-39</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="13_torchIntTensor_43"></a>1.3 torch.IntTensor</h2>
<p>torch.IntTensor用于生成数据类型为整型的Tensor,传递给传递给torch.IntTensor的参数可以是列表，也可以是一个维度值。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a<span class="token punctuation">,</span>b
</code></pre>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a 
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5625</span><span class="token punctuation">,</span> <span class="token number">0.5815</span><span class="token punctuation">,</span> <span class="token number">0.8221</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">0.3589</span><span class="token punctuation">,</span> <span class="token number">0.4180</span><span class="token punctuation">,</span> <span class="token number">0.2158</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="14_torchrandn_61"></a>1.4 torch.randn</h2>
<p>用于生成数据类型为浮点数且维度指定的随机Tensor，和在numpy中使用的numpy.randn生成的随机数的方法类似，随机生成的浮点数的取值满足均值为0，方差为1的正态分布。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a 
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0067</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0707</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6682</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.8141</span><span class="token punctuation">,</span>  <span class="token number">1.1436</span><span class="token punctuation">,</span>  <span class="token number">0.5963</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="15_torchrange_73"></a>1.5 torch.range</h2>
<p>torch.range用于生成数据类型为浮点型且起始范围和结束范围的Tensor，所以传递给torch.range的参数有三个，分别为起始值，结束值，步长，其中步长用于指定从起始值到结束值得每步的数据间隔。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
a
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="16_torchzerosonesempty_84"></a>1.6 torch.zeros/ones/empty</h2>
<p>torch.zeros用于生成数据类型为浮点型且维度指定的Tensor，不过这个浮点型的Tensor中的元素值全部为0。</p>
<p>torch.ones生成全1的数组。</p>
<p>torch.empty创建一个未被初始化数值的tensor,tensor的大小是由size确定,size: 定义tensor的shape ，这里可以是一个list 也可以是一个tuple</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h1><a id="Tensor_100"></a>二、Tensor的运算</h1>
<h2><a id="21_torchabs_101"></a>2.1 torch.abs</h2>
<p>将参数传递到torch.abs后返回输入参数的绝对值作为输出，输入参数必须是一个Tensor数据类型的变量，如：</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
</code></pre>
<p>得到的a是：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0948</span><span class="token punctuation">,</span>  <span class="token number">0.0530</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0986</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">1.8926</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.0569</span><span class="token punctuation">,</span>  <span class="token number">1.6617</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>对a进行abs处理：</p>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
b
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0948</span><span class="token punctuation">,</span> <span class="token number">0.0530</span><span class="token punctuation">,</span> <span class="token number">0.0986</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1.8926</span><span class="token punctuation">,</span> <span class="token number">2.0569</span><span class="token punctuation">,</span> <span class="token number">1.6617</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="22_torchadd_123"></a>2.2 torch.add</h2>
<p>将参数传递到torch.add后返回输入参数的求和结果作为输出，输入参数既可以全部是Tensor数据类型的变量，也可以一个是Tensor数据类型的变量，另一个是标量。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#tensor([[-0.1146, -0.3282, -0.2517],</span>
<span class="token comment">#        [-0.2474,  0.8323, -0.9292]])</span>
</code></pre>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
b
<span class="token comment">#tensor([[ 0.9526,  1.5841, -3.2665],</span>
<span class="token comment">#        [-0.4831,  0.9259, -0.5054]])</span>
</code></pre>
<pre><code class="prism language-py">c <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
c
</code></pre>
<p>输出的c:</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.8379</span><span class="token punctuation">,</span>  <span class="token number">1.2559</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.5182</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7305</span><span class="token punctuation">,</span>  <span class="token number">1.7582</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4346</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>再看一个：</p>
<pre><code class="prism language-py">d <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
d
<span class="token comment">#这里我们得到的d：</span>
<span class="token comment">#tensor([[ 0.1473,  0.7631, -0.1953],</span>
<span class="token comment">#        [-0.2796, -0.7265,  0.7142]])</span>
</code></pre>
<p>我们对d与一个标量10相加：</p>
<pre><code class="prism language-py">e <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>d<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
e
</code></pre>
<p>得到：</p>
<pre><code class="prism language-py">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.1473</span><span class="token punctuation">,</span> <span class="token number">10.7631</span><span class="token punctuation">,</span>  <span class="token number">9.8047</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">9.7204</span><span class="token punctuation">,</span>  <span class="token number">9.2735</span><span class="token punctuation">,</span> <span class="token number">10.7142</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2><a id="23_torchclamp_165"></a>2.3 torch.clamp</h2>
<p>torch.clamp是对输入参数按照自定义的范围进行裁剪，最后将参数裁剪的结果作为输出，所以输入参数一共有三个，分别是需要进行裁剪的Tensor数据类型的变量、裁剪的上上边界和裁剪的下边界，具体的裁剪过程是：使用变量中的每个元素分别和裁剪的上边界及裁剪的下边界的值进行比较，如果元素的值小于裁剪的下边界的值，该元素被重写成裁剪的下边界的值；同理，如果元素的值大于裁剪的上边界的值，该元素就被重写成裁剪的上边界的值。我们直接看例子：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#我们得到a为：</span>
<span class="token comment">#tensor([[-1.4049,  1.0336,  1.2820],</span>
<span class="token comment">#        [ 0.7610, -1.7475,  0.2414]])</span>
</code></pre>
<p>我们对b进行clamp操作：</p>
<pre><code class="prism language-py">
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>
b
<span class="token comment">#我们得到b为：</span>
<span class="token comment">#tensor([[-0.1000,  0.1000,  0.1000],</span>
<span class="token comment">#        [ 0.1000, -0.1000,  0.1000]])</span>
</code></pre>
<h2><a id="24_torchdiv_183"></a>2.4 torch.div</h2>
<p>torch.div是将参数传递到torch.div后返回输入参数的求商结果作为输出，同样，参与运算的参数可以全部是Tensor数据类型的变量，也可以是Tensor数据类型的变量和标量的组合。具体我们看例子</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#我们得到a为：</span>
<span class="token comment">#tensor([[ 0.6276,  0.6397, -0.0762],</span>
<span class="token comment">#        [-0.4193, -0.5528,  1.5192]])</span>
</code></pre>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
b
<span class="token comment">#我们得到b为：</span>
<span class="token comment">#tensor([[ 0.9219,  0.2120,  0.1155],</span>
<span class="token comment">#        [ 1.1086, -1.1442,  0.2999]])</span>
</code></pre>
<p>对a,b进行div操作</p>
<pre><code class="prism language-py">
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
c
<span class="token comment">#得到c：</span>
<span class="token comment">#tensor([[ 0.6808,  3.0173, -0.6602],</span>
<span class="token comment">#        [-0.3782,  0.4831,  5.0657]])</span>
</code></pre>
<h2><a id="25_torchpow_209"></a>2.5 torch.pow</h2>
<p>torch.pow：将参数传递到torch.pow后返回输入参数的求幂结果作为输出，参与运算的参数可以全部是Tensor数据类型的变量，也可以是Tensor数据类型的变量和标量的组合。</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#我们得到a为：</span>
<span class="token comment">#tensor([[ 0.3896, -0.1475,  0.1104],</span>
<span class="token comment">#        [-0.6908, -0.0472, -1.5310]])</span>
</code></pre>
<p>对a进行平方操作</p>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
b
<span class="token comment">#我们得到b为：</span>
<span class="token comment">#tensor([[1.5181e-01, 2.1767e-02, 1.2196e-02],</span>
<span class="token comment">#        [4.7722e-01, 2.2276e-03, 2.3441e+00]])</span>
</code></pre>
<h2><a id="26_torchmm_226"></a>2.6 torch.mm</h2>
<p><mark>torch.mm：将参数传递到torch.mm后返回输入参数的求积结果作为输出，不过这个求积的方式和之前的torch.mul运算方式不太一样，torch.mm运用矩阵之间的乘法规则进行计算，所以被传入的参数会被当作矩阵进行处理，参数的维度自然也要满足矩阵乘法的前提条件，即前一个矩阵的行数必须和后一个矩阵列数相等</mark><br/> 下面我们看实例：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#我们得到a为：</span>
<span class="token comment">#tensor([[ 0.1057,  0.0104, -0.1547],</span>
<span class="token comment">#        [ 0.5010, -0.0735,  0.4067]])</span>
</code></pre>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
b
<span class="token comment">#我们得到b为：</span>
<span class="token comment">#tensor([[ 1.1971, -1.4010,  1.1277],</span>
<span class="token comment">#        [-0.3076,  0.9171,  1.9135]])</span>
</code></pre>
<p>然后我们用产生的a,b进行矩阵乘法操作：</p>
<pre><code class="prism language-py">c <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
c
<span class="token comment">#tensor([[-0.0625, -0.3190],</span>
<span class="token comment">#        [ 1.1613,  0.5567]])</span>
</code></pre>
<h2><a id="27_torchmv_250"></a>2.7 torch.mv</h2>
<p>将参数传递到torch.mv后返回输入参数的求积结果作为输出，torch.mv运用矩阵与向量之间的乘法规则进行计算，被传入的第1个参数代表矩阵，第2个参数代表向量，循序不能颠倒。<br/> 下面我们看实例：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a
<span class="token comment">#我们得到a为：</span>
<span class="token comment">#tensor([[ 1.0909, -1.1679,  0.3161],</span>
<span class="token comment">#        [-0.8952, -2.1351, -0.9667]])</span>
</code></pre>
<pre><code class="prism language-py">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
b
<span class="token comment">#我们得到b为：</span>
<span class="token comment">#tensor([-1.4689,  1.6197,  0.7209])</span>
</code></pre>
<p>然后我们用产生的a,b进行矩阵乘法操作：</p>
<pre><code class="prism language-py">c <span class="token operator">=</span> torch<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
c
<span class="token comment">#tensor([-3.2663, -2.8402])</span>
</code></pre>
<h1><a id="torchnn_272"></a>三、神经网络工具箱torch.nn</h1>
<p>torch.autograd库虽然实现了自动求导与梯度反向传播，但如果我们要完成一个模型的训练，仍需要手写参数的自动更新、训练过程的控制等，还是不够便利。为此，PyTorch进一步提供了集成度更高的模块化接口torch.nn，该接口构建于Autograd之上，提供了网络模组、优化器和初始化策略等一系列功能。</p>
<h2><a id="31_nnModule_274"></a>3.1 nn.Module类</h2>
<p>nn.Module是PyTorch提供的神经网络类，并在类中实现了网络各层的定义及前向计算与反向传播机制。在实际使用时，如果想要实现某个神经网络，只需继承nn.Module，在初始化中定义模型结构与参数，在函数forward()中编写网络前向过程即可。</p>
<p>1．nn.Parameter函数</p>
<p>2．forward()函数与反向传播</p>
<p>3．多个Module的嵌套</p>
<p>4．nn.Module与nn.functional库</p>
<p>5．nn.Sequential()模块</p>
<pre><code class="prism language-py"><span class="token comment">#这里用torch.nn实现一个MLP</span>
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> hid_dim1<span class="token punctuation">,</span> hid_dim2<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> hid_dim1<span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hid_dim1<span class="token punctuation">,</span> hid_dim2<span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hid_dim2<span class="token punctuation">,</span> out_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre>
<h2><a id="32__305"></a>3.2 搭建简易神经网络</h2>
<p>下面我们用torch搭一个简易神经网络：<br/> 1、我们设置输入节点为1000，隐藏层的节点为100，输出层的节点为10<br/> 2、输入100个具有1000个特征的数据，经过隐藏层后变成100个具有10个分类结果的特征，然后将得到的结果后向传播</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
batch_n <span class="token operator">=</span> <span class="token number">100</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span>

w1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span>
w2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span>

epoch_n <span class="token operator">=</span> <span class="token number">20</span>
lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h1<span class="token operator">=</span>x<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token comment">#(100,1000)*(1000,100)--&gt;100*100</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>h1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    h1<span class="token operator">=</span>h1<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    y_pred <span class="token operator">=</span> h1<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span>
    
    loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:{},loss:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    grad_y_pred <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span>
    grad_w2 <span class="token operator">=</span> h1<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mm<span class="token punctuation">(</span>grad_y_pred<span class="token punctuation">)</span>
    
    grad_h <span class="token operator">=</span> grad_y_pred<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
    grad_h <span class="token operator">=</span> grad_h<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    grad_h<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#将小于0的值全部赋值为0，相当于sigmoid</span>
    grad_w1 <span class="token operator">=</span> x<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mm<span class="token punctuation">(</span>grad_h<span class="token punctuation">)</span>
    
    w1 <span class="token operator">=</span> w1 <span class="token operator">-</span>lr<span class="token operator">*</span>grad_w1
    w2 <span class="token operator">=</span> w2 <span class="token operator">-</span>lr<span class="token operator">*</span>grad_w2
</code></pre>
<pre><code class="prism language-py">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">112145.7578</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">110014.8203</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">107948.0156</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">105938.6719</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">103985.1406</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">102084.9609</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">100236.9844</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">7</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">98443.3359</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">96699.5938</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">9</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">95002.5234</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">93349.7969</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">11</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">91739.8438</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">90171.6875</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">13</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">88643.1094</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">14</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">87152.6406</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">15</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">85699.4297</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">16</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">84282.2500</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">17</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">82899.9062</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">18</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">81550.3984</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">19</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">80231.1484</span>
</code></pre>
<h1><a id="torch_387"></a>四、torch实现一个完整的神经网络</h1>
<h2><a id="41_torchautogradVariable_388"></a>4.1 torch.autograd和Variable</h2>
<p>torch.autograd包的主要功能就是完成神经网络后向传播中的链式求导，手动去写这些求导程序会导致重复造轮子的现象。</p>
<p>自动梯度的功能过程大致为：先通过输入的Tensor数据类型的变量在神经网络的前向传播过程中生成一张计算图，然后根据这个计算图和输出结果精确计算出每一个参数需要更新的梯度，并通过完成后向传播完成对参数的梯度更新。</p>
<p>完成自动梯度需要用到的torch.autograd包中的Variable类对我们定义的Tensor数据类型变量进行封装，在封装后，计算图中的各个节点就是一个Variable对象，这样才能应用自动梯度的功能。</p>
<p>下面我们使用autograd实现一个二层结构的神经网络模型</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
batch_n <span class="token operator">=</span> <span class="token number">100</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>

x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#用Variable对Tensor数据类型变量进行封装的操作。requires_grad如果是False，表示该变量在进行自动梯度计算的过程中不会保留梯度值。</span>
w1 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#学习率和迭代次数</span>
epoch_n<span class="token operator">=</span><span class="token number">50</span>
lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    h1<span class="token operator">=</span>x<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token comment">#(100,1000)*(1000,100)--&gt;100*100</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>h1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    h1<span class="token operator">=</span>h1<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    y_pred <span class="token operator">=</span> h1<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>w2<span class="token punctuation">)</span>
    <span class="token comment">#y_pred = x.mm(w1).clamp(min=0).mm(w2)</span>
    loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:{},loss:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
<span class="token comment">#     grad_y_pred = 2*(y_pred-y)</span>
<span class="token comment">#     grad_w2 = h1.t().mm(grad_y_pred)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#后向传播</span>
<span class="token comment">#     grad_h = grad_y_pred.clone()</span>
<span class="token comment">#     grad_h = grad_h.mm(w2.t())</span>
<span class="token comment">#     grad_h.clamp_(min=0)#将小于0的值全部赋值为0，相当于sigmoid</span>
<span class="token comment">#     grad_w1 = x.t().mm(grad_h)</span>
    w1<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr<span class="token operator">*</span>w1<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
    w2<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr<span class="token operator">*</span>w2<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data

    w1<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    w2<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
<span class="token comment">#     w1 = w1 -lr*grad_w1</span>
<span class="token comment">#     w2 = w2 -lr*grad_w2</span>
</code></pre>
<pre><code class="prism language-py">得到结果：
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">54572212.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">133787328.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">491439904.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">683004416.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">13681055.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">8058388.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">5327059.5000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">7</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">3777382.5000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">2818449.5000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">9</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">2190285.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">1760991.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">11</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">1457116.3750</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">1235850.6250</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">13</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">1069994.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">14</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">942082.4375</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">15</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">841170.6250</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">16</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">759670.1875</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">17</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">692380.5625</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">18</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">635755.0625</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">19</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">587267.1250</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">545102.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">21</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">508050.6250</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">22</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">475169.9375</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">23</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">445762.8750</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">24</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">419216.2812</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">25</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">395124.9375</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">26</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">373154.8438</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">27</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">352987.6875</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">28</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">334429.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">29</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">317317.7500</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">301475.8125</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">31</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">286776.8750</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">32</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">273114.4062</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">33</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">260383.6406</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">34</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">248532.8125</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">35</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">237452.3750</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">36</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">227080.5156</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">37</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">217362.9375</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">38</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">208250.5312</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">39</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">199686.1094</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">40</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">191620.0312</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">41</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">184017.4375</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">42</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">176841.0156</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">43</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">170073.1719</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">44</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">163686.5000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">45</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">157641.5000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">46</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">151907.0000</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">47</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">146470.1250</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">48</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">141305.3594</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
epoch<span class="token punctuation">:</span><span class="token number">49</span><span class="token punctuation">,</span>loss<span class="token punctuation">:</span><span class="token number">136396.7031</span>
</code></pre>
<h2><a id="42__542"></a>4.2 自定义传播函数</h2>
<p>其实除了可以采用自动梯度方法，我们还可以通过构建一个继承了torch.nn.Module的新类，来完成对前向传播函数和后向传播函数的重写。在这个新类中，我们使用forward作为前向传播函数的关键字，使用backward作为后向传播函数的关键字。下面我们进行自定义传播函数：</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
batch_n <span class="token operator">=</span> <span class="token number">64</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>
<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#完成类继承的操作</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#类的初始化</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">,</span>w1<span class="token punctuation">,</span>w2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token builtin">min</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#用Variable对Tensor数据类型变量进行封装的操作。requires_grad如果是F，表示该变量在进行自动梯度计算的过程中不会保留梯度值。</span>
w1 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

epoch_n<span class="token operator">=</span><span class="token number">30</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>
    
    loss <span class="token operator">=</span> <span class="token punctuation">(</span>y_pred<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:{},loss:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    w1<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr<span class="token operator">*</span>w1<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
    w2<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr<span class="token operator">*</span>w2<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data

    w1<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    w2<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
</code></pre>
<p>得到结果：<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/c71390ee4c1a4becb823369dc6147df3.png"/></p>
<h2><a id="43_PyTorch__torchnn_587"></a>4.3 PyTorch 之 torch.nn</h2>
<h3><a id="431_torchnnSequential_588"></a>4.3.1 torch.nn.Sequential</h3>
<p>torch.nn.Sequential类是torch.nn中的一种序列容器，通过在容器中嵌套各种实现神经网络模型的搭建，最主要的是，参数会按照我们定义好的序列自动传递下去。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
batch_n <span class="token operator">=</span> <span class="token number">100</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>

x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#用Variable对Tensor数据类型变量进行封装的操作。requires_grad如果是F，表示该变量在进行自动梯度计算的过程中不会保留梯度值。</span>

models <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment">#torch.nn.Sequential括号内就是我们搭建的神经网络模型的具体结构，Linear完成从隐藏层到输出层的线性变换，再用ReLU激活函数激活</span>
<span class="token comment">#torch.nn.Sequential类是torch.nn中的一种序列容器，通过在容器中嵌套各种实现神经网络模型的搭建，</span>
<span class="token comment">#最主要的是，参数会按照我们定义好的序列自动传递下去。</span>
</code></pre>
<h3><a id="432_torchnnLinear_611"></a>4.3.2 torch.nn.Linear</h3>
<p>torch.nn.Linear类用于定义模型的线性层，即完成前面提到的不同的层之间的线性变换。 线性层接受的参数有3个：分别是输入特征数、输出特征数、是否使用偏置，默认为True,使用torch.nn.Linear类，会自动生成对应维度的权重参数和偏置，对于生成的权重参数和偏置，我们的模型默认使用一种比之前的简单随机方式更好的参数初始化方式。</p>
<h3><a id="433_torchnnReLU_613"></a>4.3.3 torch.nn.ReLU</h3>
<p>torch.nn.ReLU属于非线性激活分类，在定义时默认不需要传入参数。当然，在torch.nn包中还有许多非线性激活函数类可供选择，比如PReLU、LeaKyReLU、Tanh、Sigmoid、Softmax等。</p>
<h3><a id="434_torchnnMSELoss_615"></a>4.3.4 torch.nn.MSELoss</h3>
<p>torch.nn.MSELoss类使用均方误差函数对损失值进行计算，定义类的对象时不用传入任何参数，但在使用实例时需要输入两个维度一样的参数方可进行计算。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
loss_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> loss_f<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>data
<span class="token comment">#tensor(1.9529)</span>
</code></pre>
<h3><a id="434_torchnnL1Loss_627"></a>4.3.4 torch.nn.L1Loss</h3>
<p>torch.nn.L1Loss类使用平均绝对误差函数对损失值进行计算，定义类的对象时不用传入任何参数，但在使用实例时需要输入两个维度一样的参数方可进行计算。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
loss_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> loss_f<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>data
<span class="token comment">#tensor(1.1356)</span>
</code></pre>
<h3><a id="435_torchnnCrossEntropyLoss_639"></a>4.3.5 torch.nn.CrossEntropyLoss</h3>
<p>torch.nn.CrossEntropyLoss类用于计算交叉熵，定义类的对象时不用传入任何参数，但在使用实例时需要输入两个满足交叉熵的计算条件的参数。</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
loss_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>random_<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#3个0-4的随机数字</span>
loss <span class="token operator">=</span> loss_f<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>data
<span class="token comment">#tensor(2.3413)</span>
</code></pre>
<h3><a id="435__651"></a>4.3.5 使用损失函数的神经网络</h3>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>


batch_n <span class="token operator">=</span> <span class="token number">100</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>

x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#用Variable对Tensor数据类型变量进行封装的操作。requires_grad如果是F，表示该变量在进行自动梯度计算的过程中不会保留梯度值。</span>

models <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment">#torch.nn.Sequential括号内就是我们搭建的神经网络模型的具体结构，Linear完成从隐藏层到输出层的线性变换，再用ReLU激活函数激活</span>
<span class="token comment">#torch.nn.Sequential类是torch.nn中的一种序列容器，通过在容器中嵌套各种实现神经网络模型的搭建，</span>
<span class="token comment">#最主要的是，参数会按照我们定义好的序列自动传递下去。</span>


<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> models<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
    <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch:{},loss:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
    models<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> param <span class="token keyword">in</span> models<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        param<span class="token punctuation">.</span>data <span class="token operator">-=</span> param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token operator">*</span>lr
</code></pre>
<h2><a id="44_PyTorch__torchoptim_695"></a>4.4 PyTorch 之 torch.optim</h2>
<p>torch.optim包提供非常多的可实现参数自动优化的类，如SGD、AdaGrad、RMSProp、Adam等<br/> 使用自动优化的类实现神经网络：</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable

batch_n <span class="token operator">=</span> <span class="token number">100</span><span class="token comment">#一个批次输入数据的数量</span>
hidden_layer <span class="token operator">=</span> <span class="token number">100</span>
input_data <span class="token operator">=</span> <span class="token number">1000</span><span class="token comment">#每个数据的特征为1000</span>
output_data <span class="token operator">=</span> <span class="token number">10</span>

x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>input_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_n<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#用Variable对Tensor数据类型变量进行封装的操作。requires_grad如果是F，表示该变量在进行自动梯度计算的过程中不会保留梯度值。</span>

models <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span>hidden_layer<span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span>output_data<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment">#torch.nn.Sequential括号内就是我们搭建的神经网络模型的具体结构，Linear完成从隐藏层到输出层的线性变换，再用ReLU激活函数激活</span>
<span class="token comment">#torch.nn.Sequential类是torch.nn中的一种序列容器，通过在容器中嵌套各种实现神经网络模型的搭建，</span>
<span class="token comment">#最主要的是，参数会按照我们定义好的序列自动传递下去。</span>

<span class="token comment"># loss_fn = torch.nn.MSELoss()</span>
<span class="token comment"># x = Variable(torch.randn(100,100))</span>
<span class="token comment"># y = Variable(torch.randn(100,100))</span>
<span class="token comment"># loss = loss_fn(x,y)</span>

epoch_n<span class="token operator">=</span><span class="token number">10000</span>
lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span>
loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimzer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>models<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>
<span class="token comment">#使用torch.optim.Adam类作为我们模型参数的优化函数，这里输入的是：被优化的参数和学习率的初始值。</span>
<span class="token comment">#因为我们需要优化的是模型中的全部参数，所以传递的参数是models.parameters()</span>

<span class="token comment">#进行，模型训练的代码如下：</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> models<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch:{},Loss:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
    optimzer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#将模型参数的梯度归0</span>
    
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimzer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#使用计算得到的梯度值对各个节点的参数进行梯度更新。</span>
</code></pre>
<h1><a id="_743"></a>五、搭建神经网络实现手写数据集</h1>
<h2><a id="51_torchvision_744"></a>5.1 torchvision</h2>
<p>torchvision 是PyTorch中专门用来处理图像的库。这个包中有四个大类。</p>
<p>torchvision.datasets</p>
<p>torchvision.models</p>
<p>torchvision.transforms</p>
<p>torchvision.utils</p>
<h3><a id="511_torchvisiondatasets_754"></a>5.1.1 torchvision.datasets</h3>
<p>torchvision.datasets可以实现对一些数据集的下载和加载如MNIST可以用torchvision.datasets.MNIST COCO、ImageNet、CIFCAR等都可用这个方法下载和载入，</p>
<p>这里用torchvision.datasets加载MNIST数据集：</p>
<pre><code class="prism language-py">data_train <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>
                           transform<span class="token operator">=</span>transform<span class="token punctuation">,</span>
                           train <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
                           download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
data_test <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>
                          transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>
                          train <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre>
<h3><a id="512_torchvisionmodels_767"></a>5.1.2 torchvision.models</h3>
<p>torchvision.models 中为我们提供了已经训练好的模型，让我们可以加载之后，直接使用。</p>
<p>torchvision.models模块的 子模块中包含以下模型结构。如：</p>
<p>AlexNet</p>
<p>VGG</p>
<p>ResNet</p>
<p>SqueezeNet</p>
<p>DenseNet等</p>
<p>我们可以直接使用如下代码来快速创建一个权重随机初始化的模型：</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models
resnet18 <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span><span class="token punctuation">)</span>
alexnet <span class="token operator">=</span> models<span class="token punctuation">.</span>alexnet<span class="token punctuation">(</span><span class="token punctuation">)</span>
squeezenet <span class="token operator">=</span> models<span class="token punctuation">.</span>squeezenet1_0<span class="token punctuation">(</span><span class="token punctuation">)</span>
densenet <span class="token operator">=</span> models<span class="token punctuation">.</span>densenet_161<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>也可以通过使用 pretrained=True 来加载一个别人预训练好的模型:</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models
resnet18 <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
alexnet <span class="token operator">=</span> models<span class="token punctuation">.</span>alexnet<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre>
<h3><a id="513_torchtransforms_796"></a>5.1.3 torch.transforms</h3>
<p>torch.transforms中有大量数据变换类，如：</p>
<h4><a id="5131_torchvisiontransformsResize_798"></a>5.1.3.1 torchvision.transforms.Resize</h4>
<p>用于对载入的图片数据按照我们需求的大小进行缩放。传递的参数可以是一个整型数据，也可以是一个类似于(h,w)的序列。h代表高度，w代表宽度，如果输入的是整型数据那么h和w都等于这个数。</p>
<h4><a id="5132_torchvisiontransformsScale_800"></a>5.1.3.2 torchvision.transforms.Scale</h4>
<p>用于对载入的图片数据按照我们需求的大小进行缩放。和Resize类似。</p>
<h4><a id="5133_torchvisiontransformsCenterCrop_802"></a>5.1.3.3 torchvision.transforms.CenterCrop</h4>
<p>用于对载入的图片以图片中心为参考点，按照我们需要的大小进行裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于(h,w)的序列。</p>
<h4><a id="5134_torchvisiontransformsRandomCrop_804"></a>5.1.3.4 torchvision.transforms.RandomCrop</h4>
<p>用于对载入的图片按照我们需要的大小进行随机裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于(h,w)的序列。</p>
<h4><a id="5135_torchvisiontransformsRandomHorizontalFlip_806"></a>5.1.3.5 torchvision.transforms.RandomHorizontalFlip</h4>
<p>用于对载入的图片按随机概率进行水平翻转。我们通过传递给这个类的自定义随机概率，如果没有定义，则使用默认的概率为0.5</p>
<h4><a id="5136_torchvisiontransformsRandomVerticalFlip_808"></a>5.1.3.6 torchvision.transforms.RandomVerticalFlip</h4>
<p>用于对载入的图片按随机概率进行垂直翻转。我们通过传递给这个类的自定义随机概率，如果没有定义，则使用默认的概率为0.5</p>
<h4><a id="5137_torchvisiontransformsToTensor_810"></a>5.1.3.7 torchvision.transforms.ToTensor</h4>
<p>用于对载入的图片数据进行类型转换，将之前构成PIL图片数据转换为Tensor数据类型的变量，让PyTorch能够对其进行计算和处理。</p>
<h4><a id="5138_torchvisiontransformsToPILImage_812"></a>5.1.3.8 torchvision.transforms.ToPILImage:</h4>
<p>用于对Tensor变量的数据转换成PIL图片数据，主要为方便图片显示。</p>
<p>这里使用transforms对MNIST数据集进行操作：</p>
<pre><code class="prism language-py"><span class="token comment">#torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；</span>
transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#将PILImage转换为张量</span>
     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#将[0, 1]归一化到[-1, 1]</span>
     <span class="token comment">#前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#上述代码我们可以将transforms.Compose()看作一种容器，它能够同时对多种数据变换进行组合。</span>
<span class="token comment">#传入的参数是一个列表，列表中的元素就是对载入数据进行的变换操作。</span>
</code></pre>
<h3><a id="514_torchutils_826"></a>5.1.4 torch.utils</h3>
<p>关于torchvision.utils我们介绍一种用来对数据进行装载的类：torch.utils.data.DataLoader和</p>
<p>torch.utils.data.DataLoader类中， dataset参数指定我们载入的数据集的名称，batch_size参数设置每个包中图片的数量， shuffle设置为True代表在装载的过程会将数据随机打乱顺序并进行打包。</p>
<pre><code class="prism language-py">data_loader_train<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_train<span class="token punctuation">,</span>
                                       batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token comment">#每个batch载入的图片数量，默认为1,这里设置为64</span>
                                        shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                        <span class="token comment">#num_workers=2#载入训练数据所需的子任务数</span>
                                       <span class="token punctuation">)</span>
data_loader_test<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_test<span class="token punctuation">,</span>
                                      batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                                      shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                                      <span class="token comment">#num_workers=2)</span>
</code></pre>
<p>还有torchvision.utils.make_grid将一个批次的图片构造成网格模式的图片。</p>
<pre><code class="prism language-py"><span class="token comment">#预览</span>
<span class="token comment">#在尝试过多次之后，发现错误并不是这一句引发的，而是因为图片格式是灰度图只有一个channel，需要变成RGB图才可以，所以将其中一行做了修改：</span>
images<span class="token punctuation">,</span>labels <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># dataiter = iter(data_loader_train) #随机从训练数据中取一些数据</span>
<span class="token comment"># images, labels = dataiter.next()</span>

img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span>

img <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
std <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
img <span class="token operator">=</span> img<span class="token operator">*</span>std<span class="token operator">+</span>mean
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
</code></pre>
<p>这里，iter和next获取一个批次的图片数据和其对应的图片标签， 再使用torchvision.utils.make_grid将一个批次的图片构造成网格模式 经过torchvision.utils.make_grid后图片维度变为channel,h,w三维， 因为要用matplotlib将图片显示，我们要使用的数据要是数组且维度为（height,weight,channel）即色彩通道在最后 因此我们需要用numpy和transpose完成原始数据类型的转换和数据维度的交换。</p>
<h2><a id="52__859"></a>5.2 模型搭建和参数优化</h2>
<p>实现卷积神经网络模型搭建：</p>
<pre><code class="prism language-py"><span class="token keyword">import</span> math
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment">#构建卷积层之后的全连接层以及分类器</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre>
<h3><a id="521_torchnnConv2d_891"></a>5.2.1 torch.nn.Conv2d</h3>
<p>用于搭建卷积神经网络的卷积层，主要参数是：</p>
<p>输入通道数、输出通道数、卷积核大小、卷积核移动步长和paddingde值（用于对边界像素的填充）</p>
<h3><a id="522_torchnnMaxPool2d_895"></a>5.2.2 torch.nn.MaxPool2d</h3>
<p>实现卷积姐神经网络的最大池化层，主要参数是：</p>
<p>池化窗口的大小，池化窗口移动步长和paddingde值</p>
<h3><a id="523_torchnnDropout_899"></a>5.2.3 torch.nn.Dropout</h3>
<p>用于防止卷积神经网络在训练过程中发生过拟合，原理是以一定的随机概率将卷积神经网络模型的部分参数归零，以达到减少相邻两层神经连接的目的</p>
<h2><a id="53__902"></a>5.3 参数优化</h2>
<p>搭完模型后，我们就可以对模型进行训练和参数优化了:</p>
<pre><code class="prism language-py">model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/f0f44c7f59c34fc09932ec95e7646385.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQ0MtTWFj,size_20,color_FFFFFF,t_70,g_se,x_16"/></p>
<h3><a id="531__911"></a>5.3.1 模型训练</h3>
<pre><code class="prism language-py">n_epochs <span class="token operator">=</span> <span class="token number">5</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    running_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch {}/{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span><span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader_train<span class="token punctuation">:</span>
        X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> data
        X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span>pred<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> cost<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
        
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data
        running_correct <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> y_train<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    testing_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader_test<span class="token punctuation">:</span>
        X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> data
        X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span>pred<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        testing_correct <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loss is:{:4f},Train Accuracy is:{:.4f}%,Test Accuracy is:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>running_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>running_correct<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_train<span class="token punctuation">)</span>
                                                                                  <span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>testing_correct<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/ef148453ff104f598fa11629e636dce5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQ0MtTWFj,size_20,color_FFFFFF,t_70,g_se,x_16"/></p>
<h2><a id="54__944"></a>5.4 模型验证</h2>
<p>为了验证我们训练的模型是不是真的已知结果显示的一样准确，则最好的方法就是随机选取一部分测试集中的图片，用训练好的模型进行预测，看看和真实值有多大的偏差，并对结果进行可视化。测试代码如下：</p>
<pre><code class="prism language-py">data_loader_test <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_test<span class="token punctuation">,</span>
                                              batch_size <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>
                                              shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
inputs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
_<span class="token punctuation">,</span>pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Predict Label is:"</span><span class="token punctuation">,</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> pred<span class="token punctuation">.</span>data<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Real Label is:"</span><span class="token punctuation">,</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> y_test<span class="token punctuation">]</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
img <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>

std <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
img <span class="token operator">=</span> img<span class="token operator">*</span>std<span class="token operator">+</span>mean
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
</code></pre>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/a57f051c797c4aef839c56b1b9d72fd8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQ0MtTWFj,size_20,color_FFFFFF,t_70,g_se,x_16"/></p>
<h2><a id="55__966"></a>5.5 完整代码</h2>
<pre><code class="prism language-py"><span class="token keyword">import</span> torch 
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span>transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；</span>
<span class="token comment"># transform=transforms.Compose(</span>
<span class="token comment">#     [transforms.ToTensor(),#将PILImage转换为张量</span>
<span class="token comment">#      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))#将[0, 1]归一化到[-1, 1]</span>
<span class="token comment">#      #前面的（0.5，0.5，0.5） 是 R G B 三个通道上的均值， 后面(0.5, 0.5, 0.5)是三个通道的标准差</span>
<span class="token comment">#     ])</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
     transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     transforms<span class="token punctuation">.</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 修改的位置</span>

data_train <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>
                           transform<span class="token operator">=</span>transform<span class="token punctuation">,</span>
                           train <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
                           download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
data_test <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./data/"</span><span class="token punctuation">,</span>
                          transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>
                          train <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>

data_loader_train<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_train<span class="token punctuation">,</span>
                                       batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token comment">#每个batch载入的图片数量，默认为1,这里设置为64</span>
                                        shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                        <span class="token comment">#num_workers=2#载入训练数据所需的子任务数</span>
                                       <span class="token punctuation">)</span>
data_loader_test<span class="token operator">=</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_test<span class="token punctuation">,</span>
                                      batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                                      shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
                                      <span class="token comment">#num_workers=2)</span>

<span class="token comment">#预览</span>
<span class="token comment">#在尝试过多次之后，发现错误并不是这一句引发的，而是因为图片格式是灰度图只有一个channel，需要变成RGB图才可以，所以将其中一行做了修改：</span>
images<span class="token punctuation">,</span>labels <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># dataiter = iter(data_loader_train) #随机从训练数据中取一些数据</span>
<span class="token comment"># images, labels = dataiter.next()</span>

img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token punctuation">)</span>

img <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
std <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
img <span class="token operator">=</span> img<span class="token operator">*</span>std<span class="token operator">+</span>mean
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

<span class="token keyword">import</span> math
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment">#构建卷积层之后的全连接层以及分类器</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">14</span><span class="token operator">*</span><span class="token number">128</span><span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>
cost <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>

n_epochs <span class="token operator">=</span> <span class="token number">5</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    running_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch {}/{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span><span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader_train<span class="token punctuation">:</span>
        X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> data
        X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span>pred<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> cost<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
        
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data
        running_correct <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> y_train<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    testing_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> data_loader_test<span class="token punctuation">:</span>
        X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> data
        X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">,</span>Variable<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span>pred<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        testing_correct <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred <span class="token operator">==</span> y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loss is:{:4f},Train Accuracy is:{:.4f}%,Test Accuracy is:{:.4f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>running_loss<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>running_correct<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_train<span class="token punctuation">)</span>
                                                                                  <span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>testing_correct<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

data_loader_test <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>data_test<span class="token punctuation">,</span>
                                              batch_size <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>
                                              shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
X_test<span class="token punctuation">,</span>y_test <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>data_loader_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
inputs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
_<span class="token punctuation">,</span>pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Predict Label is:"</span><span class="token punctuation">,</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> pred<span class="token punctuation">.</span>data<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Real Label is:"</span><span class="token punctuation">,</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> y_test<span class="token punctuation">]</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
img <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>

std <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span>
img <span class="token operator">=</span> img<span class="token operator">*</span>std<span class="token operator">+</span>mean
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

</code></pre>
<h1><a id="_1102"></a>六、结语</h1>
<p><font color="#999AAA">关于pytorch的一个学习总结，代码文件我也会上传到github，期待大家和我交流，留言或者私信，一起学习，一起进步！<br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/7fc48ab3aaf5428d972cbd918d2365f3.jpg#pic_center"/></font></p>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>