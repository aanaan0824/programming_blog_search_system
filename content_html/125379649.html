<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="htmledit_views" id="content_views">
<p><strong> 前      言：</strong>作为当前先进的深度学习目标检测算法YOLOv5，已经集合了大量的trick，但是在处理一些复杂背景问题的时候，还是容易出现错漏检的问题。此后的系列文章，将重点对YOLOv5的如何改进进行详细的介绍，目的是为了给那些搞科研的同学需要创新点或者搞工程项目的朋友需要达到更好的效果提供自己的微薄帮助和参考。</p>
<p><strong>解决问题：</strong>加入SE通道注意力机制，可以让网络更加关注待检测目标，提高检测效果</p>
<figure class="image">
<img alt="" height="300" src="image\6b94209c967b45b6a35b85788c1d6b04.png" width="838"/>
<figcaption>
  SE模块的原理和结构
 </figcaption>
</figure>
<p></p>
<p><strong>添加方法：</strong></p>
<p>第一步：确定添加的位置，作为即插即用的注意力模块，可以添加到YOLOv5网络中的任何地方。本文以添加进C3模块中为例。</p>
<p>第二步：common.py构建融入se模块的C3,与原C3模块不同的是，该模块中的bottleneck中融入se模块。这样添加主要为了更好的做实验。</p>
<pre><code>class seC3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(seC3, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[seBottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))

class seBottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super(seBottleneck, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.l1 = nn.Linear(c1, c1 // 4, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.l2 = nn.Linear(c1 // 4, c1, bias=False)
        self.sig = nn.Sigmoid()

    def forward(self, x):
        x = self.cv1(x)
        b, c, _, _ = x.size()
        y = self.avgpool(x).view(b, c)
        y = self.l1(y)
        y = self.relu(y)
        y = self.l2(y)
        y = self.sig(y)
        y = y.view(b, c, 1, 1)
        x = x * y.expand_as(x)
        return x + self.cv2(x) if self.add else self.cv2(self.cv1(x))
</code></pre>
<p>第三步：yolo.py中注册我们进行修改的seC3</p>
<pre><code>        if m in [Conv, GhostConv, Bottleneck, Bottleneck_cot,TransformerC3,GhostBottleneck, SPP, DWConv, MixConv2d, Focus, CrossConv, BottleneckCSP,
                 C3,seC3]:
            c1, c2 = ch[f], args[0]
            if c2 != no:  # if not output
                c2 = make_divisible(c2 * gw, 8)
            args = [c1, c2, *args[1:]]
            if m in [BottleneckCSP, seC3]:
                args.insert(2, n)  # number of repeats
                n = 1</code></pre>
<p>第四步：修改yaml文件，本文以修改主干特征提取网络为例，将原C3模块改为seC3即可。</p>
<p><img alt="" height="494" src="image\6f763b7d2628484fb1c30018b3590005.png" width="763"/></p>
<p>第五步：将train.py中改为本文的yaml文件即可，开始训练。</p>
<p><strong> 结    果：</strong>本人在多个数据集上做了大量实验，针对不同的数据集效果不同，同一个数据集的不同添加位置方法也是有差异，需要大家进行实验。有效果有提升的情况占大多数。</p>
<p><strong>预告一下：下一篇内容分享自己研究生期间第一篇中文核心期刊的发表。</strong>有兴趣的朋友可以关注一下我，有问题可以留言或者私聊我哦</p>
<p><strong>PS：</strong>SE通道注意力机制，参数量引入较少，不仅仅是可以添加进YOLOv5，也可以添加进任何其他的深度学习网络，不管是分类还是检测还是分割，主要是计算机视觉领域，都可能会有不同程度的提升效果。</p>
<p>最后，希望能互粉一下，做个朋友，一起学习交流。</p>
</div>
</div>