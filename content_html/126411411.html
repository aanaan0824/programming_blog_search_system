<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-github-gist" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<h1><a id="__0"></a>🚩 前言</h1>
<blockquote>
<p>活动地址：<a href="https://marketing.csdn.net/p/bdabfb52c5d56532133df2adc1a728fd">CSDN21天学习挑战赛</a><br/> 🚀 博主主页：<a href="https://blog.csdn.net/m0_63238256?spm">阿阿阿阿锋的主页_CSDN</a><br/> 🌊 <em>希望和大家一起加油，一起进步！</em></p>
</blockquote>
<p><em>今天学习《深度学习入门：基于python的理论与实践》时，被<strong>梯度确认</strong>的问题卡了很久。具体过程就不赘述，最终发现是我写的 softmax 函数的问题，导致的数值微分与反向传播求得的梯度总对不上。</em><br/> <em>softmax 问题在于我这里没有考虑好不同维度数据的情况。</em></p>
<hr/>
<p></p>
<div class="toc">
<h3>文章目录</h3>
<ul><li><a href="#__0">🚩 前言</a></li><li><a href="#1_softmax_12">1. softmax函数代码</a></li><li><a href="#2__23">2. 不能正确处理批量样本</a></li><li><a href="#3__71">3. 解决方案</a></li></ul>
</div>
<p></p>
<hr/>
<h1><a id="1_softmax_12"></a>1. softmax函数代码</h1>
<pre><code class="prism language-py"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    a <span class="token operator">-=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
    exp_a <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
    <span class="token keyword">return</span> exp_a <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>exp_a<span class="token punctuation">)</span>
</code></pre>
<h1><a id="2__23"></a>2. 不能正确处理批量样本</h1>
<p>我们对比一下处理单个样本和批量样本的情况：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
softmax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> softmax<span class="token punctuation">(</span>b<span class="token punctuation">)</span>

</code></pre>
<pre><code>输出：
(array([0.09003057, 0.24472847, 0.66524096]),
 array([[0.04501529, 0.12236424, 0.33262048],
        [0.04501529, 0.12236424, 0.33262048]]))
</code></pre>
<p>容易发现，对应的值，<strong>后者的结果都是前者的一半</strong>。问题就在<code>np.sum(exp_a)</code>这里：<br/> 在批量数据（矩阵）情况下，我们本意是每个样本求得一个和值，即按行求和。它却将所有数据相加而仅得到一个和值。</p>
<p>再验证一下：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
softmax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> softmax<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
</code></pre>
<pre><code>输出：
(array([0.09003057, 0.24472847, 0.66524096]),
 array([[0.03001019, 0.08157616, 0.22174699],
        [0.03001019, 0.08157616, 0.22174699],
        [0.03001019, 0.08157616, 0.22174699]]))
</code></pre>
<p>可以看到，样本数增加为 3 个时，后者的输出也相应地变成了前者的<strong>三分之一</strong>。此时前者输出的 3 个数和为 1 ，而后者是输出的 9 个数和为 1。</p>
<p>现在单样本和批量的输出之间还具有倍数关系，如果<strong>每个样本是数据不同</strong>，那么将会更加乱套：</p>
<pre><code class="prism language-py">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
softmax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> softmax<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
</code></pre>
<pre><code>输出：
(array([0.09003057, 0.24472847, 0.66524096]),
 array([[0.00426978, 0.01160646, 0.03154963],
        [0.08576079, 0.23312201, 0.63369132]]))
</code></pre>
<h1><a id="3__71"></a>3. 解决方案</h1>
<p>分情况处理即可：</p>
<pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> x<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>T
        x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> y<span class="token punctuation">.</span>T 

    x <span class="token operator">=</span> x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p><code>注：此代码来自前言提到的书本</code><br/> 我们之前分析了，其实就是求和函数的问题，因此我尝试着能不能写得更加简洁和统一些。</p>
<p>但是我没有成功，因为会遇到一些<strong>细节处理</strong>上的问题，例如批量情况下：最大值 max 也应当是按行求得；<code>np.sum</code>得到的是一维数组，为了最后相除时能够进行广播，进行<strong>转置</strong>是有必要的。</p>
<p>不过修改代码的尝试倒是加深了我对它的理解。</p>
<hr/>
<p><em>感谢阅读</em></p>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>