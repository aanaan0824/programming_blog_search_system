<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="htmledit_views" id="content_views">
<p><strong>学习感言</strong>：</p>
<p>从3.7第一天开始，到今天4.4，一个多月的时间，陆续完成了听课，代码实现和总结博客，过程些许艰难，作为一个刚入门的学习者，收获了很多。总结一下这一段时间的学习过程吧。后面的学习方向还在思考。</p>
<p id="main-toc"><strong>目录</strong></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123732264" title="1.0  线性回归预测">1.0 线性回归预测</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123888791?spm=1001.2014.3001.5502" title="2.0 线性可分logistic逻辑回归">2.0 线性可分logistic逻辑回归</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123890566?spm=1001.2014.3001.5502" title="2.1 线性不可分logistic逻辑回归">2.1 线性不可分logistic逻辑回归</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123892518?spm=1001.2014.3001.5502" title="3.0 logistic逻辑回归手写多分类问题">3.0 logistic逻辑回归手写多分类问题</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123894585?spm=1001.2014.3001.5502" title="3.1 神经网络正向传播">3.1 神经网络正向传播</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123906412?spm=1001.2014.3001.5502" title="4.0 神经网络反向传播（BP算法）">4.0 神经网络反向传播（BP算法）</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123908982?spm=1001.2014.3001.5502" title="5.0 方差与偏差">5.0 方差与偏差</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123918970?spm=1001.2014.3001.5502" title="6.0 SVM支持向量机">6.0 SVM支持向量机</a></p>
<p style="margin-left:0px;"><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123927269?spm=1001.2014.3001.5502" title="7.0 kmeans聚类">7.0 kmeans聚类</a></p>
<p><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123936110?spm=1001.2014.3001.5502" title="7.1 PCA主成分分析">7.1 PCA主成分分析</a></p>
<p><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123938951?spm=1001.2014.3001.5502" title="8.0 异常检测">8.0 异常检测</a></p>
<p><a class="link-info" href="https://blog.csdn.net/m0_51933492/article/details/123945201?spm=1001.2014.3001.5502" title="8.1 推荐系统（协同过滤算法）">8.1 推荐系统（协同过滤算法）</a></p>
<hr id="hr-toc"/>
<p><strong>作业涉及到的数据集：</strong></p>
<p>链接:https://pan.baidu.com/s/1Ym6WHYd0sVyThLErwLE9pg <br/> 提取码:pg7z</p>
<p><strong>Ng课程大纲总结 </strong></p>
<blockquote>
<h2>无监督学习</h2>
<p>线性规划，逻辑回归，神经网络，SVM</p>
<h2>无监督学习</h2>
<p>K-means , PCA , 异常检测</p>
<h2>应用</h2>
<p>推荐系统，</p>
<h2><strong>大规模机器学习</strong></h2>
<p><strong>映射化简和数据并行:</strong></p>
<p>将我们的数据集分配给不多台 计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和。这样 的方法叫做映射简化。如果任何学习算法能够表达为，对训练集的函数的求和，那么便能将这个任 务分配给多台计算机（或者同一台计算机的不同 CPU 核心），以达到加速处理的目的。</p>
<h2>构建机器学习系统tips</h2>
<p>方差/偏差 ，正则化</p>
<h2><strong>决定下一步做什么：</strong></h2>
<p>算法评估，学习曲线（判断高偏差/高方差问题），误差分析</p>
<p>上限分析：机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够 知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。</p>
<h2>问题描述和流程图</h2>
<h2>滑动窗口分类算法（CV）</h2>
<h2><strong>获取大量数据和人工数据</strong></h2>
</blockquote>
<h1><strong>以下是零碎：</strong></h1>
<blockquote>
<p>现有的机器学习种类繁多，我们一般可以进行如下的分类标准：</p>
<ul><li>是否在人类监督下学习（监督学习、非监督学习、半监督学习和强化学习）</li><li>是否可以动态的增量学习（在线学习和批量学习）</li><li>是简单的将新的数据点和已知的数据点进行匹配，还是像科学家那样对训练数据进行模型检测，然后建立一个预测模型（基于实例的学习和基于模型的学习）</li></ul>
</blockquote>
<h2><strong> 一 、监督学习与无监督学习</strong></h2>
<ul><li> <h3> <strong>监督学习</strong>（Supervised Learning）：对于数据集中每一个样本都有对应的标签，包括回归（regression）和分类（classification）；</h3> </li><li>K近邻算法</li><li>线性回归</li><li>logistic回归</li><li>支持向量机（SVM）</li><li>决策树和随机森林</li><li>神经网络</li><li> <h3><strong>无监督学习</strong>（Unsupervised Learning）：数据集中没有任何的标签，包括聚类（clustering），著名的一个例子是鸡尾酒晚会。<strong>实现公式</strong>：[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x’);</h3> </li><li><strong>聚类算法</strong>
<ul><li>K均值算法（K-means）</li><li>基于密度的聚类方法(DBSCAN)</li><li>最大期望算法</li></ul></li><li><strong>可视化和降维</strong>
<ul><li>主成分分析（PCA）</li><li>核主成分分析</li></ul></li><li><strong>关联规则学习</strong>
<ul><li>Apriori</li><li>Eclat</li></ul></li><li><strong> 异常检测</strong></li></ul>
<ul><li> <h3><strong>半监督学习</strong> 有些算法可以处理部分标记的训练数据，通常是大量未标记的数据和少量标记的数据，这种成为半监督学习。</h3> </li><li> <p>如照片识别就是很好的例子。在线相册可以指定识别同一个人的照片（无监督学习），当你把这些同一个人增加一个标签的后，新的有同一个人的照片就自动帮你加上标签了。</p> </li><li> <h3><strong>强化学习</strong></h3> <p>强化学习，它的学习系统能够观测环境，做出选择，执行操作并获得回报，或者是以负面回报的形式获得惩罚。它必须自行学习什么是最好的策略，从而随着时间推移获得最大的回 </p> </li></ul>
<h2>二、在线学习 </h2>
<p>    如果你有一个由连续的用户流引发的连续的数据流，进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习 用户的偏好，然后使用这些信息来优化一些关于网站的决策。</p>
<p>    在线学习算法指的是对数据流而非离线的静态数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。</p>
<ul><li>在线学习：产品搜索界面   产品推荐 </li></ul>
<h2>三、模型训练及选择（model selection）</h2>
<p>可以依据训练误差和测试误差来评估假设hθ(x)；<br/> 一般来说，我们将数据集划分成训练集（60%）、验证集（20%）和测试集（20%）；</p>
<ul><li><code>训练集</code></li></ul>
<p>训练集用来<strong>训练模型</strong>，学习参数θ ：minJ(θ)；即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数。</p>
<ul><li><code>验证集</code></li></ul>
<p>验证集用于<strong>模型的选择</strong>，更具体地来说，验证集并不参与学习参数的确定，也就是验证集并没有参与梯度下降的过程。用训练集对模型训练完毕后，再用验证集对模型测试，测试模型是否准确而不是训练模型的参数。</p>
<ul><li><code>测试集</code></li></ul>
<p>测试集只使用一次，即在训练完成后<strong>评价最终的模型</strong>时使用。它既不参与学习参数过程，也不参数超参数选择过程，而仅仅使用于模型的评价。<br/> 不能在训练过程中使用测试集，而后再用相同的测试集去测试模型。这样做其实是一个cheat，使得模型测试时准确率很高。</p>
<h2><strong>四、模型优化</strong></h2>
<p><strong>欠拟合，高偏差</strong>：说明没有很好的拟合训练数据 </p>
<p><strong>过拟合，高方差：</strong>拟合训练数据过于完美，J(θ)≈0，导致模型的<strong>泛化能力</strong>很差，对于新样本不能准确预测</p>
<p style="text-align:center;"><img alt="" height="302" src="image\9732adc62a204f378017a95f6c2c32ae.png" width="524"/></p>
<p></p>
<h2>五、机器学习系统设计</h2>
<h3><a name="t36"></a><a id="skewed_classes_236"></a>不对称分类的误差评估（skewed classes）</h3>
<p>错误率：有多少比例的西瓜被判断错误；</p>
<p>查准率（precision）：算法挑出来的西瓜中有多少比例是好西瓜；</p>
<p>查全率（recall）：所有的好西瓜中有多少比例被算法跳了出来。</p>
<ul><li>如果我们想要比较确信为正例时才判定为正例，那么提高阈值，模型会对应高查准率，低召回率；</li><li>如果希望避免假阴性，那么降低阈值，模型会对应低查准率，高召回率</li></ul>
<h2>六、高级优化算法：</h2>
<ul><li>共轭梯度算法</li><li>BFGS</li><li>L-BFGS</li></ul>
<p>        优点：无需人工选择参数α；运算速度比梯度下降更快 </p>
<p>        缺点：更加复杂</p>
<h2><strong>最后：放一下Ng的结语，激励自己继续前进吧~  感谢老师</strong></h2>
<p style="text-align:center;"><img alt="" src="image\0ab2b47c9bdb4ab6826d30cb6171a79a.png"/></p>
<p></p>
</div>
</div>