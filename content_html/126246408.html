<div class="article_content clearfix" id="article_content">
<link href="style.css" rel="stylesheet"/>
<div class="markdown_views prism-tomorrow-night" id="content_views">
<svg style="display: none;" xmlns="http://www.w3.org/2000/svg">
<path d="M5,0 0,2.5 5,5z" id="raphael-marker-block" stroke-linecap="round" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
</svg>
<p><img alt="请添加图片描述" src="https://img-blog.csdnimg.cn/154d035aa4db42df99f3b01fbf287e46.gif#pic_center"/></p>
<blockquote>
<p><strong>@作者</strong> : <font color="#409EFF"><strong>SYFStrive</strong></font><br/> <strong>@创建时间</strong> : <font color="#409EFF"><strong>2022/8/9 22:01</strong></font><br/> 📜： <font color="#009688"><strong>Scrapy案例</strong></font><br/> 🥧： <a href="https://blog.csdn.net/m0_61490399/article/details/126242058"><font color="#0096ed"><strong>点击跳转到上一篇Scrapy续文</strong></font></a>🦄<br/> 🥧： <strong>感谢支持,学习累了可以先看小段由小胖给大家带来的街舞😀</strong><br/> <img alt="请添加图片描述" src="https://img-blog.csdnimg.cn/2c353ec3abfe4f1d9980da9ac6becd57.gif#pic_center"/><br/> <img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/1a8e166d911442018cd6dac77a52cfb6.gif#pic_center"/></p>
</blockquote>
<p></p>
<div class="toc">
<h3>目录</h3>
<ul><li><a href="#_12">简介</a></li><li><ul><li><a href="#Scrapy_17">📦Scrapy使用前准备</a></li><li><a href="#yield_25">yield的使用</a></li><li><a href="#PythonScrapy_30">Python爬虫之Scrapy框架之🔔🔔爬取数据</a></li><li><ul><li><a href="#get_31">get</a></li><li><a href="#_32">案例使用的内容</a></li><li><a href="#_35">单管道</a></li><li><a href="#_41">多管道（单独使用一个管道下载图片……）</a></li><li><a href="#_100_50">实现多页面下载 （爬取100页内容）</a></li><li><a href="#_60">案例总结</a></li><li><a href="#post_77">post</a></li></ul>
</li><li><a href="#PythonScrapy_86">Python爬虫之Scrapy框架之🎦爬取数据</a></li></ul>
</li><li><a href="#_113">最后</a></li></ul>
</div>
<p></p>
<h1><a id="_12"></a>简介</h1>
<ol><li>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据 (例如 Amazon Associates Web Services ) 或者通用的网络爬虫。</li><li>Scrapy 是一个基于 Twisted 实现的异步处理爬虫框架，该框架使用纯 Python 语言编写。Scrapy 框架应用广泛，常用于数据采集、网络监测，以及自动化测试等。</li><li>提示：Twisted 是一个基于事件驱动的网络引擎框架，同样采用 Python 实现。</li></ol>
<h2><a id="Scrapy_17"></a>📦Scrapy使用前准备</h2>
<ul><li>文档如👇</li></ul>
<ol><li>官网文档：<a href="https://requests.readthedocs.io/projects/cn/zh_CN/latest/">链接</a></li><li>C语言中文文档：<a href="http://c.biancheng.net/python_spider/scrapy.html">链接</a></li></ol>
<ul><li>安装</li></ul>
<ol start="3"><li>安装语法：python -m pip install Scrapy</li><li>报错：使用pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn 加包名</li></ol>
<h2><a id="yield_25"></a>yield的使用</h2>
<ol><li>带有 yield 的函数不再是一个普通函数，而是一个生成器generator，可用于迭代</li><li>yield 是一个类似 return 的关键字，迭代一次遇到yield时就返回yield后面(右边)的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码(下一行)开始执行</li><li>简要理解：yield就是 return 返回一个值，并且记住这个返回的位置，下次迭代就从这个位置后(下一行)开始</li></ol>
<h2><a id="PythonScrapy_30"></a>Python爬虫之Scrapy框架之🔔🔔爬取数据</h2>
<h3><a id="get_31"></a>get</h3>
<h3><a id="_32"></a>案例使用的内容</h3>
<p>涉及 单管道、多管道</p>
<h3><a id="_35"></a>单管道</h3>
<p>📰代码演示：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/6704e85f58aa4a328260f1b6273d91b7.png"/></p>
<h3><a id="_41"></a>多管道（单独使用一个管道下载图片……）</h3>
<p>📰代码演示：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/3de10e52368b4228a5ef227d811d07d5.png"/></p>
<p>如下图（下载成功🆗）：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/00da822af6cd4044bc86787fb3c02362.gif"/></p>
<h3><a id="_100_50"></a>实现多页面下载 （爬取100页内容）</h3>
<p>📰代码演示：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/c1370b712fa0476184ca268baef43cfe.png"/></p>
<p>如下图（下载成功🆗）：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/64e6ab3a7bd34ad6a401360fbcddb1a4.gif"/></p>
<h3><a id="_60"></a>案例总结</h3>
<ol><li>两个生命函数</li></ol>
<pre><code class="prism language-代码">    # 在爬虫文件开始的之前就执行的一个方法
    # def open_spider():
    # 在爬虫文件执行完之后  执行的方法
    # def close_spider():
</code></pre>
<ol start="2"><li> <p>简单步骤：获取数据后 👉 使用items 定义数据结构的 👉 导入items（传递数据） 👉 使用Yield返回 👉 通过pipelines管道下载数据（使用前要开启管道（item就是yield后面的book对象））</p> </li><li> <p>添加管道：定义管道类 👉 在settings中开启管道</p> </li><li> <p>注意：<br/> 1、如果是多页下载的话 那么必须要调整的是allowed_domains的范围 一般情况下只写域名<br/> 2、write方法必须要写一个字符串 而不能是其他的对象<br/> 3、通过该案例检测的一点就是下载的图片目录文件是spiders下的理解如：‘./bookImg/’ + item.get(‘name’) + ‘.jpg’</p> </li></ol>
<h3><a id="post_77"></a>post</h3>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/2385e8804f334f639f730612998d63e7.png"/></p>
<p>效果如下:</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/dd30d266dd0d4dc396386fa81908c443.gif"/></p>
<h2><a id="PythonScrapy_86"></a>Python爬虫之Scrapy框架之🎦爬取数据</h2>
<p>📰代码演示：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/8e939b909157403f81e97f6137b7c208.png"/></p>
<p>📰代码演示：</p>
<pre><code class="prism language-代码">class DianyingtiantangPipeline:

    def open_spider(self, spider):
        self.fs = open('movie.json', 'w', encoding='utf-8')

    def process_item(self, item, spider):
        # 简单理解：这里的item相当于yield movie返回值
        self.fs.write(str(item))

        return item

    def close_spider(self, spider):
        self.fs.close()
</code></pre>
<p>如下图（下载成功🆗）：</p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/e1d1bd99390f462bb2488e42fcfe05d3.gif"/></p>
<h1><a id="_113"></a>最后</h1>
<p><strong>Scrapy框架还未结束（待更），觉得不错的请给我专栏点点订阅，你的支持是我们更新的动力，感谢大家的支持，希望这篇文章能帮到大家</strong></p>
<blockquote>
<p><a href="https://blog.csdn.net/m0_61490399/category_11945820.html?spm=1001.2014.3001.5482">点击跳转到我的Python专栏</a></p>
</blockquote>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/21ab07bbc52e422090c2b819b9318958.png"/></p>
<p><strong>下篇文章再见ヾ(￣▽￣)Bye<sub>Bye</sub></strong></p>
<p><img alt="在这里插入图片描述" src="https://img-blog.csdnimg.cn/dd8d5f8e512f4c778736eee95712d6b3.png"/></p>
</div>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css" rel="stylesheet"/>
<link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css" rel="stylesheet"/>
</div>