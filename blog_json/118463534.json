{"blogid": "118463534", "writerAge": "码龄6年", "writerBlogNum": "94", "writerCollect": "6841", "writerComment": "1308", "writerFan": "46131", "writerGrade": "6级", "writerIntegral": "8696", "writerName": "HowieXue", "writerProfileAdress": "writer_image\\profile_118463534.jpg", "writerRankTotal": "2621", "writerRankWeekly": "454", "writerThumb": "1218", "writerVisitNum": "2197191", "blog_read_count": "54064", "blog_time": "于 2021-07-04 23:28:39 发布", "blog_title": "Yolov5自定义图片训练测试及模型调优（详细过程）", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-light\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>Yolov5自定义图片训练测试及模型调优（详细过程）</h3>\n<ul><li><a href=\"#1__11\">1. 图像数据获取、标注</a></li><li><a href=\"#2__74\">2. 数据集划分及准备</a></li><li><a href=\"#3__97\">3. 配置训练参数，准备训练：</a></li><li><ul><li><a href=\"#31_dataxxxyaml_100\">3.1 修改data/训练配置xxx.yaml文件：</a></li><li><a href=\"#32_modelsxxxyaml_118\">3.2 修改models模型配置xxx.yaml文件</a></li></ul>\n</li><li><a href=\"#4__143\">4. 开始训练</a></li><li><a href=\"#5__196\">5. 测试训练后的模型：</a></li><li><a href=\"#6__223\">6. 模型的参数调优</a></li><li><a href=\"#_323\">博主热门文章推荐：</a></li></ul>\n</div>\n<p></p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704213743298.png\"/><br/> 书接上篇 <a href=\"https://howiexue.blog.csdn.net/article/details/118445766\">半小时搞定Yolov5安装配置及使用（详细过程）</a></p>\n<hr/>\n<h1><a id=\"1__11\"></a>1. 图像数据获取、标注</h1>\n<p>如果自定义训练自己的数据集，首先需要数据标注，至于数据来源可以是下载现有的开发数据集、拍照、爬虫等等。<br/> 如果是拍照、爬虫等获取的数据图片，需要进行数据标注，这个过程可以使用工具来做，但也需要一些手动操作 。。并且图片越多越好，如果样本过少，模型训练和预测都会受到影响，非常容易欠拟合。</p>\n<blockquote>\n<p>这里因为针对自定义数据大多不存在现有数据集，所以我使用了手机拍照方式，获取图片。</p>\n</blockquote>\n<p>图片标注工具有很多，这里我使用的<strong>Makesense AI</strong>工具对图像添加标签：</p>\n<ul><li>地址：<a href=\"https://www.makesense.ai/\">https://www.makesense.ai/</a></li></ul>\n<blockquote>\n<p>makesense.ai是强大且免费使用的 为照片加标签的<strong>在线工具</strong></p>\n</blockquote>\n<p>makesense.ai不需要安装，直接用浏览器即可，非常方便：而且能够直接导出Yolo格式，不需要在用工具转换了。。。</p>\n<p>（当然还有别的工具例如labelimg等，但只能导出xml，需要脚本进行xml-txt转换，不过labelimg这类本地Tools数据隐私/安全性更高）</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704161350354.png\"/></p>\n<p>将待标注的图片文件拖拽或点击上传，之后点击Object Detection：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704162441292.png\"/></p>\n<p>点击ObjectDetection后，系统提示需要我们添加标签，根据需要，添加Lable的名称<br/> （根据待测数据集，有几类就添加几个）</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\2021071222123014.png\"/></p>\n<p>添加完标签名称后，点击start project。<br/> 下一步进入工作台，通过Rect画矩形框进行标注：</p>\n<blockquote>\n<p>makesense支持点，线，区域标注</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704201031179.png\"/><br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210712221210157.png\"/></p>\n<p>标注完成后，点击Export Annotations导出labels<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704163318976.png\"/></p>\n<p>选择Yolo格式</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704163424743.png\"/></p>\n<p>导出的标注 label文件，其实就是类别和区域位置，每一个lable格式分别代表：</p>\n<ul><li>class x_center y_center width height</li></ul>\n<p>对应lable文件每行的内容，例如：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704164742280.png\"/></p>\n<p>因为我们使用了makesense.ai 可以直接生成yolo格式的label txt，所以之后不需要使用工具进行转换了，直接copy到数据集即可，非常方便。。。否则如果是xml文件格式，还需要脚本进行xml-txt转换。。。</p>\n<hr/>\n<h1><a id=\"2__74\"></a>2. 数据集划分及准备</h1>\n<p>首先划分测试数据集，将自定义测试的图像数据和标签数据集分别 划分为：训练集、验证集、测试集，，比例根据数据量不同，一般可以为 96%:2%:2%</p>\n<p>仿照Yolov5原生格式，我们新建一个datasets目录，并创建images，labels两个子目录，分别存放待训练的图像以及标注后的label数据:</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\2021070418475569.png\"/><br/> 并分别创建数据集目录 train/val/test，<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704184905651.png\"/></p>\n<p>将相应测试数据集分别放入相应文件夹中（<strong>文件名要一一对应</strong>），如下图：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704184737518.png\"/></p>\n<p>到这一步训练所需数据集划分及准备 就完成了，</p>\n<hr/>\n<h1><a id=\"3__97\"></a>3. 配置训练参数，准备训练：</h1>\n<p>和Yolov3/Yolov4中的.cfg配置文件不同，Yolov5参数配置文件都是以.yaml的格式</p>\n<h2><a id=\"31_dataxxxyaml_100\"></a>3.1 修改data/训练配置xxx.yaml文件：</h2>\n<p>下面需要修改Yolov5的训练配置参数，既自定义制作自己使用的训练.yaml配置文件：</p>\n<p>为了方便修改，我们可以copy一份原有的data/coco128.yaml, 重命名一下，并修改其中的参数为自定义训练的参数：</p>\n<p>先看下coco128.yaml，可以看到原有coco训练集的类别数量是80个，标签（模型能识别的类别名）分别是下面的name<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704171528815.png\"/><br/> 根据具体需要修改，我这里测试所用的修改为：</p>\n<ul><li>修改path/train/val/test的目录路径为自定义数据集路径</li><li>将nc（number of classes）改为 2</li><li>修改Names为自己数据的类别名</li><li>注释掉Download</li></ul>\n<p>train.py在训练过程中，会将路径中的images替换为 labels来寻找labels数据<br/> 修改后的yaml:<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704184619546.png\"/></p>\n<h2><a id=\"32_modelsxxxyaml_118\"></a>3.2 修改models模型配置xxx.yaml文件</h2>\n<p>进入models/目录，可以看到有四个模型配置的yaml文件：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704172730974.png\"/><br/> 根据需要选择其中的模型yaml进行修改，这里为了精度，以模型网络参数量最多的yolov5x为例，打开yolov5x.yaml：</p>\n<blockquote>\n<p>Model的yaml文件中都是模型网络相关配置参数，例如nc下面的depth_multiple是指网络的深度，width_multiple是网络的宽度， anchors是锚标（标出物体的方框），backbone既骨干网络</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704172942590.png\"/><br/> <strong>yolov5x.yaml</strong>里面就是yolov5x 模型训练的具体参数了，这里和上面一样对应也做修改<br/> 建议还是copy出一份新的yaml，进行修改：</p>\n<ul><li>nc 修改为2，</li><li>针对Anchors ，如果自己提前聚类过，可以同步把计算后anchors修改下，如果没有可以不修改</li></ul>\n<p>因为Yolov5默认已经能够 自动判断是否需要重新进行聚类anchors的功能（使用K-means），所以这里我没有操作</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704173902121.png\"/></p>\n<hr/>\n<h1><a id=\"4__143\"></a>4. 开始训练</h1>\n<p>在修改完两个yaml配置文件后，就可以开始训练了：</p>\n<pre><code class=\"prism language-python\">python train<span class=\"token punctuation\">.</span>py <span class=\"token operator\">-</span><span class=\"token operator\">-</span>cfg models<span class=\"token operator\">/</span>yolov5m_tstat<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">-</span><span class=\"token operator\">-</span>data data<span class=\"token operator\">/</span>Tstat<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">-</span><span class=\"token operator\">-</span>weights yolov5m<span class=\"token punctuation\">.</span>pt <span class=\"token operator\">-</span><span class=\"token operator\">-</span>epoch <span class=\"token number\">150</span> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>batch<span class=\"token operator\">-</span>size <span class=\"token number\">32</span>\n</code></pre>\n<p>开始训练：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210704184532629.png\"/></p>\n<p>然后就是漫长的traning过程，等待训练完成。。。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704222151842.png\"/></p>\n<p>训练完后，通过最后log可以看到训练好的模型的权重保存在了runs/train/exp17/weights/last.pt和best.pt</p>\n<p>其中还包括了PR Curve 曲线、Confusion matric （混淆矩阵）、results.png/txt 等训练过程数据</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210704194055765.png\"/></p>\n<p><strong>train.py相关参数解析：</strong></p>\n<ul><li>weights：权重文件路径，如果是’'则重头训练参数，如果不为空则做迁移学习，权重文件的模型需与cfg参数中的模型对应</li><li>epochs：指的就是训练过程中整个数据集将被迭代多少次</li><li>batch-size：每次梯度更新的批量数，指一次看完多少张图片才进行权重更新</li><li>config-thres: 模型目标检测的置信度阈值</li><li>cfg：存储模型结构的配置文件</li><li>data：存储训练、测试数据的文件</li><li>img-size：输入图片的宽高</li><li>rect：进行矩形训练</li><li>resume：恢复最近保存的模型开始训练</li><li>nosave：仅保存最终checkpoint</li><li>notest：仅测试最后的epoch</li><li>evolve：进化超参数</li><li>cache-images：缓存图像以加快训练速度</li><li>name： 重命名results.txt to results_name.txt</li><li>device：cuda device, i.e. 0 or 0,1,2,3 or cpu</li><li>adam：使用adam优化</li><li>multi-scale：多尺度训练，img-size +/- 50%</li><li>single-cls：单类别的训练集</li></ul>\n<hr/>\n<h1><a id=\"5__196\"></a>5. 测试训练后的模型：</h1>\n<p>同样使用detect.py，weights使用新训练后的best.pt，测试图片可以拍一个新照片，或者找一个之前没有用到的图片</p>\n<pre><code class=\"prism language-python\">python detect<span class=\"token punctuation\">.</span>py <span class=\"token operator\">-</span><span class=\"token operator\">-</span>weights runs<span class=\"token operator\">/</span>train<span class=\"token operator\">/</span>exp16<span class=\"token operator\">/</span>weights<span class=\"token operator\">/</span>best<span class=\"token punctuation\">.</span>pt <span class=\"token operator\">-</span><span class=\"token operator\">-</span>source data<span class=\"token operator\">/</span>test<span class=\"token operator\">/</span>Tc400_137<span class=\"token punctuation\">.</span>jpg\n</code></pre>\n<p>（图片的置信度0.9是在模型调优后才达到的）<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210705194858943.png\"/><br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210705194955899.png\"/><br/> <strong>train_batch0.jpg</strong>：可以看到模型在训练过程，模型分别使用0和1代表两个不同的label/class，<br/> <img alt=\"在这里插入图片描述\" src=\"image\\2021070519521048.png\"/></p>\n<p>Yolov5官网的预训练模型在训练中使用的coco数据集，也是通过0-80数字来分别代表不同的label/class</p>\n<p>例如官方文档提供的train_batch0.jpg示例图片 ，对应了预训练模型训练时的batch 0：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210706161753620.png\"/></p>\n<p>测试实时摄像头识别如下，识别的区分度还是有的~<br/> <img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/20210704231053220.gif\"/></p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/20210704225423199.gif\"/></p>\n<h1><a id=\"6__223\"></a>6. 模型的参数调优</h1>\n<p>细心的小伙伴们可以发现上面目标检测识别的置信度比较低（在实时摄像头检测的置信度都低于0.2)。。</p>\n<blockquote>\n<p>良好的模型一般置信度要在<strong>0.6</strong>以上，识别率要达到90%以上。</p>\n</blockquote>\n<p>因此这次训练出来的模型识别效果很差，不能使用，这是因为上面训练过程<strong>没有进行模型的调优</strong>。</p>\n<p>接下来需要进行YOLOv5模型参数的调优，才能提高识别率及置信度。。。（或提高样本数据量然后重新训练）</p>\n<blockquote>\n<p>train.py会默认使用的源码自带的模型超参数 (HyperParameter)，这些参数针对Githu上的源码在训练时的数据集（如coco数据集）或许最优，但不一定在我们自定义的数据中是有效的。</p>\n<p>实际上，Github上的预训练模型在识别率等方面也有一定缺陷，不能直接应用在实际工程中，在大多数应用中都需要重新调整，并基于相应数据集训练适用于自己项目的模型。。。</p>\n</blockquote>\n<p>在经过模型hyp参数调优后，置信度显著得到提升，最终测试 ，<strong>实时摄像头检测的置信度能达到0.6以上，纯img检测图像更是能达到0.9</strong>：</p>\n<blockquote>\n<p>参数调优过程一般要反复多次进行微调&lt;-&gt;训练&lt;-&gt;测试，最终得出符合需求/较优的HyperPara，应用在项目中</p>\n</blockquote>\n<p>先上图：<br/> <img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/20210705201117275.gif\"/></p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210705200248156.png\"/></p>\n<p>调整超参数在data/hyps/hyp.finetune.yaml：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210705203945281.png\"/></p>\n<p>这里最终主要是调整了lr0(学习率)为0.0030，同时修改了epoch、batch-size<br/> <img alt=\"在这里插入图片描述\" src=\"image\\20210705201546723.png\"/></p>\n<p><strong>部分hyp超参数意义：</strong></p>\n<ul><li>lr0: 0.0032 #学习率</li><li>lrf: 0.12 # 余弦退火超参数 (CosineAnnealing）</li><li>momentum: 0.843 # 学习率动量</li><li>weight_decay: 0.00036 # 权重衰减系数</li><li>warmup_epochs: 2.0 #预热学习epoch</li><li>warmup_momentum: 0.5 #预热学习率动量</li><li>warmup_bias_lr: 0.05 #预热学习率</li><li>box: 0.0296 # giou损失的系数</li><li>cls: 0.243 # 分类损失的系数</li><li>cls_pw: 0.631 #分类BCELoss中正样本的权重</li><li>obj: 0.301 # 有无物体损失的系数</li><li>obj_pw: 0.911 # 有无物体BCELoss中正样本的权重</li><li>iou_t: 0.2 # 标签与anchors的iou阈值iou training threshold</li></ul>\n<p>并且增大epoch到1000，batch-size增大到64，重新使用train.py训练，训练时间也增加了不少（这次用了12小时）</p>\n<pre><code class=\"prism language-python\">python train<span class=\"token punctuation\">.</span>py <span class=\"token operator\">-</span><span class=\"token operator\">-</span>cfg models<span class=\"token operator\">/</span>yolov5m_tstat<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">-</span><span class=\"token operator\">-</span>data data<span class=\"token operator\">/</span>Tstat<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">-</span><span class=\"token operator\">-</span>weights yolov5m<span class=\"token punctuation\">.</span>pt <span class=\"token operator\">-</span><span class=\"token operator\">-</span>epoch <span class=\"token number\">1000</span> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>batch<span class=\"token operator\">-</span>size <span class=\"token number\">64</span>\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210705202533345.png\"/></p>\n<blockquote>\n<p>当然还要考虑一点，针对视频图像识别中，移动的物体识别率本身就比静止图像差，同时运动检测越剧烈，偏差越大。。。</p>\n</blockquote>\n<p>例如把设备放到桌面上 这样的识别率及置信度都会更稳定一些：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210705204540376.png\"/></p>\n<blockquote>\n<p>同时还要考虑到，我在这里的测试过程，是手工拍照的数据量比较小，也可能会导致模型欠拟合，造成模型识别效果不良。</p>\n</blockquote>\n<p>实际图像数据量，每个类别最好大于1500张，并且做一些图像增强、变换等数据预处理技术。 增加模型的鲁棒性，防止过拟合。</p>\n<p>针对模型调优的技巧，可参考官网的Tips：<a href=\"https://docs.ultralytics.com/tutorials/training-tips-best-results/\">https://docs.ultralytics.com/tutorials/training-tips-best-results/</a></p>\n<blockquote>\n<p>在进行模型测试时，无论是加载模型的速度还是对测试图片的推理速度，都能明显感觉到Yolov5速度更快，尤其是加载模型的速度，因为同样的数据集训练出来的模型Yolov5更加轻量级，模型大小减小为Yolov3的将近四分之一。</p>\n</blockquote>\n<hr/>\n<p>至此Yolov5自定义数据训练及测试 /模型调优 都已完成。。。</p>\n<p>附Yolov5的网络模型结构图（图片来自知乎江大白​）<br/> <img alt=\"在这里插入图片描述\" src=\"image\\2021071719203413.png\"/></p>\n<p>下面将继续开始对Yolov5的源码和骨干网络进行深入探讨。。。</p>\n<hr/>\n<h1><a id=\"_323\"></a>博主热门文章推荐：</h1>\n<p><strong>一篇读懂系列：</strong></p>\n<ul><li><a href=\"https://howiexue.blog.csdn.net/article/details/77799262\">一篇读懂无线充电技术（附方案选型及原理分析）</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/79145048\">一篇读懂：Android/iOS手机如何通过音频接口（耳机孔）与外设通信</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/79167618\">一篇读懂：Android手机如何通过USB接口与外设通信（附原理分析及方案选型）</a></li></ul>\n<p><strong>LoRa Mesh系列：</strong></p>\n<ul><li><a href=\"https://blog.csdn.net/HowieXue/article/details/78028881\">LoRa学习：LoRa关键参数（扩频因子，编码率，带宽）的设定及解释</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/78052608\">LoRa学习：信道占用检测原理（CAD）</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/79199712\">LoRa/FSK 无线频谱波形分析（频谱分析仪测试LoRa/FSK带宽、功率、频率误差等）</a></li></ul>\n<p><strong>网络安全系列：</strong></p>\n<ul><li><a href=\"https://blog.csdn.net/HowieXue/article/details/75193922\">ATECC508A芯片开发笔记（一）：初识加密芯片</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/78700694\">SHA/HMAC/AES-CBC/CTR 算法执行效率及RAM消耗 测试结果</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/79283008\">常见加密/签名/哈希算法性能比较 (多平台 AES/DES, DH, ECDSA, RSA等)</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/76549487\">AES加解密效率测试（纯软件AES128/256）–以嵌入式Cortex-M0与M3 平台为例</a></li></ul>\n<p><strong>嵌入式开发系列：</strong></p>\n<ul><li><a href=\"https://blog.csdn.net/HowieXue/article/details/76696316\">嵌入式学习中较好的练手项目和课题整理（附代码资料、学习视频和嵌入式学习规划）</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/80381023\">IAR调试使用技巧汇总：数据断点、CallStack、设置堆栈、查看栈使用和栈深度、Memory、Set Next Statement等</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/76696631\">Linux内核编译配置（Menuconfig）、制作文件系统 详细步骤</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/76714314\">Android底层调用C代码（JNI实现）</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/78181871\">树莓派到手第一步：上电启动、安装中文字体、虚拟键盘、开启SSH等</a></li><li><a href=\"https://blog.csdn.net/HowieXue/article/details/75937972\">Android/Linux设备有线&amp;无线 双网共存（同时上内、外网）</a></li></ul>\n<p><strong>AI / 机器学习系列：</strong></p>\n<ul><li><a href=\"https://howiexue.blog.csdn.net/article/details/104269039\">AI: 机器学习必须懂的几个术语：Lable、Feature、Model…</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/104271227\">AI：卷积神经网络CNN 解决过拟合的方法 （Overcome Overfitting）</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/104270918\">AI: 什么是机器学习的数据清洗（Data Cleaning）</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/104270306\">AI: 机器学习的模型是如何训练的？（在试错中学习）</a></li><li><a href=\"https://howiexue.blog.csdn.net/article/details/105412155\">数据可视化：TensorboardX安装及使用（安装测试+实例演示）</a></li></ul>\n<hr/>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20190712110633686.png\"/></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>"}