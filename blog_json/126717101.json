{"blogid": "126717101", "writerAge": "码龄1年", "writerBlogNum": "426", "writerCollect": "292", "writerComment": "21", "writerFan": "10267", "writerGrade": "5级", "writerIntegral": "4393", "writerName": "饿饿好饿", "writerProfileAdress": "writer_image\\profile_126717101.jpg", "writerRankTotal": "4232", "writerRankWeekly": "649", "writerThumb": "58", "writerVisitNum": "177947", "blog_read_count": "43", "blog_time": "于 2022-09-06 08:25:52 发布", "blog_title": "elasticsearch集群搭建，以及kibana和ik分词器的安装（7.3.2）", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h2><a id=\"elasticsearch_2\"></a>elasticsearch的安装和集群的搭建</h2>\n<p><strong>1.下载elasticsearch压缩包文件，历史版本下载 ：</strong><br/> https://www.elastic.co/cn/downloads/past-releases/</p>\n<p><strong>2. 将压缩包上传至linux，解压到指定目录:</strong><br/> 创建文件夹 mkdir elasticsearch<br/> tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz -C /home/centos/elasticsearch</p>\n<p><strong>3. 查看配置文件:</strong>（虚拟机内存按需分配）<br/> vi config/jvm.options<br/> <img alt=\"\" src=\"image\\733cb62c736c4d41a0a60b7abbef47f9.png\"/></p>\n<p>vi config/elasticsearch.yml elasticsearch的配置文件（单节点）</p>\n<pre><code>#集群名称\ncluster.name: sinochem-es\n#节点名称\nnode.name: es-0\n#是不是有资格主节点\n#node.master: true\n#是否存储数据\nnode.data: true\n#最大集群节点数\n#node.max_local_storage_nodes: 3\n#ip地址（外网可访问使用 0.0.0.0）\nnetwork.host: 0.0.0.0\n#端口\nhttp.port: 9200\n#内部节点之间沟通端口\n#transport.tcp.port: 9300\n#es7.x 之后新增的配置，节点发现\n#discovery.seed_hosts: [\"localhost:9300\", \"localhost:9301\", \"localhost:9302\"]\n#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举master\n#cluster.initial_master_nodes: [\"es-0\", \"es-1\", \"es-2\"]\n#数据和存储路径\npath.data: /home/centos/elasticsearch-master/data\npath.logs: /home/centos/elasticsearch-master/logs\n# 开启跨域\nhttp.cors.enabled: true\n\n# 所有人访问\nhttp.cors.allow-origin: \"*\"\n\n#用安全性\nxpack.security.enabled: false\n</code></pre>\n<p><strong>4. 启动单机版elasticsearch:</strong><br/> 1 首先需要创建es用户，root用户无法启动<br/> 2 创建es用户：useradd es<br/> 3 创建密码：passwd es<br/> 4 需要给elasticsearch赋予es用户的执行权限：<br/> chown -R es:es /home/centos/elasticsearch-master/<br/> 5 启动：<br/> 进入到elasticsearch的bin目录下，执行 ./elasticsearch<br/> <img alt=\"在这里插入图片描述\" src=\"image\\2fc649350e77425484446fcab7f4642f.png\"/><br/> 6 访问 http://ip:9200/<br/> <img alt=\"启动成功\" src=\"image\\7ea9f14632e045b79b47d5c055b9f588.png\"/><br/> 6 后台启动elasticsearch<br/> bin目录下 执行 ./elasticsearch -d<br/> 查看进程： ps aux|grep elasticsearch</p>\n<p><strong>3. elasticsearch集群的搭建和配置:</strong><br/> 1 将elasticsearch的安装包分别复制3份<br/> cp -R elasticsearch-master elasticsearch-node1<br/> <img alt=\"在这里插入图片描述\" src=\"image\\eac1fcc66f234c528dfde04b12a1340e.png\"/><br/> 2 分别修改3个节点的配置文件 vi config/elasticsearch.yml<br/> master节点（名字有误 意思是第一个节点 不能准确的说是master）</p>\n<pre><code>#集群名称\ncluster.name: xxx-es\n#节点名称\nnode.name: es-0\n#是不是有资格主节点\nnode.master: true\n#是否存储数据\nnode.data: true\n#最大集群节点数\nnode.max_local_storage_nodes: 3\n#ip地址\nnetwork.host: 0.0.0.0\n#端口\nhttp.port: 9200\n#内部节点之间沟通端口\ntransport.tcp.port: 9300\n#es7.x 之后新增的配置，节点发现\ndiscovery.seed_hosts: [\"localhost:9300\", \"localhost:9301\", \"localhost:9302\"]\n#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举master\ncluster.initial_master_nodes: [\"es-0\", \"es-1\", \"es-2\"]\n#数据和存储路径\npath.data: /home/centos/elasticsearch-master/data\npath.logs: /home/centos/elasticsearch-master/logs\n# 开启跨域\nhttp.cors.enabled: true\n\n# 所有人访问\nhttp.cors.allow-origin: \"*\"\n\n#用安全性\nxpack.security.enabled: false\n</code></pre>\n<p>node1节点（集群中的第二个节点）</p>\n<pre><code>#集群名称\ncluster.name: xxx-es\n#节点名称\nnode.name: es-1\n#是不是有资格主节点\nnode.master: true\n#是否存储数据\nnode.data: true\n#最大集群节点数\nnode.max_local_storage_nodes: 3\n#ip地址\nnetwork.host: 0.0.0.0\n#端口\nhttp.port: 9201\n#内部节点之间沟通端口\ntransport.tcp.port: 9301\n#es7.x 之后新增的配置，节点发现\ndiscovery.seed_hosts: [\"localhost:9300\", \"localhost:9301\", \"localhost:9302\"]\n#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举master\ncluster.initial_master_nodes: [\"es-0\", \"es-1\", \"es-2\"]\n#数据和存储路径\npath.data: /home/centos/elasticsearch-master/data\npath.logs: /home/centos/elasticsearch-master/logs\n# 开启跨域\nhttp.cors.enabled: true\n\n# 所有人访问\nhttp.cors.allow-origin: \"*\"\n\n#用安全性\nxpack.security.enabled: false\n</code></pre>\n<p>node-2节点（集群中的第三个节点）</p>\n<pre><code>#集群名称\ncluster.name: xxx-es\n#节点名称\nnode.name: es-2\n#是不是有资格主节点\nnode.master: true\n#是否存储数据\nnode.data: true\n#最大集群节点数\nnode.max_local_storage_nodes: 3\n#ip地址\nnetwork.host: 0.0.0.0\n#端口\nhttp.port: 9202\n#内部节点之间沟通端口\ntransport.tcp.port: 9302\n#es7.x 之后新增的配置，节点发现\ndiscovery.seed_hosts: [\"localhost:9300\", \"localhost:9301\", \"localhost:9302\"]\n#es7.x 之后新增的配置，初始化一个新的集群时需要此配置来选举master\ncluster.initial_master_nodes: [\"es-0\", \"es-1\", \"es-2\"]\n#数据和存储路径\npath.data: /home/centos/elasticsearch-master/data\npath.logs: /home/centos/elasticsearch-master/logs\n# 开启跨域\nhttp.cors.enabled: true\n\n# 所有人访问\nhttp.cors.allow-origin: \"*\"\n</code></pre>\n<p>注意：本集群为单机版的集群搭建，三个节点中的cluster.name必须保持一致，node.name保持不同</p>\n<p>3 分别启动三个 elasticsearch</p>\n<p>4 查看集群是否搭建成功<br/> 访问 http://ip:9201/_cat/healthv<br/> <img alt=\"在这里插入图片描述\" src=\"image\\70ffc0fe191d4aeeb2b81a706c4e3b90.png\"/><br/> 注：es节点启动过程中可能遇到的错误</p>\n<pre><code>Could not rename log file 'logs/gc.log' to 'logs/gc.log.09' (Permission denied).\nInvalid -Xlog option '-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m', see error log for details.\nError: Could not create the Java Virtual Machine.\n</code></pre>\n<p>解决：root下执行 chmod 777 -R logs 这里根据你所挂载的目录要放开相应的权限</p>\n<pre><code>Exception in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.AccessDeniedException: /data/elasticSearch/elasticsearch-8.0.1-node-2/config/elasticsearch.keystore\nLikely root cause: java.nio.file.AccessDeniedException: /data/elasticSearch/elasticsearch-8.0.1-node-2/config/elasticsearch.keystore\n</code></pre>\n<p>解决：<br/> cd /data/elasticSearch/elasticsearch-8.0.1-node-2/config<br/> chown -R es:es elasticsearch.keystore</p>\n<pre><code>ERROR: [1] bootstrap checks failed\n[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]\n</code></pre>\n<p>解决：<br/> vi /etc/sysctl.conf　　<br/> 添加 一行 vm.max_map_count=655360<br/> 加载参数 sysctl -p</p>\n<h2><a id=\"kibana_209\"></a>kibana的安装</h2>\n<p>Kibana是一个针对ElasticSearch的开源分析及可视化平台,用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana ,可以通过各种图表进行高级数据分析及展示。Kibana让海量数据更容易理解。它操作简单,基于浏览器的用户界面可以快速创建仪表板( dashboard )实时显示Elasticsearch查询动态。</p>\n<p><strong>1. Kibana的下载</strong>（版本必须与ElasticSearch一致）<br/> 历史版本下载：https://www.elastic.co/cn/downloads/past-releases/<br/> 将压缩包上传至linux</p>\n<p><strong>2. Kibana的安装</strong><br/> 1 mkdir kibana 创建一个文件夹<br/> 2 解压到文件夹<br/> tar -zxvf kibana-7.3.2-linux-x86_64.tar.gz -C /home/centos/kibana<br/> 2 修改kibana 的配置文件<br/> vi config/kibana.yml</p>\n<pre><code>server.host: \"0.0.0.0\"\n\nserver.port: 5601\n\nelasticsearch.hosts: [\"http://localhost:9200\",\"http://localhost:9201\",\"http://localhost:9202\"]\n#elasticsearch.hosts: [\"http://localhost:9200\",\"http://localhost:9201\"]\n#elasticsearch.username: \"es\"\n#elasticsearch.password: \"es\"\n#kibana.index: \".kibana\"\ni18n.locale: \"zh-CN\"\n</code></pre>\n<p><strong>3. Kibana的启动</strong><br/> 1 给kibana安装目录赋予用户权限，不能使用root用户启动<br/> chown -R es:es /home/centos/kibana/kibana-7.3.2-linux-x86_64<br/> 2 运行<br/> bin目录下运行 ./kibana<br/> <img alt=\"在这里插入图片描述\" src=\"image\\16becccd70e640b99fe813e14278d347.png\"/><br/> 后台运行 nohup ./kibana &amp;<br/> 查看进程： ps -ef | grep node<br/> 3 访问<br/> http://ip:5601/app/kibana<br/> <img alt=\"在这里插入图片描述\" src=\"image\\e499ee3ae5fb40dfbf7a2e05b2ac7354.png\"/><br/> 使用kibana访问节点信息<br/> GET _cat/healthv<br/> <img alt=\"在这里插入图片描述\" src=\"image\\f3a00987503b4d32a42b1d946d524aa6.png\"/></p>\n<h2><a id=\"ik_252\"></a>ik分词器的安装</h2>\n<p><strong>1. ik分词器（中文分词器）</strong><br/> 分词：即把一段中文或者别的划分成一个个的关键字，我们在搜索时候会把自己的信息进行分词，会把数据库中或者索引库中的数据进行分词，然后进行一一个匹配操作，默认的中文分词是将每个字看成一个词（不使用用IK分词器的情况下），比如“周同学还不发专辑”会被分为”周”，”同”，”学”，”还”，”不”，”发”，”专”，”辑” ，这显然是不符合要求的，所以我们需要安装中文分词器ik来解决这个问题</p>\n<p>IK提供了两个分词算法: ik_smart和ik_max_word ,其中ik_smart为最少切分, ik_max_word为最细粒度划分</p>\n<p><strong>1. ik分词器的下载与安装</strong></p>\n<p>1 下载的版本要与ElasticSearch版本对应<br/> 2 下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases<br/> 3 安装：<br/> 将压缩包上传至linux服务器<br/> 使用unzip解压，没有unzip命令使用 yum install -y unzip 安装<br/> 在elasticsearch的plugins目录下新建ik目录，mkdir ik<br/> 使用命令解压 unzip elasticsearch-analysis-ik-7.3.2.zip -d elasticsearch-master/plugins/ik/<br/> 4 使用es账户重启es ./elasticsearch -d<br/> 5 查看效果<br/> <img alt=\"在这里插入图片描述\" src=\"image\\674339e4946d440585dcd253eb9b555b.png\"/></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>"}