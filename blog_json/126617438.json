{"blogid": "126617438", "writerAge": "码龄1年", "writerBlogNum": "462", "writerCollect": "1164", "writerComment": "58", "writerFan": "17407", "writerGrade": "6级", "writerIntegral": "5151", "writerName": "万里长江雪", "writerProfileAdress": "writer_image\\profile_126617438.jpg", "writerRankTotal": "3161", "writerRankWeekly": "316", "writerThumb": "203", "writerVisitNum": "346337", "blog_read_count": "458", "blog_time": "于 2022-08-31 09:39:51 发布", "blog_title": "超全面试汇总——Hadoop（二）", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h3><a id=\"Hadoop_2\"></a>超全面试汇总——Hadoop（二）</h3>\n<ul><li>\n<ul><li><a href=\"#Hadoop_1\">谈谈什么是Hadoop?</a></li><li><a href=\"#MapReduce_9\">@@MapReduce分布式计算</a></li><li><a href=\"#shuffle_34\">@shuffle流程</a></li><li><a href=\"#shuffle_58\">shuffle阶段的数据压缩机制了解吗</a></li><li><a href=\"#MapReduceSQL_63\">MapReduce实现基本SQL操作的原理</a></li><li>\n<ul><li><a href=\"#1_Join_67\">1. Join的实现原理</a></li><li><a href=\"#2_Group_By_77\">2. Group By的实现原理</a></li><li><a href=\"#3_Distinct_87\">3. Distinct的实现原理</a></li></ul> </li><li><a href=\"#urlTop10_108\">一个文件有上亿url，内存很小，找Top10</a></li><li><a href=\"#SQLMapReduce_124\">@SQL转化为MapReduce的过程</a></li><li><a href=\"#_140\">什么是数据倾斜</a></li><li><a href=\"#_145\">数据倾斜的表现</a></li><li><a href=\"#_157\">@发生数据倾斜的原因</a></li><li><a href=\"#_173\">@如何解决数据倾斜</a></li><li>\n<ul><li><a href=\"#group_by_175\">@聚合类group by操作，发生数据倾斜</a></li><li><a href=\"#Reduce_join_Map_join_198\">@Reduce join 改为Map join</a></li><li><a href=\"#_205\">空值产生的数据倾斜</a></li><li><a href=\"#countdistinct_sum_group_by_220\">少用count(distinct) 采用sum() group by的方式来替换</a></li><li><a href=\"#_231\">特殊值分开处理法</a></li><li><a href=\"#_join__245\">大表 join 大表</a></li><li><a href=\"#_250\">不同数据类型关联产生数据倾斜</a></li><li><a href=\"#_union_all__job_263\">多表 union all 会优化成一个 job</a></li><li><a href=\"#inexists_301\">优化in/exists语句</a></li></ul> </li><li><a href=\"#_305\">排序选择</a></li></ul> </li></ul>\n<h2><a id=\"Hadoop_29\"></a>谈谈什么是Hadoop</h2>\n<ul><li>Hadoop是一个开源软件框架，用于存储大量数据，并发计算/查询节点的集群上的数据。</li><li>Hadoop包括以下内容： \n  <ul><li><strong>HDFS(Hadoop Distributed File System)</strong>：Hadoop分布式文件存储系统。</li><li><strong>MapReduce：分布式计算框架</strong>。它以分布式和并行的方式处理大量的数据。</li><li><strong>YARN(资源定位器)</strong>：用于管理和调度集群资源的框架。hadoop2.x提出的</li></ul> </li></ul>\n<h2><a id=\"MapReduce_38\"></a>@@MapReduce分布式计算</h2>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210607142926551.png\"/></p>\n<ul><li> <p>https://blog.csdn.net/lihuazaizheli/article/details/107674269</p> </li><li> <p>理解map reduce 编程思想(<strong>分而治之</strong>)</p>\n<ul><li>Tasks 分：把复杂的问题分解为若干\"简单的任务\"</li><li>Reduce Tasks <strong>合：reduce</strong></li></ul> </li><li> <p>大数据量下优势明显，<strong>读写HDFS次数多</strong></p> </li><li> <p><strong>mapreduce流程</strong></p>\n<ul><li>inputFile通过split<strong>被切割为多个split文件, 逻辑切片&lt;偏移-数据&gt;</strong>，通过Record<strong>按行读取内容给map</strong>（自己写的处理逻辑的方法），<strong>对其结果key进行分区</strong>（默认使用的hashPartitioner），<strong>分区的数量就是 Reducer 任务运行的数量</strong>，然后写入buffer，<strong>每个map task 都有一个内存缓冲区（环形缓冲区</strong>），每个分区中对其键值对进行sort <strong>，按照paritition和key排序，排序完后会创建一个溢出文件，然后把这部分数据溢出spill写到本地磁盘。通知master位置归并merge</strong>，当一个maptask处理数据很大时，对<strong>同一个map任务产生的多个spill文件进行归并生成最终的一个已分区且已排序的大文件</strong></li><li>Reduce 大致分为 <strong>copy、sort、reduce</strong> 三个阶段，：<strong>多个map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点上</strong>。由 Fetcher 线程去 copy 数据，在此过程中会启动两个 merge 线程，分别为 inMemoryMerger 和 onDiskMerger，分别<strong>将内存中的数据 merge 到磁盘和将磁盘中的数据进行 merge</strong></li></ul> </li><li> <p><strong>maptask</strong>:</p>\n<ul><li>读数据：读取源数据，获取进行<strong>逻辑切片&lt;偏移-数据&gt;</strong>，把每一行文本内容<strong>解析成键值对</strong> <strong>形成key-value数据；&lt;0,hello you&gt; &lt;10,hello me&gt;</strong></li><li>逻辑处理：调用map方法读取<strong>每行数据进行处理</strong>；<strong>&lt;hello,1&gt; &lt;you,1&gt; &lt;hello,1&gt; &lt;me,1&gt;</strong></li><li>分区：对<strong>数据进行分区(hash)，分区的数量就是 Reducer 任务运行的数量。默认只有一个Reducer 任务。分区号相同的数据会被分发给同一reducetask</strong>；</li><li>排序：<strong>对不同分区中的数据进行排序（按照k）、分组。</strong> <strong>排序默认按照字典序列，分组指的是相同key的value放到一个集合中</strong>。排序后：<strong>&lt;hello,1&gt; &lt;hello,1&gt; &lt;me,1&gt; &lt;you,1&gt;</strong> 分组后：<strong>&lt;hello,{1,1}&gt;&lt;me,{1}&gt;&lt;you,{1}&gt;</strong></li></ul> </li><li> <p><strong>reducetask:</strong></p>\n<ul><li><strong>shuffle</strong>：<strong>多个map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点上</strong>。</li><li>处理数据：对多个map的输出进行<strong>合并、排序,覆盖reduce函数</strong>，接收的是分组后的数据，实现自己的业务逻辑，<strong>&lt;hello,2&gt; &lt;me,1&gt; &lt;you,1&gt;</strong></li><li>对reduce输出的&lt;k,v&gt;写到HDFS中</li></ul> </li><li> <p><strong>map数由分片决定</strong>，若要增加map数，可增大<code>mapred.map.tasks</code>，若减少map数，可增大<code>mapred.min.split.size</code>。减少map个数，在map执行前合并小文件，可<code>set mapred.map.split.size</code></p> </li><li> <p><strong>reduce数量由分区数决定</strong>，结果文件的数量也由此决定，且记录默认按<strong>key升序排列</strong>。reduce数量可通过<code>mapred.reduce.tasks</code>设置。</p> </li></ul>\n<h2><a id=\"shuffle_71\"></a>@shuffle流程</h2>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\20210607143001820.png\"/></p>\n<ul><li>目的： \n  <ul><li>对Map机器上的数据进行<strong>重新分组</strong></li><li>让每个<strong>Reduce知道它需要的数据分别在每个Map机器的哪里。</strong></li></ul> </li><li>shuffle阶段分为四个步骤：依次为**：分区，排序，规约（combiner），分组**，其中前三个步骤在map阶段完成，最后一个步骤在reduce阶段完成</li><li>shuffle 是 Mapreduce 的核心，它分布在 <strong>Mapreduce 的 map 阶段和 reduce 阶段。一般把从 Map 产生输出开始到 Reduce 取得数据作为输入之前的过程称作 shuffle</strong>。</li><li>shuffle中排序的目的 \n  <ul><li>这样每个Reducer都可以得知自己要处理的数据是哪些，直接拉取和计算对应的数据，避免了大量无用数据的存储和计算</li></ul> </li><li>map端shuffle \n  <ul><li><strong>后台线程根据Reducer的个数将输出结果进行分区，每一个分区对应一个Reducer</strong>，能够把map任务处理的结果**发给指定reduce执行，负载均衡，**避免数据倾斜。</li><li><strong>写入环形内存缓冲区</strong>，频繁I/O操作会严重降低效率，每个map任务都会分配一个环形内存缓冲区，用于存储map任务输出的键值对，默认大小<strong>100MB</strong>，</li><li><strong>执行溢出写 排序-&gt;合并-&gt;生成溢出写文件</strong> 一旦缓存区内容达到阈值，默认80%<strong>，就锁定着80%的内存，Map task的输出结果还可以往剩下的20MB内存中写，互不影响。并在</strong>每个分区中对其键值对进行sort**，按照paritition和key排序，排序完后会创建一个溢出文件，然后把这部分数据溢出spill写到本地磁盘。如果客户端自定义了<strong>Combiner（相当于map阶段的reduce）</strong>，则会在分区排序后到溢写出前自动调用combiner，<strong>将相同的key的value相加，这样的好处就是减少溢写到磁盘的数据量。这个过程叫</strong>合并**）</li><li><strong>归并merge</strong>，当一个maptask处理数据很大时，对<strong>同一个map任务产生的多个spill文件进行归并生成最终的一个已分区且已排序的大文件</strong></li><li><strong>合并（Combine）和归并（Merge）的区别：</strong><br/> 两个键值对<code>&lt;“a”,1&gt;</code>和<code>&lt;“a”,1&gt;</code>，如果合并，会得到<code>&lt;“a”,2&gt;</code>，如果归并，会得到<code>&lt;“a”,&lt;1,1&gt;&gt;</code></li></ul> </li><li>reduce端shuffle \n  <ul><li><strong>复制copy</strong>，Reduce 任务通过HTTP向各个Map任务拖取它所需要的数据。在 ReduceTask 远程复制数据的同时，会在后台开<strong>启两个线程对内存到本地的数据文件进行合并操作</strong></li><li><strong>归并merge</strong>，Map的输出数据已经是有序的，Merge进行一次合并排序，<strong>所谓Reduce端的 sort过程就是这个合并的过程</strong>。一般Reduce是一边copy一边sort，即<strong>copy和sort两个阶段是重叠而不是完全分开的</strong>。</li></ul> </li><li>优化shuffle：<strong>增加combiner</strong>，压缩溢写的文件</li><li>原则上<strong>缓冲区越大，磁盘io的次数越少</strong>，执行速度就越快缓冲区的大小可以通过参数调整, <strong>mapreduce.task.io.sort.mb 默认100M</strong></li></ul>\n<h2><a id=\"shuffle_96\"></a>shuffle阶段的数据压缩机制了解吗</h2>\n<ul><li>在shuffle阶段，可以看到数据<strong>通过大量的拷贝，从map阶段输出的数据，都要通过网络拷贝，发送到reduce阶段</strong>，</li><li>hadoop当中支持的压缩算法：gzip、bzip2、LZO、LZ4、<strong>Snappy</strong>，这几种压缩算法综合压缩和解压缩的速率，谷歌的Snappy是最优的，一般都选择Snappy压缩。</li></ul>\n<h2><a id=\"MapReduceSQL_102\"></a>MapReduce实现基本SQL操作的原理</h2>\n<p><strong>由于Join/GroupBy/OrderBy均需要在Reduce阶段完成</strong></p>\n<h3><a id=\"1_Join_107\"></a>1. Join的实现原理</h3>\n<pre><code> select u.name, o.orderid from order o join user u on o.uid = u.uid;\n</code></pre>\n<ul><li><strong>sql语句中on后面的字段就是key，在map阶段的输出（value）中为不同表的数据打上tag标记</strong>，<strong>在reduce阶段根据tag判断数据来源</strong>。MapReduce的过程如下（这里只是说明最基本的Join的实现，还有其他的实现方式）</li><li><img alt=\"在这里插入图片描述\" src=\"image\\20210607143023402.png\"/></li></ul>\n<h3><a id=\"2_Group_By_115\"></a>2. Group By的实现原理</h3>\n<pre><code> select rank, isonline, count(*) from city group by rank, isonline;\n</code></pre>\n<ul><li><strong>sql中 group by后面的字段组合(rank 和isonline的组合)作为map的输出key值</strong>，利用MapReduce的排序，<strong>在reduce阶段保存LastKey区分不同的key</strong>。MapReduce的过程如下（当然这里只是说明Reduce端的非Hash聚合过程）</li><li><img alt=\"在这里插入图片描述\" src=\"image\\20210607143039161.png\"/></li></ul>\n<h3><a id=\"3_Distinct_123\"></a>3. Distinct的实现原理</h3>\n<pre><code> select dealid, count(distinct uid) num from order group by dealid;\n</code></pre>\n<ul><li> <p><strong>当只有一个distinct字段时</strong>，如果<strong>不考虑Map阶段的Hash GroupBy</strong>，只需要将<strong>GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重</strong></p> </li><li> <p><img alt=\"在这里插入图片描述\" src=\"image\\20210607143055772.png\"/></p> </li><li> <p>如果有多个distinct字段呢，如下面的SQL</p> <p>select dealid, count(distinct uid), count(distinct date) from order group by dealid;</p> </li><li> <p><strong>可以对所有的distinct字段编号</strong>，每行数据生成n行数据，<strong>那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重</strong>。这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是<strong>增加了shuffle的数据量</strong>。需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空</p> </li><li> <p><img alt=\"在这里插入图片描述\" src=\"image\\20210607143110513.png\"/></p> </li></ul>\n<h2><a id=\"urlTop10_143\"></a>一个文件有上亿url，内存很小，找Top10</h2>\n<ul><li> <p><strong>外排序采用分块的方法（分而治之），首先将数据分块，对块内数据按选择一种高效的内排序策略进行排序。然后采用归并排序的思想对于所有的块进行排序，得到所有数据的一个有序序列。</strong></p> </li><li> <p>把磁盘上的1TB数据分割为40块（chunks），每份25GB。（注意，要留一些系统空间！）</p> </li><li> <p>顺序将每份25GB数据读入内存，使用quick sort算法排序。</p> </li><li> <p>把排序好的数据（也是25GB）存放回磁盘。</p> </li><li> <p>循环40次，现在，所有的40个块都已经各自排序了。（剩下的工作就是如何把它们合并排序！）</p> </li><li> <p>从40个块中分别读取25G/40=0.625G入内存（40 input buffers）。</p> </li><li> <p>执行40路合并，并将合并结果临时存储于2GB 基于内存的输出缓冲区中。当缓冲区写满2GB时，写入硬盘上最终文件，并清空输出缓冲区；当40个输入缓冲区中任何一个处理完毕时，写入该缓冲区所对应的块中的下一个0.625GB，直到全部处理完成。</p> </li></ul>\n<h2><a id=\"SQLMapReduce_161\"></a>@SQL转化为MapReduce的过程</h2>\n<ol><li>Antlr定义<strong>SQL的语法规则</strong>，完成SQL<strong>词法，语法解析</strong>，将SQL转化为<strong>抽象语法树AST Tree</strong>\n<ul><li><strong>HiveLexerX，HiveParser</strong>分别是Antlr对语法文件Hive.g编译后自动生成的<strong>词法解析和语法解析类</strong></li></ul> </li><li>遍历AST Tree，<strong>抽象出查询的基本组成单元QueryBlock</strong>\n<ul><li><strong>QueryBlock是一条SQL最基本的组成单元</strong>，包括三个部分：<strong>输入源，计算过程，输出</strong>。简单来讲一个QueryBlock就是一个子查询</li></ul> </li><li>遍历QueryBlock，<strong>翻译为执行操作树OperatorTree</strong>\n<ul><li>Hive最终生成的MapReduce任务，<strong>Map阶段和Reduce阶段均由OperatorTree组成</strong>。逻辑操作符，就是在Map阶段或者Reduce阶段完成单一特定的操作。</li></ul> </li><li><strong>逻辑层优化器进行OperatorTree变换，减少mapreduce job，减少shuffle数据量</strong>\n<ul><li>谓词下推、合并线性的OperatorTree中partition/sort key相同的reduce （from (select key,value from src group bu key, value）s select s.key group by s.key;</li><li>Map端聚合</li></ul> </li><li>遍历OperatorTree，<strong>翻译为MapReduce任务</strong></li><li><strong>物理层优化器进行MapReduce任务的变换</strong>，生成最终的执行计划</li></ol>\n<p>https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html</p>\n<h2><a id=\"_178\"></a>什么是数据倾斜</h2>\n<ul><li>Hadoop能够进行对海量数据进行批处理的核心，在于它的<strong>分布式思想，也就是多台服务器（节点）组成集群，进行分布式的数据处理</strong>。</li><li>举例：如果有10亿数据，一台电脑可能要10小时，现在集群有10台，可能1小时就够了，但是有可能大量的数据集中到一台或几台上，要5小时，发生了数据倾斜</li></ul>\n<h2><a id=\"_184\"></a>数据倾斜的表现</h2>\n<ul><li>Mapreduce任务 \n  <ul><li>reduce阶段 卡在99.99%不动</li><li>各种container报错OOM</li><li>读写数据量很大，超过其他正常reduce</li></ul> </li><li>spark任务 \n  <ul><li>个别task执行很慢</li><li>单个执行特别久</li><li>shuffle出错</li><li>sparkstreaming做实时算法使，会有executor出现内存溢出，但是其他的使用率很低</li></ul> </li></ul>\n<h2><a id=\"_197\"></a>@发生数据倾斜的原因</h2>\n<ul><li>shuffle是<strong>按照key，来进行values的数据的输出、拉取和聚合的</strong>，一旦发生shuffle，<strong>所有相同key的值就会拉到一个或几个节点上，个别key对应的数据比较多，就容易发生单个节点处理数据量爆增的情况。</strong></li><li><strong>key分布不均匀</strong>\n<ul><li>存在大量相同值的数据</li><li>存在大量异常值或者空值</li></ul> </li><li><strong>业务数据本身的特性</strong>\n<ul><li>例如某个分公司或某个城市订单量<strong>大幅提升</strong>几十倍甚至几百倍，对该城市的订单统计聚合时，容易发生数据倾斜。</li></ul> </li><li><strong>某些SQL语句本身就有数据倾斜</strong>\n<ul><li>两个表中关联字段<strong>存在大量空值</strong>（去除或者加随机数），或是关联字段的数据不统一（方法：把数字类型转为字符串类型，统一大小写）</li><li>join 一个key集中的小表 （方法：reduce join 改成 map join）</li><li>group by维度过小 某值的数量过多 （方法：两阶段聚合，放粗粒度）</li><li>count distinct 某特殊值过多 （方法：用group by）</li></ul> </li><li>数据<strong>频率倾斜</strong>——某一个区域的<strong>数据量</strong>要远远大于其他区域。</li><li>数据<strong>大小倾斜</strong>——部分记录的<strong>大小</strong>远远大于平均值。</li></ul>\n<h2><a id=\"_214\"></a>@如何解决数据倾斜</h2>\n<h3><a id=\"group_by_217\"></a>@聚合类group by操作，发生数据倾斜</h3>\n<ul><li> <p>map段部分聚合</p>\n<ul><li>开启<strong>Map端聚合参数设置set hive.map.aggr=true</strong></li><li>在Map端<strong>进行聚合操作的条目数目set hive.grouby.mapaggr.checkinterval=100000</strong></li><li>有数据倾斜的时候<strong>进行负载均衡（默认是false）set hive.groupby.skewindata = true</strong></li></ul> </li><li> <p><strong>阶段拆分-两阶段聚合</strong> 需要聚合的key前加一个随机数的前后缀，这样就均匀了，之后再按照原始的key聚合一次</p> </li><li> <p>生成的查询计划<strong>有两 个 MapReduce 任务</strong>。在第一个 MapReduce 中，map 的输出结果集合会随机分布到 reduce 中， <strong>每个 reduce 做部分聚合操作，并输出结果</strong>。相同的 Group By Key 有可 能分发到不同的 reduce 中，从而达到<strong>负载均衡的目的</strong>；第二个 MapReduce 任务再根据预处 理的<strong>数据结果按照 Group By Key 分布到 reduce 中</strong>（这个过程可以保证相同的 Group By Key 分布到同一个 reduce 中），最后完成最终的聚合操作。</p> </li><li> <pre><code>  假设 key = 水果\n  select count(substr(a.key,1,2)) as key\n  from(\n  \tselect concat(key,'_',cast(round(10*rand())+1 as string)) tmp\n  \tfrom table\n  \tgroup by tmp\n  )a\n  group by key\n</code></pre> </li></ul>\n<h3><a id=\"Reduce_join_Map_join_239\"></a>@Reduce join 改为Map join</h3>\n<ul><li><strong>适用于小表和大表 join</strong>，将较小RDD中的数据直接<strong>通过collect算子拉取到Driver端的内存中来</strong>，然后对其创建一个Broadcast变量；接着对另外RDD执行<strong>map类算子，在算子函数内</strong>，从Broadcast变量中获取较小RDD 的全量数据，与当前RDD的每一条数据按照<strong>连接key进行比对</strong>，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</li><li>设置自动选择MapJoin set hive.auto.convert.join = true;默认为true</li><li>reduce join： 先将所有相同的key，对应的values，汇聚到一个task中，然后再进行join。</li><li>map reduce：<strong>broadcast出去那个小表的数据以后</strong>，就会在每个executor的block manager中都驻留一份+map算子来实现与join同样的效果。<strong>不会发生shuffe，从根本上杜绝了join操作可能导致的数据倾斜的问题</strong>；</li></ul>\n<h3><a id=\"_246\"></a>空值产生的数据倾斜</h3>\n<ul><li> <pre><code>  1.在查询的时候，过滤掉所有为NULL的数据，比如：\n  SELECT * FROM log a\n  JOIN bmw_users b ON a.user_id IS NOT NULL AND a.user_id = b.user_id\n  UNION ALL\n  SELECT *FROM log a WHERE a.user_id IS NULL;\n  \n  2.查询出空值并给其赋上随机数,避免了key值为空（数据倾斜中常用的一种技巧）\n  SELECT *FROM log a\n  LEFT JOIN bmw_users b ON \n  CASE WHEN a.user_id IS NULL THEN concat(‘dp_hive’, rand()) ELSE a.user_id END = b.user_id;\n</code></pre> </li></ul>\n<h3><a id=\"countdistinct_sum_group_by_261\"></a>少用count(distinct) 采用sum() group by的方式来替换</h3>\n<ul><li> <pre><code>  select count(distinct a) from test ;\n  select count x.a \n  from (select a from test group by a ) x \n  \n  select a, count(distinct b) as c from tbl group by a;\n  select a, count(*) as c from (select a, b from tbl group by a, b) group by a;\n</code></pre> </li></ul>\n<h3><a id=\"_272\"></a>特殊值分开处理法</h3>\n<ul><li> <p>当需要把用户表和日志表关联起来时，再日志表中有很多没注册的用户表，可以分开处理</p> </li><li> <pre><code>  select *from\n  (select * from logs where user_id = 0)a\n  join\n  (select * from users where user_id = 0)b\n  on a.user_id = b.user_id\n  union all\n  select * from logs a join users b on a.user_id &lt;&gt; 0 and a.user_id = b.user_id;\n</code></pre> </li></ul>\n<h3><a id=\"_join__286\"></a>大表 join 大表</h3>\n<ul><li>将有大表中倾斜Key对应的数据集单独抽取出来加上<strong>随机前缀</strong>，另外一个RDD每条数据分别与<strong>随机前缀结合形成新的RDD</strong>（<strong>笛卡尔积</strong>，相当于将其数据增到到原来的N倍，N即为随机前缀的总个数）<strong>然后将二者Join后去掉前缀</strong>。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集<strong>通过union合并</strong>，即可得到全部Join结果。</li><li><strong>RDD扩容</strong></li></ul>\n<h3><a id=\"_291\"></a>不同数据类型关联产生数据倾斜</h3>\n<ul><li> <p>一张表 s8_log，每个商品一条记录，要和商品表关联。**s8_log 中有字符串商品 id，也有数字的商品 id。**字符串商品 id 类型是 string 的，但商品中的数字 id 是 bigint 的。</p> </li><li> <p>问题的原因是把 <strong>s8_log 的商品 id 转成数字 id 做 Hash（数字的 Hash 值为其本身，相同的字符串的 Hash 也不同）<strong>来分配 Reducer，所以</strong>相同字符串 id 的 s8_log</strong>，都到一个 Reducer 上了。</p> </li><li> <pre><code>  -- 把数字类型转换成字符串类型\n  SELECT *\n  FROM s8_log a\n  LEFT JOIN r_auction_auctions b ON a.auction_id = CAST(b.auction_id AS string);\n</code></pre> </li></ul>\n<h3><a id=\"_union_all__job_304\"></a>多表 union all 会优化成一个 job</h3>\n<ul><li> <p>推广效果表要和商品表关联，效果表中的 auction id 列既有商品 id，也有数字 id，和商品表关联得到商品的信息。</p> <p>SELECT *<br/> FROM effect a<br/> JOIN (<br/> SELECT auction_id AS auction_id<br/> FROM auctions<br/> UNION ALL<br/> SELECT auction_string_id AS auction_id<br/> FROM auctions<br/> ) b<br/> ON a.auction_id = b.auction_id;</p> </li><li> <p>**结论：**这样子比分别过滤数字 id，字符串 id ，然后分别和商品表关联性能要好。这样写的好处：1个 MR 作业，商品表只读取一次，推广效果表只读取一次。把这个 sql 换成 MR 代码的话，map 的时候，把 a 表的记录打上标签 a ，商品表记录每读取一条，打上标签 t，变成两个&lt;key,value&gt; 对，&lt;t,数字id,value&gt;，&lt;t,字符串id,value&gt;。所以商品表的 HDFS（Hadoop Distributed File System） 读只会是一次。</p> </li><li> <p>问题：比如推广效果表要和商品表关联，效果表中的 auction_id 列既有 32 为字符串商 品 id，也有数字 id，和商品表关联得到商品的信息。 <strong>比分别过滤数字 id，字符串 id 然后分别和商品表关联性能要好。</strong></p> <p>SELECT * FROM effect a<br/> JOIN<br/> (SELECT auction_id AS auction_id FROM auctions<br/> UNION All<br/> SELECT auction_string_id AS auction_id FROM auctions) b<br/> ON a.auction_id=b.auction_id;</p> </li><li> <p>场景：有一张user表，为卖家每天收到表，user_id，ds（日期）为key，属性有主营类目，指标有交易金额，交易笔数。每天要取前10天的总收入，总笔数，和最近一天的主营类目。</p>\n<ul><li> <pre><code>  SELECT user_id, substr(MAX(CONCAT(ds, cat)), 9) AS main_cat, SUM(qty), SUM(amt) FROM users\n  WHERE ds BETWEEN 20120301 AND 20120329\n  GROUP BY user_id\n</code></pre> </li></ul> </li></ul>\n<h3><a id=\"inexists_341\"></a>优化in/exists语句</h3>\n<ul><li>hive1.2.1也支持in/exists操作，但还是推荐使用hive的一个高效替代方案：left semi join</li></ul>\n<h2><a id=\"_345\"></a>排序选择</h2>\n<ul><li> <p><strong>cluster by</strong>: 对同一字段分桶并排序，不能和sort by连用；</p> </li><li> <p><strong>distribute by + sort by</strong>: 分桶，保证同一字段值只存在一个结果文件当中，结合sort by 保证每个reduceTask结果有序；</p> </li><li> <p><strong>sort by</strong>: 单机排序，单个reduce结果有序</p> </li><li> <p><strong>order by</strong>：全局排序，缺陷是只能使用一个reduce</p> </li></ul>\n<blockquote>\n<p>今天也是爱zz的一天哦！</p>\n</blockquote>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>"}