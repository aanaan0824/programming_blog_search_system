{"blogid": "126420288", "writerAge": "码龄91天", "writerBlogNum": "723", "writerCollect": "884", "writerComment": "82", "writerFan": "982", "writerGrade": "6级", "writerIntegral": "7767", "writerName": "肥肥技术宅", "writerProfileAdress": "writer_image\\profile_126420288.jpg", "writerRankTotal": "2032", "writerRankWeekly": "367", "writerThumb": "151", "writerVisitNum": "117445", "blog_read_count": "1559", "blog_time": "于 2022-08-19 10:46:55 发布", "blog_title": "MySQL 与 Redis 缓存的同步方案", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h2>前言</h2>\n<p>本文介绍MySQL与Redis缓存的同步的两种方案</p>\n<ul><li> <p>方案1：通过MySQL自动同步刷新Redis，MySQL触发器+UDF函数实现</p> </li><li> <p>方案2：解析MySQL的binlog实现，将数据库中的数据同步到Redis</p> </li></ul>\n<h2>一、方案1（UDF）</h2>\n<ul><li> <p>场景分析：当我们对MySQL数据库进行数据操作时，同时将相应的数据同步到Redis中，同步到Redis之后，查询的操作就从Redis中查找</p> </li><li> <p>过程大致如下：</p>\n<ul><li> <p>在MySQL中对要操作的数据设置触发器Trigger，监听操作</p> </li><li> <p>客户端（NodeServer）向MySQL中写入数据时，触发器会被触发，触发之后调用MySQL的UDF函数</p> </li><li> <p>UDF函数可以把数据写入到Redis中，从而达到同步的效果</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\9becec008d94e5010ebba2630dfe49d9.png\"/></p>\n<ul><li> <p>方案分析：</p> <p>演示案例</p>\n<ul><li> <p>这种方案适合于读多写少，并且不存并发写的场景</p> </li><li> <p>因为MySQL触发器本身就会造成效率的降低，如果一个表经常被操作，这种方案显示是不合适的</p> </li></ul></li><li> <p>下面是MySQL的表</p> </li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\db3cfa1e5ddc6b30a7e5e56dbf9f88b0.png\"/></p>\n<ul><li> <p>下面是UDF的解析代码</p> </li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\0811773a0fdbd981ba53aeae3dc070e4.png\"/></p>\n<ul><li> <p>定义对应的触发器</p> </li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\57973834ffe799d6b69e20a9f8b8199e.png\"/></p>\n<h2>二、方案2（解析binlog）</h2>\n<ul><li> <p>在介绍方案2之前我们先来介绍一下MySQL复制的原理，如下图所示：</p>\n<ul><li> <p>主服务器操作数据，并将数据写入Bin log</p> </li><li> <p>从服务器调用I/O线程读取主服务器的Bin log，并且写入到自己的Relay log中，再调用SQL线程从Relay log中解析数据，从而同步到自己的数据库中</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\446bedbed015e139f6ca0705ef4ff6b6.png\"/></p>\n<ul><li> <p>方案2就是：</p>\n<ul><li> <p>上面MySQL的整个复制流程可以总结为一句话，那就是：从服务器读取主服务器Bin log中的数据，从而同步到自己的数据库中</p> </li><li> <p>我们方案2也是如此，就是在概念上把主服务器改为MySQL，把从服务器改为Redis而已（如下图所示），当MySQL中有数据写入时，我们就解析MySQL的Bin log，然后将解析出来的数据写入到Redis中，从而达到同步的效果</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\69a8b65c02ec335b7e95015c90fcf891.png\"/></p>\n<ul><li> <p>例如下面是一个云数据库实例分析：</p>\n<ul><li> <p>云数据库与本地数据库是主从关系。云数据库作为主数据库主要提供写，本地数据库作为从数据库从主数据库中读取数据</p> </li><li> <p>本地数据库读取到数据之后，解析Bin log，然后将数据写入写入同步到Redis中，然后客户端从Redis读数据</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\8585e1974fc257a4249643b4fdedac1e.png\"/></p>\n<p>这个技术方案的难点就在于：如何解析MySQL的Bin Log。但是这需要对binlog文件以及MySQL有非常深入的理解，同时由于binlog存在Statement/Row/Mixedlevel多种形式，分析binlog实现同步的工作量是非常大的</p>\n<h3>Canal开源技术</h3>\n<ul><li> <p>canal是阿里巴巴旗下的一款开源项目，纯Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了MySQL（也支持mariaDB）</p> </li><li> <p>开源参考地址有：https://github.com/liukelin/canal_mysql_nosql_sync</p> </li><li> <p>工作原理（模仿MySQL复制）：</p>\n<ul><li> <p>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</p> </li><li> <p>mysql master收到dump请求，开始推送binary log给slave（也就是canal）</p> </li><li> <p>canal解析binary log对象（原始为byte流）</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\e24d4fcdb2c18486c11fa7436d699440.png\"/></p>\n<ul><li> <p>架构：</p>\n<ul><li> <p>eventParser (数据源接入，模拟slave协议和master进行交互，协议解析)</p> </li><li> <p>eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作)</p> </li><li> <p>eventStore (数据存储)</p> </li><li> <p>metaManager (增量订阅&amp;消费信息管理器)</p> </li><li> <p>server代表一个canal运行实例，对应于一个jvm</p> </li><li> <p>instance对应于一个数据队列 （1个server对应1..n个instance)</p> </li><li> <p>instance模块：</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\51653c06cc1ff00a7084fe5da1c3d044.png\"/></p>\n<ul><li> <p>大致的解析过程如下：</p>\n<ul><li> <p>parse解析MySQL的Bin log，然后将数据放入到sink中</p> </li><li> <p>sink对数据进行过滤，加工，分发</p> </li><li> <p>store从sink中读取解析好的数据存储起来</p> </li><li> <p>然后自己用设计代码将store中的数据同步写入Redis中就可以了</p> </li><li> <p>其中parse/sink是框架封装好的，我们做的是store的数据读取那一步</p> </li></ul></li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\bd78e462f6d2ff8f4002c37fe0aaebff.png\"/></p>\n<ul><li> <p>更多关于Cancl可以百度搜索</p> </li><li> <p>下面是运行拓扑图</p> </li></ul>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\b33e556fef1f1d3107da5fe7da131e99.png\"/></p>\n<p>MySQL表的同步，采用责任链模式，每张表对应一个Filter。例如zvsync中要用到的类设计如下：</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\41b2ada34dabec7a2d1379eb3c3d81e7.png\"/></p>\n<ul><li> <p>下面是具体化的zvsync中要用到的类， 每当新增或者删除表时，直接进行增删就可以了</p> <p class=\"img-center\"><img alt=\"\" src=\"image\\6ec0ab2d3e1786edb38506d8e5b4ab01.png\"/></p> </li></ul>\n<h2>三、附加</h2>\n<p>本文上面所介绍的都是从MySQL中同步到缓存中。但是在实际开发中可能有人会用下面的方案：客户端有数据来了之后，先将其保存到Redis中，然后再同步到MySQL中 这种方案本身也是不安全/不可靠的，因此如果Redis存在短暂的宕机或失效，那么会丢失数据</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\036aba33e630cacaab4c3063a781d4b7.png\"/></p>\n</div>\n</div>"}