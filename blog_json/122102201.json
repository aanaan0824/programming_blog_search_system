{"blogid": "122102201", "writerAge": "码龄4年", "writerBlogNum": "30", "writerCollect": "297", "writerComment": "61", "writerFan": "56", "writerGrade": "3级", "writerIntegral": "411", "writerName": "吴大炮", "writerProfileAdress": "writer_image\\profile_122102201.jpg", "writerRankTotal": "44920", "writerRankWeekly": "116009", "writerThumb": "48", "writerVisitNum": "32486", "blog_read_count": "7227", "blog_time": "已于 2022-06-17 18:39:10 修改", "blog_title": "注意力机制（SE、Coordinate Attention、CBAM、ECA，SimAM）、即插即用的模块整理", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p>总结曾经使用过的一些即插即用的模块以及一些注意力机制<br/> **</p>\n<h2><a id=\"SE_3\"></a>注意力模块：SE</h2>\n<p>**<br/> 代码源自这位大佬的仓库：<a href=\"https://github.com/moskomule/senet.pytorch\">https://github.com/moskomule/senet.pytorch</a></p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">SELayer</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> channel<span class=\"token punctuation\">,</span> reduction<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>SELayer<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>avg_pool <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>channel<span class=\"token punctuation\">,</span> channel <span class=\"token operator\">//</span> reduction<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>channel <span class=\"token operator\">//</span> reduction<span class=\"token punctuation\">,</span> channel<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Sigmoid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        b<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>avg_pool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> y<span class=\"token punctuation\">.</span>expand_as<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n</code></pre>\n<p>SE模块理解起来比较简单，总体的思想是<strong>给每个特征图不同的权重</strong>，关注更有用的特征<br/> <img alt=\"在这里插入图片描述\" src=\"image\\2fa44d6a35d04b9684ca36c0a8b65d08.png\"/></p>\n<p>具体做法<br/> 先对输入的特征图进行全局池化，将特征图变成1×1×通道数，然后全连接层和激活函数，对1×1×通道数的特征图进行调整，变成每一个特征图的权重，然后与输入的特征进行相乘。<br/> 缺点：没有考虑空间位置</p>\n<p>SE模块的插入位置<br/> 通过Resnet的基础模块和bottleneck模块 可以看出SE模块插入到，跳连结构add之前，对前面特征提取之后的特征图给与不同的权重，再与shortcut跳连分支相加</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">SEBasicBlock</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    expansion <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inplanes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> downsample<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                 base_width<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> dilation<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> norm_layer<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n                 <span class=\"token operator\">*</span><span class=\"token punctuation\">,</span> reduction<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>SEBasicBlock<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> conv3x3<span class=\"token punctuation\">(</span>inplanes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> conv3x3<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>se <span class=\"token operator\">=</span> SELayer<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">,</span> reduction<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>downsample <span class=\"token operator\">=</span> downsample\n        self<span class=\"token punctuation\">.</span>stride <span class=\"token operator\">=</span> stride\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        residual <span class=\"token operator\">=</span> x\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn1<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>se<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>downsample <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            residual <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>downsample<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">+=</span> residual\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> out\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">SEBottleneck</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    expansion <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inplanes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> downsample<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                 base_width<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> dilation<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> norm_layer<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>\n                 <span class=\"token operator\">*</span><span class=\"token punctuation\">,</span> reduction<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>SEBottleneck<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>inplanes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">,</span> planes<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span>\n                               padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>planes<span class=\"token punctuation\">,</span> planes <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>planes <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>se <span class=\"token operator\">=</span> SELayer<span class=\"token punctuation\">(</span>planes <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> reduction<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>downsample <span class=\"token operator\">=</span> downsample\n        self<span class=\"token punctuation\">.</span>stride <span class=\"token operator\">=</span> stride\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        residual <span class=\"token operator\">=</span> x\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn1<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>se<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>downsample <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            residual <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>downsample<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">+=</span> residual\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> out\n</code></pre>\n<h2><a id=\"CBAM_117\"></a>CBAM</h2>\n<p>CBAM是解决se只考虑通道而忽略空间信息的弊端，提出的结构，通过下面的图很清晰的给出了该注意力模块的结构，先是类型与se的结构，产生不同的通道权重，也就是不同通道的重要程度。<br/> 然后将所有的特征图压缩到一个特征图，求空间特征的权重，很容易理解<br/> <img alt=\"在这里插入图片描述\" src=\"image\\34c2738eb2ee4e45a181d40d766dfd59.png\"/><br/> <img alt=\"在这里插入图片描述\" src=\"image\\2272ca7990ee4ee893b348a6d09d799a.png\"/></p>\n<p>代码来自:<a href=\"https://github.com/Jongchan/attention-module\">https://github.com/Jongchan/attention-module</a></p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> math\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n<span class=\"token comment\">#基础的卷积模块 由卷积层+BN+激活函数</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">BasicConv</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_planes<span class=\"token punctuation\">,</span> out_planes<span class=\"token punctuation\">,</span> kernel_size<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> dilation<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> relu<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> bn<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>BasicConv<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>out_channels <span class=\"token operator\">=</span> out_planes\n        self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_planes<span class=\"token punctuation\">,</span> out_planes<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>kernel_size<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span>padding<span class=\"token punctuation\">,</span> dilation<span class=\"token operator\">=</span>dilation<span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span>groups<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span>bias<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_planes<span class=\"token punctuation\">,</span>eps<span class=\"token operator\">=</span><span class=\"token number\">1e-5</span><span class=\"token punctuation\">,</span> momentum<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> affine<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> bn <span class=\"token keyword\">else</span> <span class=\"token boolean\">None</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> relu <span class=\"token keyword\">else</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>bn <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>relu <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n<span class=\"token comment\">#展平层</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Flatten</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#通道注意</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ChannelGate</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> gate_channels<span class=\"token punctuation\">,</span> reduction_ratio<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> pool_types<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'avg'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>ChannelGate<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>gate_channels <span class=\"token operator\">=</span> gate_channels\n        self<span class=\"token punctuation\">.</span>mlp <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>gate_channels<span class=\"token punctuation\">,</span> gate_channels <span class=\"token operator\">//</span> reduction_ratio<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>gate_channels <span class=\"token operator\">//</span> reduction_ratio<span class=\"token punctuation\">,</span> gate_channels<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>pool_types <span class=\"token operator\">=</span> pool_types\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        channel_att_sum <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        <span class=\"token keyword\">for</span> pool_type <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>pool_types<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> pool_type<span class=\"token operator\">==</span><span class=\"token string\">'avg'</span><span class=\"token punctuation\">:</span>\n                avg_pool <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>avg_pool2d<span class=\"token punctuation\">(</span> x<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                channel_att_raw <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>mlp<span class=\"token punctuation\">(</span> avg_pool <span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">elif</span> pool_type<span class=\"token operator\">==</span><span class=\"token string\">'max'</span><span class=\"token punctuation\">:</span>\n                max_pool <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>max_pool2d<span class=\"token punctuation\">(</span> x<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                channel_att_raw <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>mlp<span class=\"token punctuation\">(</span> max_pool <span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">elif</span> pool_type<span class=\"token operator\">==</span><span class=\"token string\">'lp'</span><span class=\"token punctuation\">:</span>\n                lp_pool <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>lp_pool2d<span class=\"token punctuation\">(</span> x<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                channel_att_raw <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>mlp<span class=\"token punctuation\">(</span> lp_pool <span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">elif</span> pool_type<span class=\"token operator\">==</span><span class=\"token string\">'lse'</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\"># LSE pool only</span>\n                lse_pool <span class=\"token operator\">=</span> logsumexp_2d<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n                channel_att_raw <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>mlp<span class=\"token punctuation\">(</span> lse_pool <span class=\"token punctuation\">)</span>\n\n            <span class=\"token keyword\">if</span> channel_att_sum <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n                channel_att_sum <span class=\"token operator\">=</span> channel_att_raw\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                channel_att_sum <span class=\"token operator\">=</span> channel_att_sum <span class=\"token operator\">+</span> channel_att_raw\n\n        scale <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span> channel_att_sum <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>expand_as<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> scale\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">logsumexp_2d</span><span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    tensor_flatten <span class=\"token operator\">=</span> tensor<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    s<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>tensor_flatten<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    outputs <span class=\"token operator\">=</span> s <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>tensor_flatten <span class=\"token operator\">-</span> s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> outputs\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ChannelPool</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span> <span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#空间注意力部分</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">SpatialGate</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>SpatialGate<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        kernel_size <span class=\"token operator\">=</span> <span class=\"token number\">7</span>\n        self<span class=\"token punctuation\">.</span>compress <span class=\"token operator\">=</span> ChannelPool<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>spatial <span class=\"token operator\">=</span> BasicConv<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> relu<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_compress <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>compress<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x_out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>spatial<span class=\"token punctuation\">(</span>x_compress<span class=\"token punctuation\">)</span>\n        scale <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>x_out<span class=\"token punctuation\">)</span> <span class=\"token comment\"># broadcasting</span>\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> scale\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CBAM</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> gate_channels<span class=\"token punctuation\">,</span> reduction_ratio<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> pool_types<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'avg'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'max'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> no_spatial<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>CBAM<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>ChannelGate <span class=\"token operator\">=</span> ChannelGate<span class=\"token punctuation\">(</span>gate_channels<span class=\"token punctuation\">,</span> reduction_ratio<span class=\"token punctuation\">,</span> pool_types<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>no_spatial<span class=\"token operator\">=</span>no_spatial\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> no_spatial<span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>SpatialGate <span class=\"token operator\">=</span> SpatialGate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>ChannelGate<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>no_spatial<span class=\"token punctuation\">:</span>\n            x_out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>SpatialGate<span class=\"token punctuation\">(</span>x_out<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x_out\n</code></pre>\n<p>放在模型中的位置<br/> <img alt=\"在这里插入图片描述\" src=\"image\\c03140899eb54767bb2280596f9d2fd2.png\"/></p>\n<h2><a id=\"Coordinate_Attention_227\"></a>Coordinate Attention</h2>\n<p>发表在CVPR2021<br/> 结合下面结构图，Coordinate Attention整体思路是，对于输入的特征分别按照h方向和w方向进行池化，也就是变成c×1×w，c×h×1，<br/> 然后将池化后的特征进行concat拼接，注意不是直接拼接，先将维度调整一样。因为维度不一样，直接拼接会有广播机制，<br/> 合并后进行1×1的卷积等一系列操作，此时卷积通道数变为原来的1/r，<br/> 然后再分开，分别在不同的方向上进行sigmoid得到系数，然后相乘。</p>\n<p>😂整个结构就是这样，确实很玄学，但是有效，而且故事讲得好.<br/> <img alt=\"在这里插入图片描述\" src=\"image\\d181bed69bad4bb7b1111dfdf1429e42.png\"/><br/> 该模块整体思路如图所示</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> math\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">h_sigmoid</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>h_sigmoid<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU6<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span>inplace<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>x <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">6</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">h_swish</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>h_swish<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>sigmoid <span class=\"token operator\">=</span> h_sigmoid<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span>inplace<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CoordAtt</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inp<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> reduction<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>CoordAtt<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>pool_h <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>pool_w <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        mip <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> inp <span class=\"token operator\">//</span> reduction<span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>inp<span class=\"token punctuation\">,</span> mip<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>bn1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>mip<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>act <span class=\"token operator\">=</span> h_swish<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>conv_h <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>mip<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_w <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>mip<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        identity <span class=\"token operator\">=</span> x\n        \n        n<span class=\"token punctuation\">,</span>c<span class=\"token punctuation\">,</span>h<span class=\"token punctuation\">,</span>w <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        x_h <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>pool_h<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x_w <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>pool_w<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n        y <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x_h<span class=\"token punctuation\">,</span> x_w<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>bn1<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>act<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> \n        \n        x_h<span class=\"token punctuation\">,</span> x_w <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>h<span class=\"token punctuation\">,</span> w<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        x_w <span class=\"token operator\">=</span> x_w<span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n        a_h <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_h<span class=\"token punctuation\">(</span>x_h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        a_w <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_w<span class=\"token punctuation\">(</span>x_w<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> identity <span class=\"token operator\">*</span> a_w <span class=\"token operator\">*</span> a_h\n\n        <span class=\"token keyword\">return</span> out\n</code></pre>\n<p>接下来看一下具体的如何使用：直接加入到残差块里面</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">InvertedResidual</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> inp<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">,</span> expand_ratio<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>InvertedResidual<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">assert</span> stride <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\n\n        hidden_dim <span class=\"token operator\">=</span> <span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>inp <span class=\"token operator\">*</span> expand_ratio<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>identity <span class=\"token operator\">=</span> stride <span class=\"token operator\">==</span> <span class=\"token number\">1</span> <span class=\"token keyword\">and</span> inp <span class=\"token operator\">==</span> oup\n\n        <span class=\"token keyword\">if</span> expand_ratio <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n                <span class=\"token comment\"># dw</span>\n                nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">,</span> hidden_dim<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span>hidden_dim<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>ReLU6<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token comment\"># pw-linear</span>\n                nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>oup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n                <span class=\"token comment\"># pw</span>\n                nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>inp<span class=\"token punctuation\">,</span> hidden_dim<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>ReLU6<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token comment\"># dw</span>\n                nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">,</span> hidden_dim<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> groups<span class=\"token operator\">=</span>hidden_dim<span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>ReLU6<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token comment\"># coordinate attention</span>\n                CoordAtt<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">,</span> hidden_dim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token comment\"># pw-linear</span>\n                nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>hidden_dim<span class=\"token punctuation\">,</span> oup<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>oup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>identity<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> x <span class=\"token operator\">+</span> y\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> y\n</code></pre>\n<h2><a id=\"ECA_350\"></a>ECA</h2>\n<p>代码来自仓库：https://github.com/BangguWu/ECANet<a href=\"https://github.com/BangguWu/ECANet\">添加链接描述</a></p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\e6b364fac8cc464e8113d2edb179650f.png\"/></p>\n<p>基本思想：se模块是给每一个通道一个权重，也就是根据当前通道的特征，给出一个权值，而se中全连接层的通道却由大变小再变大，特征通道变小之后，原来通道数发生边，不再具有每个通道原有的特征。因此提出eca（不知道理解的对不对！）<br/> 首先将输入的特征通过全局平均池化，然后利用1d卷积进行特征提取，实现跨通道的交互。</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">from</span> torch <span class=\"token keyword\">import</span> nn\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>parameter <span class=\"token keyword\">import</span> Parameter\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">eca_layer</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Constructs a ECA module.\n    Args:\n        channel: Number of channels of the input feature map\n        k_size: Adaptive selection of kernel size\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> channel<span class=\"token punctuation\">,</span> k_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>eca_layer<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>avg_pool <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv1d<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span>k_size<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>k_size <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span> \n        self<span class=\"token punctuation\">.</span>sigmoid <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sigmoid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># feature descriptor on the global spatial information</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>avg_pool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Two different branches of ECA module</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Multi-scale information fusion</span>\n        y <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> y<span class=\"token punctuation\">.</span>expand_as<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n</code></pre>\n<p>SimAM<br/> 参考链接：<a href=\"https://zhuanlan.zhihu.com/p/394346975\">https://zhuanlan.zhihu.com/p/394346975</a><br/> GitHub：<a href=\"https://github.com/ZjjConan/SimAM/blob/master/networks/attentions/simam_module.py\">here</a><br/> 为了使网络学习更有区分性的神经元，作者建议直接从当前的神经元中推断出三维权重（即考虑空间和通道维度），然后反过来细化这些神经元。为了有效地推断出这种三维权值，作者定义了一个由神经科学知识指导的能量函数，并推导出一个封闭形式的解。基于此提出了一种简单有效的注意力模块SimAM，不同于现有的通道或者空域注意力模块，该模块不需要额外的参数便可以推导出3D注意力权值。</p>\n<p>说实话没看懂，总论文对公式进行了推导，推导出一个公式可以求出注意力。<br/> 虽然不太懂但是不妨碍使用它，把它放到了bottleneck里面，如下图所示， YOLOv5确实涨点了<br/> <img alt=\"在这里插入图片描述\" src=\"image\\9cf7b183a46a435d9d0a2e883125cb95.png\"/><br/> 下面是代码，不过感觉论文里的伪代码更清晰一些<br/> <img alt=\"在这里插入图片描述\" src=\"image\\cce2633f1b76408492f773bfb60437bf.png\"/></p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">simam_module</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> channels <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> e_lambda <span class=\"token operator\">=</span> <span class=\"token number\">1e-4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>simam_module<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>activaton <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sigmoid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>e_lambda <span class=\"token operator\">=</span> e_lambda\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__repr__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        s <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>__class__<span class=\"token punctuation\">.</span>__name__ <span class=\"token operator\">+</span> <span class=\"token string\">'('</span>\n        s <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'lambda=%f)'</span> <span class=\"token operator\">%</span> self<span class=\"token punctuation\">.</span>e_lambda<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> s\n\n    <span class=\"token decorator annotation punctuation\">@staticmethod</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get_module_name</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"simam\"</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        b<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">,</span> h<span class=\"token punctuation\">,</span> w <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        n <span class=\"token operator\">=</span> w <span class=\"token operator\">*</span> h <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n\n        x_minus_mu_square <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>x <span class=\"token operator\">-</span> x<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">pow</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> x_minus_mu_square <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>x_minus_mu_square<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> n <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>e_lambda<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">0.5</span>\n\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>activaton<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>将这个模块加到bottleneck里面， 这里以我之前改的YOLOv5为例的，可以参考一下</p>\n<pre><code class=\"prism language-python\"><span class=\"token comment\">#将SimAM注意力机制加在bottleneck里面</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Bottleneck_SimAM</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Standard bottleneck</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> c1<span class=\"token punctuation\">,</span> c2<span class=\"token punctuation\">,</span> shortcut<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> g<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> e<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># ch_in, ch_out, shortcut, groups, expansion</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Bottleneck_SimAM<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        c_ <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>c2 <span class=\"token operator\">*</span> e<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># hidden channels</span>\n        self<span class=\"token punctuation\">.</span>cv1 <span class=\"token operator\">=</span> Conv<span class=\"token punctuation\">(</span>c1<span class=\"token punctuation\">,</span> c_<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>cv2 <span class=\"token operator\">=</span> Conv<span class=\"token punctuation\">(</span>c_<span class=\"token punctuation\">,</span> c2<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> g<span class=\"token operator\">=</span>g<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>add <span class=\"token operator\">=</span> shortcut <span class=\"token keyword\">and</span> c1 <span class=\"token operator\">==</span> c2\n        self<span class=\"token punctuation\">.</span>attention <span class=\"token operator\">=</span> SimAM_module<span class=\"token punctuation\">(</span>channels<span class=\"token operator\">=</span>c2<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> x <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>attention<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>cv2<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>cv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>add <span class=\"token keyword\">else</span> self<span class=\"token punctuation\">.</span>cv2<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>cv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n</code></pre>\n<h2><a id=\"RFB_452\"></a>RFB（感受野模块）</h2>\n<p>参考博客：<a href=\"https://blog.csdn.net/qq_52302919/article/details/122425956\">RFB（Receptive Field Block）</a><br/> GitHub：<a href=\"https://github.com/GOATmessi7/RFBNet\">here</a><br/> 出发点是模拟人类视觉的感受野从而加强网络的特征提取能力，在结构上RFB借鉴了Inception的思想，主要是在Inception的基础上加入了空洞卷积，从而有效增大了感受野</p>\n<p>RFB的效果示意图如所示，其中中间虚线框部分就是RFB结构。RFB结构主要有两个特点：<br/> 1、不同尺寸卷积核的卷积层构成的多分枝结构，这部分可以参考Inception结构。在Figure2的RFB结构中也用不同大小的圆形表示不同尺寸卷积核的卷积层。<br/> 2、引入了dilated卷积层，dilated卷积层之前应用在分割算法Deeplab中，主要作用也是增加感受野，和deformable卷积有异曲同工之处。</p>\n<p>在RFB结构中用不同rate表示dilated卷积层的参数。结构中最后会将不同尺寸和rate的卷积层输出进行concat，达到融合不同特征的目的。结构中用3种不同大小和颜色的输出叠加来展示。<br/> <img alt=\"在这里插入图片描述\" src=\"image\\37eb54bbf10b4807b68b34ca43cc2d7e.png\"/></p>\n<p>后续有时间慢慢补充</p>\n<h2><a id=\"BAM_466\"></a>BAM</h2>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>"}