{"blogid": "126174080", "writerAge": "码龄1年", "writerBlogNum": "117", "writerCollect": "785", "writerComment": "17", "writerFan": "672", "writerGrade": "5级", "writerIntegral": "1971", "writerName": "爱摸鱼的菜鸟码农.", "writerProfileAdress": "writer_image\\profile_126174080.jpg", "writerRankTotal": "11332", "writerRankWeekly": "14767", "writerThumb": "246", "writerVisitNum": "75420", "blog_read_count": "1608", "blog_time": "于 2022-08-05 11:16:46 发布", "blog_title": "实战干货！用 Python 爬取股票实时数据！", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p>今天我们一起来学习一个 Python 爬虫实战案例，我们的目标网站就是东方财富网，废话不多说，开搞</p>\n<h2>网站分析</h2>\n<p>东方财富网地址如下</p>\n<blockquote>\n<p>http://quote.eastmoney.com/center/gridlist.html#hs_a_board</p>\n</blockquote>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\2552eac9c874cf41de9f61a7dbd03585.png\"/></p>\n<p>我们通过点击该网站的下一页发现，网页内容有变化，但是网站的 URL 却不变，也就是说这里使用了 Ajax 技术，动态从服务器拉取数据，这种方式的好处是可以在不重新加载整幅网页的情况下更新部分数据，减轻网络负荷，加快页面加载速度。</p>\n<p>我们通过 F12 来查看网络请求情况，可以很容易的发现，网页上的数据都是通过如下地址请求的</p>\n<blockquote>\n<p>http://38.push2.eastmoney.com/api/qt/clist/get?cb=jQuery112409036039385296142_1658838397275&amp;pn=3&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid=f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1658838404848</p>\n</blockquote>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\a7c7844c8e1c7f134b0c802087dcb428.png\"/></p>\n<p>接下来我们多请求几次，来观察该地址的变化情况，发现其中的<code>pn</code>参数代表这页数，于是，我们可以通过修改<code>&amp;pn=</code>后面的数字来访问不同页面对应的数据</p>\n<pre><code>import requests\n\njson_url = \"http://48.push2.eastmoney.com/api/qt/clist/get?cb=jQuery112402508937289440778_1658838703304&amp;pn=1&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid=f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1658838703305\"\n\nres = requests.get(json_url)\n</code></pre>\n<h2>数据处理</h2>\n<p>接下来我们观察返回的数据，可以看出数据并不是标准的 json 数据</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\ba1ae5af78fe781d04354e97d06d042c.png\"/></p>\n<p>于是我们先进行 json 化</p>\n<pre><code>result = res.text.split(\"jQuery112402508937289440778_1658838703304\")[1].split(\"(\")[1].split(\");\")[0]\nresult_json = json.loads(result)\nresult_json\n</code></pre>\n<p>Output:</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\67cefd559dc9a423734e74eb916e36e2.png\"/></p>\n<p>这样数据就整齐多了，所有的股票数据都在<code>data.diff</code>下面，我们只需要编写解析函数即可</p>\n<p>返回各参数对应含义：</p>\n<ul><li> <p>f2：最新价</p> </li><li> <p>f3：涨跌幅</p> </li><li> <p>f4：涨跌额</p> </li><li> <p>f5：成交量（手）</p> </li><li> <p>f6：成交额</p> </li><li> <p>f7：振幅</p> </li><li> <p>f8：换手率</p> </li><li> <p>f9：市盈率</p> </li><li> <p>f10：量比</p> </li><li> <p>f12：股票代码</p> </li><li> <p>f14：股票名称</p> </li><li> <p>f15：最高</p> </li><li> <p>f16：最低</p> </li><li> <p>f17：今开</p> </li><li> <p>f18：昨收</p> </li><li> <p>f22：市净率</p> </li></ul>\n<p>先准备一个存储函数</p>\n<pre><code>def save_data(data, date):\n    if not os.path.exists(r'stock_data_%s.csv' % date):\n        with open(\"stock_data_%s.csv\" % date, \"a+\", encoding='utf-8') as f:\n            f.write(\"股票代码,股票名称,最新价,涨跌幅,涨跌额,成交量（手）,成交额,振幅,换手率,市盈率,量比,最高,最低,今开,昨收,市净率\\n\")\n            for i in data:\n                Code = i[\"f12\"]\n                Name = i[\"f14\"]\n                Close = i['f2']\n                ChangePercent = i[\"f3\"]\n                Change = i['f4']\n                Volume = i['f5']\n                Amount = i['f6']\n                Amplitude = i['f7']\n                TurnoverRate = i['f8']\n                PERation = i['f9']\n                VolumeRate = i['f10']\n                Hign = i['f15']\n                Low = i['f16']\n                Open = i['f17']\n                PreviousClose = i['f18']\n                PB = i['f22']\n                row = '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}'.format(\n                    Code,Name,Close,ChangePercent,Change,Volume,Amount,Amplitude,\n                    TurnoverRate,PERation,VolumeRate,Hign,Low,Open,PreviousClose,PB)\n                f.write(row)\n                f.write('\\n')\n    else:\n    ...\n</code></pre>\n<p>然后再把前面处理好的 json 数据传入</p>\n<pre><code>stock_data = result_json['data']['diff']\nsave_data(stock_data, '2022-07-28')\n</code></pre>\n<p>这样我们就得到了第一页的股票数据</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\a73246ac1d7260524776e8f2bb892050.png\"/></p>\n<p>最后我们只需要循环抓取所有网页即可</p>\n<pre><code>for i in range(1, 5):\n    print(\"抓取网页%s\" % str(i))\n    url = \"http://48.push2.eastmoney.com/api/qt/clist/get?cb=jQuery112402508937289440778_1658838703304&amp;pn=%s&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid=f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1658838703305\" % str(i)\n    res = requests.get(json_url)\n    result = res.text.split(\"jQuery112402508937289440778_1658838703304\")[1].split(\"(\")[1].split(\");\")[0]\n    result_json = json.loads(result)\n    stock_data = result_json['data']['diff']\n    save_data(stock_data, '2022-07-28')\n</code></pre>\n<p>这样我们就完成了整个股票数据的抓取，喜欢就点个<strong>赞</strong>吧~</p>\n<p>后面我们还会基于以上代码，完成一个股票数据抓取 GUI 程序，再之后再一起完成一个股票数据 Web 展示程序，最终完成一个股票量化平台，敬请期待哦！</p>\n<p>【python学习】<br/> 学Python的伙伴,欢迎加入新的交流【君羊】：1020465983<br/> 一起探讨编程知识,成为大神,群里还有软件安装包，实战案例、学习资料 </p>\n</div>\n</div>"}