{"blogid": "125491850", "writerAge": "码龄2年", "writerBlogNum": "23", "writerCollect": "133", "writerComment": "58", "writerFan": "1015", "writerGrade": "2级", "writerIntegral": "314", "writerName": "MendozaG", "writerProfileAdress": "writer_image\\profile_125491850.jpg", "writerRankTotal": "44321", "writerRankWeekly": "13677", "writerThumb": "32", "writerVisitNum": "29826", "blog_read_count": "3364", "blog_time": "已于 2022-07-17 12:33:52 修改", "blog_title": "【全网最详细yolov6】yoloV6调试记录（含训练自己的数据集及常见报错及解决方法）--持续更新ing", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p>本文手把手教你如何调试最新的yolov6，复现运行COCO2017及训练自己的数据集，目前该项目刚发布，BUG会比较多，调起来一般不会那么顺利，本文含windows+ubuntu，并给出了一些常见问题和解决方法：</p>\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"1.%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B-toc\" style=\"margin-left:0px;\"><a href=\"#1.%E9%A1%B9%E7%9B%AE%E7%AE%80%E4%BB%8B\">1.项目简介</a></p>\n<p id=\"2.%E6%B3%A8%E6%84%8F%E5%92%8C%E6%8E%A8%E8%8D%90-toc\" style=\"margin-left:0px;\"><a href=\"#2.%E6%B3%A8%E6%84%8F%E5%92%8C%E6%8E%A8%E8%8D%90\">2.注意和推荐</a></p>\n<p id=\"3.%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%EF%BC%88%E5%90%ABCOCO%E6%95%B0%E6%8D%AE%E9%9B%86%E9%85%8D%E7%BD%AE%EF%BC%89-toc\" style=\"margin-left:0px;\"><a href=\"#3.%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%EF%BC%88%E5%90%ABCOCO%E6%95%B0%E6%8D%AE%E9%9B%86%E9%85%8D%E7%BD%AE%EF%BC%89\">3.项目配置（含COCO数据集配置）</a></p>\n<p id=\"4.%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%9A-toc\" style=\"margin-left:0px;\"><a href=\"#4.%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%9A\">4.训练自己的数据：</a></p>\n<p id=\"5.%E8%B8%A9%E5%9D%91%E5%B0%8F%E8%AE%B0%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%9A-toc\" style=\"margin-left:0px;\"><a href=\"#5.%E8%B8%A9%E5%9D%91%E5%B0%8F%E8%AE%B0%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%9A\">5.踩坑小记与解决方法：</a></p>\n<p id=\"6.%E8%87%AA%E5%B7%B1%E8%AE%AD%E7%BB%83%E7%9A%84%E5%B0%9D%E8%AF%95%E5%92%8Ctips%EF%BC%88%E4%BE%9B%E5%A4%A7%E5%AE%B6%E5%8F%82%E8%80%83%EF%BC%89-toc\" style=\"margin-left:0px;\"><a href=\"#6.%E8%87%AA%E5%B7%B1%E8%AE%AD%E7%BB%83%E7%9A%84%E5%B0%9D%E8%AF%95%E5%92%8Ctips%EF%BC%88%E4%BE%9B%E5%A4%A7%E5%AE%B6%E5%8F%82%E8%80%83%EF%BC%89\">6.自己训练的尝试和tips（供大家参考）</a></p>\n<hr id=\"hr-toc\"/>\n<h1>1.项目简介</h1>\n<p>最近由美团发布了yoloV6，声称达到了如下的效果：</p>\n<p></p>\n<p><img alt=\"\" height=\"963\" src=\"image\\e702773742f64e87840b04add04d9368.png\" width=\"1200\"/></p>\n<p></p>\n<p> 其中YOLOv6-nano在COCO val2017数据集上达到了35.0 mAP， YOLOv6-s在同样的数据集上达到了43.1 mAP。</p>\n<p>工程和说明见：<a class=\"has-card\" href=\"https://github.com/meituan/YOLOv6\" title=\"GitHub - meituan/YOLOv6: YOLOv6: a single-stage object detection framework dedicated to industrial applications.\"><span class=\"link-card-box\"><span class=\"link-title\">GitHub - meituan/YOLOv6: YOLOv6: a single-stage object detection framework dedicated to industrial applications.</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"image\\icon-default.png\"/>https://github.com/meituan/YOLOv6</span></span></a></p>\n<p> 目前由于工程是近期发布的，有一定的问题，而且GIthub中的说明也不是很详细，特此写一篇关于调试的文章。</p>\n<p>---------------------------------------------------------------------------------------------------------</p>\n<h1 id=\"2.%E6%B3%A8%E6%84%8F%E5%92%8C%E6%8E%A8%E8%8D%90\">2.注意和推荐</h1>\n<p><u><strong>由于该工程较新，bug还是非常多的，建议大家多去github上看看自己的issue是否有出现，这几天代码修改的也比较勤，大家尽量保持更新，会有bug fixed。现在更多的问题表现在训练自己的数据集上。</strong></u></p>\n<p>-------------------------------------------------------------------------------------------------------</p>\n<p><strong><span style=\"color:#b95514;\">写在最前面：</span></strong></p>\n<p><u><span style=\"color:#1c7331;\">经过测试该工程不适合笔记本（测试电脑为r9000p 2021）及普通台式机，适合运行在性能较好的电脑或者服务器上，本文为windows上的配置，供大家参考学习！</span></u></p>\n<p><u><span style=\"color:#1c7331;\">2022 7.1更新服务器运行，新版本工程加入了end2end</span></u></p>\n<p>----------------------------------------------------------------------------------------------------------</p>\n<h1 id=\"3.%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%EF%BC%88%E5%90%ABCOCO%E6%95%B0%E6%8D%AE%E9%9B%86%E9%85%8D%E7%BD%AE%EF%BC%89\">3.项目配置（含COCO数据集配置）</h1>\n<p><strong><span style=\"color:#b95514;\">本部分是重现作者的效果，即在COCO上尝试运行该程序。</span></strong></p>\n<p>以下开始windows上的配置：</p>\n<p>从requirement.txt可以看出该工程依赖于以下：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"548\" src=\"image\\642c901eb7964494897af7458bf46712.png\" width=\"387\"/></p>\n<p><span style=\"color:#fe2c24;\"><strong> 注意：请勿安装最新版本的torch（1.11.0）+torchvison（0.12）会出现问题！</strong></span></p>\n<p>我的成功运行的环境供大家参考：python 3.8.13 torchvision 0.11.1+cu113 torch 1.10.0+cu113 numpy 1.21.5 opencv-python 4.6.0.66 opencv-python-headless 4.5.5.64 addict 2.4.0 pyyaml 6.0 等等</p>\n<p><strong>此处省略安装torch配套的cuda和cudnn过程。</strong></p>\n<p></p>\n<p>--------------------------------------------------------------------------------------------------------</p>\n<p><span style=\"color:#b95514;\"><strong>说明：本调试完成与windows10+pycharm，但仍然强烈推荐在服务器（linux）上完成调试</strong></span></p>\n<p>首先第一步克隆工程</p>\n<pre><code>git clone https://github.com/meituan/YOLOv6\ncd YOLOv6\npip install -r requirements.txt</code></pre>\n<p> 先加载一下预训练模型（测试）：（下载地址）</p>\n<p><a class=\"has-card\" href=\"https://github.com/meituan/YOLOv6/releases/tag/0.1.0\" title=\"https://github.com/meituan/YOLOv6/releases/tag/0.1.0\"><span class=\"link-card-box\"><span class=\"link-title\">https://github.com/meituan/YOLOv6/releases/tag/0.1.0</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"image\\icon-default.png\"/>https://github.com/meituan/YOLOv6/releases/tag/0.1.0</span></span></a></p>\n<p class=\"img-center\"><img alt=\"\" height=\"654\" src=\"image\\feed9ad38cfd4657a43ac0bece743d20.png\" width=\"1117\"/></p>\n<p> 先将这三个文件下载下来，放入weights文件夹（需要自行创建）下。</p>\n<p>若要在pycharm中运行则需要，在其终端下的command Prompt而非windows的powershell，否则会报错（使用虚拟环境的话会找不到例如torch等库）</p>\n<p><img alt=\"\" height=\"261\" src=\"image\\f9b4c116dd374f2e97c53386986b15f6.png\" width=\"1084\"/></p>\n<p> 然后运行inference模型：</p>\n<pre><code>python tools/infer.py --weights yolov6s.pt \n                                \nyolov6n.pt（此处可替换别的模型）</code></pre>\n<p>imagedir保持默认即可，该路径存在 ，可选项如下：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"905\" src=\"image\\b85af1590b424b129b0ce5b8e64f5247.png\" width=\"1200\"/></p>\n<p>可以看到测试推断结果： </p>\n<p class=\"img-center\"><img alt=\"\" height=\"536\" src=\"image\\11d1c4213d9242a1ae105211ee390960.png\" width=\"640\"/></p>\n<p></p>\n<p class=\"img-center\"><img alt=\"\" height=\"480\" src=\"image\\f76657f854f84c68a75734b1a53d5648.png\" width=\"640\"/></p>\n<p></p>\n<p class=\"img-center\"><img alt=\"\" height=\"640\" src=\"image\\195e68786cde4e54916f42b51fa4c436.png\" width=\"431\"/></p>\n<p> 看起来效果不错。</p>\n<p>----------------------------------------------------------------------------------------------------</p>\n<p>测试完毕后到训练阶段：</p>\n<p>准备工作：下载COCO数据集（可能需要科学上网），并在yaml文件中更改相应路径</p>\n<p><a class=\"has-card\" href=\"https://cocodataset.org/#home\" title=\"COCO - Common Objects in Context\"><span class=\"link-card-box\"><span class=\"link-title\">COCO - Common Objects in Context</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"image\\icon-default.png\"/>https://cocodataset.org/#home</span></span></a>建议下载2017</p>\n<p class=\"img-center\"><img alt=\"\" height=\"320\" src=\"image\\29c9f4c383d74a6e8d676f32864595c8.png\" width=\"1184\"/></p>\n<p><u><strong><span style=\"color:#b95514;\"> 如果json格式的annotations没有成功转化并且报错说没有labels那么可以下载下面的转化好的laebls并放入labels文件夹下（文件夹结构如下图）</span></strong></u></p>\n<p>下载链接：https://pan.baidu.com/s/12AIzhR-4wWdFrsjW7RSX0g?pwd=8e2t <br/> 提取码：8e2t </p>\n<p>在项目文件中创建data文件夹，布局如下：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"564\" src=\"image\\485cf2a0f2734819a9d9b4a200fa1726.png\" width=\"557\"/></p>\n<p> images文件夹：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"211\" src=\"image\\961ace0852f24a5db8dbd4a0e6e15997.png\" width=\"1092\"/></p>\n<p> labels文件夹：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"246\" src=\"image\\c31b16b7433a425392f5980ed5f5facd.png\" width=\"1072\"/></p>\n<p> annotations文件夹：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"308\" src=\"image\\f154b9e4b3ca4211858c234acb4b815b.png\" width=\"1067\"/></p>\n<p>按照此结构部署的COCO数据集coco.yaml应修改为：</p>\n<pre><code># COCO 2017 dataset http://cocodataset.org\ntrain: ./data/coco/images/train2017 # 118287 images\nval: ./data/coco/images/val2017  # 5000 images\ntest: ./data/coco/images/test2017\nanno_path: ./data/coco/annotations/instances_val2017.json\n# number of classes\nnc: 80\n\n# class names\nnames: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n         'hair drier', 'toothbrush' ]\n</code></pre>\n<p> 至此COCO数据集部署完毕，在windows下训练还需要修改一处（否则会因为正反斜杠混用，报路径错误）：</p>\n<p>在yolov6-&gt;data-&gt;datasets.py中第184行：</p>\n<pre><code>label_dir = osp.join(osp.dirname(osp.dirname(img_dir)), 'labels', osp.basename(img_dir))\n\n改为：\n\nlabel_dir = osp.join(osp.dirname(osp.dirname(img_dir)), 'labels', osp.basename(img_dir)).replace('\\\\','/')</code></pre>\n<p> 接下来开始训练：</p>\n<p>单个GPU：</p>\n<pre><code>python tools/train.py --batch 32 --conf configs/yolov6s.py --data data/coco.yaml --device 0\n                                   </code></pre>\n<p> configs/yolov6s.py处可以更换models中的其他模型。</p>\n<p>多个GPU（推荐使用DDP）</p>\n<pre><code>python -m torch.distributed.launch --nproc_per_node 8 tools/train.py --batch 256 --conf configs/yolov6s.py --data data/coco.yaml --device 0,1,2,3,4,5,6,7</code></pre>\n<p> 评估：</p>\n<p>重现该模型在COCO val2017的mAP</p>\n<pre><code>python tools/eval.py --data data/coco.yaml  --batch 32 --weights yolov6s.pt --task val\n                                                                 </code></pre>\n<p> 装载：</p>\n<p><a href=\"https://github.com/meituan/YOLOv6/tree/main/deploy/ONNX\" title=\"ONNX\">ONNX</a></p>\n<p><a href=\"https://github.com/meituan/YOLOv6/tree/main/deploy/OpenVINO\" title=\"OpenVINO\">OpenVINO</a></p>\n<p>性能测试：略，见github原地址。</p>\n<p> Benchmark：</p>\n<p class=\"img-center\"><img alt=\"\" height=\"640\" src=\"image\\14c999fe4a634bf498159b6070d0a1c5.png\" width=\"1200\"/></p>\n<h1 id=\"4.%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%9A\">4.<span style=\"color:#0d0016;\"><strong>训练自己的数据：</strong></span></h1>\n<p><u><span style=\"color:#fe2c24;\"><strong>本部分为新更新的部分，训练自己的数据集bug比较多，建议大家及时下载（更新）最新的代码。</strong></span></u></p>\n<p><u><span style=\"color:#fe2c24;\"><strong>本部分尝试分别在windows上和服务器上运行。</strong></span></u></p>\n<p>训练自己的数据集官方说明：</p>\n<p><a class=\"has-card\" href=\"https://github.com/meituan/YOLOv6/blob/main/docs/Train_custom_data.md\" title=\"https://github.com/meituan/YOLOv6/blob/main/docs/Train_custom_data.md\"><span class=\"link-card-box\"><span class=\"link-title\">https://github.com/meituan/YOLOv6/blob/main/docs/Train_custom_data.md</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"image\\icon-default.png\"/>https://github.com/meituan/YOLOv6/blob/main/docs/Train_custom_data.md</span></span></a>首先就是准备数据集阶段，值得注意的是本项目使用的是YOLO格式的数据集，别的格式的数据集需要经过转换</p>\n<p>label（txt）的样例</p>\n<pre><code># class_id center_x center_y bbox_width bbox_height\n0 0.300926 0.617063 0.601852 0.765873\n1 0.575 0.319531 0.4 0.551562</code></pre>\n<p> 准备好的数据集需要这么放置：（<strong><span style=\"color:#fe2c24;\">test可选，注意必须按照图中形式放置</span></strong>）</p>\n<pre><code>custom_dataset\n├── images\n│   ├── train\n│   │   ├── train0.jpg\n│   │   └── train1.jpg\n│   ├── val\n│   │   ├── val0.jpg\n│   │   └── val1.jpg\n│   └── test\n│       ├── test0.jpg\n│       └── test1.jpg\n└── labels\n    ├── train\n    │   ├── train0.txt\n    │   └── train1.txt\n    ├── val\n    │   ├── val0.txt\n    │   └── val1.txt\n    └── test\n        ├── test0.txt\n        └── test1.txt</code></pre>\n<p> <span style=\"color:#fe2c24;\"><strong>另外这里有个坑，数据集的名称推荐使用纯数字的（如000000，jpg 000000.txt经过测试没问题），如果有“.”等特殊符号会读取错误或者找不到labels。</strong></span></p>\n<p> data.yaml配置：</p>\n<pre><code># 数据集路径\ntrain: ../custom_dataset/images/train # train images\nval: ../custom_dataset/images/val # val images\ntest: ../custom_dataset/images/test # test images (可选的)\n\n# 是否是COCO格式的数据集，用YOLO的话设置为False即可\nis_coco: False\n\n# 类别\nnc: 20  # 类的个数\nnames: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog','horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']  # 类名</code></pre>\n<p> config文件：自己配置好放到configs文件夹下，默认我们使用提供的配置文件如configs文件夹下的：yolov6n_finetune.py</p>\n<pre><code>## YOLOv6s Model config file\nmodel = dict(\n    type='YOLOv6s',\n    pretrained='./weights/yolov6s.pt', # download pretrain model from YOLOv6 github if use pretrained model\n    depth_multiple = 0.33,\n    width_multiple = 0.50,\n    ...\n)\nsolver=dict(\n    optim='SGD',\n    lr_scheduler='Cosine',\n    ...\n)\n\ndata_aug = dict(\n    hsv_h=0.015,\n    hsv_s=0.7,\n    hsv_v=0.4,\n    ...\n)</code></pre>\n<p>准备好了开始训练： </p>\n<p><strong><span style=\"background-color:#79c6cd;\">Train：</span></strong></p>\n<p>单个GPU：（根据设备情况设置batch、workers并选择data.yaml）</p>\n<pre><code>python tools/train.py --batch 16 --conf configs/yolov6s_finetune.py --data data/xxx.yaml --device 0 --workers x --epochs x</code></pre>\n<p> 多个GPU：（推荐）</p>\n<pre><code>python -m torch.distributed.launch --nproc_per_node 4 tools/train.py --batch 64 --conf configs/yolov6s_finetune.py --data data/xxx.yaml --device 0,1,2,3 --epochs x --workers 16</code></pre>\n<p>上面多个方法有可能出现如下训练就卡住不动  （如何修改未知）：</p>\n<p>Using 4 GPU for training...<br/> Initializing process group...</p>\n<p>这时候可以尝试<strong><span style=\"color:#fe2c24;\">不推荐</span></strong>的指令：（即直接追加device）</p>\n<pre><code>python tools/train.py --batch 16 --conf configs/yolov6s_finetune.py --data data/xxx.yaml --device 0,1,2,3 --workers x --epochs x</code></pre>\n<p> windows下尝试跑了5个epochs（成功）</p>\n<p><img alt=\"\" height=\"102\" src=\"image\\6b47964f6a7c4ff595b00942e958c7ac.png\" width=\"911\"/></p>\n<p> val：<img alt=\"\" height=\"632\" src=\"image\\62eae78270cb4162b73ffb989a45ae36.png\" width=\"1200\"/></p>\n<p></p>\n<p><strong><span style=\"background-color:#79c6cd;\">Evaluation:</span></strong></p>\n<pre><code>python tools/eval.py --data data/data.yaml  --weights output_dir/name/weights/best_ckpt.pt --device 0</code></pre>\n<p><strong><span style=\"background-color:#79c6cd;\">Inference推断效果</span></strong><span style=\"background-color:#79c6cd;\">:</span>（目前只能推断图片）</p>\n<pre><code>python tools/infer.py --weights output_dir/name/weights/best_ckpt.pt --source img.jpg --device 0</code></pre>\n<p> 结果默认指向data/images中的那三张图，这里需要替换为你的路径或将你的图片放入文件夹中</p>\n<p></p>\n<p>训练10个epochs推断结果： </p>\n<p><img alt=\"\" height=\"759\" src=\"image\\b0ce111b119e4ca3ac0b9ea78b0f3c2a.png\" width=\"1200\"/></p>\n<p><img alt=\"\" height=\"708\" src=\"image\\839c907ab86248e0967a9471d06b9e92.png\" width=\"1200\"/></p>\n<p></p>\n<p><strong><span style=\"background-color:#79c6cd;\">Deployment：</span></strong></p>\n<p>1.输出为 ONNX 格式:</p>\n<pre><code>python deploy/ONNX/export_onnx.py --weights output_dir/name/weights/best_ckpt.pt --device 0</code></pre>\n<p>2.输出为OpenVINO格式：</p>\n<pre><code>python deploy/OpenVINO/export_openvino.py --weights output_dir/name/weights/best_ckpt.pt --device 0</code></pre>\n<p></p>\n<p><strong>ubunbtu服务器：</strong></p>\n<p>这里的data.yaml中数据集的地址推荐设置为绝对路径，相对路径可能会找不到，配置依赖见前面windows配置，建议创建conda环境进行配置。</p>\n<p>按照<span style=\"color:#ad720d;\"><strong>报错7（下文中常见报错7）</strong></span>的方式修改文件或者如果有linux pycharm等编译器的设置YOLOv6文源文件夹。</p>\n<p>在terminal中（conda环境下的）输入与上面相同的指令进行训练即可。</p>\n<p>目前BUG还是非常多的。欢迎讨论！</p>\n<p></p>\n<p></p>\n<p>使用服务器跑了200个epochs（batchsize 128）</p>\n<p><img alt=\"\" height=\"1108\" src=\"image\\d008ffd1b4794d5f8923278f8b961a1b.png\" width=\"1200\"/></p>\n<p></p>\n<p> val<img alt=\"\" height=\"637\" src=\"image\\b0554b630a5541b2aacd4933b14cd9f6.png\" width=\"1200\"/></p>\n<p></p>\n<p>-------------------------------------------------------------------------------------------------------------------</p>\n<h1>5.踩坑小记与解决方法：</h1>\n<p><strong>1.AttributeError: 'NoneType' object has no attribute '_free_weak_ref'</strong></p>\n<p>这是pytorch版本问题 我第一次已安装：torch1.11.0 torchvision 0.12.0不支持</p>\n<p>解决办法：</p>\n<p>第一步：卸载，打开conda环境，pip list查看安装的包 使用 pip uninstall torch torchvision 卸载<br/> 再进行：pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html<br/> （以上方法测试成功）<br/> 或pip install --upgrade --force-reinstall torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0（强制重新安装）</p>\n<p><strong>2.RuntimeError: DataLoader worker (pid(s) 2244, 652) exited unexpectedly</strong><br/> 原因多线程的使用造成内存不足，将workers调整至不会出错的数目，如若仍然报错，让workers为0即不使用多线程。</p>\n<p>解决方法更改训练指令（添加 --workers x（x为能接受的数目，默认为8））：</p>\n<pre><code>python tools/train.py --batch 32 --conf configs/yolov6s.py --data data/coco.yaml --device 0 --workers 0</code></pre>\n<p><strong> 3.OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.</strong><br/> 这是因为你的环境中安装了多个libiomp5md.dll库，</p>\n<p>解决办法：到你的环境搜索libiomp5md.dll删除多出来的库（仅保留一个）。</p>\n<p><strong>4.训练时使用GPU训练但出现 ------------CPU Mode for This Batch-------------</strong><br/> 可以看到这里抛出了异常：OOM RuntimeError is raised due to the huge memory cost during label assignment. CPU mode is applied in this batch. If you want to avoid this issue,try to reduce the batch size or image size.<br/> 这是由于内存不够导致的，需要缩减Batch_size（但应当大于8）或者减小图片尺寸（若使用COCO数据集则不建议修改）使用torch.cuda.empty_cache()释放未占用缓存。</p>\n<p>解决方法：缩小batch_size（如下改为16）</p>\n<pre><code>python tools/train.py --batch 16 --conf configs/yolov6s.py --data data/coco.yaml --device 0 </code></pre>\n<p><strong> 5.RuntimeError: Unable to find a valid cuDNN algorithm to run convolution</strong></p>\n<p><img alt=\"\" height=\"48\" src=\"image\\d6b6b27b81be4f1c83119d4632e92070.png\" width=\"909\"/> 原因：显卡显存不够，调小batch_size或者降低workers即可。</p>\n<p><strong> warning：UserWarning: torch.meshgrid: in an upcoming release, it will be requ<br/> ired to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.) return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]</strong><br/> 是因为：下个版本 VF.meshgrid(tensors, **kwargs) 改为修改为return _VF.meshgrid(tensors, **kwargs, indexing = ‘ij’) <br/> 解决方法：使用return _VF.meshgrid(tensors, **kwargs, indexing = ‘ij’) # type: ignore[attr-defined] 解除警告</p>\n<p>此外由于对于性能要求比较高，从而会出现： <strong>“OSError: [WinError 1455]页面文件太小，无法完成操作”</strong>的问题，这是由于内存不足造成的</p>\n<p><img alt=\"\" height=\"112\" src=\"image\\233b0107712847288a3093dea57831ef.png\" width=\"1200\"/></p>\n<p>解决方法：增大虚拟内存或者更换更大的内存条。增大虚拟内存的方法这里就不在赘述了。</p>\n<p><strong>6.module没有xxx，一般是由于库的版本问题，调整到适合的版本即可。</strong></p>\n<p><strong>7.在自己训练数据集时，找不到tools.xxx等module 例如AttributeError: module 'tools.eval' has no attribute 'run'</strong></p>\n<p>一般是项目目录设置错误，导致找不到，在windows端使用pycharm等编译器时将源目录设置为yolov6，若使用ubuntu直接通过terminal调用，因为读不到系统sys路径，所以会找不到。这里需要进行如下调整（解决方法之一）：</p>\n<p>在YOLOv6/tools/目录下创建__init__.py，并调整train.py的内容：</p>\n<pre><code>#原\nROOT = os.getcwd()\nif str(ROOT) not in sys.path:\n    sys.path.append(str(ROOT))\n\n\n#替换为\nROOT = os.getcwd()\nif str(ROOT) not in sys.path:\n    sys.path.insert(0，str(ROOT))</code></pre>\n<p><strong>8.COCOEval Error</strong></p>\n<p>验证时出错，是老版本bug，更新到新版即可。</p>\n<p><strong>9.路径xxx/mages（你设置的数据集相对路径）不存在</strong></p>\n<p>将data.yaml中的数据集路径设置为绝对路径。</p>\n<p>10.多GPU训练，使用分布式（distributed）出现：No rendezvous handler for env://</p>\n<p>检查是否自己是在windows中使用，windows不支持nccl，将torch的distributed_c10d.py中的backend = \"nccl\"改为backend = \"gloo\"</p>\n<p>如是在ubuntu下运行，则更改tcp（附加）： </p>\n<pre><code>--dist_url tcp://localhost:1001</code></pre>\n<p> 若都不能解决可以尝试上面的<strong><span style=\"color:#fe2c24;\">不推荐</span></strong>的方法运行。</p>\n<pre><code>python tools/train.py --batch 16 --conf configs/yolov6s_finetune.py --data data/xxx.yaml --device 0,1,2,3 --workers x --epochs x</code></pre>\n<p></p>\n<p> <u><strong><span style=\"color:#ad720d;\">未解决的问题：（有小伙伴遇到了解决了欢迎留言！！！）</span></strong></u></p>\n<p>分布式训练卡在：</p>\n<p><strong>Using 4 GPU for training...<br/> Initializing process group...</strong></p>\n<p></p>\n<p>---------------------------------------------------------------------------------------------</p>\n<h1 id=\"6.%E8%87%AA%E5%B7%B1%E8%AE%AD%E7%BB%83%E7%9A%84%E5%B0%9D%E8%AF%95%E5%92%8Ctips%EF%BC%88%E4%BE%9B%E5%A4%A7%E5%AE%B6%E5%8F%82%E8%80%83%EF%BC%89\">6.自己训练的尝试和tips（供大家参考）</h1>\n<p>tips：因为该项目对于硬件要求较高，有时候会出现上述第四个的显卡“爆显存”的问题，使用下面的代码段（在cmd控制台中输入）来监控显卡状态并每秒更新。</p>\n<pre><code>nvidia-smi -l \n（是l不是1，每秒显示一次）</code></pre>\n<p class=\"img-center\"><img alt=\"\" height=\"318\" src=\"image\\29a604b3d7ec4f938ba25c8a1609b13a.png\" width=\"991\"/></p>\n<p>可以看到我的3060laptop显卡也只有6G的显存，所以很容易就爆显存了。 </p>\n<p>供大家参考：</p>\n<p>在我的r9000p 2021中GPU可跑动的train运行方式为：</p>\n<pre><code>python tools/train.py --batch 24 --conf configs/yolov6s.py --data data/coco.yaml --device 0  --workers 3\n</code></pre>\n<p>注：没有继续尝试了，batch_size 32会爆显存，worker 8（默认）会内存不足（已添加30G虚拟内存）。再微调batch和workers效果不大，每个epoch需要约50分钟，一共400个epoch，是不可接受的。还是在服务器上跑比较合适！</p>\n<p><img alt=\"\" height=\"418\" src=\"image\\0cd19509eab04ea69bcf45bebe36b330.png\" width=\"1200\"/></p>\n<p>花两个小时跑两个epoch感受一下：</p>\n<p>epoch 0：</p>\n<p><img alt=\"\" height=\"172\" src=\"image\\c576a60f82044310a9006b7a2c1403af.png\" width=\"1200\"/></p>\n<p><img alt=\"\" height=\"538\" src=\"image\\151f160043784f2bba106e45c8857ca6.png\" width=\"1200\"/></p>\n<p> epoch 1：</p>\n<p><img alt=\"\" height=\"124\" src=\"image\\6ac99b7d2c524a82ba9cc6454d5fcd09.png\" width=\"1200\"/></p>\n<p>打开tensorboard：(<u><strong><span style=\"color:#be191c;\">指定路径到train文件夹下，而非命名的name，如exp文件夹下</span></strong></u>)</p>\n<pre><code>tensorboard ==logdir=xxx/runs/train</code></pre>\n<p>TensorBoard：（仅两个epoch，仅供参考）</p>\n<p><img alt=\"\" height=\"1186\" src=\"image\\7813771217a0490c831f2cb7bb595f81.png\" width=\"1200\"/></p>\n<p><img alt=\"\" height=\"655\" src=\"image\\70d9ca5b32fa410e88307c8f131d22d4.png\" width=\"1200\"/></p>\n<p></p>\n<p>-------------更新  5 epochs----------------</p>\n<p>loss</p>\n<p><img alt=\"\" height=\"1091\" src=\"image\\81b91b2b8c044c6fb8418f8b7400febf.png\" width=\"1200\"/></p>\n<p> mAP</p>\n<p><img alt=\"\" height=\"622\" src=\"image\\4ceb44fd07c24161bcc6f8bc270e3758.png\" width=\"1200\"/></p>\n<p> <img alt=\"\" height=\"326\" src=\"image\\2002b9bd50a34cfc8f45d960faff1450.png\" width=\"959\"/></p>\n<p><img alt=\"\" height=\"137\" src=\"image\\7e916f8e2a4047ccb0c81a5704f802ef.png\" width=\"958\"/></p>\n<p> ----------------------------------------------------------------------------------------------</p>\n<p></p>\n<p>训练自己的数据集时（<span style=\"color:#b95514;\"><strong>windows10个epochs，batch_size 16</strong></span>）</p>\n<p>loss </p>\n<p><img alt=\"\" height=\"1074\" src=\"image\\80b728422e0942bcae48e362744a9341.png\" width=\"1200\"/></p>\n<p> val</p>\n<p><img alt=\"\" height=\"654\" src=\"image\\cd80e1591956495a86251fdbfe6f5927.png\" width=\"1200\"/></p>\n<p> 验证：（Inference）</p>\n<p><img alt=\"\" height=\"708\" src=\"image\\f45840f2d91a4c85aaa3efcce81c5a53.png\" width=\"1200\"/></p>\n<p> <img alt=\"\" height=\"759\" src=\"image\\2860445617a94477b935d6cca6083f69.png\" width=\"1200\"/></p>\n<p>对比：yolov5 200epochs</p>\n<p><img alt=\"\" height=\"759\" src=\"image\\53ab3d5048694de29496a3cdaaa54ef0.png\" width=\"1200\"/></p>\n<p></p>\n</div>\n</div>"}