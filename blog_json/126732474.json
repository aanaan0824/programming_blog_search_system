{"blogid": "126732474", "writerAge": "码龄4年", "writerBlogNum": "843", "writerCollect": "13784", "writerComment": "2311", "writerFan": "16075", "writerGrade": "8级", "writerIntegral": "43342", "writerName": "宋宋_浩浩_Java工程师", "writerProfileAdress": "writer_image\\profile_126732474.jpg", "writerRankTotal": "93", "writerRankWeekly": "2539", "writerThumb": "4009", "writerVisitNum": "4293424", "blog_read_count": "26", "blog_time": "于 2022-09-06 20:25:17 发布", "blog_title": "Java集合源码剖析——基于JDK1.8中ConcurrentHashMap的实现原理", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h1 id=\"main-toc\"><strong>文章目录：</strong></h1>\n<p id=\"1.%E8%A7%A3%E5%86%B3HashMap%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%AE%89%E5%85%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95-toc\" style=\"margin-left:0px;\"><a href=\"#1.%E8%A7%A3%E5%86%B3HashMap%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%AE%89%E5%85%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95\">1.解决HashMap线程不安全的几种方法</a></p>\n<p id=\"1.1%20Hashtable-toc\" style=\"margin-left:40px;\"><a href=\"#1.1%20Hashtable\">1.1 Hashtable</a></p>\n<p id=\"1.2%20Collections.synchronizedMap-toc\" style=\"margin-left:40px;\"><a href=\"#1.2%20Collections.synchronizedMap\">1.2 Collections.synchronizedMap</a></p>\n<p id=\"1.3%C2%A0ConcurrentHashMap%EF%BC%88JDK1.7%EF%BC%89-toc\" style=\"margin-left:40px;\"><a href=\"#1.3%C2%A0ConcurrentHashMap%EF%BC%88JDK1.7%EF%BC%89\">1.3 ConcurrentHashMap（JDK1.7）</a></p>\n<p id=\"2.JDK1.8%E4%B8%AD%E7%9A%84ConcurrentHashMap-toc\" style=\"margin-left:0px;\"><a href=\"#2.JDK1.8%E4%B8%AD%E7%9A%84ConcurrentHashMap\">2.JDK1.8中的ConcurrentHashMap</a></p>\n<p id=\"2.1%20put%E6%96%B9%E6%B3%95-toc\" style=\"margin-left:40px;\"><a href=\"#2.1%20put%E6%96%B9%E6%B3%95\">2.1 put方法</a></p>\n<p id=\"2.2%C2%A0initTable%E6%96%B9%E6%B3%95-toc\" style=\"margin-left:40px;\"><a href=\"#2.2%C2%A0initTable%E6%96%B9%E6%B3%95\">2.2 initTable方法</a></p>\n<p id=\"2.3%20get%E6%96%B9%E6%B3%95-toc\" style=\"margin-left:40px;\"><a href=\"#2.3%20get%E6%96%B9%E6%B3%95\">2.3 get方法</a></p>\n<p id=\"3.%E6%80%BB%E7%BB%93-toc\" style=\"margin-left:0px;\"><a href=\"#3.%E6%80%BB%E7%BB%93\">3.总结</a></p>\n<hr id=\"hr-toc\"/>\n<h1>1.解决HashMap线程不安全的几种方法</h1>\n<h2 id=\"1.1%20Hashtable\">1.1 Hashtable</h2>\n<blockquote>\n<p>第一种方法就是使用Hashtable，这是个线程安全的集合类，而它在针对 put、get等一系列操作时，都是对整个方法进行上锁。</p>\n</blockquote>\n<pre><code class=\"language-java\">    public synchronized V put(K key, V value) {\n        // Make sure the value is not null\n        if (value == null) {\n            throw new NullPointerException();\n        }\n\n        // Makes sure the key is not already in the hashtable.\n        Entry&lt;?,?&gt; tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index];\n        for(; entry != null ; entry = entry.next) {\n            if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) {\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            }\n        }\n\n        addEntry(hash, key, value, index);\n        return null;\n    }</code></pre>\n<pre><code class=\"language-java\">    public synchronized V get(Object key) {\n        Entry&lt;?,?&gt; tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash &amp; 0x7FFFFFFF) % tab.length;\n        for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) {\n            if ((e.hash == hash) &amp;&amp; e.key.equals(key)) {\n                return (V)e.value;\n            }\n        }\n        return null;\n    }</code></pre>\n<blockquote>\n<p>可以看到，不管是往 map 里边添加元素还是获取元素，都会用 synchronized 关键字加锁。那么如果有多个线程同时操作这个map集合，肯定会存在资源竞争，同时也只能有一个线程可以获取到锁，操作资源。所以，Hashtable 的缺点显而易见，它不管是 get 还是 put 操作，都是锁住了整个 哈希表，效率十分低下，因此并不适合高并发场景。</p>\n</blockquote>\n<h2 id=\"1.2%20Collections.synchronizedMap\">1.2 Collections.synchronizedMap</h2>\n<blockquote>\n<p>这个集合工具类中提供了一系列 synchronizedXXX 的静态方法，用于将那些线程不安全的集合转为线程安全的，不过不太推荐使用，原因来看看：↓↓↓</p>\n</blockquote>\n<pre><code class=\"language-java\">    public static &lt;K,V&gt; Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m) {\n        return new SynchronizedMap&lt;&gt;(m);\n    }\n\n    /**\n     * @serial include\n     */\n    private static class SynchronizedMap&lt;K,V&gt;\n        implements Map&lt;K,V&gt;, Serializable {\n        private static final long serialVersionUID = 1978198479659022715L;\n\n        private final Map&lt;K,V&gt; m;     // Backing Map\n        final Object      mutex;        // Object on which to synchronize\n\n        SynchronizedMap(Map&lt;K,V&gt; m) {\n            this.m = Objects.requireNonNull(m);\n            mutex = this;\n        }\n\n        SynchronizedMap(Map&lt;K,V&gt; m, Object mutex) {\n            this.m = m;\n            this.mutex = mutex;\n        }\n\n        public int size() {\n            synchronized (mutex) {return m.size();}\n        }\n        public boolean isEmpty() {\n            synchronized (mutex) {return m.isEmpty();}\n        }\n        public boolean containsKey(Object key) {\n            synchronized (mutex) {return m.containsKey(key);}\n        }\n        public boolean containsValue(Object value) {\n            synchronized (mutex) {return m.containsValue(value);}\n        }\n        public V get(Object key) {\n            synchronized (mutex) {return m.get(key);}\n        }\n\n        public V put(K key, V value) {\n            synchronized (mutex) {return m.put(key, value);}\n        }\n        public V remove(Object key) {\n            synchronized (mutex) {return m.remove(key);}\n        }\n        public void putAll(Map&lt;? extends K, ? extends V&gt; map) {\n            synchronized (mutex) {m.putAll(map);}\n        }\n        public void clear() {\n            synchronized (mutex) {m.clear();}\n        }\n</code></pre>\n<blockquote>\n<p>在调用 Collections.synchronizedMap 之后，它实际上是为我们 new 了一个 SynchronizedMap 类，追进这个类的源码（截取了部分代码），发现它和Hashtable差不多，也是锁住了整个哈希表，那就不用多说了，在高并发场景下效率肯定是个大问题。</p>\n</blockquote>\n<h2 id=\"1.3%C2%A0ConcurrentHashMap%EF%BC%88JDK1.7%EF%BC%89\">1.3 ConcurrentHashMap（JDK1.7）</h2>\n<blockquote>\n<p>主角登场啦，针对上面两种解决方法的局限性，它们都是把整个哈希表锁住再进行后续的操作。那么为了进一步提升效率，我们能不能把整张哈希表分成 N 个部分，并使元素尽量均匀的分布到每个部分中，分别给每个部分加锁，使它们互相之间并不影响，这种方式岂不是更好 。这就是在 JDK1.7 中 ConcurrentHashMap 采用的方案，被叫做锁分段技术，每个部分就是一个 Segment（段）。</p>\n<hr/>\n<p><strong>在 JDK1.7中，本质上还是采用链表+数组的形式存储键值对的。但是，为了提高并发，把原来的整个 table 划分为 n 个 Segment 。所以，从整体来看，它是一个由 Segment 组成的数组。然后，每个 Segment 里边是由 HashEntry 组成的数组，每个 HashEntry之间又可以形成链表。我们可以把每个 Segment 看成是一个小的 HashMap，其内部结构和 HashMap 是一模一样的。</strong></p>\n</blockquote>\n<p style=\"text-align:center;\"><img alt=\"\" height=\"398\" src=\"image\\cf3e6300821a4d96825c8eca0b7bb1ec.png\" width=\"630\"/></p>\n<blockquote>\n<p>当对某个 Segment 加锁时，如图中 Segment2，并不会影响到其他 Segment 的读写。每个 Segment 内部自己操作自己的数据。这样一来，我们要做的就是尽可能的让元素均匀的分布在不同的 Segment中。最理想的状态是，所有执行的线程操作的元素都是不同的 Segment，这样就可以降低锁的竞争。</p>\n</blockquote>\n<hr/>\n<h1 id=\"2.JDK1.8%E4%B8%AD%E7%9A%84ConcurrentHashMap\">2.JDK1.8中的ConcurrentHashMap</h1>\n<blockquote>\n<p>上面针对1.7的ConcurrentHashMap就简单的说这么多了，我主要是考虑目前基本用的都是JDK1.8，所以这里主要来说一下JDK1.8中ConcurrentHashMap的实现原理。</p>\n<p></p>\n<p>JDK 1.8 的 CHM（ConcurrentHashMap） 实现，完全重构了 1.7 。不再有 Segment 的概念，只是为了兼容 1.7 才申明了一下，并没有用到。因此，不再使用分段锁，而是给数组中的每一个头节点（为了方便，以后都叫桶）都加锁，锁的粒度降低了。采用的是 Synchronized + CAS ，把锁的粒度进一步降低，而放弃了 Segment 分段。</p>\n</blockquote>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"image\\f4ea6a15a3384b18a4490c2565218093.png\"/></p>\n<h2 id=\"2.1%20put%E6%96%B9%E6%B3%95\">2.1 put方法</h2>\n<blockquote>\n<p>注释写的很详细了，唉，花了好长时间才理解。。。还是自己太菜了</p>\n<ol><li> <p><strong>根据 key 计算出 hashcode 对应的桶下标。</strong></p> </li><li> <p><strong>判断是否需要进行初始化。</strong></p> </li><li> <p><strong>即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。</strong></p> </li><li> <p><strong>如果当前位置的 <code>hashcode == MOVED == -1</code>,则需要进行扩容。</strong></p> </li><li> <p><strong>如果都不满足，则利用 synchronized 锁写入数据。</strong></p> </li><li> <p><strong>如果数量大于 <code>TREEIFY_THRESHOLD</code> 则要执行树化方法，在 <code>treeifyBin</code> 中会首先判断当前数组长度≥64时才会将链表转换为红黑树</strong></p> </li></ol>\n</blockquote>\n<pre><code class=\"language-java\">public V put(K key, V value) {\n\treturn putVal(key, value, false);\n}\n\nfinal V putVal(K key, V value, boolean onlyIfAbsent) {\n\t//可以看到，在并发情况下，key 和 value 都不能为null。有一个为null直接空指针\n\tif (key == null || value == null) throw new NullPointerException();\n\t//这里就是计算key的hash值（具体的好像还挺复杂，我这里没有深入研究）\n\tint hash = spread(key.hashCode());\n\t//用来计算当前链表上kv键值对的个数\n\tint binCount = 0;\n\tfor (Node&lt;K,V&gt;[] tab = table;;) {\n\t\tNode&lt;K,V&gt; f; int n, i, fh;\n\t\t//如果哈希表为空，说明还未进行初始化\n\t\tif (tab == null || (n = tab.length) == 0)\n\t\t\t//initTable()方法用来初始化哈希表，后面我来说这个方法\n\t\t\ttab = initTable();\n\t\t//根据key的hash值通过哈希算法计算得到对应的桶下标，并且判断是否为空\n\t\telse if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {\n\t\t\t//走进来则说明当前桶为空，进而通过CAS原子操作将新节点插入到此位置，保证了只有一个线程可以CAS成功\n\t\t\t//判断哈希表下标为i的节点是否为null，如果为null，则更新为new Node&lt;K,V&gt;(hash, key, value, null)\n\t\t\tif (casTabAt(tab, i, null,\n\t\t\t\t\t\t new Node&lt;K,V&gt;(hash, key, value, null)))\n\t\t\t\tbreak;                   // no lock when adding to empty bin\n\t\t}\n\t\t//如果计算得到对应的桶下标不为空，则判断该节点的hash值是否为MOVED(值为-1)\n\t\telse if ((fh = f.hash) == MOVED)\n\t\t\t//如果节点的hash值为-1，则说明当前桶下的数组正在扩容，需要当前线程帮忙迁移数据\n\t\t\ttab = helpTransfer(tab, f);\n\t\t//排除上面三种情况，则会走到这里\n\t\telse {\n\t\t\t//临时变量，用来保存key对应的旧值\n\t\t\tV oldVal = null;\n\t\t\t//加上同步锁，保证线程安全，这里是对当前桶中的第一个节点对象加锁\n\t\t\tsynchronized (f) {\n\t\t\t\t//这里先再次检查一下，确保当前桶的第一个节点没有变化\n\t\t\t\t//tabAt(tab, i)方法表明获取tab这个哈希表中下标为i的第一个节点对象\n\t\t\t\tif (tabAt(tab, i) == f) {\n\t\t\t\t\t//如果key的hash值大于等于0，则说明是链表结构\n\t\t\t\t\tif (fh &gt;= 0) {\n\t\t\t\t\t\tbinCount = 1;\n\t\t\t\t\t\t//从头节点开始遍历，每遍历一次binCount计数加1\n\t\t\t\t\t\tfor (Node&lt;K,V&gt; e = f;; ++binCount) {\n\t\t\t\t\t\t\tK ek;\n\t\t\t\t\t\t\t//找到了和当前key相同的节点(hash值相同 &amp;&amp; equals为true)\n\t\t\t\t\t\t\tif (e.hash == hash &amp;&amp;\n\t\t\t\t\t\t\t\t((ek = e.key) == key ||\n\t\t\t\t\t\t\t\t (ek != null &amp;&amp; key.equals(ek)))) {\n\t\t\t\t\t\t\t\t//先将key对应的旧值保存到变量oldVal中\n\t\t\t\t\t\t\t\toldVal = e.val;\n\t\t\t\t\t\t\t\tif (!onlyIfAbsent)\n\t\t\t\t\t\t\t\t\t//用新的value值替换key对应的旧值\n\t\t\t\t\t\t\t\t\te.val = value;\n\t\t\t\t\t\t\t\tbreak; //已经找到，可以退出循环\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tNode&lt;K,V&gt; pred = e;\n\t\t\t\t\t\t\t//如果遍历到了链表的尾节点，还没有找到与要插入的key相同的节点\n\t\t\t\t\t\t\tif ((e = e.next) == null) {\n\t\t\t\t\t\t\t\t//则将要插入的节点放在链表的最后(尾插)\n\t\t\t\t\t\t\t\tpred.next = new Node&lt;K,V&gt;(hash, key,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  value, null);\n\t\t\t\t\t\t\t\tbreak; //退出循环\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t//不是链表了话，那就是树节点了。这里提一下，TreeBin只是头结点对TreeNode的再封装\n\t\t\t\t\telse if (f instanceof TreeBin) {\n\t\t\t\t\t\tNode&lt;K,V&gt; p;\n\t\t\t\t\t\tbinCount = 2;\n\t\t\t\t\t\t//这里进行红黑树的相关操作\n\t\t\t\t\t\tif ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   value)) != null) {\n\t\t\t\t\t\t\toldVal = p.val;\n\t\t\t\t\t\t\tif (!onlyIfAbsent)\n\t\t\t\t\t\t\t\tp.val = value;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t//注意下，这个判断是在同步锁的外部，因为treeifyBin方法内部也有同步锁，所以并不影响\n\t\t\tif (binCount != 0) {\n\t\t\t\tif (binCount &gt;= TREEIFY_THRESHOLD)\n\t\t\t\t\ttreeifyBin(tab, i);\n\t\t\t\tif (oldVal != null)\n\t\t\t\t\treturn oldVal;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t//put完成之后，哈希表的元素要加1，并且可能触发扩容，这个比较复杂，我没有深入研究\n\taddCount(1L, binCount);\n\treturn null;\n}</code></pre>\n<h2 id=\"2.2%C2%A0initTable%E6%96%B9%E6%B3%95\">2.2 initTable方法</h2>\n<blockquote>\n<p><strong>从源码中可以发现 <code>ConcurrentHashMap</code> 的初始化是通过自旋和 CAS 操作完成的。里面需要注意的是变量 <code>sizeCtl</code> ，它的值决定着当前的初始化状态</strong></p>\n</blockquote>\n<pre><code class=\"language-java\">//此时哈希表为空，要进行初始化操作\nprivate final Node&lt;K,V&gt;[] initTable() {\n\tNode&lt;K,V&gt;[] tab; int sc;\n\t//循环判断哈希表是否为空，直到初始化成功为止\n\twhile ((tab = table) == null || tab.length == 0) {\n\t\t//sizeCtl这个值有很多情况，默认值为0，\n\t\t//当为 -1 时，说明有其它线程正在对哈希表进行初始化操作\n        //当哈希表初始化成功后，又会把它设置为扩容阈值\n\t\t//当为一个小于 -1 的负数，用来表示当前有几个线程正在帮助扩容\n\t\tif ((sc = sizeCtl) &lt; 0)\n\t\t\t//若sc小于0，其实在这里就是-1，因为此时哈希表是空的，不会发生扩容，sc只能为正数或者-1\n            //因此，当前线程放弃CPU时间片，只是自旋\n\t\t\tThread.yield(); // lost initialization race; just spin\n\t\t//通过CAS把 sc 的值设置为-1，表明当前线程正在进行哈希表的初始化\n\t\t//当其中一个线程将sc更新为-1之后，其它失败的线程就会自旋\n\t\telse if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n\t\t\ttry {\n\t\t\t\t//重新检查一下哈希表是否为空\n\t\t\t\tif ((tab = table) == null || tab.length == 0) {\n\t\t\t\t\t//如果sc大于0，则为sc，否则返回默认容量16\n                    //当调用有参构造创建 Map 时，sc的值是大于0的\n\t\t\t\t\tint n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;\n\t\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\t\t//创建哈希表，长度大小为n\n\t\t\t\t\tNode&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];\n\t\t\t\t\ttable = tab = nt;\n\t\t\t\t\t//n - 1/4 n，也就是0.75n，表示扩容阈值\n\t\t\t\t\tsc = n - (n &gt;&gt;&gt; 2);\n\t\t\t\t}\n\t\t\t} finally {\n\t\t\t\t//最后将sizeCtl更新为扩容阈值\n\t\t\t\tsizeCtl = sc;\n\t\t\t}\n\t\t\t//如果当前线程初始化哈希表成功，则跳出循环\n\t\t\t//其他自旋的线程因为判断哈希表不为空，也会停止自旋\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn tab;\n}</code></pre>\n<h2 id=\"2.3%20get%E6%96%B9%E6%B3%95\">2.3 get方法</h2>\n<blockquote>\n<ol><li><strong>根据 hash 值计算位置。</strong></li><li><strong>查找到指定位置，如果头节点就是要找的，直接返回它的 value.</strong></li><li><strong>如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，find查找。</strong></li><li><strong>如果是链表，遍历查找。</strong></li></ol>\n</blockquote>\n<pre><code class=\"language-java\">public V get(Object key) {\n\tNode&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;\n\t//这里就是计算key的hash值\n\tint h = spread(key.hashCode());\n\t//如果哈希表不为空，并且根据key的hash值计算得到的桶下标对应的节点也不为空\n\tif ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;\n\t\t(e = tabAt(tab, (n - 1) &amp; h)) != null) {\n\t\t//如果当前桶的头节点直接命中，匹配成功\n\t\tif ((eh = e.hash) == h) {\n\t\t\tif ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))\n\t\t\t\t//直接返回key对应的value\n\t\t\t\treturn e.val;\n\t\t}\n\t\t//头节点的hash值小于0，说明正在扩容或者是红黑树，find查找\n\t\telse if (eh &lt; 0)\n\t\t\treturn (p = e.find(h, key)) != null ? p.val : null;\n\t\t//否则说明是正常的链表，遍历查找即可\n\t\twhile ((e = e.next) != null) {\n\t\t\tif (e.hash == h &amp;&amp;\n\t\t\t\t((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))\n\t\t\t\treturn e.val;\n\t\t}\n\t}\n\treturn null;\n}</code></pre>\n<hr/>\n<h1 id=\"3.%E6%80%BB%E7%BB%93\">3.总结</h1>\n<blockquote>\n<p>以上分享借鉴了很多大佬的文章博客，最后加上自己的理解。</p>\n<p></p>\n<p><strong>Java7 中 <code>ConcurrentHashMap</code> 使用的分段锁，也就是每一个 Segment 上同时只有一个线程可以操作，每一个 <code>Segment</code> 都是一个类似 <code>HashMap</code> 数组的结构，它可以扩容，它的冲突会转化为链表。但是 <code>Segment</code> 的个数一但初始化就不能改变。</strong></p>\n<p></p>\n<p><strong>Java8 中的 <code>ConcurrentHashMap</code> 使用的 <code>Synchronized</code> 锁加 CAS 的机制。结构也由 Java7 中的 <code>Segment</code> 数组 + <code>HashEntry</code> 数组 + 链表 进化成了 Node 数组 + 链表 / 红黑树，Node 是类似于一个 HashEntry 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表。</strong></p>\n</blockquote>\n</div>\n</div>"}