{"blogid": "124673115", "writerAge": "码龄3年", "writerBlogNum": "10", "writerCollect": "57", "writerComment": "6", "writerFan": "8", "writerGrade": "2级", "writerIntegral": "129", "writerName": "alwaysluc", "writerProfileAdress": "writer_image\\profile_124673115.jpg", "writerRankTotal": "113031", "writerRankWeekly": "493694", "writerThumb": "19", "writerVisitNum": "5782", "blog_read_count": "2711", "blog_time": "于 2022-05-09 19:58:05 发布", "blog_title": "[python]LDA模型使用流程及代码", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"-toc\" style=\"margin-left:0px;\"></p>\n<p id=\"%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-toc\" style=\"margin-left:0px;\"><a href=\"#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\">数据预处理</a></p>\n<p id=\"%E5%8E%BB%E9%99%A4%E5%81%9C%E7%94%A8%E8%AF%8D-toc\" style=\"margin-left:0px;\"><a href=\"#%E5%8E%BB%E9%99%A4%E5%81%9C%E7%94%A8%E8%AF%8D\">去除停用词</a></p>\n<p id=\"%E6%9E%84%E5%BB%BALDA%E6%A8%A1%E5%9E%8B-toc\" style=\"margin-left:0px;\"><a href=\"#%E6%9E%84%E5%BB%BALDA%E6%A8%A1%E5%9E%8B\">构建LDA模型</a></p>\n<p id=\"%E5%8F%AF%E8%A7%86%E5%8C%96%E2%80%94%E2%80%94pyLDAvis-toc\" style=\"margin-left:0px;\"><a href=\"#%E5%8F%AF%E8%A7%86%E5%8C%96%E2%80%94%E2%80%94pyLDAvis\">可视化——pyLDAvis</a></p>\n<p id=\"%C2%A0%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%95%B0%E7%A1%AE%E8%AE%A4-toc\" style=\"margin-left:0px;\"><a href=\"#%C2%A0%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%95%B0%E7%A1%AE%E8%AE%A4\"> 主题个数确认</a></p>\n<p id=\"%E5%9B%B0%E6%83%91%E5%BA%A6%E8%AE%A1%E7%AE%97-toc\" style=\"margin-left:40px;\"><a href=\"#%E5%9B%B0%E6%83%91%E5%BA%A6%E8%AE%A1%E7%AE%97\">困惑度计算</a></p>\n<p id=\"%E4%B8%80%E8%87%B4%E6%80%A7%E5%BE%97%E5%88%86-toc\" style=\"margin-left:40px;\"><a href=\"#%E4%B8%80%E8%87%B4%E6%80%A7%E5%BE%97%E5%88%86\">一致性得分</a></p>\n<hr id=\"hr-toc\"/>\n<p></p>\n<h1 id=\"%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\">数据预处理</h1>\n<p>该步骤可自行处理，用excel也好，用python也罢，只要将待分析文本处理为csv或txt存储格式即可。注意：一条文本占一行</p>\n<p>例如感想.txt：</p>\n<p>我喜欢吃汉堡</p>\n<p>小明喜欢吃螺蛳粉</p>\n<p>螺蛳粉外卖好贵</p>\n<p>以上句子来源于吃完一个汉堡还想再点碗螺蛳粉，但外卖好贵从而选择放弃的我</p>\n<h1 id=\"%E5%8E%BB%E9%99%A4%E5%81%9C%E7%94%A8%E8%AF%8D\">去除停用词</h1>\n<pre><code class=\"language-python\">import re\nimport jieba as jb\ndef stopwordslist(filepath):\n    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n    return stopwords\n\n# 对句子进行分词\ndef seg_sentence(sentence):\n    sentence = re.sub(u'[0-9\\.]+', u'', sentence)\n    #jb.add_word('词汇')\t\t# 这里是加入自定义的词来补充jieba词典\n    sentence_seged = jb.cut(sentence.strip())\n    stopwords = stopwordslist('自己搜来的停用词表.txt')  # 这里加载停用词的路径\n    outstr = ''\n    for word in sentence_seged:\n        if word not in stopwords and word.__len__()&gt;1:\n            if word != '\\t':\n                outstr += word\n                outstr += \" \"\n    return outstr\n\n\ninputs = open('感想.txt', 'r', encoding='utf-8')\n\noutputs = open('感想分词.txt', 'w',encoding='utf-8')\nfor line in inputs:\n    line_seg = seg_sentence(line)  # 这里的返回值是字符串\n    outputs.write(line_seg + '\\n')\noutputs.close()\ninputs.close()\n\n</code></pre>\n<p>该步骤生成感想分词.txt:</p>\n<p>我 喜欢 吃 汉堡</p>\n<p>小明 喜欢 吃 螺蛳粉</p>\n<p>螺蛳粉 外卖 好贵</p>\n<p>句子 来源于 吃完 一个 汉堡  再点碗 螺蛳粉 外卖 好贵  选择 放弃 </p>\n<h1 id=\"%E6%9E%84%E5%BB%BALDA%E6%A8%A1%E5%9E%8B\">构建LDA模型</h1>\n<p>假设主题个数设为4个（num_topics的参数）</p>\n<pre><code>import codecs\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\n\n\ntrain = []\n\nfp = codecs.open('感想分词.txt','r',encoding='utf8')\nfor line in fp:\n    if line != '':\n        line = line.split()\n        train.append([w for w in line])\n\ndictionary = corpora.Dictionary(train)\n\ncorpus = [dictionary.doc2bow(text) for text in train]\n\nlda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=4, passes=100)\n# num_topics：主题数目\n# passes：训练伦次\n# num_words：每个主题下输出的term的数目\n\nfor topic in lda.print_topics(num_words = 20):\n    termNumber = topic[0]\n    print(topic[0], ':', sep='')\n    listOfTerms = topic[1].split('+')\n    for term in listOfTerms:\n        listItems = term.split('*')\n        print('  ', listItems[1], '(', listItems[0], ')', sep='')</code></pre>\n<h1 id=\"%E5%8F%AF%E8%A7%86%E5%8C%96%E2%80%94%E2%80%94pyLDAvis\">可视化——pyLDAvis</h1>\n<pre><code>import pyLDAvis.gensim_models\n\n'''插入之前的代码片段'''\nimport codecs\nfrom gensim import corpora\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\n\n\ntrain = []\n\nfp = codecs.open('感想分词.txt','r',encoding='utf8')\nfor line in fp:\n    if line != '':\n        line = line.split()\n        train.append([w for w in line])\n\ndictionary = corpora.Dictionary(train)\n\ncorpus = [dictionary.doc2bow(text) for text in train]\n\nlda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=4, passes=100)\n# num_topics：主题数目\n# passes：训练伦次\n# num_words：每个主题下输出的term的数目\n\nfor topic in lda.print_topics(num_words = 20):\n    termNumber = topic[0]\n    print(topic[0], ':', sep='')\n    listOfTerms = topic[1].split('+')\n    for term in listOfTerms:\n        listItems = term.split('*')\n        print('  ', listItems[1], '(', listItems[0], ')', sep='')\n        \nd=pyLDAvis.gensim_models.prepare(lda, corpus, dictionary)\n\n'''\nlda: 计算好的话题模型\n\ncorpus: 文档词频矩阵\n\ndictionary: 词语空间\n'''\n\n#pyLDAvis.show(d)\t\t#展示在浏览器\n# pyLDAvis.displace(d) #展示在notebook的output cell中\npyLDAvis.save_html(d, 'lda_pass4.html')</code></pre>\n<p>这样就会生成看起来很炫酷的图啦（只是示例）：</p>\n<p><img alt=\"\" height=\"444\" src=\"image\\9f4bf68319eb438986b780f836bd5b44.png\" width=\"865\"/></p>\n<h1 id=\"%C2%A0%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%95%B0%E7%A1%AE%E8%AE%A4\"> 主题个数确认</h1>\n<p style=\"margin-left:0;text-align:justify;\"><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">计算不同参数下结果的</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\"> Perlexity(</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">困惑度</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">)</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">和</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\"> Coherence score(</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">一致性评分</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">)</span></span><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">，选择困惑度最低且一致性评分最高的参数值作为最终参数设定。</span></span></p>\n<h2 id=\"%E5%9B%B0%E6%83%91%E5%BA%A6%E8%AE%A1%E7%AE%97\" style=\"margin-left:0px;text-align:justify;\"><span style=\"background-color:#FFFFFF;\"><span style=\"color:#4d4d4d;\">困惑度计算</span></span></h2>\n<pre><code>import gensim\nfrom gensim import corpora, models\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\n \n \n \n # 准备数据\nPATH = \"感想分词.txt\"  #已经进行了分词的文档（如何分词前面的文章有介绍）\n \n \nfile_object2=open(PATH,encoding = 'utf-8',errors = 'ignore').read().split('\\n')  \ndata_set=[] #建立存储分词的列表\nfor i in range(len(file_object2)):\n    result=[]\n    seg_list = file_object2[i].split()  #读取没一行文本\n    for w in seg_list :#读取每一行分词\n        result.append(w)\n    data_set.append(result)\nprint(data_set)  #输出所有分词列表\n \n \ndictionary = corpora.Dictionary(data_set)  # 构建 document-term matrix\ncorpus = [dictionary.doc2bow(text) for text in data_set]\nLda = gensim.models.ldamodel.LdaModel  # 创建LDA对象\n \n#计算困惑度\ndef perplexity(num_topics):\n    ldamodel = Lda(corpus, num_topics=num_topics, id2word = dictionary, passes=50)  #passes为迭代次数，次数越多越精准\n    print(ldamodel.print_topics(num_topics=num_topics, num_words=20))  #num_words为每个主题下的词语数量\n    print(ldamodel.log_perplexity(corpus))\n    return ldamodel.log_perplexity(corpus)\n \n# 绘制困惑度折线图\nx = range(1,20)  #主题范围数量\ny = [perplexity(i) for i in x]\nplt.plot(x, y)\nplt.xlabel('主题数目')\nplt.ylabel('困惑度大小')\nplt.rcParams['font.sans-serif']=['SimHei']\nmatplotlib.rcParams['axes.unicode_minus']=False\nplt.title('主题-困惑度变化情况')\nplt.show()</code></pre>\n<h2 id=\"%E2%80%8B\"><img alt=\"\" height=\"275\" src=\"image\\da4b3f093aa04b10973abd948d935722.png\" width=\"399\"/></h2>\n<p> </p>\n<h2 id=\"%E4%B8%80%E8%87%B4%E6%80%A7%E5%BE%97%E5%88%86\">一致性得分</h2>\n<pre><code>import gensim\nfrom gensim import corpora, models\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n \n \n \n # 准备数据\nPATH = \"感想分词.txt\"  #已经进行了分词的文档（如何分词前面的文章有介绍）\n \n \nfile_object2=open(PATH,encoding = 'utf-8',errors = 'ignore').read().split('\\n')  \ndata_set=[] #建立存储分词的列表\nfor i in range(len(file_object2)):\n    result=[]\n    seg_list = file_object2[i].split()  #读取没一行文本\n    for w in seg_list :#读取每一行分词\n        result.append(w)\n    data_set.append(result)\nprint(data_set)  #输出所有分词列表\n \n \ndictionary = corpora.Dictionary(data_set)  # 构建 document-term matrix\ncorpus = [dictionary.doc2bow(text) for text in data_set]\nLda = gensim.models.ldamodel.LdaModel  # 创建LDA对象\n \n\ndef coherence(num_topics):\n    ldamodel = Lda(corpus, num_topics=num_topics, id2word = dictionary, passes=50)  #passes为迭代次数，次数越多越精准\n    coherence_model_lda = CoherenceModel(model=ldamodel, texts=data_set, dictionary=dictionary, coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    print('\\nCoherence Score: ', coherence_lda)\n    return coherence_lda\n \n# 绘制困惑度折线图\nx = range(1,20)  #主题范围数量\ny = [coherence(i) for i in x]\nplt.plot(x,y)\nplt.xlabel('主题数目')\nplt.ylabel('coherence大小')\nplt.rcParams['font.sans-serif']=['SimHei']\nmatplotlib.rcParams['axes.unicode_minus']=False\nplt.title('主题-coherence变化情况')\nplt.show()</code></pre>\n<p><img alt=\"\" height=\"275\" src=\"image\\fb48c3dd70d544d1bc284f80883aa3a2.png\" width=\"389\"/></p>\n<h1> 结语</h1>\n<p>整个流程就大致是这样啦！有问题欢迎一起交流！！</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\dfd5038263cc797ca5057804c1030cce.png\"/></p>\n<p> </p>\n</div>\n</div>"}