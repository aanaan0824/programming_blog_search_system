{"blogid": "126592390", "writerAge": "码龄2年", "writerBlogNum": "38", "writerCollect": "264", "writerComment": "30", "writerFan": "42", "writerGrade": "3级", "writerIntegral": "462", "writerName": "—Xi—", "writerProfileAdress": "writer_image\\profile_126592390.jpg", "writerRankTotal": "33876", "writerRankWeekly": "18966", "writerThumb": "57", "writerVisitNum": "37319", "blog_read_count": "49", "blog_time": "已于 2022-09-06 21:35:20 修改", "blog_title": "【机器学习】随机森林及调参 学习笔记", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h1>集成学习</h1>\n<p>集成学习通过构建多个学习器来完成任务，通过多个弱学习器组成一个强学习器。</p>\n<h2>Boosting（提升法）：</h2>\n<p>个体学习器之间存在强依赖关系，通过<strong>串行</strong>生成的序列化方法，通过加法模型将弱分类器（基评估器）进行线性组合。</p>\n<p>提高前一轮被弱分类器分错的样本的权重，减少在前一轮被弱分类器分对的样本的权值。</p>\n<p><img alt=\"\" src=\"image\\25db6ada146c4e039b73063015b264e4.png\"/></p>\n<h3> 代表算法</h3>\n<ul><li>Adaboost</li><li>GBDT</li><li>XGBoost</li><li>LightGBM</li></ul>\n<h2>Bagging(装袋法)：</h2>\n<p>个体学习器之间不存在强依赖关系，采取并行化</p>\n<p style=\"text-align:center;\"><img alt=\"\" height=\"228\" src=\"image\\62696605125b4529958f00c7f51b8473.png\" width=\"521\"/></p>\n<p> 随机森林中，还会随机抽取一定数量的特征。</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"image\\98025df7a2754bdb83d79cb30435f1f9.png\"/></p>\n<h1> 随机森林</h1>\n<p>随机森林的所有基评估器都是决策树，分类树组成的森林就叫做随机森林分类器，回归树所集成的森林叫做<a href=\"https://so.csdn.net/so/search?q=%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%9B%9E%E5%BD%92&amp;spm=1001.2101.3001.7020\" title=\"随机森林回归\">随机森林回归</a>器。</p>\n<p class=\"img-center\"><img alt=\"\" height=\"1168\" src=\"image\\20201014135020635.png\" width=\"467\"/></p>\n<h2> 随机森林参数</h2>\n<p> 随机森林中树的参数</p>\n<p class=\"img-center\"><img alt=\"\" src=\"image\\cc610753a087dce6b32e87b59a4c558b.png\"/></p>\n<p>数据集：</p>\n<p>链接：https://pan.baidu.com/s/1wUK0-u6pTsMqKy5dqcfQew?pwd=ectd <br/> 提取码：ectd</p>\n<h1>随机森林调参实战：</h1>\n<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\n\ndf = pd.read_csv(\"creditcard.csv\")\ndata=df.iloc[:,1:31]\ndata.head()\n\nX = data.loc[:,data.columns != 'Class']\ny = data.loc[:,data.columns == 'Class']\n\nnum_record_fraud = len(data[data.Class==1])#欺诈的样本数目\nfraud_indices = np.array(data[data.Class==1].index)#样本等于1的索引值\nnormal_indices= np.array(data[data.Class==0].index)#样本等于0的索引值\n##随机抽样与正样本同数量的负样本\nrandom_normal_indices = np.random.choice(normal_indices,num_record_fraud,replace = True)\nrandom_normal_indices = np.array(random_normal_indices)\n#合并正负样本索引\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n#按索引抽取数据\nunder_sample_data = data.iloc[under_sample_indices,:]\n\nX_undersample = under_sample_data.loc[:,under_sample_data.columns != 'Class']\ny_undersample = under_sample_data.loc[:,under_sample_data.columns == 'Class']\nX_train,X_test,y_train,y_test = train_test_split(X_undersample,y_undersample,test_size = 0.3)\n\nrf0 = RandomForestClassifier(oob_score = True,random_state = 666)\nrf0.fit(X_train,y_train)\nprint(rf0.oob_score_)#袋外样本\n'''predict返回的是一个预测的值，predict_proba返回的是对于预测为各个类别的概率。\npredict_proba返回的是一个 n 行 k 列的数组， 第 i 行 j列的数值是模型预测 第 i 个预测样本为某个标签的概率\n并且每一行的概率和为1。'''\ny_pred = rf0.predict_proba(X_test)[:,1]#返回模型预测样本标签为1的概率\nprint('AUC Score(Train): %f' % roc_auc_score(y_test,y_pred))\n#0.936046511627907\n# AUC Score(Train): 0.976516\n\n\n#网格搜索\nparam1 = {'n_estimators':range(10,101,10)}\nsearch1 = GridSearchCV(estimator = RandomForestClassifier(oob_score = True,random_state = 666,n_jobs = 2),\n                      param_grid = param1,scoring = 'roc_auc',cv = 5)\nsearch1.fit(X_train,y_train)\nsearch1.cv_results_,search1.best_params_,search1.best_score_\n# {'n_estimators': 70},\n#  0.9707089376393281)\n\n#网格搜索\nparam2 = {'max_depth':range(2,12,2)}\nsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 70,oob_score = True,random_state = 666,n_jobs = 2),\n                      param_grid = param2,scoring = 'roc_auc',cv = 5)\nsearch2.fit(X_train,y_train)\nsearch2.cv_results_,search2.best_params_,search2.best_score_\n# {'max_depth': 10},\n#  0.9710400329003688)\n\nparam3 = {'min_samples_split':range(2,8,1)}\nsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators = 70,\n                                                          max_depth = 10, oob_score = True,\n                                                          random_state = 666,n_jobs = 2),\n                      param_grid = param3,scoring = 'roc_auc',cv = 5)\nsearch3.fit(X_train,y_train)\nsearch3.cv_results_,search3.best_params_,search3.best_score_\n\n\n# {'min_samples_split': 4},\n#  0.972142760065589)\nrf1 =  RandomForestClassifier(n_estimators = 70,max_depth = 10, oob_score = True,\n                              min_samples_split = 4,\n                              random_state = 666,n_jobs = 2)\nrf1.fit(X_train,y_train)\nprint(rf1.oob_score_)\ny_pred = rf1.predict_proba(X_test)[:,1]#返回模型预测样本标签为1的概率\nprint('AUC Score(Train): %f' % roc_auc_score(y_test,y_pred))\n# 0.9433139534883721\n# AUC Score(Train): 0.987851</code></pre>\n<h2 id=\"随机森林优缺点总结\">随机森林优缺点总结</h2>\n<p>RF优点<br/> 1.不容易出现过拟合，因为选择训练样本的时候就不是全部样本。<br/> 2.可以既可以处理属性为离散值的量，比如ID3算法来构造树，也可以处理属性为连续值的量，比如C4.5算法来构造树。<br/> 3.对于高维数据集的处理能力令人兴奋，它可以处理成千上万的输入变量，并确定最重要的变量，因此被认为是一个不错的降维方法。此外，该模型能够输出变量的重要性程度，这是一个非常便利的功能。<br/> 4.分类不平衡的情况时，随机森林能够提供平衡数据集误差的有效方法<br/> RF缺点<br/> 1.随机森林在解决回归问题时并没有像它在分类中表现的那么好，这是因为它并不能给出一个连续型的输出。当进行回归时，随机森林不能够作出超越训练集数据范围的预测，这可能导致在对某些还有特定噪声的数据进行建模时出现过度拟合。<br/> 2.对于许多统计建模者来说，随机森林给人的感觉像是一个黑盒子——你几乎无法控制模型内部的运行，只能在不同的参数和随机种子之间进行尝试。</p>\n<p><a class=\"link-info\" href=\"https://blog.csdn.net/qq_42374697/article/details/106848818?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166234560916782248585767%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=166234560916782248585767&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-106848818-null-null.nonecase&amp;utm_term=%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97&amp;spm=1018.2226.3001.4450\" title=\"sklearn-随机森林\">sklearn-随机森林</a></p>\n</div>\n</div>"}