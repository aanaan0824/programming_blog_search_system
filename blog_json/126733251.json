{"blogid": "126733251", "writerAge": "码龄82天", "writerBlogNum": "148", "writerCollect": "37", "writerComment": "7", "writerFan": "16", "writerGrade": "4级", "writerIntegral": "1548", "writerName": "蜀州凯哥", "writerProfileAdress": "writer_image\\profile_126733251.jpg", "writerRankTotal": "17381", "writerRankWeekly": "3397", "writerThumb": "43", "writerVisitNum": "6593", "blog_read_count": "12", "blog_time": "于 2022-09-07 12:19:18 发布", "blog_title": "接口性能优化的11个小技巧，每个都是精髓", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h2>前言</h2>\n<p><strong>接口性能优化</strong>对于从事后端开发的同学来说，肯定再熟悉不过了，因为它是一个跟开发语言无关的公共问题。</p>\n<p>该问题说简单也简单，说复杂也复杂。</p>\n<p>有时候，只需加个索引就能解决问题。</p>\n<p>有时候，需要做代码重构。</p>\n<p>有时候，需要增加缓存。</p>\n<p>有时候，需要引入一些中间件，比如mq。</p>\n<p>有时候，需要需要分库分表。</p>\n<p>有时候，需要拆分服务。</p>\n<p>等等。。。</p>\n<p>导致接口性能问题的原因千奇百怪，不同的项目不同的接口，原因可能也不一样。</p>\n<p>本文我总结了一些行之有效的，优化接口性能的办法，给有需要的朋友一个参考。</p>\n<h2>1.索引</h2>\n<p>接口性能优化大家第一个想到的可能是：<code>优化索引</code>。</p>\n<p>没错，优化索引的成本是最小的。</p>\n<p>你通过查看线上日志或者监控报告，查到某个接口用到的某条sql语句耗时比较长。</p>\n<p>这时你可能会有下面这些疑问：</p>\n<ol><li> <p>该sql语句加索引了没？</p> </li><li> <p>加的索引生效了没？</p> </li><li> <p>mysql选错索引了没？</p> </li></ol>\n<h3>1.1 没加索引</h3>\n<p>sql语句中<code>where</code>条件的关键字段，或者<code>order by</code>后面的排序字段，忘了加索引，这个问题在项目中很常见。</p>\n<p>项目刚开始的时候，由于表中的数据量小，加不加索引sql查询性能差别不大。</p>\n<p>后来，随着业务的发展，表中数据量越来越多，就不得不加索引了。</p>\n<p>可以通过命令：</p>\n<pre><code>show index from `order`;\n</code></pre>\n<p>能单独查看某张表的索引情况。</p>\n<p>也可以通过命令：</p>\n<pre><code>show create table `order`;\n</code></pre>\n<p>查看整张表的建表语句，里面同样会显示索引情况。</p>\n<p>通过<code>ALTER TABLE</code>命令可以添加索引：</p>\n<pre><code>ALTER TABLE `order` ADD INDEX idx_name (name);\n</code></pre>\n<p>也可以通过<code>CREATE INDEX</code>命令添加索引：</p>\n<pre><code>CREATE INDEX idx_name ON `order` (name);\n</code></pre>\n<p>不过这里有一个需要注意的地方是：想通过命令修改索引，是不行的。</p>\n<p>目前在mysql中如果想要修改索引，只能先删除索引，再重新添加新的。</p>\n<p>删除索引可以用<code>DROP INDEX</code>命令：</p>\n<pre><code>ALTER TABLE `order` DROP INDEX idx_name;\n</code></pre>\n<p>用<code>DROP INDEX</code>命令也行：</p>\n<pre><code>DROP INDEX idx_name ON `order`;\n</code></pre>\n<h3>1.2 索引没生效</h3>\n<p>通过上面的命令我们已经能够确认索引是有的，但它生效了没？此时你内心或许会冒出这样一个疑问。</p>\n<p>那么，如何查看索引有没有生效呢？</p>\n<p>答：可以使用<code>explain</code>命令，查看mysql的执行计划，它会显示索引的使用情况。</p>\n<p>例如：</p>\n<pre><code>explain select * from `order` where code='002';\n</code></pre>\n<p>结果：</p>\n<p style=\"text-align:center;\"><img alt=\"18eefde9c3174a099c01ddcce4d88fcb.png\" src=\"image\\18eefde9c3174a099c01ddcce4d88fcb.png\"/> </p>\n<p>通过这几列可以判断索引使用情况，执行计划包含列的含义如下图所示：</p>\n<p style=\"text-align:center;\"><img alt=\"845cdd25379c4efc895cbff57ba2dba8.png\" src=\"image\\845cdd25379c4efc895cbff57ba2dba8.png\"/> </p>\n<p>说实话，sql语句没有走索引，排除没有建索引之外，最大的可能性是索引失效了。</p>\n<p>下面说说索引失效的常见原因：</p>\n<p style=\"text-align:center;\"><img alt=\"00aa0667b00d4f9c8481cbc87e313ba8.png\" src=\"image\\00aa0667b00d4f9c8481cbc87e313ba8.png\"/> </p>\n<p>如果不是上面的这些原因，则需要再进一步排查一下其他原因。</p>\n<h3>1.3 选错索引</h3>\n<p>此外，你有没有遇到过这样一种情况：明明是同一条sql，只有入参不同而已。有的时候走的索引a，有的时候却走的索引b？</p>\n<p>没错，有时候mysql会选错索引。</p>\n<p>必要时可以使用<code>force index</code>来强制查询sql走某个索引。</p>\n<p>至于为什么mysql会选错索引，后面有专门的文章介绍的，这里先留点悬念。</p>\n<h2>2. sql优化</h2>\n<p>如果优化了索引之后，也没啥效果。</p>\n<p>接下来试着优化一下sql语句，因为它的改造成本相对于java代码来说也要小得多。</p>\n<p>下面给大家列举了sql优化的15个小技巧：</p>\n<p style=\"text-align:center;\"><img alt=\"3cd13efd05ca4e1f8dd74f5bf6fa9809.png\" src=\"image\\3cd13efd05ca4e1f8dd74f5bf6fa9809.png\"/> </p>\n<p>由于这些技巧在我之前的文章中已经详细介绍过了，在这里我就不深入了。</p>\n<h2>3. 远程调用</h2>\n<p>很多时候，我们需要在某个接口中，调用其他服务的接口。</p>\n<p>比如有这样的业务场景：</p>\n<p>在用户信息查询接口中需要返回：用户名称、性别、等级、头像、积分、成长值等信息。</p>\n<p>而用户名称、性别、等级、头像在用户服务中，积分在积分服务中，成长值在成长值服务中。为了汇总这些数据统一返回，需要另外提供一个对外接口服务。</p>\n<p>于是，用户信息查询接口需要调用用户查询接口、积分查询接口 和 成长值查询接口，然后汇总数据统一返回。</p>\n<p>调用过程如下图所示：</p>\n<p style=\"text-align:center;\"><img alt=\"9f36faf193394561aef1975573f0d914.png\" src=\"image\\9f36faf193394561aef1975573f0d914.png\"/> </p>\n<p>调用远程接口总耗时 530ms = 200ms + 150ms + 180ms</p>\n<p>显然这种串行调用远程接口性能是非常不好的，调用远程接口总的耗时为所有的远程接口耗时之和。</p>\n<p>那么如何优化远程接口性能呢？</p>\n<h3>3.1 并行调用</h3>\n<p>上面说到，既然串行调用多个远程接口性能很差，为什么不改成并行呢？</p>\n<p>如下图所示：</p>\n<p style=\"text-align:center;\"><img alt=\"40d9b00f8dfb4b408adb53d7ab012622.png\" src=\"image\\40d9b00f8dfb4b408adb53d7ab012622.png\"/> </p>\n<p>调用远程接口总耗时 200ms = 200ms（即耗时最长的那次远程接口调用）</p>\n<p>在java8之前可以通过实现<code>Callable</code>接口，获取线程返回结果。</p>\n<p>java8以后通过<code>CompleteFuture</code>类实现该功能。我们这里以CompleteFuture为例：</p>\n<pre><code>public UserInfo getUserInfo(Long id) throws InterruptedException, ExecutionException {\n    final UserInfo userInfo = new UserInfo();\n    CompletableFuture userFuture = CompletableFuture.supplyAsync(() -&gt; {\n        getRemoteUserAndFill(id, userInfo);\n        return Boolean.TRUE;\n    }, executor);\n\n    CompletableFuture bonusFuture = CompletableFuture.supplyAsync(() -&gt; {\n        getRemoteBonusAndFill(id, userInfo);\n        return Boolean.TRUE;\n    }, executor);\n\n    CompletableFuture growthFuture = CompletableFuture.supplyAsync(() -&gt; {\n        getRemoteGrowthAndFill(id, userInfo);\n        return Boolean.TRUE;\n    }, executor);\n    CompletableFuture.allOf(userFuture, bonusFuture, growthFuture).join();\n\n    userFuture.get();\n    bonusFuture.get();\n    growthFuture.get();\n\n    return userInfo;\n}\n</code></pre>\n<blockquote>\n<p>温馨提醒一下，这两种方式别忘了使用线程池。示例中我用到了executor，表示自定义的线程池，为了防止高并发场景下，出现线程过多的问题。</p>\n</blockquote>\n<h3>3.2 数据异构</h3>\n<p>上面说到的用户信息查询接口需要调用用户查询接口、积分查询接口 和 成长值查询接口，然后汇总数据统一返回。</p>\n<p>那么，我们能不能把数据冗余一下，把用户信息、积分和成长值的数据统一存储到一个地方，比如：redis，存的数据结构就是用户信息查询接口所需要的内容。然后通过用户id，直接从redis中查询数据出来，不就OK了？</p>\n<p>如果在高并发的场景下，为了提升接口性能，远程接口调用大概率会被去掉，而改成保存冗余数据的数据异构方案。</p>\n<p style=\"text-align:center;\"><img alt=\"81287d232e074950990f5e661d8aeadb.png\" src=\"image\\81287d232e074950990f5e661d8aeadb.png\"/> </p>\n<p>但需要注意的是，如果使用了数据异构方案，就可能会出现数据一致性问题。</p>\n<p>用户信息、积分和成长值有更新的话，大部分情况下，会先更新到数据库，然后同步到redis。但这种跨库的操作，可能会导致两边数据不一致的情况产生。</p>\n<h2>4. 重复调用</h2>\n<p><code>重复调用</code>在我们的日常工作代码中可以说随处可见，但如果没有控制好，会非常影响接口的性能。</p>\n<p>不信，我们一起看看。</p>\n<h3>4.1 循环查数据库</h3>\n<p>有时候，我们需要从指定的用户集合中，查询出有哪些是在数据库中已经存在的。</p>\n<p>实现代码可以这样写：</p>\n<pre><code>public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) {\n    if (CollectionUtils.isEmpty(searchList)) {\n        return Collections.emptyList();\n    }\n\n    List&lt;User&gt; result = Lists.newArrayList();\n    searchList.forEach(user -&gt; result.add(userMapper.getUserById(user.getId())));\n    return result;\n}\n</code></pre>\n<p>这里如果有50个用户，则需要循环50次，去查询数据库。我们都知道，每查询一次数据库，就是一次远程调用。</p>\n<p>如果查询50次数据库，就有50次远程调用，这是非常耗时的操作。</p>\n<p>那么，我们如何优化呢？</p>\n<p>具体代码如下：</p>\n<pre><code>public List&lt;User&gt; queryUser(List&lt;User&gt; searchList) {\n    if (CollectionUtils.isEmpty(searchList)) {\n        return Collections.emptyList();\n    }\n    List&lt;Long&gt; ids = searchList.stream().map(User::getId).collect(Collectors.toList());\n    return userMapper.getUserByIds(ids);\n}\n</code></pre>\n<p>提供一个根据用户id集合批量查询用户的接口，只远程调用一次，就能查询出所有的数据。</p>\n<blockquote>\n<p>这里有个需要注意的地方是：id集合的大小要做限制，最好一次不要请求太多的数据。要根据实际情况而定，建议控制每次请求的记录条数在500以内。</p>\n</blockquote>\n<h3>4.2 死循环</h3>\n<p>有些小伙伴看到这个标题，可能会感到有点意外，死循环也算？</p>\n<p>代码中不是应该避免死循环吗？为啥还是会产生死循环？</p>\n<p>有时候死循环是我们自己写的，例如下面这段代码：</p>\n<pre><code>while(true) {\n    if(condition) {\n        break;\n    }\n    System.out.println(\"do samething\");\n}\n</code></pre>\n<p>这里使用了while(true)的循环调用，这种写法在<code>CAS自旋锁</code>中使用比较多。</p>\n<p>当满足condition等于true的时候，则自动退出该循环。</p>\n<p>如果condition条件非常复杂，一旦出现判断不正确，或者少写了一些逻辑判断，就可能在某些场景下出现死循环的问题。</p>\n<p>出现死循环，大概率是开发人员人为的bug导致的，不过这种情况很容易被测出来。</p>\n<blockquote>\n<p>还有一种隐藏的比较深的死循环，是由于代码写的不太严谨导致的。如果用正常数据，可能测不出问题，但一旦出现异常数据，就会立即出现死循环。</p>\n</blockquote>\n<h3>4.3 无限递归</h3>\n<p>如果想要打印某个分类的所有父分类，可以用类似这样的递归方法实现：</p>\n<pre><code>public void printCategory(Category category) {\n  if(category == null \n      || category.getParentId() == null) {\n     return;\n  } \n  System.out.println(\"父分类名称：\"+ category.getName());\n  Category parent = categoryMapper.getCategoryById(category.getParentId());\n  printCategory(parent);\n}\n</code></pre>\n<p>正常情况下，这段代码是没有问题的。</p>\n<p>但如果某次有人误操作，把某个分类的parentId指向了它自己，这样就会出现无限递归的情况。导致接口一直不能返回数据，最终会发生堆栈溢出。</p>\n<blockquote>\n<p>建议写递归方法时，设定一个递归的深度，比如：分类最大等级有4级，则深度可以设置为4。然后在递归方法中做判断，如果深度大于4时，则自动返回，这样就能避免无限循环的情况。</p>\n</blockquote>\n<h2>5. 异步处理</h2>\n<p>有时候，我们接口性能优化，需要重新梳理一下业务逻辑，看看是否有设计上不太合理的地方。</p>\n<p>比如有个用户请求接口中，需要做业务操作，发站内通知，和记录操作日志。为了实现起来比较方便，通常我们会将这些逻辑放在接口中同步执行，势必会对接口性能造成一定的影响。</p>\n<p>接口内部流程图如下：</p>\n<p style=\"text-align:center;\"><img alt=\"e1e64d3ff82d422da7196f3c0d8f5720.png\" src=\"image\\e1e64d3ff82d422da7196f3c0d8f5720.png\"/> </p>\n<p>这个接口表面上看起来没有问题，但如果你仔细梳理一下业务逻辑，会发现只有业务操作才是<code>核心逻辑</code>，其他的功能都是<code>非核心逻辑</code>。</p>\n<blockquote>\n<p>在这里有个原则就是：核心逻辑可以同步执行，同步写库。非核心逻辑，可以异步执行，异步写库。</p>\n</blockquote>\n<p>上面这个例子中，发站内通知和用户操作日志功能，对实时性要求不高，即使晚点写库，用户无非是晚点收到站内通知，或者运营晚点看到用户操作日志，对业务影响不大，所以完全可以异步处理。</p>\n<p>通常异步主要有两种：<code>多线程</code> 和 <code>mq</code>。</p>\n<h3>5.1 线程池</h3>\n<p>使用<code>线程池</code>改造之后，接口逻辑如下：</p>\n<p style=\"text-align:center;\"><img alt=\"34daf38c259249d4aaf872129b45b3db.png\" src=\"image\\34daf38c259249d4aaf872129b45b3db.png\"/> </p>\n<p>发站内通知和用户操作日志功能，被提交到了两个单独的线程池中。</p>\n<p>这样接口中重点关注的是业务操作，把其他的逻辑交给线程异步执行，这样改造之后，让接口性能瞬间提升了。</p>\n<p>但使用线程池有个小问题就是：如果服务器重启了，或者是需要被执行的功能出现异常了，无法重试，会丢数据。</p>\n<p>那么这个问题该怎么办呢？</p>\n<h3>5.2 mq</h3>\n<p>使用<code>mq</code>改造之后，接口逻辑如下：</p>\n<p style=\"text-align:center;\"><img alt=\"c895154707e24b468e78a225ab5d6117.png\" src=\"image\\c895154707e24b468e78a225ab5d6117.png\"/> </p>\n<p>对于发站内通知和用户操作日志功能，在接口中并没真正实现，它只发送了mq消息到mq服务器。然后由mq消费者消费消息时，才真正的执行这两个功能。</p>\n<p>这样改造之后，接口性能同样提升了，因为发送mq消息速度是很快的，我们只需关注业务操作的代码即可。</p>\n<h2>6. 避免大事务</h2>\n<p>很多小伙伴在使用spring框架开发项目时，为了方便，喜欢使用<code>@Transactional</code>注解提供事务功能。</p>\n<p>没错，使用@Transactional注解这种声明式事务的方式提供事务功能，确实能少写很多代码，提升开发效率。</p>\n<p>但也容易造成大事务，引发其他的问题。</p>\n<p>下面用一张图看看大事务引发的问题。</p>\n<p style=\"text-align:center;\"><img alt=\"1848b8bacad64b90bd4161b583a0250d.png\" src=\"image\\1848b8bacad64b90bd4161b583a0250d.png\"/> </p>\n<p>从图中能够看出，大事务问题可能会造成接口超时，对接口的性能有直接的影响。</p>\n<p>我们该如何优化大事务呢？</p>\n<ol><li> <p>少用@Transactional注解</p> </li><li> <p>将查询(select)方法放到事务外</p> </li><li> <p>事务中避免远程调用</p> </li><li> <p>事务中避免一次性处理太多数据</p> </li><li> <p>有些功能可以非事务执行</p> </li><li> <p>有些功能可以异步处理</p> </li></ol>\n<h2>7. 锁粒度</h2>\n<p>在某些业务场景中，为了防止多个线程并发修改某个共享数据，造成数据异常。</p>\n<p>为了解决并发场景下，多个线程同时修改数据，造成数据不一致的情况。通常情况下，我们会：<code>加锁</code>。</p>\n<p>但如果锁加得不好，导致锁的粒度太粗，也会非常影响接口性能。</p>\n<h3>7.1 synchronized</h3>\n<p>在java中提供了<code>synchronized</code>关键字给我们的代码加锁。</p>\n<p>通常有两种写法：<code>在方法上加锁</code> 和 <code>在代码块上加锁</code>。</p>\n<p>先看看如何在方法上加锁：</p>\n<pre><code>public synchronized doSave(String fileUrl) {\n    mkdir();\n    uploadFile(fileUrl);\n    sendMessage(fileUrl);\n}\n</code></pre>\n<p>这里加锁的目的是为了防止并发的情况下，创建了相同的目录，第二次会创建失败，影响业务功能。</p>\n<p>但这种直接在方法上加锁，锁的粒度有点粗。因为doSave方法中的上传文件和发消息方法，是不需要加锁的。只有创建目录方法，才需要加锁。</p>\n<p>我们都知道文件上传操作是非常耗时的，如果将整个方法加锁，那么需要等到整个方法执行完之后才能释放锁。显然，这会导致该方法的性能很差，变得得不偿失。</p>\n<p>这时，我们可以改成在代码块上加锁了，具体代码如下：</p>\n<pre><code>public void doSave(String path,String fileUrl) {\n    synchronized(this) {\n      if(!exists(path)) {\n          mkdir(path);\n       }\n    }\n    uploadFile(fileUrl);\n    sendMessage(fileUrl);\n}\n</code></pre>\n<p>这样改造之后，锁的粒度一下子变小了，只有并发创建目录功能才加了锁。而创建目录是一个非常快的操作，即使加锁对接口的性能影响也不大。</p>\n<p>最重要的是，其他的上传文件和发送消息功能，任然可以并发执行。</p>\n<p>当然，这种做在单机版的服务中，是没有问题的。但现在部署的生产环境，为了保证服务的稳定性，一般情况下，同一个服务会被部署在多个节点中。如果哪天挂了一个节点，其他的节点服务任然可用。</p>\n<p>多节点部署避免了因为某个节点挂了，导致服务不可用的情况。同时也能分摊整个系统的流量，避免系统压力过大。</p>\n<p>同时它也带来了新的问题：synchronized只能保证一个节点加锁是有效的，但如果有多个节点如何加锁呢?</p>\n<p>答：这就需要使用：<code>分布式锁</code>了。目前主流的分布式锁包括：redis分布式锁、zookeeper分布式锁 和 数据库分布式锁。</p>\n<p>由于zookeeper分布式锁的性能不太好，真实业务场景用的不多，这里先不讲。</p>\n<p>下面聊一下redis分布式锁。</p>\n<h3>7.2 redis分布式锁</h3>\n<p>在分布式系统中，由于redis分布式锁相对于更简单和高效，成为了分布式锁的首先，被我们用到了很多实际业务场景当中。</p>\n<p>使用redis分布式锁的伪代码如下：</p>\n<pre><code>public void doSave(String path,String fileUrl) {\n  try {\n    String result = jedis.set(lockKey, requestId, \"NX\", \"PX\", expireTime);\n    if (\"OK\".equals(result)) {\n      if(!exists(path)) {\n         mkdir(path);\n         uploadFile(fileUrl);\n         sendMessage(fileUrl);\n      }\n      return true;\n    }\n  } finally{\n      unlock(lockKey,requestId);\n  }  \n  return false;\n}\n</code></pre>\n<p>跟之前使用<code>synchronized</code>关键字加锁时一样，这里锁的范围也太大了，换句话说就是锁的粒度太粗，这样会导致整个方法的执行效率很低。</p>\n<p>其实只有创建目录的时候，才需要加分布式锁，其余代码根本不用加锁。</p>\n<p>于是，我们需要优化一下代码：</p>\n<pre><code>public void doSave(String path,String fileUrl) {\n   if(this.tryLock()) {\n      mkdir(path);\n   }\n   uploadFile(fileUrl);\n   sendMessage(fileUrl);\n}\n\nprivate boolean tryLock() {\n    try {\n    String result = jedis.set(lockKey, requestId, \"NX\", \"PX\", expireTime);\n    if (\"OK\".equals(result)) {\n      return true;\n    }\n  } finally{\n      unlock(lockKey,requestId);\n  }  \n  return false;\n}\n</code></pre>\n<p>上面代码将加锁的范围缩小了，只有创建目录时才加了锁。这样看似简单的优化之后，接口性能能提升很多。说不定，会有意外的惊喜喔。哈哈哈。</p>\n<p>redis分布式锁虽说好用，但它在使用时，有很多注意的细节，隐藏了很多坑，如果稍不注意很容易踩中。</p>\n<h3>7.3 数据库分布式锁</h3>\n<p>mysql数据库中主要有三种锁：</p>\n<ul><li> <p>表锁：加锁快，不会出现死锁。但锁定粒度大，发生锁冲突的概率最高，并发度最低。</p> </li><li> <p>行锁：加锁慢，会出现死锁。但锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</p> </li><li> <p>间隙锁：开销和加锁时间界于表锁和行锁之间。它会出现死锁，锁定粒度界于表锁和行锁之间，并发度一般。</p> </li></ul>\n<p>并发度越高，意味着接口性能越好。</p>\n<p>所以数据库锁的优化方向是：</p>\n<p>优先使用<code>行锁</code>，其次使用<code>间隙锁</code>，再其次使用<code>表锁</code>。</p>\n<p>赶紧看看，你用对了没？</p>\n<h2>8.分页处理</h2>\n<p>有时候我会调用某个接口批量查询数据，比如：通过用户id批量查询出用户信息，然后给这些用户送积分。</p>\n<p>但如果你一次性查询的用户数量太多了，比如一次查询2000个用户的数据。参数中传入了2000个用户的id，远程调用接口，会发现该用户查询接口经常超时。</p>\n<p>调用代码如下：</p>\n<pre><code>List&lt;User&gt; users = remoteCallUser(ids);\n</code></pre>\n<p>众所周知，调用接口从数据库获取数据，是需要经过网络传输的。如果数据量太大，无论是获取数据的速度，还是网络传输受限于带宽，都会导致耗时时间比较长。</p>\n<p>那么，这种情况要如何优化呢？</p>\n<p>答：<code>分页处理</code>。</p>\n<p>将一次获取所有的数据的请求，改成分多次获取，每次只获取一部分用户的数据，最后进行合并和汇总。</p>\n<p>其实，处理这个问题，要分为两种场景：<code>同步调用</code> 和 <code>异步调用</code>。</p>\n<h3>8.1 同步调用</h3>\n<p>如果在<code>job</code>中需要获取2000个用户的信息，它要求只要能正确获取到数据就好，对获取数据的总耗时要求不太高。</p>\n<p>但对每一次远程接口调用的耗时有要求，不能大于500ms，不然会有邮件预警。</p>\n<p>这时，我们可以同步分页调用批量查询用户信息接口。</p>\n<p>具体示例代码如下：</p>\n<pre><code>List&lt;List&lt;Long&gt;&gt; allIds = Lists.partition(ids,200);\n\nfor(List&lt;Long&gt; batchIds:allIds) {\n   List&lt;User&gt; users = remoteCallUser(batchIds);\n}\n</code></pre>\n<p>代码中我用的<code>google</code>的<code>guava</code>工具中的<code>Lists.partition</code>方法，用它来做分页简直太好用了，不然要巴拉巴拉写一大堆分页的代码。</p>\n<h3>8.2 异步调用</h3>\n<p>如果是在<code>某个接口</code>中需要获取2000个用户的信息，它考虑的就需要更多一些。</p>\n<p>除了需要考虑远程调用接口的耗时之外，还需要考虑该接口本身的总耗时，也不能超时500ms。</p>\n<p>这时候用上面的同步分页请求远程接口，肯定是行不通的。</p>\n<p>那么，只能使用<code>异步调用</code>了。</p>\n<p>代码如下：</p>\n<pre><code>List&lt;List&lt;Long&gt;&gt; allIds = Lists.partition(ids,200);\n\nfinal List&lt;User&gt; result = Lists.newArrayList();\nallIds.stream().forEach((batchIds) -&gt; {\n   CompletableFuture.supplyAsync(() -&gt; {\n        result.addAll(remoteCallUser(batchIds));\n        return Boolean.TRUE;\n    }, executor);\n})\n</code></pre>\n<p>使用CompletableFuture类，多个线程异步调用远程接口，最后汇总结果统一返回。</p>\n<h2>9.加缓存</h2>\n<p>解决接口性能问题，<code>加缓存</code>是一个非常高效的方法。</p>\n<p>但不能为了缓存而缓存，还是要看具体的业务场景。毕竟加了缓存，会导致接口的复杂度增加，它会带来数据不一致问题。</p>\n<p>在有些并发量比较低的场景中，比如用户下单，可以不用加缓存。</p>\n<p>还有些场景，比如在商城首页显示商品分类的地方，假设这里的分类是调用接口获取到的数据，但页面暂时没有做静态化。</p>\n<p>如果查询分类树的接口没有使用缓存，而直接从数据库查询数据，性能会非常差。</p>\n<p>那么如何使用缓存呢？</p>\n<h3>9.1 redis缓存</h3>\n<p>通常情况下，我们使用最多的缓存可能是：<code>redis</code>和<code>memcached</code>。</p>\n<p>但对于java应用来说，绝大多数都是使用的redis，所以接下来我们以redis为例。</p>\n<p>由于在关系型数据库，比如：mysql中，菜单是有上下级关系的。某个四级分类是某个三级分类的子分类，这个三级分类，又是某个二级分类的子分类，而这个二级分类，又是某个一级分类的子分类。</p>\n<p>这种存储结构决定了，想一次性查出这个分类树，并非是一件非常容易的事情。这就需要使用程序递归查询了，如果分类多的话，这个递归是比较耗时的。</p>\n<p>所以，如果每次都直接从数据库中查询分类树的数据，是一个非常耗时的操作。</p>\n<p>这时我们可以使用缓存，大部分情况，接口都直接从缓存中获取数据。操作redis可以使用成熟的框架，比如：jedis和redisson等。</p>\n<p>用jedis伪代码如下：</p>\n<pre><code>String json = jedis.get(key);\nif(StringUtils.isNotEmpty(json)) {\n   CategoryTree categoryTree = JsonUtil.toObject(json);\n   return categoryTree;\n}\nreturn queryCategoryTreeFromDb();\n</code></pre>\n<p>先从redis中根据某个key查询是否有菜单数据，如果有则转换成对象，直接返回。如果redis中没有查到菜单数据，则再从数据库中查询菜单数据，有则返回。</p>\n<p>此外，我们还需要有个job每隔一段时间，从数据库中查询菜单数据，更新到redis当中，这样以后每次都能直接从redis中获取菜单的数据，而无需访问数据库了。</p>\n<p style=\"text-align:center;\"><img alt=\"be0d43a3c79c46d799f3eb425dd6ee68.png\" src=\"image\\be0d43a3c79c46d799f3eb425dd6ee68.png\"/> </p>\n<p>这样改造之后，能快速的提升性能。</p>\n<p>但这样做性能提升不是最佳的，还有其他的方案，我们一起看看下面的内容。</p>\n<h3>9.2 二级缓存</h3>\n<p>上面的方案是基于redis缓存的，虽说redis访问速度很快。但毕竟是一个远程调用，而且菜单树的数据很多，在网络传输的过程中，是有些耗时的。</p>\n<p>有没有办法，不经过请求远程，就能直接获取到数据呢？</p>\n<p>答：使用<code>二级缓存</code>，即基于内存的缓存。</p>\n<p>除了自己手写的内存缓存之后，目前使用比较多的内存缓存框架有：guava、Ehcache、caffine等。</p>\n<p>我们在这里以<code>caffeine</code>为例，它是spring官方推荐的。</p>\n<p>第一步，引入caffeine的相关jar包</p>\n<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt;\n    &lt;artifactId&gt;caffeine&lt;/artifactId&gt;\n    &lt;version&gt;2.6.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n<p>第二步，配置CacheManager，开启EnableCaching</p>\n<pre><code>@Configuration\n@EnableCaching\npublic class CacheConfig {\n    @Bean\n    public CacheManager cacheManager(){\n        CaffeineCacheManager cacheManager = new CaffeineCacheManager();\n        //Caffeine配置\n        Caffeine&lt;Object, Object&gt; caffeine = Caffeine.newBuilder()\n                //最后一次写入后经过固定时间过期\n                .expireAfterWrite(10, TimeUnit.SECONDS)\n                //缓存的最大条数\n                .maximumSize(1000);\n        cacheManager.setCaffeine(caffeine);\n        return cacheManager;\n    }\n}\n</code></pre>\n<p>第三步，使用Cacheable注解获取数据</p>\n<pre><code>@Service\npublic class CategoryService {\n   \n   @Cacheable(value = \"category\", key = \"#categoryKey\")\n   public CategoryModel getCategory(String categoryKey) {\n      String json = jedis.get(categoryKey);\n      if(StringUtils.isNotEmpty(json)) {\n         CategoryTree categoryTree = JsonUtil.toObject(json);\n         return categoryTree;\n      }\n      return queryCategoryTreeFromDb();\n   }\n}\n</code></pre>\n<p>调用categoryService.getCategory()方法时，先从caffine缓存中获取数据，如果能够获取到数据，则直接返回该数据，不进入方法体。</p>\n<p>如果不能获取到数据，则再从redis中查一次数据。如果查询到了，则返回数据，并且放入caffine中。</p>\n<p>如果还是没有查到数据，则直接从数据库中获取到数据，然后放到caffine缓存中。</p>\n<p>具体流程图如下：</p>\n<p style=\"text-align:center;\"><img alt=\"8eae70f4082b42e7a78fe713d5e3185e.png\" src=\"image\\8eae70f4082b42e7a78fe713d5e3185e.png\"/> </p>\n<p>该方案的性能更好，但有个缺点就是，如果数据更新了，不能及时刷新缓存。此外，如果有多台服务器节点，可能存在各个节点上数据不一样的情况。</p>\n<p>由此可见，二级缓存给我们带来性能提升的同时，也带来了数据不一致的问题。使用二级缓存一定要结合实际的业务场景，并非所有的业务场景都适用。</p>\n<p>但上面我列举的分类场景，是适合使用二级缓存的。因为它属于用户不敏感数据，即使出现了稍微有点数据不一致也没有关系，用户有可能都没有察觉出来。</p>\n<h2>10. 分库分表</h2>\n<p>有时候，接口性能受限的不是别的，而是数据库。</p>\n<p>当系统发展到一定的阶段，用户并发量大，会有大量的数据库请求，需要占用大量的数据库连接，同时会带来磁盘IO的性能瓶颈问题。</p>\n<p>此外，随着用户数量越来越多，产生的数据也越来越多，一张表有可能存不下。由于数据量太大，sql语句查询数据时，即使走了索引也会非常耗时。</p>\n<p>这时该怎么办呢？</p>\n<p>答：需要做<code>分库分表</code>。</p>\n<p>如下图所示：</p>\n<p style=\"text-align:center;\"><img alt=\"1b99881a1385439097ef4f59ff813eef.png\" src=\"image\\1b99881a1385439097ef4f59ff813eef.png\"/> </p>\n<p>图中将用户库拆分成了三个库，每个库都包含了四张用户表。</p>\n<p>如果有用户请求过来的时候，先根据用户id路由到其中一个用户库，然后再定位到某张表。</p>\n<p>路由的算法挺多的：</p>\n<ul><li> <p><code>根据id取模</code>，比如：id=7，有4张表，则7%4=3，模为3，路由到用户表3。</p> </li><li> <p><code>给id指定一个区间范围</code>，比如：id的值是0-10万，则数据存在用户表0，id的值是10-20万，则数据存在用户表1。</p> </li><li> <p><code>一致性hash算法</code></p> </li></ul>\n<p>分库分表主要有两个方向：<code>垂直</code>和<code>水平</code>。</p>\n<p>说实话垂直方向（即业务方向）更简单。</p>\n<p>在水平方向（即数据方向）上，分库和分表的作用，其实是有区别的，不能混为一谈。</p>\n<ul><li> <p><code>分库</code>：是为了解决数据库连接资源不足问题，和磁盘IO的性能瓶颈问题。</p> </li><li> <p><code>分表</code>：是为了解决单表数据量太大，sql语句查询数据时，即使走了索引也非常耗时问题。此外还可以解决消耗cpu资源问题。</p> </li><li> <p><code>分库分表</code>：可以解决 数据库连接资源不足、磁盘IO的性能瓶颈、检索数据耗时 和 消耗cpu资源等问题。</p> </li></ul>\n<p>如果在有些业务场景中，用户并发量很大，但是需要保存的数据量很少，这时可以只分库，不分表。</p>\n<p>如果在有些业务场景中，用户并发量不大，但是需要保存的数量很多，这时可以只分表，不分库。</p>\n<p>如果在有些业务场景中，用户并发量大，并且需要保存的数量也很多时，可以分库分表。</p>\n<h2>11. 辅助功能</h2>\n<p>优化接口性能问题，除了上面提到的这些常用方法之外，还需要配合使用一些辅助功能，因为它们真的可以帮我们提升查找问题的效率。</p>\n<h3>11.1 开启慢查询日志</h3>\n<p>通常情况下，为了定位sql的性能瓶颈，我们需要开启mysql的慢查询日志。把超过指定时间的sql语句，单独记录下来，方面以后分析和定位问题。</p>\n<p>开启慢查询日志需要重点关注三个参数：</p>\n<ul><li> <p><code>slow_query_log</code> 慢查询开关</p> </li><li> <p><code>slow_query_log_file</code> 慢查询日志存放的路径</p> </li><li> <p><code>long_query_time</code> 超过多少秒才会记录日志</p> </li></ul>\n<p>通过mysql的<code>set</code>命令可以设置：</p>\n<pre><code>set global slow_query_log='ON'; \nset global slow_query_log_file='/usr/local/mysql/data/slow.log';\nset global long_query_time=2;\n</code></pre>\n<p>设置完之后，如果某条sql的执行时间超过了2秒，会被自动记录到slow.log文件中。</p>\n<p>当然也可以直接修改配置文件<code>my.cnf</code></p>\n<pre><code>[mysqld]\nslow_query_log = ON\nslow_query_log_file = /usr/local/mysql/data/slow.log\nlong_query_time = 2\n</code></pre>\n<p>但这种方式需要重启mysql服务。</p>\n<p>很多公司每天早上都会发一封慢查询日志的邮件，开发人员根据这些信息优化sql。</p>\n<h3>11.2 加监控</h3>\n<p>为了出现sql问题时，能够让我们及时发现，我们需要对系统做<code>监控</code>。</p>\n<p>目前业界使用比较多的开源监控系统是：<code>Prometheus</code>。</p>\n<p>它提供了 <code>监控</code> 和 <code>预警</code> 的功能。</p>\n<p>架构图如下：</p>\n<p style=\"text-align:center;\"><img alt=\"b939f466d69f455f933ddee6be460ef5.png\" src=\"image\\b939f466d69f455f933ddee6be460ef5.png\"/> </p>\n<p>我们可以用它监控如下信息：</p>\n<ul><li> <p>接口响应时间</p> </li><li> <p>调用第三方服务耗时</p> </li><li> <p>慢查询sql耗时</p> </li><li> <p>cpu使用情况</p> </li><li> <p>内存使用情况</p> </li><li> <p>磁盘使用情况</p> </li><li> <p>数据库使用情况</p> </li></ul>\n<p>等等。。。</p>\n<p>它的界面大概长这样子：</p>\n<p style=\"text-align:center;\"><img alt=\"36de46088d714d4b83c3cffb9271e3f0.png\" src=\"image\\36de46088d714d4b83c3cffb9271e3f0.png\"/> </p>\n<p>可以看到mysql当前qps，活跃线程数，连接数，缓存池的大小等信息。</p>\n<p>如果发现数据量连接池占用太多，对接口的性能肯定会有影响。</p>\n<p>这时可能是代码中开启了连接忘了关，或者并发量太大了导致的，需要做进一步排查和系统优化。</p>\n<p>截图中只是它一小部分功能，如果你想了解更多功能，可以访问Prometheus的官网：https://prometheus.io/</p>\n<h3>11.3 链路跟踪</h3>\n<p>有时候某个接口涉及的逻辑很多，比如：查数据库、查redis、远程调用接口，发mq消息，执行业务代码等等。</p>\n<p>该接口一次请求的链路很长，如果逐一排查，需要花费大量的时间，这时候，我们已经没法用传统的办法定位问题了。</p>\n<p>有没有办法解决这问题呢？</p>\n<p>用分布式链路跟踪系统：<code>skywalking</code>。</p>\n<p>架构图如下：</p>\n<p style=\"text-align:center;\"><img alt=\"1cbf0ac63cdb4e8bb2accd06eb8002b9.png\" src=\"image\\1cbf0ac63cdb4e8bb2accd06eb8002b9.png\"/> </p>\n<p><img alt=\"e2f139a7f39144fbb08852ecc60edbfd.png\" src=\"image\\e2f139a7f39144fbb08852ecc60edbfd.png\"/>通过skywalking定位性能问题：<img alt=\"67bec4274b9645c1888d9dba16526a17.png\" src=\"image\\67bec4274b9645c1888d9dba16526a17.png\"/></p>\n<p>在skywalking中可以通过<code>traceId</code>（全局唯一的id），串联一个接口请求的完整链路。可以看到整个接口的耗时，调用的远程服务的耗时，访问数据库或者redis的耗时等等，功能非常强大。</p>\n<p>之前没有这个功能的时候，为了定位线上接口性能问题，我们还需要在代码中加日志，手动打印出链路中各个环节的耗时情况，然后再逐一排查。</p>\n<p>如果你用过skywalking排查接口性能问题，不自觉的会爱上它的。如果你想了解更多功能，可以访问skywalking的官网。</p>\n<h3>最后说一句(求关注，别白嫖我)</h3>\n<p> </p>\n<p> </p>\n</div>\n</div>"}