{"blogid": "121301896", "writerAge": "码龄10年", "writerBlogNum": "219", "writerCollect": "18336", "writerComment": "2039", "writerFan": "61112", "writerGrade": "8级", "writerIntegral": "27672", "writerName": "PKing666666", "writerProfileAdress": "writer_image\\profile_121301896.jpg", "writerRankTotal": "252", "writerRankWeekly": "169", "writerThumb": "5200", "writerVisitNum": "4180745", "blog_read_count": "68095", "blog_time": "已于 2022-08-20 18:11:50 修改", "blog_title": "双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h1 id=\"%E5%8F%8C%E7%9B%AE%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%B3%BB%E7%BB%9F(%E5%8F%8C%E7%9B%AE%E6%A0%87%E5%AE%9A%2B%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3%2B%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%2B%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA)Pyhton\">双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python</h1>\n<hr/>\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"%E5%8F%8C%E7%9B%AE%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%B3%BB%E7%BB%9F(%E5%8F%8C%E7%9B%AE%E6%A0%87%E5%AE%9A%2B%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3%2B%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%2B%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA)Pyhton-toc\" style=\"margin-left:0px;\"><a href=\"#%E5%8F%8C%E7%9B%AE%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%B3%BB%E7%BB%9F%28%E5%8F%8C%E7%9B%AE%E6%A0%87%E5%AE%9A%2B%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3%2B%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%2B%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%29Pyhton\">双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python</a></p>\n<p id=\"1.%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84-toc\" style=\"margin-left:40px;\"><a href=\"#1.%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84\">1.项目结构</a></p>\n<p id=\"2.%20Environment-toc\" style=\"margin-left:40px;\"><a href=\"#2.%20Environment\">2. Environment</a></p>\n<p id=\"3.%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86-toc\" style=\"margin-left:40px;\"><a href=\"#3.%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">3.双目相机标定和校准</a></p>\n<p id=\"(0)%C2%A0%E5%8F%8C%E7%9B%AE%E6%91%84%E5%83%8F%E5%A4%B4-toc\" style=\"margin-left:80px;\"><a href=\"#%280%29%C2%A0%E5%8F%8C%E7%9B%AE%E6%91%84%E5%83%8F%E5%A4%B4\">(0) 双目摄像头</a></p>\n<p id=\"(1)%20%E9%87%87%E9%9B%86%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%9A%84%E5%B7%A6%E5%8F%B3%E8%A7%86%E5%9B%BE-toc\" style=\"margin-left:80px;\"><a href=\"#%281%29%20%E9%87%87%E9%9B%86%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%9A%84%E5%B7%A6%E5%8F%B3%E8%A7%86%E5%9B%BE\">(1) 采集标定板的左右视图</a></p>\n<p id=\"(2)%C2%A0%E5%8D%95%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86-toc\" style=\"margin-left:80px;\"><a href=\"#%282%29%C2%A0%E5%8D%95%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">(2) 单目相机标定和校准</a></p>\n<p id=\"(3)%C2%A0%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86-toc\" style=\"margin-left:80px;\"><a href=\"#%283%29%C2%A0%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">(3) 双目相机标定和校准</a></p>\n<p id=\"4.%E8%A7%86%E5%B7%AE%E5%9B%BE%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%9B%BE-toc\" style=\"margin-left:40px;\"><a href=\"#4.%E8%A7%86%E5%B7%AE%E5%9B%BE%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%9B%BE\">4.视差图和深度图</a></p>\n<p id=\"(1)%20%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3-toc\" style=\"margin-left:80px;\"><a href=\"#%281%29%20%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3\">(1) 立体校正</a></p>\n<p id=\"%C2%A0(2)%C2%A0%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E4%B8%8E%E8%A7%86%E5%B7%AE%E5%9B%BE%E8%AE%A1%E7%AE%97-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A0%282%29%C2%A0%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E4%B8%8E%E8%A7%86%E5%B7%AE%E5%9B%BE%E8%AE%A1%E7%AE%97\">(2) 立体匹配与视差图计算</a></p>\n<p id=\"%C2%A0(2)%20OpenCV%E5%AE%9E%E7%8E%B0-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A0%282%29%20OpenCV%E5%AE%9E%E7%8E%B0\">(3) Demo</a></p>\n<p id=\"5.%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D-toc\" style=\"margin-left:40px;\"><a href=\"#5.%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D\">5.双目测距</a></p>\n<p id=\"6.3D%E7%82%B9%E4%BA%91-toc\" style=\"margin-left:40px;\"><a href=\"#6.3D%E7%82%B9%E4%BA%91\">6.3D点云显示</a></p>\n<p id=\"%C2%A07.Demo-toc\" style=\"margin-left:40px;\"><a href=\"#%C2%A07.Demo\">7.项目代码</a></p>\n<p id=\"7.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-toc\" style=\"margin-left:40px;\"><a href=\"#7.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\">8.参考资料</a></p>\n<hr/>\n<p>本篇博客将实现Python版本的双目三维重建系统，项目代码实现包含<span style=\"color:#fe2c24;\"><strong>：`双目标定`，`立体校正（含消除畸变)`，`立体匹配`，`视差计算`和`深度距离计算/3D坐标计算` </strong></span>的知识点。限于篇幅，本博客不会过多赘述算法原理，而是手把手教你，如何搭建一套属于自己的双目三维重建的系统。项目代码包含：</p>\n<ul><li>支持双USB连接线的双目摄像头</li><li>支持单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)</li><li>支持单目相机标定:mono_camera_calibration.py ，无需Matlab标定</li><li>支持双目相机标定:stereo_camera_calibration.py，无需Matlab标定</li><li>支持使用<span style=\"color:#fe2c24;\"><strong>WLS滤波器对视差图进行滤波</strong></span></li><li><strong><span style=\"color:#fe2c24;\">支持双目测距，误差在1cm内</span></strong>(鼠标点击图像即可获得其深度距离)</li><li>支持Open3D和PCL点云显示</li></ul>\n<p>诚然，网上有很多双测距的代码，但项目都不是十分完整，而且恢复视差图效果也一般，难以达到商业实际应用，究其原因，主要有下面2个：</p>\n<ol><li>双目摄像头质量问题，</li><li>双目标定存在问题，导致校准误差较大</li><li>没有使用<span style=\"color:#fe2c24;\"><strong>WLS滤波器对视差图进行滤波，该方法可以极大提高视差图的效果</strong></span></li></ol>\n<p>【<strong><a class=\"link-info\" href=\"https://panjinquan.blog.csdn.net/article/details/121301896\" title=\"尊重原创，转载请注明出处\">尊重原创，转载请注明出处</a></strong>】：<a href=\"https://panjinquan.blog.csdn.net/article/details/121301896\" title=\"https://panjinquan.blog.csdn.net/article/details/121301896\">https://panjinquan.blog.csdn.net/article/details/121301896</a></p>\n<p>【<span style=\"color:#be191c;\"><strong>完整的项目代码】</strong></span><a href=\"https://mp.weixin.qq.com/s/any-zhYmhZ1eEoB9RCM6nA\" title=\"双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码\">双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码</a></p>\n<p>先放一张动图，这是最终重建的效果：</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/53cf049177734c9d93cc087296ac8eed.gif\"/></p>\n<p>三维重建中，除了双目相机，还有TOF和结构光3D 相机</p>\n<blockquote>\n<ol><li> <p><strong>飞行时间(Time of flight,TOF)</strong>，代表公司微软Kinect2，PMD，SoftKinect， 联想 Phab，在手机中一般用于3D建模、AR应用，AR测距(华为TOF镜头)</p> </li><li> <p><strong>双目视觉(Stereo Camera)</strong>，代表公司 Leap Motion， ZED， 大疆;</p> </li><li> <p><strong>结构光(Structured-light)</strong>，代表公司有奥比中光，苹果<strong>iPhone X</strong>(Prime Sense)，微软 Kinect1，英特尔RealSense, Mantis Vision 等，在手机（<strong>iPhone，华为</strong>）中3D结构光主要用于人脸解锁、支付、美颜等场景。</p> </li></ol>\n</blockquote>\n<p>关于3D相机技术(飞行时间+双目+结构光)的区别，可以参考我的一篇博客《<a class=\"link-info\" href=\"https://panjinquan.blog.csdn.net/article/details/119649838\" title=\"3D相机技术调研(飞行时间TOF+双目+结构光)\">3D相机技术调研(飞行时间TOF+双目+结构光)</a>》：</p>\n<p><a class=\"has-card\" href=\"https://panjinquan.blog.csdn.net/article/details/119649838\" title=\"3D相机技术调研(飞行时间TOF+双目+结构光)_pan_jinquan的博客-CSDN博客\"><span class=\"link-card-box\"><span class=\"link-title\">3D相机技术调研(飞行时间TOF+双目+结构光)_pan_jinquan的博客-CSDN博客</span><span class=\"link-desc\">1.深度估计3D相机方案目前市面上常有的 3D 相机方案就就是这3种：飞行时间(Time of flight,TOF)，代表公司微软Kinect2，PMD，SoftKinect， 联想 Phab，在手机中一般用于3D建模、AR应用，AR测距(华为TOF镜头)双目视觉(Stereo Camera)，代表公司 Leap Motion， ZED， 大疆;结构光(Structured-light)，代表公司有奥比中光，苹果iPhone X(Prime Sense)，微软Kin..</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"https://g.csdnimg.cn/static/logo/favicon32.ico\"/>https://panjinquan.blog.csdn.net/article/details/119649838</span></span></a>如果你对结构光三维重建感兴趣，可参考鄙人的博客《<a class=\"link-info\" href=\"https://panjinquan.blog.csdn.net/article/details/121113787\" title=\"结构光三维重建-3D Scanning Software实现三维重建\">结构光三维重建-3D Scanning Software实现三维重建</a>》</p>\n<p><a class=\"has-card\" href=\"https://panjinquan.blog.csdn.net/article/details/121113787\" title=\"结构光三维重建-3D Scanning Software实现三维重建_pan_jinquan的博客-CSDN博客\"><span class=\"link-card-box\"><span class=\"link-title\">结构光三维重建-3D Scanning Software实现三维重建_pan_jinquan的博客-CSDN博客</span><span class=\"link-desc\">结构光相机标定-3D Scanning Software使用1. 说明2.Requirements（1）下载相关文件（2）3D Scanning Software源码编译3. Data capture（1）运行程序：scan3d-capture（2）采集校准图片：Capture calibration images（3） 进行校准：Calibration4.扫描模型：Model Scannin</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"https://g.csdnimg.cn/static/logo/favicon32.ico\"/>https://panjinquan.blog.csdn.net/article/details/121113787</span></span></a></p>\n<hr/>\n<h2 id=\"1.%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84\">1.项目结构</h2>\n<p><img alt=\"\" height=\"378\" src=\"image\\841f1927eb494d43bc42f83387964bd2.png\" width=\"792\"/></p>\n<p></p>\n<pre><code class=\"language-bash\">.\n├── config       # 相机参数文件\n├── core         # 相机核心算法包\n├── data         # 相机采集的数据\n├── demo         # demo文件\n├── libs         # 第三方依赖包\n├── scripts      # 脚本\n│   ├── mono_camera_calibration.sh     # 单目相机校准Linux脚本\n│   ├── mono_camera_calibration.bat    # 单目相机校准Windows脚本\n│   ├── stereo_camera_calibration.sh   # 双目相机校准Linux脚本\n│   └── stereo_camera_calibration.bat  # 双目相机校准Windows脚本\n├── get_stereo_images.py                      # 采集标定文件\n├── mono_camera_calibration.py                # 单目相机标定\n├── stereo_camera_calibration.py              # 双目相机标定\n└── README.md\n\n</code></pre>\n<hr/>\n<h2 id=\"2.%20Environment\">2. Environment</h2>\n<ul><li>依赖包，可参考requirements.txt</li><li>python-pcl (<span style=\"color:#fe2c24;\">安装python-pcl需要一丢丢耐心，实在不行，就用open3d吧</span>)</li><li>open3d-python=0.7.0.0</li><li>opencv-python</li><li>opencv-contrib-python</li></ul>\n<hr/>\n<h2 id=\"3.%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">3.双目相机标定和校准</h2>\n<h3 id=\"(0)%C2%A0%E5%8F%8C%E7%9B%AE%E6%91%84%E5%83%8F%E5%A4%B4\">(0) 双目摄像头</h3>\n<p>下面这款双目摄像头（RGB+RGB）是在某宝购买的（几百元，链接就不发了，免得说我打广告），作为本项目的双目相机，其基线是固定的6cm，是单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)，基本满足我们测试需求。一般基线越长，可测量的距离越远，网友也可以根据自己需要购买。</p>\n<p><strong>一点注意事项</strong>：</p>\n<blockquote>\n<ol><li>双目相机三维重建也可以使用RGB+IR(红外)的摄像头，甚至IR+IR的也是可以，本人亲测，RGB+IR的相机，其效果也是杠杠的。</li><li>基线不太建议太小，作为测试，一般baseline在3~9cm就可以满足需求，有些无人车的双目基线更是恐怖到1~2米长</li><li>从双目三维重建原理中可知，左右摄像头的成像平面尽可能在一个平面内，成像平面不在同一个平面的，尽管可以立体矫正，其效果也差很多。</li><li>一分钱，一分货，相机的质量好坏，直接决定了你的成像效果</li></ol>\n</blockquote>\n<p><img alt=\"\" height=\"250\" src=\"image\\933fbf588e014e238ffbf2ec56d0b5f2.png\" width=\"701\"/></p>\n<p></p>\n<h3 id=\"(1)%20%E9%87%87%E9%9B%86%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%9A%84%E5%B7%A6%E5%8F%B3%E8%A7%86%E5%9B%BE\">(1) 采集标定板的左右视图</h3>\n<ul><li>采集数据前，请<strong>调节相机焦距</strong>，尽可能保证视图中标定板清洗可见</li><li>采集棋盘格图像时，标定板一般占视图1/2到1/3左右</li><li>一般采集15~30张左右</li></ul>\n<pre><code class=\"language-bash\">width=8                \nheight=11\nleft_video=0\nright_video=-1\nsave_dir=\"data/camera\"\ndetect=True\n\npython get_stereo_images.py \\\n    --left_video $left_video \\\n    --right_video $right_video \\\n    --width $width  \\\n    --height $height  \\\n    --save_dir $save_dir \\\n    --detect $detect \\\n</code></pre>\n<p>参数说明： </p>\n<blockquote>\n<ol><li>参数width指的是<strong>棋盘格宽方向黑白格子相交点个数</strong></li><li>参数height指的是<strong>棋盘格长方向黑白格子相交点个数</strong></li><li>参数left_video是左路相机ID，一般就是相机连接主板的USB接口号</li><li>参数right_video是右路相机ID，一般就是相机连接主板的USB接口号</li><li>PS：如果你的双目相机是单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)，则设置left_video=相机ID，而right_video=-1，</li><li>参数<code>detect</code>建议设置<code>True</code>，这样可实时检测棋盘格，方面调整角度</li><li><span style=\"color:#fe2c24;\">按键盘<code>s</code>或者<code>c</code>保存左右视图图片</span></li></ol>\n</blockquote>\n<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\"><tbody><tr><td style=\"text-align:center;\"><strong>left_image</strong></td><td style=\"text-align:center;\"><strong>right_image</strong></td></tr><tr><td><img alt=\"\" src=\"image\\ac3c129377e14373b1658153a9f8ae2a.png\"/></td><td><img alt=\"\" src=\"image\\2af86ffcae3d478a9be587e5aecd29bd.png\"/></td></tr></tbody></table>\n<p> 下面是采集双目摄像头标定板左右视图的Python代码：get_stereo_images.py，除了OpenCV，没啥依赖，直接干就完事。</p>\n<pre><code class=\"language-python\">import os\nimport argparse\nimport cv2\n\n\nclass StereoCamera(object):\n    \"\"\"采集双目标定图片，按键盘【c】或【s】保存图片\"\"\"\n\n    def __init__(self, chess_width, chess_height, detect=False):\n        \"\"\"\n        :param chess_width: chessboard width size，即棋盘格宽方向黑白格子相交点个数，\n        :param chess_height: chessboard height size，即棋盘格长方向黑白格子相交点个数\n        :param detect: 是否实时检测棋盘格，方便采集数据\n        \"\"\"\n        self.chess_width = chess_width\n        self.chess_height = chess_height\n        self.detect = detect\n        self.criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n\n    def detect_chessboard(self, image):\n        \"\"\"检测棋盘格\"\"\"\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        ret, corners = cv2.findChessboardCorners(gray, (self.chess_width, self.chess_height), None)\n        if ret:\n            # 角点精检测\n            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), self.criteria)\n            # Draw and display the corners\n            image = cv2.drawChessboardCorners(image, (self.chess_width, self.chess_height), corners2, ret)\n        return image\n\n    def capture2(self, left_video, right_video, save_dir):\n        \"\"\"\n        用于采集双USB连接线的双目摄像头\n        :param left_video:int or str,左路视频路径或者摄像头ID\n        :param right_video:int or str,右视频路径或者摄像头ID\n        :param save_dir: str,保存左右图片的路径\n        :return:\n        \"\"\"\n        self.create_file(save_dir)\n        capL = cv2.VideoCapture(left_video)\n        capR = cv2.VideoCapture(right_video)\n        widthL, heightL, numFramesL, fpsL = self.get_video_info(capL)\n        widthR, heightR, numFramesR, fpsR = self.get_video_info(capR)\n        print(\"capL:\\n\", widthL, heightL, numFramesL, fpsL)\n        print(\"capR:\\n\", widthR, heightR, numFramesR, fpsR)\n        save_videoL = self.create_file(save_dir, \"video\", \"left_video.avi\")\n        save_videoR = self.create_file(save_dir, \"video\", \"right_video.avi\")\n        writerL = self.get_video_writer(save_videoL, widthL, heightL, fpsL)\n        writerR = self.get_video_writer(save_videoR, widthR, heightR, fpsR)\n        i = 0\n        while True:\n            isuccessL, frameL = capL.read()\n            isuccessR, frameR = capR.read()\n            if not (isuccessL and isuccessR):\n                print(\"No more frames\")\n                break\n            if self.detect:\n                l = self.detect_chessboard(frameL.copy())\n                r = self.detect_chessboard(frameR.copy())\n            else:\n                l = frameL.copy()\n                r = frameR.copy()\n            cv2.imshow('left', l)\n            cv2.imshow('right', r)\n            key = cv2.waitKey(10)\n            if key == ord('q'):\n                break\n            elif key == ord('c') or key == ord('s'):\n                print(\"save image:{:0=3d}\".format(i))\n                cv2.imwrite(os.path.join(save_dir, \"left_{:0=3d}.png\".format(i)), frameL)\n                cv2.imwrite(os.path.join(save_dir, \"right_{:0=3d}.png\".format(i)), frameR)\n                i += 1\n            writerL.write(frameL)\n            writerR.write(frameR)\n        capL.release()\n        capR.release()\n        cv2.destroyAllWindows()\n\n    def capture1(self, video, save_dir):\n        \"\"\"\n        用于采集单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        :param video:int or str,视频路径或者摄像头ID\n        :param save_dir: str,保存左右图片的路径\n        \"\"\"\n        self.create_file(save_dir)\n        cap = cv2.VideoCapture(video)\n        width, height, numFrames, fps = self.get_video_info(cap)\n        print(\"capL:\\n\", width, height, numFrames, fps)\n        save_videoL = self.create_file(save_dir, \"video\", \"left_video.avi\")\n        save_videoR = self.create_file(save_dir, \"video\", \"right_video.avi\")\n        writerL = self.get_video_writer(save_videoL, int(width / 2), height, fps)\n        writerR = self.get_video_writer(save_videoR, int(width / 2), height, fps)\n        i = 0\n        while True:\n            isuccess, frame = cap.read()\n            if not isuccess:\n                print(\"No more frames\")\n                break\n            # 分离左右摄像头\n            frameL = frame[:, :int(width / 2), :]\n            frameR = frame[:, int(width / 2):, :]\n            if self.detect:\n                l = self.detect_chessboard(frameL.copy())\n                r = self.detect_chessboard(frameR.copy())\n            else:\n                l = frameL.copy()\n                r = frameR.copy()\n            cv2.imshow('left', l)\n            cv2.imshow('right', r)\n            key = cv2.waitKey(10)\n            if key == ord('q'):\n                break\n            elif key == ord('c') or key == ord('s'):\n                print(\"save image:{:0=3d}\".format(i))\n                cv2.imwrite(os.path.join(save_dir, \"left_{:0=3d}.png\".format(i)), frameL)\n                cv2.imwrite(os.path.join(save_dir, \"right_{:0=3d}.png\".format(i)), frameR)\n                i += 1\n            writerL.write(frameL)\n            writerR.write(frameR)\n        cap.release()\n        cv2.destroyAllWindows()\n\n    @staticmethod\n    def get_video_info(video_cap):\n        width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        numFrames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n        return width, height, numFrames, fps\n\n    @staticmethod\n    def get_video_writer(save_path, width, height, fps):\n        if not os.path.exists(os.path.dirname(save_path)):\n            os.makedirs(os.path.dirname(save_path))\n        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n        frameSize = (int(width), int(height))\n        video_writer = cv2.VideoWriter(save_path, fourcc, fps, frameSize)\n        print(\"video:width:{},height:{},fps:{}\".format(width, height, fps))\n        return video_writer\n\n    @staticmethod\n    def create_file(parent_dir, dir1=None, filename=None):\n        out_path = parent_dir\n        if dir1:\n            out_path = os.path.join(parent_dir, dir1)\n        if not os.path.exists(out_path):\n            os.makedirs(out_path)\n        if filename:\n            out_path = os.path.join(out_path, filename)\n        return out_path\n\n\ndef str2bool(v):\n    return v.lower() in ('yes', 'true', 't', 'y', '1')\n\n\ndef get_parser():\n    width = 8\n    height = 11\n    left_video = -1\n    right_video = 0\n    save_dir = \"data/camera\"\n    parser = argparse.ArgumentParser(description='Camera calibration')\n    parser.add_argument('--width', type=int, default=width, help='chessboard width size')\n    parser.add_argument('--height', type=int, default=height, help='chessboard height size')\n    parser.add_argument('--left_video', type=int, default=left_video, help='left video file or camera ID')\n    parser.add_argument('--right_video', type=int, default=right_video, help='right video file or camera ID')\n    parser.add_argument('--detect', type=str2bool, nargs='?', const=True, help='detect chessboard ')\n    parser.add_argument('--save_dir', type=str, default=save_dir, help='YML file to save calibrate matrices')\n    return parser\n\n\nif __name__ == '__main__':\n    args = get_parser().parse_args()\n    stereo = StereoCamera(args.width, args.height, detect=args.detect)\n    if args.left_video &gt; -1 and args.right_video &gt; -1:\n        # 双USB连接线的双目摄像头\n        stereo.capture2(left_video=args.left_video, right_video=args.right_video, save_dir=args.save_dir)\n    elif args.left_video &gt; -1:\n        # 单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        stereo.capture1(video=args.left_video, save_dir=args.save_dir)\n    elif args.right_video &gt; -1:\n        # 单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        stereo.capture1(video=args.right_video, save_dir=args.save_dir)\n    else:\n        raise Exception(\"Error: Check your camera{}\".format(args.left_video, args.right_video))\n</code></pre>\n<blockquote>\n<p>双目标定的目标是获得左右两个相机的内参、外参和畸变系数，其中内参包括左右相机的fx，fy，cx，cy，外参包括左相机相对于右相机的旋转矩阵和平移向量，畸变系数包括径向畸变系数（k1， k2，k3）和切向畸变系数（p1，p2）。</p>\n<p>双目标定工具最常用的莫过于是MATLAB的工具箱： Stereo Camera Calibrator App，网上有太多教程，我就不赘述了。</p>\n</blockquote>\n<p>我采用的是Deepin系统，懒得去安装Matlab了，所以就参考各路神仙，使用OpenCV实现了单目和双目的标定程序。</p>\n<h3 id=\"(2)%C2%A0%E5%8D%95%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">(2) 单目相机标定和校准</h3>\n<pre><code class=\"language-bash\"># Linux\nbash scripts/mono_camera_calibration.sh\n# windows\nscripts/mono_camera_calibration.bat</code></pre>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\nimage_dir=data/lenacv-camera # 棋盘格图片\nsave_dir=configs/lenacv-camera # 保存标定结果\nwidth=8\nheight=11\nsquare_size=20 #mm\nimage_format=png # 图片格式，如png,jpg\nshow=True # 是否显示检测结果\n# left camera calibration\npython mono_camera_calibration.py \\\n    --image_dir  $image_dir \\\n    --image_format $image_format  \\\n    --square_size $square_size  \\\n    --width $width  \\\n    --height $height  \\\n    --prefix left  \\\n    --save_dir $save_dir \\\n    --show $show\n\n# right camera calibration\npython mono_camera_calibration.py \\\n    --image_dir  $image_dir \\\n    --image_format  $image_format  \\\n    --square_size $square_size  \\\n    --width $width  \\\n    --height $height  \\\n    --prefix right  \\\n    --save_dir $save_dir \\\n    --show $show</code></pre>\n<p>一点注意事项： </p>\n<blockquote>\n<ul><li>标定代码会显示每一张图像的棋盘格的角点检测效果，如果发现有检测不到，或者角点检测出错，则需要自己手动删除这些图像，避免引入太大的误差</li><li>若误差超过0.1，建议重新调整摄像头并标定，不然效果会差很多</li></ul>\n</blockquote>\n<p><img alt=\"\" height=\"644\" src=\"image\\faf200ae85ec4c6c974c1027995c30e4.png\" width=\"830\"/></p>\n<p> 执行后，在<code>$save_dir</code>目录下会生成<code>left_cam.yml</code>和<code>right_cam.yml</code>左右相机参数文件</p>\n<pre><code class=\"language-bash\">%YAML:1.0\n---\nK: !!opencv-matrix\n   rows: 3\n   cols: 3\n   dt: d\n   data: [ 7.6327773983725410e+02, 0., 2.8768149780495781e+02, 0.,\n       7.6350419482076416e+02, 2.1897333674659842e+02, 0., 0., 1. ]\nD: !!opencv-matrix\n   rows: 1\n   cols: 5\n   dt: d\n   data: [ 3.5020967324140520e-02, -4.0770563420764315e-02,\n       -4.4231047037511739e-04, -1.0552565305999332e-03,\n       -9.7750323762439514e-02 ]\n</code></pre>\n<blockquote>\n<p>其中K是相机内参矩阵，D是畸变系数矩阵</p>\n</blockquote>\n<h3 id=\"(3)%C2%A0%E5%8F%8C%E7%9B%AE%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A%E5%92%8C%E6%A0%A1%E5%87%86\">(3) 双目相机标定和校准</h3>\n<pre><code class=\"language-bash\"># Linux\nbash scripts/stereo_camera_calibration.sh\n# windows\nscripts/stereo_camera_calibration.bat</code></pre>\n<pre><code class=\"language-bash\">image_dir=data/lenacv-camera # 棋盘格图片\nsave_dir=configs/lenacv-camera # 保存标定结果\nwidth=8\nheight=11\nsquare_size=20 #mm\nimage_format=png # 图片格式，如png,jpg\n#show=True # 是否显示检测结果\nshow=False # 是否显示检测结果\n# stereo camera calibration\npython stereo_camera_calibration.py \\\n    --left_file $save_dir/left_cam.yml \\\n    --right_file $save_dir/right_cam.yml \\\n    --left_prefix left \\\n    --right_prefix right \\\n    --width $width \\\n    --height $height \\\n    --left_dir $image_dir \\\n    --right_dir $image_dir \\\n    --image_format  $image_format  \\\n    --square_size $square_size \\\n    --save_dir $save_dir \\\n</code></pre>\n<p>一点注意事项：  </p>\n<blockquote>\n<ul><li>若误差超过0.1，建议重新调整摄像头并标定</li></ul>\n</blockquote>\n<p>执行后，在<code>$save_dir</code>目录下会生成<code>stereo_cam.yml</code>相机参数文件，这个文件，包含了<span style=\"color:#fe2c24;\"><strong>左右相机的相机内参矩阵(K1,K2)，畸变系数矩阵(D1,D2)，左右摄像机之间的旋转矩阵R和平移矩阵T，以及本质矩阵E和基本矩阵F等.</strong></span></p>\n<p><span style=\"color:#0d0016;\">有了双目相机内外参数信息(</span><code>stereo_cam.yml</code><span style=\"color:#0d0016;\">)，下面就可以进行立体矫正，计算视差了</span></p>\n<h2 id=\"4.%E8%A7%86%E5%B7%AE%E5%9B%BE%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%9B%BE\">4.视差图和深度图</h2>\n<h3 id=\"(1)%20%E7%AB%8B%E4%BD%93%E6%A0%A1%E6%AD%A3\">(1) 立体校正</h3>\n<blockquote>\n<p>这部分基础知识来源于：<a href=\"https://blog.csdn.net/dulingwen/article/details/100115157\" title=\"https://blog.csdn.net/dulingwen/article/details/100115157\">https://blog.csdn.net/dulingwen/article/details/100115157</a></p>\n</blockquote>\n<p>立体校正的目的是将拍摄于同一场景的左右两个视图进行数学上的投影变换，使得两个成像平面平行于基线，且同一个点在左右两幅图中位于同一行，简称共面行对准。只有达到共面行对准以后才可以应用三角原理计算距离。</p>\n<p><img alt=\"\" src=\"https://img-blog.csdnimg.cn/20200613221307783.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1bGluZ3dlbg==,size_16,color_FFFFFF,t_70\"/></p>\n<pre><code class=\"language-python\">    def get_rectify_image(self, imgL, imgR):\n        \"\"\"\n        畸变校正和立体校正\n        根据更正map对图片进行重构\n        获取用于畸变校正和立体校正的映射矩阵以及用于计算像素空间坐标的重投影矩阵\n        :param imgL:\n        :param imgR:\n        :return:\n        \"\"\"\n        # camera_params.get_rectify_transform(K1, D1, K2, D2, R, T, image_size)\n        left_map_x, left_map_y = self.camera_config[\"left_map_x\"], self.camera_config[\"left_map_y\"]\n        right_map_x, right_map_y = self.camera_config[\"right_map_x\"], self.camera_config[\"right_map_y\"]\n        rectifiedL = cv2.remap(imgL, left_map_x, left_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n        rectifiedR = cv2.remap(imgR, right_map_x, right_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n        return rectifiedL, rectifiedR</code></pre>\n<h3 id=\"%C2%A0(2)%C2%A0%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D%E4%B8%8E%E8%A7%86%E5%B7%AE%E5%9B%BE%E8%AE%A1%E7%AE%97\">(2) <strong>立体匹配与视差图计算</strong></h3>\n<p>立体匹配的目的是为左图中的每一个像素点在右图中找到其对应点（世界中相同的物理点），这样就可以计算出视差：<img alt=\"\" src=\"https://private.codecogs.com/gif.latex?disparity%20%3D%20x_%7Bi%7D%20-%20x_%7Bj%7D\"/>（xi和xj分别表示两个对应点在图像中的列坐标）。</p>\n<p>大部分立体匹配算法的计算过程可以分成以下几个阶段：<span style=\"color:#fe2c24;\"><strong>匹配代价计算、代价聚合、视差优化、视差细化</strong></span>。立体匹配是立体视觉中一个很难的部分，主要困难在于：</p>\n<blockquote>\n<p>1.图像中可能存在重复纹理和弱纹理，这些区域很难匹配正确；</p>\n<p>2.由于左右相机的拍摄位置不同，图像中几乎必然存在遮挡区域，在遮挡区域，左图中有一些像素点在右图中并没有对应的点，反之亦然；</p>\n<p>3.左右相机所接收的光照情况不同；</p>\n<p>4.过度曝光区域难以匹配；</p>\n<p>5.倾斜表面、弯曲表面、非朗伯体表面；</p>\n<p>6.较高的图像噪声等。</p>\n</blockquote>\n<p>常用的立体匹配方法基本上可以分为两类：<strong>局部方法，例如BM、SGM、ELAS、Patch Match等，非局部的，即全局方法，例如Dynamic Programming、Graph Cut、Belief Propagation</strong>等，局部方法计算量小，匹配质量相对较低，全局方法省略了代价聚合而采用了优化能量函数的方法，匹配质量较高，但是计算量也比较大。</p>\n<p>目前OpenCV中已经实现的方法有BM、binaryBM、SGBM、binarySGBM、BM(cuda)、Bellief Propogation(cuda)、Constant Space Bellief Propogation(cuda)这几种方法。比较好用的是SGBM算法，它的核心是基于SGM算法，但和SGM算法又有一些不同，比如匹配代价部分用的是BT代价（原图+梯度图）而不是HMI代价等等。有关SGM算法的原理解释，可以参考另一篇博客 : 《<strong>双目立体匹配算法：SGM </strong>》<a href=\"https://blog.csdn.net/dulingwen/article/details/104142149\" title=\"https://blog.csdn.net/dulingwen/article/details/104142149\">https://blog.csdn.net/dulingwen/article/details/104142149</a></p>\n<pre><code class=\"language-python\">    def get_disparity(self, imgL, imgR, use_wls=True):\n        \"\"\"\n        :param imgL: 畸变校正和立体校正后的左视图\n        :param imgR：畸变校正和立体校正后的右视图\n        :param use_wls：是否使用WLS滤波器对视差图进行滤波\n        :return dispL:ndarray(np.float32),返回视差图\n        \"\"\"\n        dispL = disparity.get_disparity_filter(imgL, imgR, use_wls=use_wls)\n        # dispL = disparity.get_disparity_simple(imgL, imgR)\n        return dispL</code></pre>\n<h3 id=\"%C2%A0(2)%20OpenCV%E5%AE%9E%E7%8E%B0\">(3) Demo</h3>\n<ul><li>运行Demo进行立体矫正，计算视差图并恢复深度图,</li><li>Demo的参数说明如下</li></ul>\n<table><thead><tr><th>参数</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>calibration_file</td><td>str</td><td>双目相机的配置文件，如\"configs/lenacv-camera/stereo_cam.yml\"</td></tr><tr><td>left_video</td><td>str</td><td>左路相机ID或者视频文件</td></tr><tr><td>right_video</td><td>str</td><td>右路相机ID或者视频文件</td></tr><tr><td>left_file</td><td>str</td><td>左路测试图像文件</td></tr><tr><td>right_file</td><td>str</td><td>右路测试图像文件</td></tr><tr><td>filter</td><td>bool</td><td>是否对视差图进行滤波</td></tr></tbody></table>\n<pre><code class=\"language-bash\">python demo.py  \\\n  --stereo_file \"configs/lenacv-camera/stereo_cam.yml\" \\\n  --left_video \"data/lenacv-video/left_video.avi\" \\\n  --right_video \"data/lenacv-video/right_video.avi\" \\\n  --filter True</code></pre>\n<ul><li><strong><span style=\"color:#fe2c24;\">视差图滤波</span>:</strong></li></ul>\n<blockquote>\n<p>在立体匹配生成视差图之后，还可以对<strong>视差图</strong>进行滤波后处理，例如Guided Filter、Fast Global Smooth Filter（一种<span style=\"color:#fe2c24;\"><strong>快速WLS滤波</strong></span>方法）、Bilatera Filter、TDSR、RBS等。 视差图滤波能够将稀疏视差转变为稠密视差，并在一定程度上降低视差图噪声，改善视差图的视觉效果，但是比较依赖初始视差图的质量。</p>\n</blockquote>\n<table align=\"center\"><thead><tr><th style=\"text-align:center;\">左视图</th><th style=\"text-align:center;\">右视图</th></tr></thead><tbody><tr><td><img alt=\"\" src=\"image\\7a7397441869493cbb81b1bea4b2cd73.png\"/></td><td><img alt=\"\" src=\"image\\64b101ff2b024169b178fe247bc2d853.png\"/></td></tr><tr><td style=\"text-align:center;\"><strong>视差图(未滤波)</strong></td><td style=\"text-align:center;\"><strong>深度图(未滤波)</strong></td></tr><tr><td><img alt=\"\" src=\"image\\23ea8b03a0804c5ea96c5e9308ea5cb1.png\"/></td><td><img alt=\"\" src=\"image\\08105a97b75c4d2f86cdf7ef89a063f5.png\"/></td></tr><tr><td style=\"text-align:center;\"><strong>视差图(滤波后)</strong></td><td style=\"text-align:center;\"><strong>深度图(滤波后)</strong></td></tr><tr><td><img alt=\"\" src=\"image\\111d09257ae044889fea13ca7fcc7909.png\"/></td><td><img alt=\"\" src=\"image\\15fe1a60d733405782cf4d25d4b0d5e4.png\"/></td></tr></tbody></table>\n<blockquote>\n<p>可以看到，使用<span style=\"color:#fe2c24;\"><strong>WLS滤波后，视差图的整体效果都有明显改善</strong></span></p>\n<p></p>\n</blockquote>\n<ul><li>最终效果图</li></ul>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/53cf049177734c9d93cc087296ac8eed.gif\"/></p>\n<hr/>\n<h2 id=\"5.%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D\">5.双目测距</h2>\n<p>得到了视差图之后，就可以计算像素深度了,在opencv中使用StereoRectify()函数可以得到一个<span style=\"color:#fe2c24;\"><strong>重投影矩阵Q</strong></span>，它是一个4*4的视差图到深度图的映射矩阵(disparity-to-depth mapping matrix )，使用Q矩阵和cv2.reprojectImageTo3D即可实现将像素坐标转换为三维坐标，该函数会返回一个3通道的矩阵，分别存储X、Y、Z坐标（左摄像机坐标系下）。</p>\n<pre><code class=\"language-python\">def reprojectImageTo3D(disparity, Q, _3dImage=None, handleMissingValues=None, ddepth=None):\n    \"\"\"\n    :param disparity: 输入视差图\n    :param Q: 输入4*4的视差图到深度图的映射矩阵，即重投影矩阵 通过stereoRectify得到\n            (disparity-to-depth mapping matrix)\n    :param _3dImage: 映射后存储三维坐标的图像\n             contains 3D coordinates of the point (x,y) computed from the disparity map\n    :param handleMissingValues: 计算得到的非正常值是否给值，如果为true则给值10000\n    :param ddepth: 输出类型 -1 即默认为CV_32FC3 还可以是 CV_16S, CV_32S, CV_32F\n    :return:\n    \"\"\"</code></pre>\n<p>运算如下：</p>\n<p style=\"text-align:center;\"><br/>  <img alt=\"[X,Y,Z,W] ^T=Q*[x,y,disparity(x,y),1]^ T\" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?%5BX%2CY%2CZ%2CW%5D%20%5ET%3DQ*%5Bx%2Cy%2Cdisparity%28x%2Cy%29%2C1%5D%5E%20T\"/></p>\n<p style=\"text-align:center;\"><img alt=\"_3dImage(x,y)=(X/W,Y/W,Z/W)\" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?_3dImage%28x%2Cy%29%3D%28X/W%2CY/W%2CZ/W%29\"/></p>\n<p style=\"text-align:center;\"><img alt=\"\" height=\"234\" src=\"image\\763b04f79f594fd29fdee97d73e37fe4.png\" width=\"507\"/></p>\n<p><span style=\"color:#fe2c24;\"><strong>重投影矩阵Q中</strong></span><img alt=\"c_x\" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?c_x\"/>和<img alt=\"c_y\" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?c_y\"/>为左相机主点在图像中的坐标，f为焦距，<img alt=\"T_x\" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?T_x\"/>为两台相机投影中心间的平移（负值），即基线baseline,相当于平移向量T[0], <img alt=\"c_{x}^{`}  \" class=\"mathcode\" src=\"https://latex.codecogs.com/gif.latex?c_%7Bx%7D%5E%7B%60%7D\"/>是右相机主点在图像中的坐标。</p>\n<p>其中Z即是深度距离depth：</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"https://latex.codecogs.com/gif.latex?depth%20%3D%5Cfrac%7B%20f%5Ctimes%20b%7D%7Bd%20&amp;plus;%20%5Cleft%28c_%7Bxr%7D-%20c_%7Bxl%7D%5Cright%20%29%7D\"/></p>\n<p>其中 f 为焦距长度（像素焦距），b为基线长度，d为视差，<img alt=\"c_{xl}\" src=\"https://latex.codecogs.com/gif.latex?c_%7Bxl%7D\"/>与<img alt=\"c_{xr}\" src=\"https://latex.codecogs.com/gif.latex?c_%7Bxr%7D\"/>为两个相机主点的列坐标。</p>\n<blockquote>\n<p>这里有个地方需要注意，如果获得视差图像是CV_16S类型的，这样的视差图的每个像素值由一个16bit表示，其中低位的4位存储的是视差值得小数部分，所以真实视差值应该是该值除以16。在进行映射后应该乘以16，以获得毫米级真实位置。</p>\n</blockquote>\n<pre><code class=\"language-python\">    def get_depth(self, disparity, Q, scale=1.0, method=False):\n        \"\"\"\n        reprojectImageTo3D(disparity, Q),输入的Q,单位必须是毫米(mm)\n        :param disparity: 视差图\n        :param Q: 重投影矩阵Q=[[1, 0, 0, -cx]\n                           [0, 1, 0, -cy]\n                           [0, 0, 0,  f]\n                           [1, 0, -1/Tx, (cx-cx`)/Tx]]\n            其中f为焦距，Tx相当于平移向量T的第一个参数\n        :param scale: 单位变换尺度,默认scale=1.0,单位为毫米\n        :return depth:ndarray(np.uint16),depth返回深度图, 即距离\n        \"\"\"\n        # 将图片扩展至3d空间中，其z方向的值则为当前的距离\n        if method:\n            points_3d = cv2.reprojectImageTo3D(disparity, Q)  # 单位是毫米(mm)\n            x, y, depth = cv2.split(points_3d)\n        else:\n            # baseline = abs(camera_config[\"T\"][0])\n            baseline = 1 / Q[3, 2]  # 基线也可以由T[0]计算\n            fx = abs(Q[2, 3])\n            depth = (fx * baseline) / disparity\n        depth = depth * scale\n        # depth = np.asarray(depth, dtype=np.uint16)\n        depth = np.asarray(depth, dtype=np.float32)\n        return depth</code></pre>\n<ul><li>运行<code>demo.py</code>后，鼠标点击图像任意区域，终端会打印对应距离</li><li>鼠标点击手部区域会打印距离摄像头的距离约633mm,即0.63米，还是比较准的</li></ul>\n<pre><code>(x,y)=(203,273),depth=633.881653mm\n(x,y)=(197,329),depth=640.386047mm\n(x,y)=(222,292),depth=631.549072mm\n(x,y)=(237,270),depth=630.389221mm\n(x,y)=(208,246),depth=652.560669mm\n</code></pre>\n<p> 双目测距的精度 说明：</p>\n<blockquote>\n<p>根据上式可以看出，某点像素的深度精度取决于该点处估计的视差d的精度。假设视差d的误差恒定，当测量距离越远，得到的深度精度则越差，因此使用双目相机不适宜测量太远的目标。</p>\n<p>如果想要对与较远的目标能够得到较为可靠的深度，一方面需要提高相机的基线距离，但是基线距离越大，左右视图的重叠区域就会变小，内容差异变大，从而提高立体匹配的难度，另一方面可以选择更大焦距的相机，然而焦距越大，相机的视域则越小，导致离相机较近的物体的距离难以估计。</p>\n<p>理论上，<span style=\"color:#fe2c24;\">深度方向的测量误差与测量距离的平方成正比，而X/Y方向的误差与距离成正比；而距离很近时，由于存在死角，会导致难以匹配的问题；想象一下，如果你眼前放置一块物体，那你左眼只能看到物体左侧表面，右眼同理只能看到物体右侧表面，这时由于配准失败，导致视差计算失败；这个问题在基线越长，问题就越严重</span></p>\n</blockquote>\n<p> <a class=\"has-card\" href=\"https://blog.csdn.net/xuyuhua1985/article/details/50151269\" title=\"双目立体视觉系统精度分析_3D Vision-CSDN博客_双目视觉定位精度\"><span class=\"link-card-box\"><span class=\"link-title\">双目立体视觉系统精度分析_3D Vision-CSDN博客_双目视觉定位精度</span><span class=\"link-desc\">在一个三维测量项目中，如果采用立体视觉方案，首先，要根据测量需求（精度、测量范围、速度等），确定立体视觉的硬件方案。Thomas Luhmann在他的《Close-Range Photogrammetry and 3D Imaging》（2014）中，给出立体视觉系统的简化分析方法。这个方法假设两个相机的光轴平行，基线与光轴垂直，基线长度b和焦距值c不存在误差。分析了图像处理误差对立体定位</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"https://g.csdnimg.cn/static/logo/favicon32.ico\"/>https://blog.csdn.net/xuyuhua1985/article/details/50151269</span></span></a></p>\n<hr/>\n<h2 id=\"6.3D%E7%82%B9%E4%BA%91\">6.3D点云显示</h2>\n<p>恢复三维坐标后，就可以使用python-pcl和Open3D库显示点云图</p>\n<blockquote>\n<p>PCL Python版比较难安装，如果安装不了，那可以采用Open3D勉强凑合使用吧</p>\n<p>如下图所示，你可以用鼠标旋转坐标轴，放大点云</p>\n</blockquote>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\"><tbody><tr><td style=\"text-align:center;\"><strong>2D-RGB</strong></td><td style=\"text-align:center;\"><strong>Open3D点云显示</strong></td><td style=\"text-align:center;\"><strong>PCL点云显示</strong></td></tr><tr><td style=\"text-align:center;\"><img alt=\"\" height=\"800\" src=\"image\\6554d1a67153400593eae2f97b39382a.png\" width=\"1057\"/></td><td style=\"text-align:center;\"><img alt=\"\" height=\"800\" src=\"image\\39155feb351a44f4a902dff46337840d.png\" width=\"1058\"/></td><td style=\"text-align:center;\"><img alt=\"\" height=\"800\" src=\"image\\82ec1f9cb17f41b298a554dd7b27249b.png\" width=\"1194\"/></td></tr></tbody></table>\n<p></p>\n<pre><code class=\"language-python\">    def show_3dcloud_for_open3d(self, frameL, frameR, points_3d):\n        \"\"\"\n        使用open3d显示点云\n        :param frameL:\n        :param frameR:\n        :param points_3d:\n        :return:\n        \"\"\"\n        if self.use_open3d:\n            x, y, depth = cv2.split(points_3d)  # depth = points_3d[:, :, 2]\n            self.open3d_viewer.show(color_image=frameL, depth_image=depth)\n\n    def show_3dcloud_for_pcl(self, frameL, frameR, points_3d):\n        \"\"\"\n        使用PCL显示点云\n        :param frameL:\n        :param frameR:\n        :param points_3d:\n        :return:\n        \"\"\"\n        if self.use_pcl:\n            self.pcl_viewer.add_3dpoints(points_3d, frameL)\n            self.pcl_viewer.show()</code></pre>\n<h2 id=\"%C2%A07.Demo\">7.项目代码</h2>\n<p> 【<span style=\"color:#be191c;\"><strong>完整的项目代码</strong></span>】<a href=\"https://mp.weixin.qq.com/s/any-zhYmhZ1eEoB9RCM6nA\" title=\"双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码\">双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码</a></p>\n<pre><code class=\"language-bash\">python demo.py</code></pre>\n<p>示例代码如下， 项目配套了双目摄像头的校准参数文件，以及左右摄像的视频文件，可以作为Demo直接测试和使用</p>\n<pre><code class=\"language-python\"># -*-coding: utf-8 -*-\n\"\"\"\n    @Author : panjq\n    @E-mail : pan_jinquan@163.com\n    @Date   : 2020-04-10 18:24:06\n\"\"\"\n\nimport os\nimport cv2\nimport argparse\nimport numpy as np\nfrom core.utils import image_utils, file_utils\nfrom core import camera_params, stereo_matcher\n\n\nclass StereoDepth(object):\n    \"\"\"双目测距\"\"\"\n\n    def __init__(self, stereo_file, width=640, height=480, filter=True, use_open3d=True, use_pcl=True):\n        \"\"\"\n        :param stereo_file: 双目相机内外参数配置文件\n        :param width: 相机分辨率width\n        :param height:相机分辨率height\n        :param filter: 是否使用WLS滤波器对视差图进行滤波\n        :param use_open3d: 是否使用open3d显示点云\n        :param use_pcl: 是否使用PCL显示点云\n        \"\"\"\n        self.count = 0\n        self.filter = filter\n        self.camera_config = camera_params.get_stereo_coefficients(stereo_file)\n        self.use_pcl = use_pcl\n        self.use_open3d = use_open3d\n        # 初始化3D点云\n        if self.use_pcl:\n            # 使用open3d显示点云\n            from core.utils_pcl import pcl_tools\n            self.pcl_viewer = pcl_tools.PCLCloudViewer()\n        if self.use_open3d:\n            # 使用PCL显示点云\n            from core.utils_3d import open3d_visual\n            self.open3d_viewer = open3d_visual.Open3DVisual(camera_intrinsic=self.camera_config[\"K1\"],\n                                                            depth_width=width,\n                                                            depth_height=height)\n            self.open3d_viewer.show_image_pcd(True)\n            self.open3d_viewer.show_origin_pcd(True)\n            self.open3d_viewer.show_image_pcd(True)\n        assert (width, height) == self.camera_config[\"size\"], Exception(\"Error:{}\".format(self.camera_config[\"size\"]))\n\n    def test_pair_image_file(self, left_file, right_file):\n        \"\"\"\n        测试一对左右图像\n        :param left_file: 左路图像文件\n        :param right_file: 右路图像文件\n        :return:\n        \"\"\"\n        frameR = cv2.imread(left_file)\n        frameL = cv2.imread(right_file)\n        self.task(frameR, frameL, waitKey=0)\n\n    def capture1(self, video):\n        \"\"\"\n        用于采集单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        :param video:int or str,视频路径或者摄像头ID\n        :param save_dir: str,保存左右图片的路径\n        \"\"\"\n        cap = image_utils.get_video_capture(video)\n        width, height, numFrames, fps = image_utils.get_video_info(cap)\n        self.count = 0\n        while True:\n            success, frame = cap.read()\n            if not success:\n                print(\"No more frames\")\n                break\n            frameL = frame[:, :int(width / 2), :]\n            frameR = frame[:, int(width / 2):, :]\n            self.count += 1\n            self.task(frameL, frameR, waitKey=5)\n            if cv2.waitKey(1) &amp; 0xFF == ord('q'):  # Get key to stop stream. Press q for exit\n                break\n        cap.release()\n        cv2.destroyAllWindows()\n\n    def capture2(self, left_video, right_video):\n        \"\"\"\n        用于采集双USB连接线的双目摄像头\n        :param left_video:int or str,左路视频路径或者摄像头ID\n        :param right_video:int or str,右视频路径或者摄像头ID\n        :return:\n        \"\"\"\n        capL = image_utils.get_video_capture(left_video)\n        capR = image_utils.get_video_capture(right_video)\n        width, height, numFrames, fps = image_utils.get_video_info(capL)\n        width, height, numFrames, fps = image_utils.get_video_info(capR)\n        self.count = 0\n        while True:\n            successL, frameL = capL.read()\n            successR, frameR = capR.read()\n            if not (successL and successR):\n                print(\"No more frames\")\n                break\n            self.count += 1\n            self.task(frameL, frameR, waitKey=50)\n            if cv2.waitKey(1) &amp; 0xFF == ord('q'):  # Get key to stop stream. Press q for exit\n                break\n        capL.release()\n        capR.release()\n        cv2.destroyAllWindows()\n\n    def get_3dpoints(self, disparity, Q, scale=1.0):\n        \"\"\"\n        计算像素点的3D坐标（左相机坐标系下）\n        reprojectImageTo3D(disparity, Q),输入的Q,单位必须是毫米(mm)\n        :param disparity: 视差图\n        :param Q: 重投影矩阵Q=[[1, 0, 0, -cx]\n                           [0, 1, 0, -cy]\n                           [0, 0, 0,  f]\n                           [1, 0, -1/Tx, (cx-cx`)/Tx]]\n            其中f为焦距，Tx相当于平移向量T的第一个参数\n        :param scale: 单位变换尺度,默认scale=1.0,单位为毫米\n        :return points_3d:ndarray(np.float32),返回三维坐标points_3d，三个通道分布表示(X,Y,Z)\n                    其中Z是深度图depth, 即距离,单位是毫米(mm)\n        \"\"\"\n        # 返回三维坐标points_3d，三个通道分布表示(X,Y,Z)\n        # depth = stereo_matcher.get_depth(disparity, Q, scale=1.0)\n        points_3d = cv2.reprojectImageTo3D(disparity, Q)\n        # x, y, depth = cv2.split(points_3d)\n        # baseline = abs(camera_config[\"T\"][0])\n        # baseline = 1 / Q[3, 2]  # 基线也可以由T[0]计算\n        # fx = abs(Q[2, 3])\n        # depth = (fx * baseline) / disparity\n        points_3d = points_3d * scale\n        points_3d = np.asarray(points_3d, dtype=np.float32)\n        return points_3d\n\n    def get_disparity(self, imgL, imgR, use_wls=True):\n        \"\"\"\n        :param imgL: 畸变校正和立体校正后的左视图\n        :param imgR：畸变校正和立体校正后的右视图\n        :param use_wls：是否使用WLS滤波器对视差图进行滤波\n        :return dispL:ndarray(np.float32),返回视差图\n        \"\"\"\n        dispL = stereo_matcher.get_filter_disparity(imgL, imgR, use_wls=use_wls)\n        # dispL = disparity.get_simple_disparity(imgL, imgR)\n        return dispL\n\n    def get_rectify_image(self, imgL, imgR):\n        \"\"\"\n        畸变校正和立体校正\n        根据更正map对图片进行重构\n        获取用于畸变校正和立体校正的映射矩阵以及用于计算像素空间坐标的重投影矩阵\n        :param imgL:\n        :param imgR:\n        :return:\n        \"\"\"\n        # camera_params.get_rectify_transform(K1, D1, K2, D2, R, T, image_size)\n        left_map_x, left_map_y = self.camera_config[\"left_map_x\"], self.camera_config[\"left_map_y\"]\n        right_map_x, right_map_y = self.camera_config[\"right_map_x\"], self.camera_config[\"right_map_y\"]\n        rectifiedL = cv2.remap(imgL, left_map_x, left_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n        rectifiedR = cv2.remap(imgR, right_map_x, right_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n        return rectifiedL, rectifiedR\n\n    def task(self, frameL, frameR, waitKey=5):\n        \"\"\"\n        :param frameL: 左路视频帧图像(BGR)\n        :param frameR: 右路视频帧图像(BGR)\n        \"\"\"\n        # 畸变校正和立体校正\n        rectifiedL, rectifiedR = self.get_rectify_image(imgL=frameL, imgR=frameR)\n        # 绘制等间距平行线，检查立体校正的效果\n        # calibrate_tools.draw_line_rectify_image(rectifiedL, rectifiedR)\n        # We need grayscale for disparity map.\n        grayL = cv2.cvtColor(rectifiedL, cv2.COLOR_BGR2GRAY)\n        grayR = cv2.cvtColor(rectifiedR, cv2.COLOR_BGR2GRAY)\n        # Get the disparity map\n        dispL = self.get_disparity(grayL, grayR, self.filter)\n        points_3d = self.get_3dpoints(disparity=dispL, Q=self.camera_config[\"Q\"])\n        self.show_3dcloud_for_open3d(frameL, frameR, points_3d)\n        self.show_3dcloud_for_pcl(frameL, frameR, points_3d)\n        self.show_2dimage(frameL, frameR, points_3d, dispL, waitKey=waitKey)\n\n    def show_3dcloud_for_open3d(self, frameL, frameR, points_3d):\n        \"\"\"\n        使用open3d显示点云\n        :param frameL:\n        :param frameR:\n        :param points_3d:\n        :return:\n        \"\"\"\n        if self.use_open3d:\n            x, y, depth = cv2.split(points_3d)  # depth = points_3d[:, :, 2]\n            self.open3d_viewer.show(color_image=frameL, depth_image=depth)\n\n    def show_3dcloud_for_pcl(self, frameL, frameR, points_3d):\n        \"\"\"\n        使用PCL显示点云\n        :param frameL:\n        :param frameR:\n        :param points_3d:\n        :return:\n        \"\"\"\n        if self.use_pcl:\n            self.pcl_viewer.add_3dpoints(points_3d, frameL)\n            self.pcl_viewer.show()\n\n    def show_2dimage(self, frameL, frameR, points_3d, dispL, waitKey=0):\n        \"\"\"\n        :param frameL:\n        :param frameR:\n        :param dispL:\n        :param points_3d:\n        :return:\n        \"\"\"\n        x, y, depth = cv2.split(points_3d)  # depth = points_3d[:, :, 2]\n        depth_colormap = stereo_matcher.get_visual_depth(depth)\n        dispL_colormap = stereo_matcher.get_visual_disparity(dispL)\n        image_utils.addMouseCallback(\"left\", depth, info=\"depth=%fmm\")\n        image_utils.addMouseCallback(\"right\", depth, info=\"depth=%fmm\")\n        image_utils.addMouseCallback(\"disparity-color\", depth, info=\"depth=%fmm\")\n        image_utils.addMouseCallback(\"depth-color\", depth, info=\"depth=%fmm\")\n        result = {\"frameL\": frameL, \"frameR\": frameR, \"disparity\": dispL_colormap, \"depth\": depth_colormap}\n        cv2.imshow('left', frameL)\n        cv2.imshow('right', frameR)\n        cv2.imshow('disparity-color', dispL_colormap)\n        cv2.imshow('depth-color', depth_colormap)\n        key = cv2.waitKey(waitKey)\n        self.save_images(result, self.count, key)\n        if self.count &lt;= 2:\n            cv2.moveWindow(\"left\", 700, 0)\n            cv2.moveWindow(\"right\", 1400, 0)\n            cv2.moveWindow(\"disparity-color\", 700, 700)\n            cv2.moveWindow(\"depth-color\", 1400, 700)\n\n    def save_images(self, result, count, key, save_dir=\"./data/temp\"):\n        \"\"\"\n        :param result:\n        :param count:\n        :param key:\n        :param save_dir:\n        :return:\n        \"\"\"\n        if key == ord('q'):\n            exit(0)\n        elif key == ord('c') or key == ord('s'):\n            file_utils.create_dir(save_dir)\n            print(\"save image:{:0=4d}\".format(count))\n            cv2.imwrite(os.path.join(save_dir, \"left_{:0=4d}.png\".format(count)), result[\"frameL\"])\n            cv2.imwrite(os.path.join(save_dir, \"right_{:0=4d}.png\".format(count)), result[\"frameR\"])\n            cv2.imwrite(os.path.join(save_dir, \"disparity_{:0=4d}.png\".format(count)), result[\"disparity\"])\n            cv2.imwrite(os.path.join(save_dir, \"depth_{:0=4d}.png\".format(count)), result[\"depth\"])\n\n\ndef str2bool(v):\n    return v.lower() in ('yes', 'true', 't', 'y', '1')\n\n\ndef get_parser():\n    stereo_file = \"configs/lenacv-camera/stereo_cam.yml\"\n    # left_video = None\n    # right_video = None\n    left_video = \"data/lenacv-video/left_video.avi\"\n    right_video = \"data/lenacv-video/right_video.avi\"\n    left_file = \"docs/left.png\"\n    right_file = \"docs/right.png\"\n    parser = argparse.ArgumentParser(description='Camera calibration')\n    parser.add_argument('--stereo_file', type=str, default=stereo_file, help='stereo calibration file')\n    parser.add_argument('--left_video', default=left_video, help='left video file or camera ID')\n    parser.add_argument('--right_video', default=right_video, help='right video file or camera ID')\n    parser.add_argument('--left_file', type=str, default=left_file, help='left image file')\n    parser.add_argument('--right_file', type=str, default=right_file, help='right image file')\n    parser.add_argument('--filter', type=str2bool, nargs='?', default=True, help='use disparity filter')\n    return parser\n\n\nif __name__ == '__main__':\n    args = get_parser().parse_args()\n    stereo = StereoDepth(args.stereo_file, filter=args.filter)\n    if args.left_video is not None and args.right_video is not None:\n        # 双USB连接线的双目摄像头\n        stereo.capture2(left_video=args.left_video, right_video=args.right_video)\n    elif args.left_video is not None:\n        # 单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        stereo.capture1(video=args.left_video)\n    elif args.right_video is not None:\n        # 单USB连接线的双目摄像头(左右摄像头被拼接在同一个视频中显示)\n        stereo.capture1(video=args.right_video)\n    if args.left_file and args.right_file:\n        # 测试一对左右图像\n        stereo.test_pair_image_file(args.left_file, args.right_file)\n</code></pre>\n<hr/>\n<h2 id=\"7.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\">8.参考资料</h2>\n<ul><li>&lt;真实场景的双目立体匹配（Stereo Matching）获取深度图详解&gt; : <a href=\"https://www.cnblogs.com/riddick/p/8486223.html\" title=\"真实场景的双目立体匹配（Stereo Matching）获取深度图详解 - 一度逍遥 - 博客园\">真实场景的双目立体匹配（Stereo Matching）获取深度图详解 - 一度逍遥 - 博客园</a></li><li>&lt;双目测距理论及其python实现&gt; </li><li> <p>【<span style=\"color:#be191c;\"><strong>完整的项目代码</strong></span>】​​​​​​​​​​​​​​<a href=\"https://mp.weixin.qq.com/s/any-zhYmhZ1eEoB9RCM6nA\" title=\"双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码\">双目三维重建系统(双目标定+立体校正+双目测距+点云显示)Python源码</a></p> </li></ul>\n</div>\n</div>"}