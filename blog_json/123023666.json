{"blogid": "123023666", "writerAge": "码龄5年", "writerBlogNum": "309", "writerCollect": "9999", "writerComment": "1494", "writerFan": "31582", "writerGrade": "8级", "writerIntegral": "25308", "writerName": "白水baishui", "writerProfileAdress": "writer_image\\profile_123023666.jpg", "writerRankTotal": "637", "writerRankWeekly": "1950", "writerThumb": "4835", "writerVisitNum": "3588860", "blog_read_count": "4537", "blog_time": "已于 2022-02-22 09:12:56 修改", "blog_title": "CUDA C/C++ 教程一：加速应用程序", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"style.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>文章目录</h3>\n<ul><li><ul><li><ul><li><a href=\"#1_CUDA__9\">1. CUDA 基础</a></li><li><ul><li><a href=\"#11_CUDA__10\">1.1. CUDA 简介</a></li><li><a href=\"#12__19\">1.2. 学习前的准备工作</a></li><li><a href=\"#13__35\">1.3. 加速系统的硬件设施</a></li></ul>\n</li><li><a href=\"#2_GPU_51\">2. 编写在GPU运行的代码</a></li><li><ul><li><a href=\"#21__Hello_GPU__93\">2.1. 编写运行一个 Hello GPU 核函数</a></li></ul>\n</li><li><a href=\"#3_CUDA__128\">3. CUDA 线程的层次结构</a></li><li><ul><li><a href=\"#31__133\">3.1. 运行核函数</a></li><li><a href=\"#32__170\">3.2. 线程和块的索引</a></li><li><a href=\"#33__CUDA__For__212\">3.3. 用 CUDA 加速 For 循环</a></li><li><a href=\"#34__254\">3.4. 管理不同块之间的线程</a></li></ul>\n</li><li><a href=\"#4_GPUCPU_301\">4. 分配可同时被GPU和CPU访问的内存</a></li><li><a href=\"#5__388\">5. 网格大小与实际并行工作量不匹配</a></li><li><ul><li><a href=\"#51__390\">5.1. 网格大于工作量</a></li><li><a href=\"#52__474\">5.2. 网格小于工作量</a></li></ul>\n</li><li><a href=\"#6__566\">6. 错误处理</a></li><li><ul><li><a href=\"#61__CUDA__665\">6.1. 定制一个 CUDA 错误处理宏</a></li></ul>\n</li><li><a href=\"#7__688\">7. 总结</a></li><li><ul><li><a href=\"#71__CUDA__699\">7.1 用 CUDA 实现向量加法</a></li><li><a href=\"#72__779\">7.2. 二维和三维的网格和块</a></li><li><a href=\"#73__CUDA__790\">7.3 用 CUDA 实现矩阵乘法</a></li></ul>\n</li></ul>\n</li></ul>\n</li></ul>\n</div>\n<p></p>\n<p><img alt=\"在这里插入图片描述\" src=\"image\\9869beb601904d54a76527c9ec4e8652.png\"/></p>\n<h3><a id=\"1_CUDA__9\"></a>1. CUDA 基础</h3>\n<h4><a id=\"11_CUDA__10\"></a>1.1. CUDA 简介</h4>\n<p>GPU 加速计算正在逐步取代 CPU 计算，近年来加速计算带来了越来越多的突破性进展，各类应用程序对加速计算日益增长地需求、便捷地编写加速计算的程序的需求以及不断改进的支持加速计算的硬件设施，所有这一切都在推动着计算方式从 CPU 计算过渡到 GPU 加速计算。</p>\n<p>无论是从出色的性能还是易用性来看，<a href=\"https://developer.nvidia.com/about-cuda\">CUDA</a> 计算平台均是加速计算的重要实现方式。CUDA 提供了一种可扩展于 C、C++、Python 和 Fortran 等语言的编码接口，并行化后的代码能够在 NVIDIA GPU 上运行，以大幅加速应用程序。它包含有 DNN、BLAS、图形分析 和 FFT 等等库，并且还附带功能强大的命令行和可视化分析器。</p>\n<p>CUDA 支持许多领域的超性能计算应用程序：计算流体动力学、分子动力学、量子化学、物理学 和高性能计算 (HPC)等等。</p>\n<p>学习 CUDA 将能帮你加速自己的应用程序。应用程序加速后的执行速度会远远超过原本在 CPU 上的执行速度，使那些在 CPU 上性能受限的计算得以进行下去。在本教程中, 你将学习使用 CUDA 的 C/C++ 接口作为加速应用程序编程的入门知识，这些入门知识足以让你加速自己的 CPU 应用程序，以获得性能上的巨大提升并帮你迈入全新的计算领域。</p>\n<h4><a id=\"12__19\"></a>1.2. 学习前的准备工作</h4>\n<p>如要充分利用本教程学习CUDA，那么你应该要先有如下知识储备：</p>\n<ul><li>在 C++/C 中声明变量、编写循环并使用 if/else 语句。</li><li>在 C++/C 中定义和调用函数。</li><li>在 C++/C 中分配数组。</li></ul>\n<p>说白了就是要有C或C++语言的基础，此外不需要事先知道任何关于 CUDA 的知识，当你在本教程完成学习后，你就可以做到：</p>\n<ul><li>编写、编译及运行既<strong>可调用 CPU 函数</strong>也<strong>可启动 GPU 核函数</strong>的 C/C++ 程序。</li><li>通过配置参数控制并行线程的层次结构。</li><li>重构串行循环以在 GPU 上并行执行其迭代。</li><li>分配和释放可用于 CPU 和 GPU 的内存。</li><li>处理 CUDA 代码产生的错误。</li><li>加速 CPU 应用程序。</li></ul>\n<h4><a id=\"13__35\"></a>1.3. 加速系统的硬件设施</h4>\n<p>带有GPU的计算机系统称为加速系统（又称异构系统，即指包含CPU和GPU的系统）。在一个包含 NVIDIA GPU 的加速系统的实验环境上，可以使用 nvidia-smi 命令查询有关此 GPU 的信息。例如：</p>\n<pre><code class=\"prism language-python\">nvidia<span class=\"token operator\">-</span>smi\n</code></pre>\n<p>按回车之后，将输出该机器上的GPU信息<br/> <img alt=\"在这里插入图片描述\" src=\"image\\03f02015262a4a2d9fdff89d91bcfc9b.png\"/></p>\n<p>需要注意的是，加速系统在运行程序时首先会运行 CPU 程序，在运行到需要GPU进行大规模并行计算的函数时，再将对应函数载入GPU执行。</p>\n<p>也就是说，由GPU加速的依然还是纯CPU的应用程序，只是某些模块在运行时调入了GPU中，该模块在同步完毕后将会重新回到CPU中执行主程序的后续代码：<br/> <img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/9918806f95be416daca598055f6a758b.gif#pic_center\"/></p>\n<h3><a id=\"2_GPU_51\"></a>2. 编写在GPU运行的代码</h3>\n<p>CUDA 为许多编程语言提供了扩展接口，而在本教程用CUDA为 C/C++ 提供的接口来展示。对编程语言的扩展可以让开发人员在 GPU 上更加方便的运行 CUDA 库的函数。</p>\n<p>以下是一个 <code>.cu</code> 文件（<code>.cu</code> 是 CUDA 加速程序的文件扩展名，实际上<code>.cu</code>文件只是含有CUDA代码的<code>.cpp</code>文件，没有别的特殊之处）。其中包含两个函数，第一个函数 <code>CPUFunction()</code> 将在 CPU 上运行，第二个函数 <code>GPUFunction()</code> 将在 GPU 上运行：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token comment\">// 在CPU上运行的函数</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">CPUFunction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"This function is defined to run on the CPU.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 在GPU上运行的函数</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">GPUFunction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"This function is defined to run on the GPU.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">CPUFunction</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 调用CPU函数</span>\n\n  GPUFunction<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 调用GPU函数</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>根据上面的代码，我们来讲解一些需要特别注意的重要代码行，以及加速计算中使用的一些其他常用术语：<br/> <code>__global__ void GPUFunction()</code>：</p>\n<ul><li><code>__global__</code> 关键字表明该函数将在 GPU 上运行并可全局调用（ 既可以由CPU ，也可以由 GPU 调用）；</li><li>通常，我们将在 CPU 上执行的代码称为 <code>Host</code> （主机）代码，而将在 GPU 上运行的代码称为 <code>Device</code> （设备）代码；</li><li>注意返回类型为 <code>void</code>。使用 <code>__global__</code> 关键字定义的函数返回值需为 <code>void</code> 类型。</li></ul>\n<p><code>GPUFunction&lt;&lt;&lt;1, 1&gt;&gt;&gt;()</code>：</p>\n<ul><li>通常，我们把要运行在 GPU 上的函数称为 kernel （核）函数;</li><li>启动核(kernel)函数时，我们必须事先配置GPU参数，使用 <code>&lt;&lt;&lt; ... &gt;&gt;&gt;</code> 语法向核函数传递两个必要的参数;</li><li>在 <code>&lt;&lt;&lt; ... &gt;&gt;&gt;</code> 中传递的参数用于为核函数设定线程的层次结构，第一个参数定义线程块(Block)的数量，第二个参数定义Block中含有的线程(Thread)数量。例如本例中的核函数 <code>GPUFunction()</code> 将在包含 1 个线程（第二个配置参数）的 1 个线程块（第一个执行配置参数）上运行。</li></ul>\n<p><code>cudaDeviceSynchronize()</code>：</p>\n<ul><li>与其他并行化的代码类似，核函数启动方式为异步，即 CPU 代码将继续执行而不会等待核函数执行完成；</li><li>调用 CUDA 提供的函数 <code>cudaDeviceSynchronize</code> 可以让Host 代码(CPU) 等待 Device 代码(GPU) 执行完毕，再在CPU上继续执行。</li></ul>\n<h4><a id=\"21__Hello_GPU__93\"></a>2.1. 编写运行一个 Hello GPU 核函数</h4>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token keyword\">void</span> <span class=\"token function\">helloCPU</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Hello from the CPU.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// __global__ 表明这是一个全局GPU核函数.</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">helloGPU</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Hello from the GPU.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">helloCPU</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 调用CPU函数</span>\n\n   <span class=\"token comment\">/* 使用 &lt;&lt;&lt;...&gt;&gt;&gt; 配置核函数的GPU参数，\n   * 第一个1表示1个线程块，第二个1表示每个线程块1个线程。*/</span>\n  helloGPU<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 调用GPU函数</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// `cudaDeviceSynchronize` 同步CPU和GPU</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>现在来编译并运行加速后的CUDA代码。将上述文件命名为<code>hello-gpu.cu</code>，执行命令：</p>\n<pre><code class=\"prism language-cpp\">nvcc hello<span class=\"token operator\">-</span>gpu<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o hello<span class=\"token operator\">-</span>gpu\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>hello<span class=\"token operator\">-</span>gpu\n</code></pre>\n<p>得到结果：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\9a5ab8202cc1453da0ab8e626395ea65.png\"/></p>\n<h3><a id=\"3_CUDA__128\"></a>3. CUDA 线程的层次结构</h3>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/c0892be7cf7e489e99bb7225109200d3.gif#pic_center\"/></p>\n<p>从上面的图中可以看出，CUDA线程的层次结构分为三层：Thread（线程）、Block（块）、Grid（网格），网格由块组成，块由线程组成。</p>\n<h4><a id=\"31__133\"></a>3.1. 运行核函数</h4>\n<p>我们可以通过配置参数指定核函数如何在 GPU 的多个线程中并行运行。具体来说，就可以配置 Block 的数量以及每个 Block 中所包含 Thread 的数量。配置参数的语法如下：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span> Block 数<span class=\"token punctuation\">,</span> 每个Block中的 Thread 数<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span>\n</code></pre>\n<p>启动核函数时，核函数代码由我们自行配置的 Block 中的每个 Thread 执行。因此，如果假设已定义一个名为 <code>someKernel</code> 的核函数，则GPU线程可以配置为下列情况：</p>\n<ul><li><code>someKernel&lt;&lt;&lt;1, 1&gt;&gt;()</code> 在GPU中为该核函数分配1个具有1个线程的线程块，核函数中的代码将只运行1次；</li><li><code>someKernel&lt;&lt;&lt;1, 10&gt;&gt;()</code> 在GPU中为该核函数分配1个具有10个线程的线程块，核函数中的代码将运行10次；</li><li><code>someKernel&lt;&lt;&lt;10, 1&gt;&gt;()</code> 在GPU中为该核函数分配10个具有1个线程的线程块，核函数中的代码将运行10次；</li><li><code>someKernel&lt;&lt;&lt;10, 10&gt;&gt;()</code> 在GPU中为该核函数分配10个具有10个线程的线程块，核函数中的代码将运行100次；</li></ul>\n<p>启动并行运行的核函数示例：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">firstParallel</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"This is running in parallel.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  firstParallel<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 在GPU中为核函数分配5个具有5个线程的线程块，将运行25次；</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>basic-parallel.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc basic<span class=\"token operator\">-</span>parallel<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o basic<span class=\"token operator\">-</span>parallel\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>basic<span class=\"token operator\">-</span>parallel\n</code></pre>\n<p>结果如下，数了一下，确实是25次：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\c2a76717889a4eb9b76a781ef8719968.png\"/></p>\n<h4><a id=\"32__170\"></a>3.2. 线程和块的索引</h4>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/652e6bdd92a94401b6d3711c74f6d543.gif#pic_center\"/></p>\n<p>如图所示，每个线程在其线程块的内部都会被分配一个索引，从 0 开始。此外，每个线程块也会被分配一个索引，也是从 0 开始。正如线程组成线程块，线程块又会组成网格(Grid)，而网格是 CUDA 线程层次结构中级别最高的实体，它没有索引。</p>\n<p>简言之，CUDA 核函数在由一个或多个线程块组成的网格中执行，且每个线程块中均包含<strong>相同数量</strong>的一个或多个线程（每个线程块中的线程数量相同）。</p>\n<p>在核函数中，可以通过两个变量来获取到索引： <code>threadIdx.x</code> （线程索引）和 <code>blockIdx.x</code>（线程块索引）。</p>\n<p>现在让我们来使用索引控制特定的线程和块：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token comment\">// 核函数</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">printSuccessForCorrectExecutionConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">// 当执行到第255个线程块的第1023个线程时，才输出</span>\n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">==</span> <span class=\"token number\">1023</span> <span class=\"token operator\">&amp;&amp;</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">==</span> <span class=\"token number\">255</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Success!\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 输出 Success！</span>\n    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"threadIdx.x: %d\\n\"</span><span class=\"token punctuation\">,</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 输出线程ID</span>\n    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"blockIdx.x: %d\\n\"</span><span class=\"token punctuation\">,</span> blockIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 输出线程块ID</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">// 配置该核函数由256个含有1024个线程的线程块中执行</span>\n  printSuccessForCorrectExecutionConfiguration<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1024</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>thread-and-block-idx.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc thread<span class=\"token operator\">-</span><span class=\"token operator\">and</span><span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>idx<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o thread<span class=\"token operator\">-</span><span class=\"token operator\">and</span><span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>idx\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>thread<span class=\"token operator\">-</span><span class=\"token operator\">and</span><span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>idx\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\8c08406a0e044b289d8bda630ce15235.png\"/></p>\n<h4><a id=\"33__CUDA__For__212\"></a>3.3. 用 CUDA 加速 For 循环</h4>\n<p>到此为止，加速 for 循环就是一个可行的操作了。在加速计算中，for 循环不再顺序执行每次迭代，而是让每次迭代都在不同的线程中并行执行。</p>\n<p>例如，现在有以下在 CPU 中执行的 for 循环：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%d\\n\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>如要并行此循环，必须执行以下 2 个步骤：</p>\n<ul><li>编写用于执行单次迭代工作的核函数。</li><li>调用核函数时为它配置执行参数，即并行的线程数，每个线程执行一次迭代。</li></ul>\n<p>如下例程序：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token comment\">// 核函数</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">loop</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">// 输出每一个线程的线程号（0~9）</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"This is iteration number %d\\n\"</span><span class=\"token punctuation\">,</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  loop<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行核函数</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>single-block-loop.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc single<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o single<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>single<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\0b01fe3311f8489897ff61f0fc08bded.png\"/></p>\n<h4><a id=\"34__254\"></a>3.4. 管理不同块之间的线程</h4>\n<p>之前提到过，一个线程块可以包含多个线程，那么我们就可以调整线程块的大小以实现更多类型的并行化。线程块包含的线程具有数量限制：确切地说是 <strong>1024</strong> 个（即每个块中的线程数量 &lt;= 1024）。通常为了增加加速应用程序中的并行量，我们需要利用多个线程块，并在它们之间进行协调。</p>\n<p>CUDA 核函数中，记录了每个块中线程数的变量是 <code>blockDim.x</code>（一个线程块中包含的线程数量，每个块中包含的线程数都是一样的）。通过将此变量与 <code>blockIdx.x</code> 和 <code>threadIdx.x</code> 变量结合使用，并借助表达式 <code>threadIdx.x + blockIdx.x * blockDim.x</code> 计算线程ID。该表达式可以用C++中访问二维数组的索引计算来类比看待，以增强理解。</p>\n<p>以下是详细示例：</p>\n<p>配置参数 <code>&lt;&lt;&lt;10, 10&gt;&gt;&gt;</code> 将启动共计拥有 100 个线程的网格，该网格又分为由 10 个线程组成的 10 个线程块（即一个线程块中含有10个线程，<code>blockDim.x=10</code>）。这时候，就可以利用表达式 <code>threadIdx.x + blockIdx.x * blockDim.x</code> 来计算某个线程的唯一索引（0 至 99 之间）了。</p>\n<ul><li>如果线程块 <code>blockIdx.x</code> 索引为 0，则 <code>blockIdx.x * blockDim.x</code> 为 0。以 0 为起始索引加上可能的 <code>threadIdx.x</code> 值（0 至 9），便可在网格中找到索引为 0 至 9 的线程。</li><li>如果线程块 <code>blockIdx.x</code> 索引为 1，则 <code>blockIdx.x * blockDim.x</code> 为 10。以 10 为起始索引加上可能的 <code>threadIdx.x</code> 值（0 至 9），便可在网格中找到索引为 10 至 19 的线程。</li><li>如果线程块 <code>blockIdx.x</code> 索引为 5，则 <code>blockIdx.x * blockDim.x</code> 为 50。以 50 为起始索引加上可能的 <code>threadIdx.x</code> 值（0 至 9），便可在网格中找到索引为 50 至 59 的线程。</li><li>如果线程块 <code>blockIdx.x</code> 索引为 9，则 <code>blockIdx.x * blockDim.x</code> 为 90。以 90 为起始索引加上可能的 <code>threadIdx.x</code> 值（0 至 9），便可在网格中找到索引为 90 至 99 的线程。</li></ul>\n<p>现在我们来加速具有多个线程块的For循环：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">loop</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">// 在Grid中遍历所有thread</span>\n  <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%d\\n\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">/*\n   * 配置参数还可以试试其他的，例如：\n   * &lt;&lt;&lt;5, 2&gt;&gt;&gt;\n   * &lt;&lt;&lt;10, 1&gt;&gt;&gt;\n   */</span>\n  loop<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>multi-block-loop.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc multi<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o multi<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>multi<span class=\"token operator\">-</span>block<span class=\"token operator\">-</span>loop\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\a219e4f1fb7640e2b4c0b55e74b0757b.png\"/></p>\n<h3><a id=\"4_GPUCPU_301\"></a>4. 分配可同时被GPU和CPU访问的内存</h3>\n<p>CUDA 的最新版本（版本 6 和更高版本）可以便捷地分配和释放既可用于 Host 也可被 Device 访问的内存。</p>\n<p>在 Host（CPU）中，我们一般适用<code>malloc</code> 和 <code>free</code> 来分配和释放内存，但这样分配的内存无法直接被Device（GPU）访问，所以在这里我们用<code>cudaMallocManaged</code> 和 <code>cudaFree</code> 两个函数来分配和释放同时可被 Host 和 Device 访问的内存。如下例所示：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token comment\">// CPU</span>\n<span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\nsize_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n\na <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span><span class=\"token punctuation\">)</span><span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 分配CPU内存</span>\n<span class=\"token function\">free</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 释放CPU内存</span>\n</code></pre>\n<pre><code class=\"prism language-cpp\"><span class=\"token comment\">// GPU</span>\n<span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\nsize_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n\n<span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\">// 为a分配CPU和GPU内存</span>\n<span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 释放GPU内存</span>\n</code></pre>\n<p>实际上，<code>cudaMallocManaged</code>在统一内存中创建了一个托管内存池（CPU上有，GPU上也有），内存池中已分配的空间可以通过相同的指针直接被CPU和GPU访问，底层系统在统一的内存空间中自动地在设备和主机间进行传输。数据传输对应用来说是透明的，大大简化了代码。</p>\n<p>现在让我们来看看如何利用GPU来执行数组元素的乘法操作：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token comment\">// 初始化数组</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">init</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// CUDA 核函数，所有元素乘2</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">doubleElements</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  i <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 检查数组内所有元素的值是否均为复数</span>\n<span class=\"token keyword\">bool</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> i<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n\n  size_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 为a分配CPU和GPU空间</span>\n\n  <span class=\"token function\">init</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 为数组a赋值</span>\n  size_t threads_per_block <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 定义每个block的thread数量</span>\n  size_t number_of_blocks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">+</span> threads_per_block <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> threads_per_block<span class=\"token punctuation\">;</span> <span class=\"token comment\">// 定义block的数量</span>\n\n  doubleElements<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行核函数</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步</span>\n\n  <span class=\"token keyword\">bool</span> areDoubled <span class=\"token operator\">=</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 检查元素是否为复数</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"All elements were doubled? %s\\n\"</span><span class=\"token punctuation\">,</span> areDoubled <span class=\"token operator\">?</span> <span class=\"token string\">\"TRUE\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"FALSE\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 释放由cudaMallocManaged</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>double-elements.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc <span class=\"token keyword\">double</span><span class=\"token operator\">-</span>elements<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o <span class=\"token keyword\">double</span><span class=\"token operator\">-</span>elements\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span><span class=\"token keyword\">double</span><span class=\"token operator\">-</span>elements\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\a45dac6d61a84fb897f69f196d718e07.png\"/></p>\n<h3><a id=\"5__388\"></a>5. 网格大小与实际并行工作量不匹配</h3>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/a9da8a81d43d488b97efa6da84f9a3c1.gif#pic_center\"/></p>\n<h4><a id=\"51__390\"></a>5.1. 网格大于工作量</h4>\n<p>鉴于 GPU 的硬件特性，线程块中的线程数最好配置为 32 的倍数。但是在实际工作中，很可能会出现这样的情况，我们手动配置参数所创建的线程数无法匹配为实现并行循环所需的线程数，比如实际上需要执行1230次循环，但是你却配置了2048个线程。</p>\n<p>我们不可能每次配置参数的时候都手动去算一遍最佳配置，更何况并不是所有的数都是 32 的倍数。不过这个问题现在已经可以通过以下三个步骤轻松地解决：</p>\n<ul><li>首先，设置配置参数，使线程总数超过实际工作所需的线程数。</li><li>然后，在向核函数传递参数时传递一个用于表示要处理的数据集总大小或完成工作所需的总线程数 N。</li><li>最后，计算网格内的线程索引后（使用 <code>threadIdx + blockIdx*blockDim</code>），判断该索引是否超过 N，只在不超过的情况下执行与核函数相关的工作。</li></ul>\n<p>以下是一种可选的配置方式，适用于 工作总量 N 和线程块中的线程数已知的情况。如此一来，便可确保网格中至少始终能执行 N 次任务，且最多只浪费 1 个线程块的线程数量：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token comment\">// 假设N是已知的</span>\n<span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">100000</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// 把每个block中的thread数设为256</span>\nsize_t threads_per_block <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// 根据N和thread数量配置Block数量</span>\nsize_t number_of_blocks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">+</span> threads_per_block <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> threads_per_block<span class=\"token punctuation\">;</span>\n\nsome_kernel<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>由于上述执行配置致使网格中的线程数超过 N，因此需要注意 some_kernel 定义中的内容，以确保 some_kernel 在由其中一个额外的（大于N的）线程执行时不会尝试访问超出范围的数据元素，也就是要加个判断：</p>\n<pre><code class=\"prism language-cpp\">__global__ <span class=\"token function\">some_kernel</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>idx <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span> <span class=\"token comment\">// 保证线程ID小于元素数量N</span>\n    <span class=\"token comment\">// 并行代码</span>\n  <span class=\"token punctuation\">}</span>\n</code></pre>\n<p>使用不匹配的配置参数来加速 For 循环</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">initializeElementsTo</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> initialValue<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> initialValue<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n  size_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  size_t threads_per_block <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\">// 这是惯用的CUDA语法</span>\n  <span class=\"token comment\">// 为 number_of_blocks 分配一个值，以确保线程数至少与指针 a 中可供访问的元素数同样多。</span>\n  size_t number_of_blocks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">+</span> threads_per_block <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> threads_per_block<span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">int</span> initialValue <span class=\"token operator\">=</span> <span class=\"token number\">6</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 初始化的值</span>\n  initializeElementsTo<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>initialValue<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// 检查元素值是否被初始化</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> initialValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n      <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"FAILURE: target value: %d\\t a[%d]: %d\\n\"</span><span class=\"token punctuation\">,</span> initialValue<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token function\">exit</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"SUCCESS!\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>mismatched-config-loop.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc mismatched<span class=\"token operator\">-</span>config<span class=\"token operator\">-</span>loop<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o mismatched<span class=\"token operator\">-</span>config<span class=\"token operator\">-</span>loop\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>mismatched<span class=\"token operator\">-</span>config<span class=\"token operator\">-</span>loop\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\4631cb420b5b4a3d9b73be6933cb7275.png\"/></p>\n<h4><a id=\"52__474\"></a>5.2. 网格小于工作量</h4>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/1cc6f30b9b3142a29f0b61913fed7797.gif#pic_center\"/></p>\n<p>有时，工作量比网格大，或者出于某种原因，一个网格中的线程数量可能会小于实际工作量的大小。请思考一下包含 1000 个元素的数组和包含 250 个线程的网格（此处使用极小的规模以便于说明）。此网格中的每个线程将需使用 4 次。如要实现此操作，一种常用方法便是在核函数中使用跨网格循环。</p>\n<p>在跨网格循环中，每个线程将在网格内使用 <code>threadIdx + blockIdx*blockDim</code> 计算自身唯一的索引，并对数组内该索引的元素执行相应运算，然后用网格中的<strong>线程数</strong>加上自身索引值，并重复此操作，直至超出数组范围。</p>\n<p>例如，对于包含 500 个元素的数组 <code>a</code> 和包含 250 个线程的网格，网格中索引为 20 的线程将执行如下操作：</p>\n<ul><li>对 <code>a[20]</code> 执行相应运算；</li><li>将线程索引增加 250，使网格的大小达到 270</li><li>对<code>a[270]</code> 执行相应运算；</li><li>将线程索引增加 250，使网格的大小达到 520</li><li>由于 520 现已超出数组范围，因此线程将停止工作。</li></ul>\n<p>CUDA 提供一个记录了网格中线程块数的变量：<code>gridDim.x</code>。然后可以利用它来计算网格中的总线程数，即网格中的线程块数乘以每个线程块中的线程数：<code>gridDim.x * blockDim.x</code>。现在来看看以下核函数中网格跨度循环的示例：</p>\n<pre><code class=\"prism language-cpp\">__global <span class=\"token keyword\">void</span> <span class=\"token function\">kernel</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> indexWithinTheGrid <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> gridStride <span class=\"token operator\">=</span> gridDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span> <span class=\"token comment\">// grid 的一个跨步</span>\n\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> indexWithinTheGrid<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> gridStride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token comment\">// 对 a[i] 的操作;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>上面是一个简单的例子，现在我们来看看一个更详细的例子，使用了跨网格循环来处理比网格更大的数组：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token comment\">// 初始化数组a</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">init</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">doubleElements</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n\n  <span class=\"token comment\">// 使用grid-stride循环，这样每个线程可以处理数组中的多个元素。</span>\n  <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> stride <span class=\"token operator\">=</span> gridDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span> <span class=\"token comment\">// grid 的一个跨步</span>\n\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 检查数组内所有元素的值是否均为复数</span>\n<span class=\"token keyword\">bool</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> i<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n  size_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">init</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 初始化数组a</span>\n\n  size_t threads_per_block <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 每个block的thread数量</span>\n  size_t number_of_blocks <span class=\"token operator\">=</span> <span class=\"token number\">32</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// block数量</span>\n\n  doubleElements<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">bool</span> areDoubled <span class=\"token operator\">=</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token comment\">// 检查数组内所有元素的值是否均为复数</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"All elements were doubled? %s\\n\"</span><span class=\"token punctuation\">,</span> areDoubled <span class=\"token operator\">?</span> <span class=\"token string\">\"TRUE\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"FALSE\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>grid-stride-double.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc grid<span class=\"token operator\">-</span>stride<span class=\"token operator\">-</span><span class=\"token keyword\">double</span><span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o grid<span class=\"token operator\">-</span>stride<span class=\"token operator\">-</span><span class=\"token keyword\">double</span>\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>grid<span class=\"token operator\">-</span>stride<span class=\"token operator\">-</span><span class=\"token keyword\">double</span>\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\8eacd65fed7146dc92b72c779ab9e4ce.png\"/></p>\n<h3><a id=\"6__566\"></a>6. 错误处理</h3>\n<p>CUDA 函数发生错误时会返回一个类型为 <code>cudaError_t</code> 的变量，该变量可用于检查调用函数时是否发生错误。以下是对调用 <code>cudaMallocManaged</code> 函数执行错误处理的示例：</p>\n<pre><code class=\"prism language-cpp\">cudaError_t err<span class=\"token punctuation\">;</span>\nerr <span class=\"token operator\">=</span> <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span>                    <span class=\"token comment\">// 假设a和N已经被定义</span>\n\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>err <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span> <span class=\"token comment\">// `cudaSuccess` 是一个 CUDA 变量.</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// `cudaGetErrorString` 是一个 CUDA 函数.</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>但是，核函数并不会返回类型为 <code>cudaError_t</code> 的值（因为核函数的返回值为void）。为检查执行核函数时是否发生错误（例如配置错误），CUDA 提供了 <code>cudaGetLastError</code> 函数，可以用于检查核函数执行期间发生的错误。</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token comment\">// 这段程序中的核函数会出一个CUDA错误，但是核函数本身无法捕获该错误</span>\nsomeKernel<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// 线程数不能为-1</span>\n\ncudaError_t err<span class=\"token punctuation\">;</span>\nerr <span class=\"token operator\">=</span> <span class=\"token function\">cudaGetLastError</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// `cudaGetLastError` 会捕获上面代码中的最近的一个错误</span>\n<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>err <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>另一个要注意的点是，为了捕捉在异步核函数执行期间发生的错误，一定要检查后续同步 CPU 与 GPU 时 API 调用所返回的状态（例如 <code>cudaDeviceSynchronize</code>）；如果之前执行的某一个核函数失败了，则将会返回错误。</p>\n<p>添加错误处理的示例：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n\n<span class=\"token comment\">// 初始化数组a</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">init</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// CUDA 核函数 数组元素值乘2</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">doubleElements</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> idx <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> stride <span class=\"token operator\">=</span> gridDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// for (int i = idx; i &lt; N; i += stride) {<!-- --></span>\n  <span class=\"token comment\">// 这里出现一个数值越界错误</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> idx<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N <span class=\"token operator\">+</span> stride<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 检查数组元素是否均为复数</span>\n<span class=\"token keyword\">bool</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> i<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n\n  size_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">init</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  cudaError_t syncErr<span class=\"token punctuation\">,</span> asyncErr<span class=\"token punctuation\">;</span> <span class=\"token comment\">// 定义错误处理变量</span>\n  \n  <span class=\"token comment\">// size_t threads_per_block = 1024;</span>\n  <span class=\"token comment\">// 线程数大于1024（前面说过每个block的线程数不能超过1024）</span>\n  size_t threads_per_block <span class=\"token operator\">=</span> <span class=\"token number\">2048</span><span class=\"token punctuation\">;</span>\n  size_t number_of_blocks <span class=\"token operator\">=</span> <span class=\"token number\">32</span><span class=\"token punctuation\">;</span>\n  doubleElements<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行核函数</span>\n\n  syncErr <span class=\"token operator\">=</span> <span class=\"token function\">cudaGetLastError</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 捕获核函数执行期间发生的错误</span>\n  asyncErr <span class=\"token operator\">=</span> <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步，并捕获同步期间发生的错误</span>\n\n  <span class=\"token comment\">// 输出错误 说明：两个错误需分别设置（即每次运行时只保留一个错误）</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>syncErr <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>syncErr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>asyncErr <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>asyncErr<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">bool</span> areDoubled <span class=\"token operator\">=</span> <span class=\"token function\">checkElementsAreDoubled</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 验证数组元素值是否均为复数</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"All elements were doubled? %s\\n\"</span><span class=\"token punctuation\">,</span> areDoubled <span class=\"token operator\">?</span> <span class=\"token string\">\"TRUE\"</span> <span class=\"token operator\">:</span> <span class=\"token string\">\"FALSE\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>将上述代码命名为<code>add-error-handling.cu</code>，然后编译运行：</p>\n<pre><code class=\"prism language-cpp\">nvcc add<span class=\"token operator\">-</span>error<span class=\"token operator\">-</span>handling<span class=\"token punctuation\">.</span>cu <span class=\"token operator\">-</span>o add<span class=\"token operator\">-</span>error<span class=\"token operator\">-</span>handling\n<span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>add<span class=\"token operator\">-</span>error<span class=\"token operator\">-</span>handling\n</code></pre>\n<p>输出：<br/> <img alt=\"在这里插入图片描述\" src=\"image\\ff69ccd182ba4991a8f427fc9de7c319.png\"/></p>\n<h4><a id=\"61__CUDA__665\"></a>6.1. 定制一个 CUDA 错误处理宏</h4>\n<p>创建一个包装 CUDA 函数调用的宏对于检查错误十分有用。以下是一个宏示例，我们可以在其他的 CUDA 代码中随时使用：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;assert.h&gt;</span></span>\n\n<span class=\"token comment\">// CUDA 错误处理宏</span>\n<span class=\"token keyword\">inline</span> cudaError_t <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span>cudaError_t result<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>result <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token function\">fprintf</span><span class=\"token punctuation\">(</span><span class=\"token constant\">stderr</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"CUDA Runtime Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">assert</span><span class=\"token punctuation\">(</span>result <span class=\"token operator\">==</span> cudaSuccess<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token comment\">// checkCuda 宏可以返回 CUDA 函数返回的错误类型`cudaError_t`的值</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h3><a id=\"7__688\"></a>7. 总结</h3>\n<p>至此，我们已经完成了我们预期的学习目标：</p>\n<ul><li>编写、编译及运行既可调用 CPU 函数也可启动GPU核函数的 C/C++ 程序。</li><li>使用执行配置控制并行线程层次结构。</li><li>重构串行循环以在 GPU 上并行执行其迭代。</li><li>分配和释放可用于 CPU 和 GPU 的内存。</li><li>处理 CUDA 代码生成的错误。</li></ul>\n<p>现在，加速 CPU 应用程序进行是可行的了。</p>\n<h4><a id=\"71__CUDA__699\"></a>7.1 用 CUDA 实现向量加法</h4>\n<p>为了展示一下如何综合运用本篇教程提到的内容，我们通过一个向量与向量加分的案例来串用以上知识：</p>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;assert.h&gt;</span></span>\n\n<span class=\"token comment\">// CUDA 错误处理宏</span>\n<span class=\"token keyword\">inline</span> cudaError_t <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span>cudaError_t result<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>result <span class=\"token operator\">!=</span> cudaSuccess<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token function\">fprintf</span><span class=\"token punctuation\">(</span><span class=\"token constant\">stderr</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"CUDA Runtime Error: %s\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">cudaGetErrorString</span><span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">assert</span><span class=\"token punctuation\">(</span>result <span class=\"token operator\">==</span> cudaSuccess<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 初始化数组 a</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">initWith</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span> num<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> num<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 向量加法核函数</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">addVectorsInto</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>result<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>b<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> index <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> stride <span class=\"token operator\">=</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> gridDim<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> index<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    result<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 元素a[i] + 元素 b[i]</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// 检查 CUDA 向量加分是否计算正确</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">checkElementsAre</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span> target<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>array<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> target<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n      <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"FAIL: array[%d] - %0.0f does not equal %0.0f\\n\"</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token function\">exit</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"SUCCESS! All values added correctly.\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n  size_t size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>b<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>c<span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// 分配内存，且检查执行期间发生的错误</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>b<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaMallocManaged</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>c<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token function\">initWith</span><span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 将数组a中所有的元素初始化为3</span>\n  <span class=\"token function\">initWith</span><span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 将数组b中所有的元素初始化为4</span>\n  <span class=\"token function\">initWith</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 将数组c中所有的元素初始化为0，数组c是结果向量</span>\n\n  <span class=\"token comment\">// 配置参数</span>\n  size_t threadsPerBlock <span class=\"token operator\">=</span> <span class=\"token number\">256</span><span class=\"token punctuation\">;</span>\n  size_t numberOfBlocks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">+</span> threadsPerBlock <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> threadsPerBlock<span class=\"token punctuation\">;</span>\n  addVectorsInto<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>numberOfBlocks<span class=\"token punctuation\">,</span> threadsPerBlock<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">,</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行核函数</span>\n\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaGetLastError</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 检查核函数执行期间发生的错误</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步，且检查执行期间发生的错误</span>\n\n  <span class=\"token function\">checkElementsAre</span><span class=\"token punctuation\">(</span><span class=\"token number\">7</span><span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// 检查向量加的结果是否正确</span>\n\n  <span class=\"token comment\">// 释放内存，且检查执行期间发生的错误</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">checkCuda</span><span class=\"token punctuation\">(</span> <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre>\n<h4><a id=\"72__779\"></a>7.2. 二维和三维的网格和块</h4>\n<p>网格和线程块最多可以定义有 3 个维度，使用多个维度定义网格和线程块在处理具有多个维度的数据时可能很有效，例如二维矩阵。如果要定义二维或三维的网格或线程块，可以使用 CUDA 的 <code>dim3</code> 关键字来定义多维网格或块，即如下所示：</p>\n<pre><code class=\"prism language-cpp\">dim3 <span class=\"token function\">threads_per_block</span><span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndim3 <span class=\"token function\">number_of_blocks</span><span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsomeKernel<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block<span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p>鉴于以上示例，someKernel 内部的变量 gridDim.x、gridDim.y、blockDim.x 和 blockDim.y 均将等于 16。</p>\n<h4><a id=\"73__CUDA__790\"></a>7.3 用 CUDA 实现矩阵乘法</h4>\n<pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">N</span>  <span class=\"token expression\"><span class=\"token number\">64</span></span></span>\n\n<span class=\"token comment\">// GPU 矩阵乘法</span>\n__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">matrixMulGPU</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> c <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>row <span class=\"token operator\">&lt;</span> N <span class=\"token operator\">&amp;&amp;</span> col <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k <span class=\"token punctuation\">)</span>\n      val <span class=\"token operator\">+=</span> a<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>k <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    c<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> val<span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// CPU矩阵乘法</span>\n<span class=\"token keyword\">void</span> <span class=\"token function\">matrixMulCPU</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> a<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span> c <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> row <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>row <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> col <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>col <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n      val <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k <span class=\"token punctuation\">)</span>\n        val <span class=\"token operator\">+=</span> a<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>k <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n      c<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> val<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n  <span class=\"token keyword\">int</span> <span class=\"token operator\">*</span>a<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>b<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>c_cpu<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>c_gpu<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> size <span class=\"token operator\">=</span> N <span class=\"token operator\">*</span> N <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// Number of bytes of an N x N matrix</span>\n\n  <span class=\"token comment\">// 分配内存</span>\n  <span class=\"token function\">cudaMallocManaged</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>a<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>b<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>c_cpu<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaMallocManaged</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>c_gpu<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// 初始化数组</span>\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> row <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>row <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> col <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>col <span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{<!-- --></span>\n      a<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> row<span class=\"token punctuation\">;</span>\n      b<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> col <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n      c_cpu<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n      c_gpu<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n  dim3 <span class=\"token function\">threads_per_block</span> <span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 一个 16 * 16 的线程阵</span>\n  dim3 <span class=\"token function\">number_of_blocks</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>N <span class=\"token operator\">/</span> threads_per_block<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">/</span> threads_per_block<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  matrixMulGPU <span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span> number_of_blocks<span class=\"token punctuation\">,</span> threads_per_block <span class=\"token operator\">&gt;&gt;</span><span class=\"token operator\">&gt;</span> <span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> c_gpu <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行核函数</span>\n\n  <span class=\"token function\">cudaDeviceSynchronize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 同步</span>\n\n  <span class=\"token function\">matrixMulCPU</span><span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">,</span> c_cpu <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 执行 CPU 版本的矩阵乘法</span>\n\n  <span class=\"token comment\">// 比较 CPU 和 GPU 两种方法的计算结果是否一致</span>\n  <span class=\"token keyword\">bool</span> error <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> row <span class=\"token operator\">&lt;</span> N <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span>error<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>row <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span> <span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> col <span class=\"token operator\">&lt;</span> N <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span>error<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>col <span class=\"token punctuation\">)</span>\n      <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>c_cpu<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> c_gpu<span class=\"token punctuation\">[</span>row <span class=\"token operator\">*</span> N <span class=\"token operator\">+</span> col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{<!-- --></span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"FOUND ERROR at c[%d][%d]\\n\"</span><span class=\"token punctuation\">,</span> row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        error <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span>\n      <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>error<span class=\"token punctuation\">)</span>\n    <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Success!\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// 释放内存</span>\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span> c_cpu <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token function\">cudaFree</span><span class=\"token punctuation\">(</span> c_gpu <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>"}