{"blogid": "125192385", "writerAge": "码龄1年", "writerBlogNum": "75", "writerCollect": "1131", "writerComment": "768", "writerFan": "5065", "writerGrade": "5级", "writerIntegral": "2859", "writerName": "Aaron-ywl", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_125192385.jpg", "writerRankTotal": "6173", "writerRankWeekly": "848", "writerThumb": "763", "writerVisitNum": "113132", "blog_read_count": "7816", "blog_time": "已于 2022-07-06 19:40:57 修改", "blog_title": "安装tensorflow的GPU版本（详细图文教程）--CUDA11.6的安装", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-light\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>文章目录</h3>\n<ul><li><a href=\"#TensorFlow_1\">TensorFlow简介</a></li><li><ul><li><a href=\"#TensorFlow_3\">TensorFlow是什么</a></li><li><a href=\"#tensorflow_32\">tensorflow版本变迁</a></li><li><a href=\"#tensorflow_20__37\">tensorflow 2.0 架构</a></li></ul>\n</li><li><a href=\"#_64\">安装过程</a></li><li><ul><li><a href=\"#IDE_66\">常用IDE安装</a></li><li><ul><li><a href=\"#python39_67\">python3.9的安装</a></li><li><a href=\"#Anaconda_70\">Anaconda的安装</a></li></ul>\n</li><li><a href=\"#CUDA_75\">CUDA安装</a></li><li><ul><li><a href=\"#cuda_89\">cuda软件安装</a></li><li><a href=\"#cuDNN_143\">cuDNN神经网络加速库安装</a></li><li><a href=\"#_160\">配置环境变量</a></li></ul>\n</li><li><a href=\"#TensorFlowgpu_186\">TensorFlow的gpu版本安装</a></li></ul>\n</li></ul>\n</div>\n<p></p>\n<h1><a id=\"TensorFlow_1\"></a>TensorFlow简介</h1>\n<h2><a id=\"TensorFlow_3\"></a>TensorFlow是什么</h2>\n<ul><li> <p>TensorFlow是深度学习领域使用最为广泛的一个Google的开源软件库（最初由Google brain team进行开发的内部库，由于它的易用性Google决定把它开源出来）.</p> </li><li> <p>采取数据流图，用于数值计算.</p> <p>节点——处理数据</p> <p>线——节点间的输入输出关系</p> <p>数据流图中的数据叫做tensor, 表示张量, 即N维数据, tensor在数据流图中流动表示计算的过程, 这也是tensorflow名字的由来.</p> <p><img alt=\"[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-PFbJnP45-1654697407695)(.\\img\\数据流图.gif)]\" src=\"https://img-blog.csdnimg.cn/cae3eb3eaa55484fac038ba1b581f196.gif\"/></p> </li><li> <p>支持多种平台，GPU、CPU、移动设备</p> </li><li> <p>tensorflow特性:</p>\n<ul><li>高度的灵活性: 只要能把数据的计算表示成数据流图就可以使用tensorflow</li><li>真正的可移植性: 比如CPU、GPU、移动设备等等</li><li>产品和科研结合 \n    <ul><li>tensorflow研究最初是用于科研的，其实科研和工程还有一定的距离，科研的代码需要进一步各种各样的优化才能真正的做到产品上去，但是对于tensorflow则没有这个问题，Google团队把tensorflow优化的已经比较好了，做研究的代码可以无缝的用到产品上</li></ul> </li><li>自动求微分</li><li>多语言支持 \n    <ul><li>tensorflow除了python以外，还支持各种各样的语言，比如说c++、java、javascript、R语言等</li></ul> </li><li>性能最优化 \n    <ul><li>在tensorflow刚刚出来的时候由于它运行的比较慢，很多深度学习库呢都会拿tensorflow来进行比较，然后来证明自己比tensorflow好多少倍，但是随着tensorflow一步一步的进行开发，这种情况一去不复返了，tensorflow现在应该是运行最快的一个库，对于分布式的tensorflow来说，它的加速比几乎是线性的</li></ul> </li></ul> </li></ul>\n<h2><a id=\"tensorflow_32\"></a>tensorflow版本变迁</h2>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\a7e3be89412c499fa8da4bd113e2dc25.jpeg\"/></p>\n<h2><a id=\"tensorflow_20__37\"></a>tensorflow 2.0 架构</h2>\n<p><img alt=\"[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-pnFMJlYW-1654697407696)(.\\img\\TensorFlow2.0架构.jpg)]\" src=\"..\\..\\static\\image\\38c6e6a223d14e8b8841ab3493f28aaf.jpeg\"/></p>\n<ul><li>tensorflow2.0主要特性: \n  <ul><li>使用tf.keras和eager mode（动态图模式）进行更简单的模型构建. \n    <ul><li>使用tf.data加载数据</li><li>使用tf.keras构建模型，也可使用premade estimator来验证模型 \n      <ul><li>使用tensorflow hub进行迁移学习</li></ul> </li><li>使用eager mode运行和调试</li><li>使用分发策略来进行分布式训练</li><li>导出到SavedMode</li><li>使用TensorFlow Serve、Tensorflow Lite、Tensorflow.js部署模型</li></ul> </li><li>鲁棒的跨平台模型部署 \n    <ul><li>TensorFlow服务 \n      <ul><li>直接通过HTTP/RESR或GRPC/协议缓冲区</li></ul> </li><li>TensorFlow Lite——可部署到Android、iOS和嵌入式系统上</li><li>TensorFlow.js——在JavaScript中部署</li><li>其他语言 \n      <ul><li>C、Java、Go、C#、Rust、Julia、R等</li></ul> </li></ul> </li><li>强大的研究试验 \n    <ul><li>Keras功能API和子类API、允许创建复杂的拓扑结构</li><li>自定义训练逻辑、使用tf.GraddientTape和tf.custom_gradient进行更细粒度的控制</li><li>底层API自始至终可以与高层结合使用、完全的可定制</li><li>高级扩展：Ragged Tensor、Tensor2Tensor等</li></ul> </li><li>清除不推荐使用的API和减少重复来简化API</li></ul> </li></ul>\n<h1><a id=\"_64\"></a>安装过程</h1>\n<h2><a id=\"IDE_66\"></a>常用IDE安装</h2>\n<h3><a id=\"python39_67\"></a>python3.9的安装</h3>\n<p>在官网可以下载python3.9并安装好。这里我就不介绍了，想详细了解的可以看看我的这篇文档哦：<a href=\"https://download.csdn.net/download/weixin_56197703/85586766\">机器学习常用的环境和工具安装和使用介绍<br/> </a></p>\n<h3><a id=\"Anaconda_70\"></a>Anaconda的安装</h3>\n<p>这里我也不重点介绍了，我之前也重点详细地写过相关文章↓<br/> <a href=\"https://blog.csdn.net/weixin_56197703/article/details/124630222\">还是搞不懂Anaconda是什么?读这一篇文章就够了</a><br/> <a href=\"https://blog.csdn.net/weixin_56197703/article/details/124629964\">Jupyter notebook/Pycharm调用Anaconda虚拟环境</a><br/> 有需要的可以自行查看哦！一定会对你有帮助的！！!</p>\n<h2><a id=\"CUDA_75\"></a>CUDA安装</h2>\n<p>CUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 开发人员可以使用C语言来为CUDA架构编写程序，所编写出的程序可以在支持CUDA™的处理器上以超高性能运行。CUDA3.0已经开始支持C++和FORTRAN。</p>\n<blockquote>\n<p>我们可以安装CUDA来进行深度学习在NVIDIA的GPU显卡加速运算。</p>\n</blockquote>\n<p>但是我们在安装CUDA之前，要先确认计算机上是否支持CUDA程序的NVIDIA显卡设备。<br/> <strong>打开设备管理器，查看显示适配器是否有英伟达的显卡配置</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\aa6e2543224b4dd5bad561fab5ea5cad.png\"/><br/> 可以看出我的是1660Ti的配置支持。<br/> 如果计算机上没有NVIDIA显卡，则无法安装CUDA程序。<br/> CUDA的安装很简单，就分成三步：<br/> 1、cuda的软件安装<br/> 2、cvDNN的神经网络加速库安装<br/> 3、配置环境变量</p>\n<h3><a id=\"cuda_89\"></a>cuda软件安装</h3>\n<p>我们进入cuda软件下载的界面：<a href=\"https://developer.nvidia.com/cuda-toolkit-archive\">CUDA下载页</a><br/> 进入后选择CUDA Toolkit 11.6.0版本<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\0b50240b78e24fdf814726eb0470c1f9.png\"/><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\0c434ae6e8654ddcba79ed7e10e23f99.png\"/><br/> 大约是2.4GB，如果嫌麻烦也没关系，我已经下载好了，大家可以根据我分享的百度网盘下载：<br/> 链接：https://pan.baidu.com/s/10aHSylaMn8aEGj062c0HLA<br/> 提取码：qjuz<br/> 安装包安装完毕后，打开安装软件：路径可自行更改<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\c7fe4f6f78be4b1cb4c602cc95d912af.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\94ae34674e134d84bba06495c1d0a989.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\2c93efdd25434cffb07450b29ecbe57c.png\"/></p>\n<p>这里我们选择自定义安装。</p>\n<p><img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\b0adc9a34c6247b8a68c2d44ce381014.png\"/><br/> 在组件CUDA一栏中，取消勾选Visual Studio Integration（因为我们并没有使用Visual Stduio环境，即使勾选上了也会安装失败）<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\1d4fdd25867a489c9bb57ed096ca4a14.png\"/><br/> 在Driver components一栏比较Display Driver的新版本和当前版本的信息。若当前版本高于新版本，则取消勾选Display Driver；若若当前版本低于新版本，则保留默认安装信息即可，否则电脑会死机或者卡顿，甚至可能蓝屏。！！！<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\6f21a8c2891a4bec918b26c9496f2e6b.png\"/><br/> 在CUDA的安装路径这里，保持默认就好，默然安装在C盘，<strong>一定一定</strong>不要修改。（来自一个手贱的人的警告）<br/> <strong>一定一定要记住安装路径，因为后面配置环境要用到！！！</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\3953ef253d72431386f77735a6ad2b7a.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\5bd7b9baf25949cdb5cdc201fb9e9660.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\e2809cc5f6454abeb10ad1a6f66f52f4.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\62f295ba77a14c809630a103868d44f4.png\"/><br/> 安装完成后，我们打开环境变量查看环境是否配置好了，打开系统变量：<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\3a1a6a43c93e4d898c22ae397ab6f85a.png\"/><br/> 如果系统变量没有自动配置的话，需要我们手动配置。路径是根据前面是否自己有没有修改来指定。↓<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\d9492bceaca249e792096aba60a146e7.png\"/><br/> 配置好环境变量后，我们检查下CUDA是否安装成功。打开cmd，输入以下命令查看CUDA是否安装成功（二选一）<br/> 如果不能显示以下信息，则说明安装失败。</p>\n<pre><code class=\"prism language-python\">nvcc <span class=\"token operator\">-</span>V\n</code></pre>\n<p>或者</p>\n<pre><code class=\"prism language-python\">nvcc <span class=\"token operator\">-</span><span class=\"token operator\">-</span>version\n</code></pre>\n<p><img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\53e41e0551784295b9d024569b260a67.png\"/><br/> 还可以查看CUDA 设置的环境变量。</p>\n<pre><code class=\"prism language-python\"><span class=\"token builtin\">set</span> cuda\n</code></pre>\n<p><img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\35da4f8b8ee6462aa6845e24b9a78b19.png\"/><br/> 我们还可以搜索CUDA 的安装目录，找到“nvcc.exe”文件。<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\bc68423c821d45a69032859196310d37.png\"/></p>\n<h3><a id=\"cuDNN_143\"></a>cuDNN神经网络加速库安装</h3>\n<p>CUDA并不是实现GPU的神经网络加速库，如果希望针对的是神经网络进行加速，我们还需要安装cuDNN神经网络加速库。<br/> cuDNN并非是应用程序，而是几个文件包，下载后把它复制到CUDA 的目录下即可。<br/> cuDNN下载页：<a href=\"https://developer.nvidia.com/rdp/cudnn-archive\">cuDNN下载页</a><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\82c454246568451abf8e7ecb2cb31c55.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\35d99ec14d7d42508a21f0e23bb726c4.png\"/><br/> <strong>注意！如果要下载cuDNN，必须要登录NVIDIA的账户。登录完成后才能下载。没登录过的先注册。</strong> 如果大家嫌麻烦的话也不要紧，我已经下载好了，大家下载我的百度网盘分享连接下载即可：<br/> 链接：https://pan.baidu.com/s/10aHSylaMn8aEGj062c0HLA<br/> 提取码：qjuz<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\c45f1da9e3934d5f90e1b9951681ce6e.png\"/><br/> 下载好安装包后，我们解压可以看到有四个文件：<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\6ee170b7f74749518b9f799a1f4d90cc.png\"/><br/> 我们查看CUDA11.6的原文件：<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\54ede01a5d0b41b48cfc6d6c70104c12.png\"/><br/> 将cuDNN的文件全部复制到该文件夹下，复制后的文件展示：（有重复的文件是正常的，覆盖掉就好）<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\2eb2232ede844463ba71fd800d5c66bf.png\"/><br/> cuDNN其实就是CUDA的一个补丁而已，专为深度学习运算进行优化的，然后我们再添加环境变量！继续往下走。</p>\n<h3><a id=\"_160\"></a>配置环境变量</h3>\n<p>我们打开环境变量，在系统变量的path路径下添加以下路径：（具体要根据自己的安装路径下做调整）</p>\n<pre><code class=\"prism language-python\">C<span class=\"token punctuation\">:</span>\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11<span class=\"token punctuation\">.</span><span class=\"token number\">6</span>\\<span class=\"token builtin\">bin</span>\nC<span class=\"token punctuation\">:</span>\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11<span class=\"token punctuation\">.</span><span class=\"token number\">6</span>\\libnvvp\nC<span class=\"token punctuation\">:</span>\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11<span class=\"token punctuation\">.</span><span class=\"token number\">6</span>\\lib\nC<span class=\"token punctuation\">:</span>\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11<span class=\"token punctuation\">.</span><span class=\"token number\">6</span>\\include\n</code></pre>\n<p>添加好后是这样的：<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\5fc8515300e540bf9b08e8ad6e809237.png\"/><br/> 配置好环境后，我们需要验证环境变量是否配置成功：<br/> 打开cmd，我们进入到以下路径：</p>\n<pre><code class=\"prism language-python\">C<span class=\"token punctuation\">:</span>\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11<span class=\"token punctuation\">.</span><span class=\"token number\">6</span>\\extras\\demo_suite\n</code></pre>\n<p>然后分别执行以下两个命令：.\\bandwidthTest.exe<br/> 和.\\deviceQuery.exe<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\0a120a1a5781493cbb1a43ceac27d37c.png\"/><br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\ae9264a4cf1e4eb8af76924313e28ba3.png\"/><br/> 如果Result都为PASS的话则配置成功！</p>\n<p>都安装好之后，我们可以继续输入<code>nvidia-smi</code>查看CUDA的信息，然后根据安装版本的信息再去实现其他的库（环境）安装和使用！<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\9e8c221a97394f3c851450821e566e8d.png\"/><br/> 如图所示，可以看到驱动的版本是511.23；最高支持的CUDA版本是11.6版本。</p>\n<h2><a id=\"TensorFlowgpu_186\"></a>TensorFlow的gpu版本安装</h2>\n<p>国内利用pip命令下载安装经常会遇到下载速度很慢甚至连接断开、响应超时等导致安装失败的情况。这时，我们可以选择国内的镜像配置pip源，仅需要在“pip install”命令后加入“-i 源地址”即可。<br/> 现在我们利用国内清华源安装TensorFlow的最新版本。<br/> 打开cmd，以下命令安装：</p>\n<pre><code class=\"prism language-python\">pip install <span class=\"token operator\">-</span>U tensorflow<span class=\"token operator\">-</span>gpu <span class=\"token operator\">-</span>i https<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>pypi<span class=\"token punctuation\">.</span>tuna<span class=\"token punctuation\">.</span>tsinghua<span class=\"token punctuation\">.</span>edu<span class=\"token punctuation\">.</span>cn<span class=\"token operator\">/</span>simple\n</code></pre>\n<p>“-U”参数指定如果已安装此包，则进行升级命令。<img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\7dae2c0681934a6fbc49c26ecbe599ad.png\"/><br/> 安装好后，我们检测是否安装成功：<br/> 进入python环境，打开ipython交互命令终端，导包：import tensorflow as tf</p>\n<p>若无错误信息，输入</p>\n<pre><code class=\"prism language-python\">tf<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>is_gpu_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>会返回tensorflow的gpu版本信息。<br/> 在末尾如果显示True，则tensorflow的gpu版本安装成功；若为False，则说明安装失败，需要重新检查CUDA，cuDNN的安装及其环境变量的配置。注意看返回的错误信息，重点检查CUDA和cuDNN的版本和tensorflow的版本是否匹配！<img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\569ce96fce04456a9dc902105ccae948.png\"/><br/> 或者输入</p>\n<pre><code class=\"prism language-python\">tf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>list_physical_devices<span class=\"token punctuation\">(</span><span class=\"token string\">'GPU'</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>还能查看服务类型。<br/> <img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\fb85e8db123240c5ba0426ebf17c6a55.png\"/><br/> 还可以查看可用的gpu数量：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Num GPUs Available:'</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>list_physical_devices<span class=\"token punctuation\">(</span><span class=\"token string\">'GPU'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p><img alt=\"请添加图片描述\" src=\"..\\..\\static\\image\\a8cafa66171d45209cf101dac8309e3f.png\"/><br/> 还可以查看TensorFlow的版本信息：</p>\n<pre><code class=\"prism language-python\">tf<span class=\"token punctuation\">.</span>__version__\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\64d920623c5c4463b9ba6eeaddc12cb8.png\"/></p>\n<blockquote>\n<p>后面如果我们通过tensorflow进行模型训练，系统会自动使用GPU来训练，不用我们自己手动设置。</p>\n</blockquote>\n<p>最后，希望这篇文章可以帮助到你！</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "JavaScript", "cpp": 1, "csharp": 1, "python": 1, "javascript": 1, "java": 0, "sql": 0, "php": 0, "time": "2022-07-06 19:40:57", "summary": "文章目录简介是什么版本变迁架构安装过程常用安装的安装的安装安装软件安装神经网络加速库安装配置环境变量的版本安装简介是什么是深度学习领域使用最为广泛的一个的开源软件库最初由进行开发的内部库，由于它的易用"}