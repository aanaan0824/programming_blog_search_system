{"blogid": "126639901", "writerAge": "码龄7年", "writerBlogNum": "84", "writerCollect": "378", "writerComment": "40", "writerFan": "106", "writerGrade": "5级", "writerIntegral": "2450", "writerName": "温殿飞", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126639901.jpg", "writerRankTotal": "8523", "writerRankWeekly": "17218", "writerThumb": "112", "writerVisitNum": "406524", "blog_read_count": "39", "blog_time": "于 2022-09-05 18:05:18 发布", "blog_title": "【k8s学习2】二进制文件方式安装 Kubernetes之kubernetesmaster部署", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p><a href=\"https://blog.csdn.net/qq_26711103/article/details/126562791?spm=1001.2014.3001.5501\" title=\"【k8s学习2】二进制文件方式安装 Kubernetes之etcd集群部署_温殿飞的博客-CSDN博客\">【k8s学习2】二进制文件方式安装 Kubernetes之etcd集群部署_温殿飞的博客-CSDN博客</a></p>\n<p> 如果已经完成了etcd的部署，可以按照这个文章继续部署。</p>\n<h1>部署安全的kubernetes master高可用集群。</h1>\n<h2>（1）下载kubernetes</h2>\n<p> 直接到github网站上搜索kubernetes，然后点击对应的项目进入。<img alt=\"\" height=\"539\" src=\"..\\..\\static\\image\\a385c223c39f426f85d65933b2574719.png\" width=\"1200\"/></p>\n<p>找到releases页面</p>\n<p><a href=\"https://github.com/kubernetes/kubernetes/releases?page=1\" title=\"https://github.com/kubernetes/kubernetes/releases?page=1\">https://github.com/kubernetes/kubernetes/releases?page=1</a></p>\n<p>然后再对应版本点击CHANGELOG就会跳转到下面页面，1.19即版本号，url里面可以直接修改。 </p>\n<p> <a class=\"link-info\" href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md\" title=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md</a> </p>\n<p>页面往下拉找到对应的版本， 点击Server Binaries，按道理应该会调到对应版本的下载段但是我的没有跳转。</p>\n<ul><li><a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#server-binaries-16\" title=\"Server Binaries\">Server Binaries</a></li></ul>\n<p><img alt=\"\" height=\"206\" src=\"..\\..\\static\\image\\f8bea971eaa44a55a92c80f8f6da6a4f.png\" width=\"754\"/></p>\n<p></p>\n<p>直接往下拉滚动条找到对应的版本。</p>\n<p><img alt=\"\" height=\"540\" src=\"..\\..\\static\\image\\73a897362dd447788c018fe32e26ac7f.png\" width=\"1200\"/></p>\n<p> 再往下拉倒server binaries就可以看到下载地址了。<img alt=\"\" height=\"494\" src=\"..\\..\\static\\image\\5b0e09e6234440eeb38d413186a71384.png\" width=\"1084\"/></p>\n<blockquote>\n<p>wget https://dl.k8s.io/v1.19.0/kubernetes-server-linux-amd64.tar.gz</p>\n<p>wget https://dl.k8s.io/v1.19.0/kubernetes-client-darwin-amd64.tar.gz</p>\n<p>wget https://dl.k8s.io/v1.19.0/kubernetes-node-linux-amd64.tar.gz</p>\n</blockquote>\n<p>解压kubernetes-server-linux-amd64.tar.gz</p>\n<blockquote>\n<p>#tar -zxvf kubernetes-server-linux-amd64.tar.gz</p>\n<p>#cd kubernetes/server/bin/</p>\n<p>#ls<br/> apiextensions-apiserver  kube-apiserver             kube-controller-manager             kubectl     kube-proxy.docker_tag  kube-scheduler.docker_tag<br/> kubeadm                  kube-apiserver.docker_tag  kube-controller-manager.docker_tag  kubelet     kube-proxy.tar         kube-scheduler.tar<br/> kube-aggregator          kube-apiserver.tar         kube-controller-manager.tar         kube-proxy  kube-scheduler         mounter</p>\n<p>#将可执行文件放到/usr/bin/</p>\n<p>#mv apiextensions-apiserver kubeadm kube-aggregator kube-apiserver kube-controller-manager kubectl kubelet kube-proxy kube-scheduler   /usr/bin/</p>\n</blockquote>\n<table><thead><tr><td>文件名</td><td>说明</td></tr></thead><tbody><tr><td>kube-apiserver</td><td>kube-apiserver 主程序</td></tr><tr><td>kube-apiserver.docker_tag</td><td>kube-apiserver docker 镜像的 tag</td></tr><tr><td>kube-apiserver.tar</td><td>kube-apiserver docker 镜像文件</td></tr><tr><td>kube-controller-manager</td><td>kube-controller-manager 主程序</td></tr><tr><td>kube-controller-manager.docker_tag</td><td>kube-controller-manager docker 镜像的 tag</td></tr><tr><td>kube-controller-manager.tar</td><td>kube-controller-manager docker 镜像文件</td></tr><tr><td>kube-scheduler</td><td>kube-scheduler 主程序</td></tr><tr><td>kube-scheduler.docker_tag</td><td>kube-scheduler docker 镜像的 tag</td></tr><tr><td>kube-scheduler.tar</td><td>kube-scheduler docker 镜像文件</td></tr><tr><td>kubelet</td><td>kubelet 主程序</td></tr><tr><td>kube-proxy</td><td>kube-proxy 主程序</td></tr><tr><td>kube-proxy.docker_tag</td><td>kube-proxy docker 镜像的 tag</td></tr><tr><td>kube-proxy.tar</td><td>kube-proxy docker 镜像文件</td></tr><tr><td>kubectl</td><td>客户端命令行工具</td></tr><tr><td>kubeadm</td><td>Kubernetes 集群安装的命令工具</td></tr><tr><td>apiextensions-apiserver</td><td>提供实现自定义资源对象的扩展 API Server</td></tr><tr><td>kube-aggregator</td><td>聚合 API Server 程序</td></tr></tbody></table>\n<p>然后需要在/usr/lib/systemd/system/目录下为各个服务创建systemd服务配置文件，就完成了服务的安装。</p>\n<h2>（2）部署kube-apiserver服务</h2>\n<h3>（2.1）设置kube-apiserver服务所需的ca证书。</h3>\n<blockquote>\n<p> #mkdir k8s_ssl </p>\n<p>#cd k8s_ssl/</p>\n<p>#vim master_ssl.cnf</p>\n<p>[req]<br/> req_extensions = v3_req<br/> distinguished_name = req_distinguished_name<br/> [req_distinguished_name]</p>\n<p></p>\n<p>[ v3_req ]<br/> basicConstraints = CA:FALSE<br/> keyUsage = nonRepudiation,digitalSignature,keyEncipherment<br/> subjectAltName = @alt_names</p>\n<p></p>\n<p>[alt_names]<br/> DNS.1 = kubernetes<br/> DNS.2 = kubernetes.default<br/> DNS.3 = kubernetes.default.svc<br/> DNS.4 = kubernetes.default.svc.cluster.local #上面4个都是虚拟服务名称<br/> DNS.5 = master01             ##主机名<br/> DNS.6 = master02             ##主机名<br/> IP.1 = 169.169.0.1              ##master service虚拟服务的clusterIP地址。<br/> IP.2 = 192.168.52.21          ##主机ip<br/> IP.3 = 192.168.52.22          ##主机ip<br/> IP.4 = 192.168.52.100        ##lvs用的vip</p>\n</blockquote>\n<p> 创建证书</p>\n<blockquote>\n<p>#openssl genrsa -out apiserver.key 2048</p>\n<p>#openssl req -new -key apiserver.key -config master_ssl.cnf -subj \"/CN=192.168.52.21\" -out apiserver.csr</p>\n<p>#openssl x509 -req -in apiserver.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -days 36500 -extensions v3_req -extfile master_ssl.cnf -out apiserver.crt <br/> #mv apiserver.crt apiserver.key  /etc/kubernetes/pki/</p>\n</blockquote>\n<h3> （2.2）为kube-apiserver服务创建systemd服务</h3>\n<p>配置文件/usr/lib/systemd/system/kube-apiserver.service </p>\n<pre><code>[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service]\nEnvironmentFile=/etc/kubernetes/apiserver\nExecStart=/usr/bin/kube-apiserver $KUBE_API_ARGS\nRestart=always\n\n[Install]\nWantedBy=multi-user.target</code></pre>\n<p>配置文件 <code>/etc/kubernetes/apiserver</code> 的内容通过环境变量 <code>KUBE_API_ARGS</code> 设置 <code>kube-apiserver</code> 的全部启动参数。新版的参数可能不同。</p>\n<pre><code>KUBE_API_ARGS=\"--secure-port=6443 \\\n--tls-cert-file=/etc/kubernetes/pki/apiserver.crt \\\n--tls-private-key-file=/etc/kubernetes/pki/apiserver.key \\\n--client-ca-file=/etc/kubernetes/pki/ca.crt \\\n--apiserver-count=1 \\\n--endpoint-reconciler-type=master-count \\\n--etcd-servers=https://192.168.52.21:2379,https://192.168.52.22:2379 \\\n--etcd-cafile=/etc/kubernetes/pki/ca.crt \\\n--etcd-certfile=/etc/etcd/pki/etcd_client.crt \\\n--etcd-keyfile=/etc/etcd/pki/etcd_client.key \\\n--service-cluster-ip-range=169.169.0.0/16 \\\n--service-node-port-range=30000-32767 \\\n--allow-privileged=true \\\n--v=0\"\n</code></pre>\n<p>启动服务</p>\n<p><code>systemctl restart kube-apiserver &amp;&amp; systemctl enable kube-apiserver</code></p>\n<p><code>systemctl status kube-apiserver</code></p>\n<p><img alt=\"\" height=\"176\" src=\"..\\..\\static\\image\\7869da67a8484dd9ab040292b8384759.png\" width=\"1200\"/></p>\n<p>很好没有报错直接成功了。 同样的配置把另外一台也配置上。</p>\n<h3>（2.3）创建客户端证书</h3>\n<p>kube-controller-manager、kube-scheduler、kublet和kube-proxy 都是apiserver的客户端，访问kube-apiserver的服务。用openssl创建证书并放到/etc/kubernetes/pki/ 创建好的证书考到同集群的其他服务器使用。</p>\n<pre><code>openssl genrsa -out client.key 2048 \nopenssl req -new -key client.key -subj \"/CN=admin\" -out client.csr\nopenssl x509 -req -in client.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out client.crt -days 36500</code></pre>\n<p>cp client.key client.crt /etc/kubernetes/pki/</p>\n<h3>(2.4). 创建客户端连接 kube-apiserver 服务所需的 kubeconfig 配置文件。</h3>\n<p>两台都要部署，为kube-controller-manager、kube-scheduler/kubelet、kube-proxy、kubectl统一使用的链接kube-api的配置文件。</p>\n<pre><code>apiVersion: v1\nkind: Config\nclusters:\n- name: default\n  cluster:\n    server: https://192.168.52.100:9443\n    certificate-authority: /etc/kubernetes/pki/ca.crt\nusers:\n- name: admin\n  user:\n    client-certificate: /etc/kubernetes/pki/client.crt\n    client-key: /etc/kubernetes/pki/client.key\ncontexts:\n- context:\n    cluster: default\n    user: admin\n  name: default\ncurrent-context: default\n</code></pre>\n<h3> （2.5）部署kube-controller-manager服务</h3>\n<p>两台都要部署，创建systemd的service文件，<code>/usr/lib/systemd/system/kube-controller-manager.service</code></p>\n<pre><code>[Unit]\nDescription=Kubernetes Controller Manager\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service]\nEnvironmentFile=/etc/kubernetes/controller-manager\nExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGS\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>配置文件 /etc/kubernetes/kube-controller-manager.service 的内容通过环境变量KUBE_CONTROLLER_MANAGER_ARGS设置的kube-controller-manager 的全部启动参数，包含CA安全配置的启动参数示例如下：</p>\n<pre><code>KUBE_CONTROLLER_MANAGER_ARGS=\"--kubeconfig=/etc/kubernetes/kubeconfig \\\n--leader-elect=false \\\n--service-cluster-ip-range=169.169.0.0/16 \\\n--service-account-private-key-file=/etc/kubernetes/pki/apiserver.key \\\n--root-ca-file=/etc/kubernetes/pki/ca.crt \\\n--v=0\"\n</code></pre>\n<p>systemd执行的时候其实是执行下面的命令。</p>\n<p>/usr/bin/kube-controller-manager --kubeconfig=/etc/kubernetes/kubeconfig --leader-elect=false --service-cluster-ip-range=169.169.0.0/16 --service-account-private-key-file=/etc/kubernetes/pki/apiserver.key --root-ca-file=/etc/kubernetes/pki/ca.crt --v=0 </p>\n<p> 接下来启动服务即可</p>\n<blockquote>\n<p>systemctl restart kube-controller-manager</p>\n<p>systemctl enable kube-controller-manager</p>\n</blockquote>\n<h3> （2.6）部署kube-scheduler服务</h3>\n<p>两台都要部署，为kube-scheduler服务创建systemd服务配置文件<code>//usr/lib/systemd/system/kube-scheduler.service</code></p>\n<pre><code>[Unit]\nDescription=Kubernetes Scheduler\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service]\nEnvironmentFile=/etc/kubernetes/scheduler\nExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_ARGS\nRestart=always\n\n[Install]\nWantedBy=multi-user.target</code></pre>\n<p>配置文件 /etc/kubernetes/scheduler通过环境变量$KUBE_SCHEDULER_ARGS 实现设置服务的全部参数。</p>\n<pre><code>KUBE_SCHEDULER_ARGS=\"--kubeconfig=/etc/kubernetes/kubeconfig \\\n--leader-elect=false \\\n--v=0\"</code></pre>\n<h3> （2.7）. 使用 HAProxy 和 keepalived 部署高可用负载均衡器</h3>\n<p>使用docker进行安装，docker的安装方法参考我之前的文章使用yum安装。</p>\n<p><a href=\"https://blog.csdn.net/qq_26711103/article/details/108724395\" title=\"Docker学习笔记1-在centos服务器上安装docker_温殿飞的博客-CSDN博客\">Docker学习笔记1-在centos服务器上安装docker_温殿飞的博客-CSDN博客</a></p>\n<p> 也可以使用二进制形式安装docker</p>\n<blockquote>\n<p> wget https://download.docker.com/linux/static/stable/x86_64/docker-18.03.1-ce.tgz<br/> tar -xf docker-18.03.1-ce.tgz</p>\n<p>cp docker/* /usr/bin/</p>\n</blockquote>\n<p>创建docker的systemd服务文件/usr/lib/systemd/system/docker.service</p>\n<pre><code>[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network-online.target firewalld.service\nWants=network-online.target\n \n[Service]\nType=notify\nExecStart=/usr/bin/dockerd\nExecReload=/bin/kill -s HUP $MAINPID\nLimitNOFILE=infinity\nLimitNPROC=infinity\nTimeoutStartSec=0\nDelegate=yes\nKillMode=process\nRestart=on-failure\nStartLimitBurst=3\nStartLimitInterval=60s\n \n[Install]\nWantedBy=multi-user.target\n\n</code></pre>\n<blockquote>\n<p>systemctl daemon-reload</p>\n<p>systemctl start docker</p>\n<p>systemctl enable docker</p>\n</blockquote>\n<p>接下来就是使用docker启动一个haproxy服务，创建haproxy配置文件/etc/kubernetes/haproxy.cfg </p>\n<pre><code>[root@master01 kubernetes]# cat haproxy.cfg \nglobal\n    log         127.0.0.1 local2\n    chroot      /var/lib/haproxy\n    pidfile     /var/run/haproxy.pid\n    maxconn     4096\n    user        haproxy\n    group       haproxy\n    daemon\n    stats socket /var/lib/haproxy/stats\n    \ndefaults\n    mode                http\n    log                 global\n    option              httplog\n    option              dontlognull\n    option              http-server-close\n    option              forwardfor      except 127.0.0.0/8\n    option              redispatch\n    retries             3\n    timeout http-request        10s\n    timeout queue               1m\n    timeout connect             10s\n    timeout client              1m\n    timeout server              1m\n    timeout http-keep-alive     10s\n    timeout check               10s\n    maxconn                     3000\n    \nfrontend kube-apiserver\n    mode                tcp\n    bind                *:9443\n    option              tcplog\n    default_backend     kube-apiserver\n    \nlisten stats\n    mode                http\n    bind                *:8888\n    stats auth          admin:password\n    stats refresh       5s\n    stats realm         HAProxy\\ Statistics\n    stats uri           /stats\n    log                 127.0.0.1 local3 err\n    \nbackend kube-apiserver\n    mode        tcp\n    balance     roundrobin\n    server master01 192.168.52.21:6443 check\n    server master02 192.168.52.22:6443 check\n</code></pre>\n<p> 然后执行命令启动容器，并将文件挂载到容器</p>\n<p> docker run -d --name k8s-haproxy --net=host --restart=always -v ${PWD}/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro haproxytech/haproxy-debian</p>\n<p> 然后浏览器打开，输入用户admin 密码password </p>\n<p><a href=\"http://192.168.52.21:8888/stats\" title=\"http://192.168.52.21:8888/stats\">http://192.168.52.21:8888/stats</a></p>\n<p><img alt=\"\" height=\"553\" src=\"..\\..\\static\\image\\754819ec668e436291e4a39376b14661.png\" width=\"1200\"/></p>\n<p> 另外一台也部署上hapeoxy服务。</p>\n<p>（2.8）部署lvs做vip的高可用，这里是实验都放在这两台服务器上了，生产环境可以分开设服务器。</p>\n<p>创建keepalive配置</p>\n<pre><code>! Configuration File for keepalived\n\nglobal_defs {\n    router_id LVS_1\n}\n\nvrrp_script checkhaproxy\n{\n   script \"/usr/bin/check-haproxy.sh\"\n   interval 2\n   weight -30\n}\n\nvrrp_instance VI_1 {\n   state MASTER     #主用master唯一  备用BACKUP可以有多个\n   interface ens33  #注意这里是你的服务器网卡名\n   virtual_router_id 51 \n   priority 100\n   advert_int 1\n   \n   virtual_ipaddress {\n      192.168.52.100/24 dev ens33      ##vip\n   }\n   \n   authentication {\n      auth_type PASS\n      auth_pass password\n   }\n   \n   track_script {\n      checkhaproxy\n   }\n}\n</code></pre>\n<p>在/usr/bin目录创建hapoxy端口检测脚本check-haproxy.sh，用于keepalived判断服务状态切换vip</p>\n<pre><code>#!/bin/bash\n# Program:\n#       check health\n# History:\n# 2022/01/14    wendianfei version:0.0.1\n\npath=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin\nexport path\n\ncount=$(netstat -apn | grep 9443 | wc -l)\n\nif [ ${count} -gt 0 ]\nthen\n\n    exit 0\n    \nelse\n\n    exit 1\n    \nfi</code></pre>\n<p>使用docker创建keepalived服务。 </p>\n<pre><code class=\"hljs\">docker run -d --name k8s-keepalived --restart=always --net=host --cap-add=NET_ADMIN --cap-add=NET_BROADCAST --cap-add=NET_RAW -v ${PWD}/keepalived.conf:/container/service/keepalived/assets/keepalived.conf -v ${PWD}/check-haproxy.sh:/usr/bin/check-haproxy.sh osixia/keepalived:2.0.20 --copy-service</code></pre>\n<p> 使用docker ps 查看容器运行成功 </p>\n<p><img alt=\"\" height=\"86\" src=\"..\\..\\static\\image\\babdaa84e91a4910a922d10a26e8182d.png\" width=\"1080\"/></p>\n<p> ip -a 查看服务器网卡已经挂载vip</p>\n<p><img alt=\"\" height=\"286\" src=\"..\\..\\static\\image\\be34be0f9ee440449b61f1b21341e118.png\" width=\"710\"/></p>\n<p> 浏览器访问能返回http页面证明keepalived+hapoxy组成的负载均衡系统部署完成，到这一步master就部署完了</p>\n<p><a href=\"http://192.168.52.100:9443/\" title=\"http://192.168.52.100:9443/\">http://192.168.52.100:9443/</a></p>\n<p><a href=\"http://192.168.52.100:8888/stats\" title=\"http://192.168.52.100:8888/stats\">http://192.168.52.100:8888/stats</a></p>\n</div>\n</div>", "first_tag": "Others", "cpp": 0, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-05 18:05:18", "summary": "学习二进制文件方式安装之集群部署温殿飞的博客博客学习二进制文件方式安装之集群部署温殿飞的博客博客如果已经完成了的部署，可以按照这个文章继续部署。部署安全的高可用集群。下载直接到网站上搜索，然后点击对应"}