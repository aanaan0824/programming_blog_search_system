{"blogid": "126675626", "writerAge": "码龄13年", "writerBlogNum": "502", "writerCollect": "391", "writerComment": "109", "writerFan": "172", "writerGrade": "6级", "writerIntegral": "5605", "writerName": "信息化未来", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126675626.jpg", "writerRankTotal": "3314", "writerRankWeekly": "3585", "writerThumb": "250", "writerVisitNum": "189489", "blog_read_count": "246", "blog_time": "于 2022-09-03 12:33:56 发布", "blog_title": "小学生python编程----学爬虫", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-toc\" style=\"margin-left:40px;\"><a href=\"#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86\">基础知识</a></p>\n<p style=\"margin-left:40px;\"><a href=\"#1%E3%80%81%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5\">1、请求网页</a></p>\n<p id=\"%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84requset%E5%BA%93%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%A8%A1%E6%8B%9F%E4%BA%BA%E7%B1%BB%E6%89%93%E5%BC%80%E7%BD%91%E9%A1%B5%EF%BC%8C%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E8%A1%8C%E4%B8%BA%E3%80%82%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%8F%AB%22%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5%22%E3%80%82-toc\" style=\"margin-left:80px;\"><a href=\"#%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84requset%E5%BA%93%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%A8%A1%E6%8B%9F%E4%BA%BA%E7%B1%BB%E6%89%93%E5%BC%80%E7%BD%91%E9%A1%B5%EF%BC%8C%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E8%A1%8C%E4%B8%BA%E3%80%82%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%8F%AB%22%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5%22%E3%80%82\">爬虫用到的requset库，可以模拟人类打开网页，获取网页的行为。这个过程叫\"请求网页\"。</a></p>\n<p id=\"2%E3%80%81%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E6%96%87%E6%9C%AC-toc\" style=\"margin-left:40px;\"><a href=\"#2%E3%80%81%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E6%96%87%E6%9C%AC\">2、获取网页文本</a></p>\n<p id=\"3%E3%80%81%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5%E7%BD%91%E9%A1%B5%E4%BB%A3%E7%A0%81%E6%98%AF%E7%94%B1%E4%B8%80%E4%B8%AA%E4%B8%AA%E6%A0%87%E7%AD%BE%E7%BB%84%E6%88%90%E7%9A%84%EF%BC%8C%E5%A4%A7%E5%A4%9A%E6%95%B0%E9%83%BD%E6%88%90%E5%AF%B9%E5%87%BA%E7%8E%B0%E3%80%82-toc\" style=\"margin-left:40px;\"><a href=\"#3%E3%80%81%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5%E7%BD%91%E9%A1%B5%E4%BB%A3%E7%A0%81%E6%98%AF%E7%94%B1%E4%B8%80%E4%B8%AA%E4%B8%AA%E6%A0%87%E7%AD%BE%E7%BB%84%E6%88%90%E7%9A%84%EF%BC%8C%E5%A4%A7%E5%A4%9A%E6%95%B0%E9%83%BD%E6%88%90%E5%AF%B9%E5%87%BA%E7%8E%B0%E3%80%82\">3、分析网页网页代码是由一个个标签组成的，大多数都成对出现。</a></p>\n<p id=\"4%E3%80%81%E5%8F%98%E4%B8%BA%E8%A7%A3%E6%9E%90%E5%AF%B9%E8%B1%A1bs4%E5%BA%93%EF%BC%9A%E7%94%A8%E6%9D%A5%E8%A7%A3%E6%9E%90%E7%88%AC%E5%8F%96%E7%9A%84%E7%BD%91%E9%A1%B5%EF%BC%8C%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AF%E3%80%82-toc\" style=\"margin-left:40px;\"><a href=\"#4%E3%80%81%E5%8F%98%E4%B8%BA%E8%A7%A3%E6%9E%90%E5%AF%B9%E8%B1%A1bs4%E5%BA%93%EF%BC%9A%E7%94%A8%E6%9D%A5%E8%A7%A3%E6%9E%90%E7%88%AC%E5%8F%96%E7%9A%84%E7%BD%91%E9%A1%B5%EF%BC%8C%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AF%E3%80%82\">4、变为解析对象bs4库：用来解析爬取的网页，提取信息。</a></p>\n<p id=\"5%E3%80%81%E8%8E%B7%E5%8F%96%E5%86%85%E5%AE%B9-toc\" style=\"margin-left:40px;\"><a href=\"#5%E3%80%81%E8%8E%B7%E5%8F%96%E5%86%85%E5%AE%B9\">5、获取内容</a></p>\n<p id=\"data%E4%BF%9D%E5%AD%98%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E6%98%AF%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E3%80%82-toc\" style=\"margin-left:40px;\"><a href=\"#data%E4%BF%9D%E5%AD%98%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E6%98%AF%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E3%80%82\">data保存获取到的内容，是一个列表。</a></p>\n<p id=\"6%E3%80%81%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E6%96%87%E5%AD%97%E6%A0%87%E7%AD%BE.text%E6%96%B9%E6%B3%95%EF%BC%9A%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E3%80%82-toc\" style=\"margin-left:40px;\"><a href=\"#6%E3%80%81%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E6%96%87%E5%AD%97%E6%A0%87%E7%AD%BE.text%E6%96%B9%E6%B3%95%EF%BC%9A%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E3%80%82\">6、获取标签文字标签.text方法：获取标签中的文本信息。</a></p>\n<p id=\"7%E3%80%81%E7%A4%BA%E4%BE%8B-toc\" style=\"margin-left:40px;\"><a href=\"#7%E3%80%81%E7%A4%BA%E4%BE%8B\">7、示例</a></p>\n<hr id=\"hr-toc\"/>\n<h2>基础知识</h2>\n<p>网络爬虫（又称为网页蜘蛛，<a href=\"https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C/143243?fromModule=lemma_inlink\" title=\"网络\">网络</a>机器人），是一种按照一定的规则，自动地抓取互网联信息的<a href=\"https://baike.baidu.com/item/%E7%A8%8B%E5%BA%8F/13831935?fromModule=lemma_inlink\" title=\"程序\">程序</a>或者<a href=\"https://baike.baidu.com/item/%E8%84%9A%E6%9C%AC/1697005?fromModule=lemma_inlink\" title=\"脚本\">脚本</a>。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序.</p>\n<p>爬虫又叫网络爬虫（web Spider），网络像一张大网，上面布满\"数据\"。爬虫就是从网上获取数据的\"程序蜘蛛\"。</p>\n<p>步骤：请求网页-分析网页-展示结果</p>\n<h3 id=\"1%E3%80%81%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5\"><br/> 1、请求网页</h3>\n<h3 id=\"%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84requset%E5%BA%93%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%A8%A1%E6%8B%9F%E4%BA%BA%E7%B1%BB%E6%89%93%E5%BC%80%E7%BD%91%E9%A1%B5%EF%BC%8C%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E7%9A%84%E8%A1%8C%E4%B8%BA%E3%80%82%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%8F%AB%22%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5%22%E3%80%82\"><br/> 爬虫用到的requset库，可以模拟人类打开网页，获取网页的行为。这个过程叫\"请求网页\"。</h3>\n<p>requset中的get()方法是进入网站的\"法宝\"。</p>\n<p>request库使用get()来获取网页信息，并输出response对象名和状态码，表示成功获取到了网页。</p>\n<p>get(\"url\")函数：get函数用于请求网页，URL是需要请求的网址。</p>\n<p>UTF-8：编码格式，避免中文乱码</p>\n<p>直接输出get获取的内容，是网页对象名和状态码，其中200是状态码--表示网页请求成功。</p>\n<p>代码：</p>\n<p># 爬取网页内容<br/> import requests<br/> response = requests.get(\"https://www.baidu.com/“)<br/> response.encoding = \"UTF-8\"<br/> print(response)</p>\n<p>如没有安装requests模块，要先安装他 pip install requests<br/> 输出结果：</p>\n<p>E:\\乐乐python\\venv\\Scripts\\python.exe E:/乐乐python/思成/爬虫/读百度.py<br/><span style=\"color:#fe2c24;\"><strong>&lt;Response [200]&gt;</strong></span></p>\n<p>进程已结束，退出代码 0</p>\n<h2 id=\"2%E3%80%81%E8%8E%B7%E5%8F%96%E7%BD%91%E9%A1%B5%E6%96%87%E6%9C%AC\">2、获取网页文本</h2>\n<p><br/> 网页对象.text：获取网页的文本。</p>\n<p>格式1：</p>\n<p>response = requests.get(）</p>\n<p>response.text</p>\n<p>格式2:</p>\n<p>response = requests.get().text</p>\n<p>注意text后不加括号</p>\n<pre>import requests\nresponse = requests.get(\"https://www.baidu.com/\")\nresponse.encoding = \"UTF-8\"\nmytext=response.text\nprint(mytext)</pre>\n<p>结果：</p>\n<p>E:\\乐乐python\\venv\\Scripts\\python.exe E:/乐乐python/思成/爬虫/读百度2.py<br/> &lt;!DOCTYPE html&gt;<br/> &lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=\"bg s_ipt_wr\"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus&gt;&lt;/span&gt;&lt;span class=\"bg s_btn_wr\"&gt;&lt;input type=submit id=su value=百度一下 class=\"bg s_btn\" autofocus&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=https://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write('&lt;a href=\"http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === \"\" ? \"?\" : \"&amp;\")+ \"bdorz_come=1\")+ '\" name=\"tj_login\" class=\"lb\"&gt;登录&lt;/a&gt;');<br/>                 &lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=\"display: block;\"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;</p>\n<h2 id=\"3%E3%80%81%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5%E7%BD%91%E9%A1%B5%E4%BB%A3%E7%A0%81%E6%98%AF%E7%94%B1%E4%B8%80%E4%B8%AA%E4%B8%AA%E6%A0%87%E7%AD%BE%E7%BB%84%E6%88%90%E7%9A%84%EF%BC%8C%E5%A4%A7%E5%A4%9A%E6%95%B0%E9%83%BD%E6%88%90%E5%AF%B9%E5%87%BA%E7%8E%B0%E3%80%82\">3、分析网页<br/> 网页代码是由一个个标签组成的，大多数都成对出现。</h2>\n<p>alt 网页代码标签</p>\n<p>从网页代码中找信息的过程叫做“解析网页”。</p>\n<h2 id=\"4%E3%80%81%E5%8F%98%E4%B8%BA%E8%A7%A3%E6%9E%90%E5%AF%B9%E8%B1%A1bs4%E5%BA%93%EF%BC%9A%E7%94%A8%E6%9D%A5%E8%A7%A3%E6%9E%90%E7%88%AC%E5%8F%96%E7%9A%84%E7%BD%91%E9%A1%B5%EF%BC%8C%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AF%E3%80%82\">4、变为解析对象<br/> bs4库：用来解析爬取的网页，提取信息。</h2>\n<p>soup是变量名，用来存储解析之后的内容。response.text表示网页文本。lxml表示解析器。</p>\n<p>我们可以把创建的对象soup看作是由代码组成的汤。想要提取“汤”中的内容还要借助勺子--“lxml”。import bs4<br/> soup = bs4.beautifulSoup(response.text,\"lxml\")</p>\n<h2 id=\"5%E3%80%81%E8%8E%B7%E5%8F%96%E5%86%85%E5%AE%B9\"><br/> 5、获取内容</h2>\n<h2 id=\"data%E4%BF%9D%E5%AD%98%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E6%98%AF%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%E3%80%82\">data保存获取到的内容，是一个列表。</h2>\n<p>参数name和属性可以根据需要选择使用一个或多个。</p>\n<p>常用的属性有id、class_。</p>\n<p>data = soup.find_all(name=\"属性名\",属性=\"属性值\")</p>\n<h2 id=\"6%E3%80%81%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E6%96%87%E5%AD%97%E6%A0%87%E7%AD%BE.text%E6%96%B9%E6%B3%95%EF%BC%9A%E8%8E%B7%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%AD%E7%9A%84%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E3%80%82\">6、获取标签文字<br/> 标签.text方法：获取标签中的文本信息。</h2>\n<p>格式： data = &lt;标签名&gt;文本信息&lt;/标签名&gt; data.text</p>\n<p>注意： response.text表示获取字符串格式的网页代码。</p>\n<p>这里的data是一对标签，data.text获取标签内容</p>\n<h2 id=\"7%E3%80%81%E7%A4%BA%E4%BE%8B\">7、示例</h2>\n<p><br/> 代码：</p>\n<p># 爬取网页新闻</p>\n<pre>import requests, bs4, time\nresponse = requests.get(\"https://icourse.xesimg.com/programme/static/py/pcdata/lw-web/新闻网站/index.html\")\nresponse.encoding = \"UTF-8\"\nsoup = bs4.BeautifulSoup(response.text, \"lxml\")\ndata1 = soup.find_all(name=\"div\", attrs={'class': 'article'})\n\nfor n in data1:\n    data2 = n.find_all(name=\"a\")\n    print(\"--------------------------------------\")\n    print(\"题目:\"+data2[0].text)\n    print(\"摘要:\"+data2[1].text)\n    print(\"主题:\"+data2[2].text)</pre>\n<p>运行结果：</p>\n<p>运行上述代码如出错：</p>\n<p>bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?需安装下：pip install lxml</p>\n<p><img alt=\"\" height=\"178\" src=\"..\\..\\static\\image\\a7e9ea8e916c4f119126e8d9f3705a60.png\" width=\"712\"/></p>\n<p>8、状态码 response.status_code<br/> response.status_code：用来获取网页当前的状态</p>\n<p>response = request.get(\"url\")</p>\n<p>response.status_code</p>\n<p>状态码    网页状态<br/> 404    找不到网页啦<br/> 200    成功找到网页<br/> 403    网页禁止访问<br/> 503    现在打不开网页，需等待</p>\n<p></p>\n</div>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-03 12:33:56", "summary": "目录基础知识、请求网页爬虫用到的库，可以模拟人类打开网页，获取网页的行为。这个过程叫请求网页。、获取网页文本、分析网页网页代码是由一个个标签组成的，大多数都成对出现。、变为解析对象库：用来解析爬取的网"}