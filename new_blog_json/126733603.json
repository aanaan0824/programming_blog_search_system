{"blogid": "126733603", "writerAge": "码龄2年", "writerBlogNum": "54", "writerCollect": "946", "writerComment": "1483", "writerFan": "11747", "writerGrade": "5级", "writerIntegral": "3173", "writerName": "ぃ灵彧が", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126733603.jpg", "writerRankTotal": "5596", "writerRankWeekly": "14", "writerThumb": "960", "writerVisitNum": "34404", "blog_read_count": "145", "blog_time": "于 2022-09-06 22:19:30 发布", "blog_title": "猿创征文｜【深度学习前沿应用】文本生成", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-light\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h1><a id=\"_1\"></a>猿创征文｜【深度学习前沿应用】文本生成</h1>\n<hr/>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/8b354a7916f240d0bc7839822301ba90.gif#pic_center\"/></p>\n<hr/>\n<blockquote>\n<p><strong>作者简介</strong>：在校大学生一枚，C/C++领域新星创作者，华为云享专家，阿里云专家博主，腾云先锋（TDP）成员，云曦智划项目总负责人，全国高等学校计算机教学与产业实践资源建设专家委员会（TIPCC）志愿者，以及编程爱好者，期待和大家一起学习，一起进步~<br/> .<br/> <strong>博客主页</strong>：<a href=\"https://yxsmarter.blog.csdn.net/\"><strong>ぃ灵彧が的学习日志</strong></a><br/> .<br/> <strong>本文专栏</strong>：<a href=\"https://blog.csdn.net/m0_54754302/category_11952567.html\"><strong>人工智能</strong></a><br/> .<br/> <strong>专栏寄语</strong>：若你决定灿烂，山无遮，海无拦<br/> .<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\bea1eb377636404d83973726569f1a6c.jpeg\"/></p>\n</blockquote>\n<p></p>\n<div class=\"toc\">\n<h3>文章目录</h3>\n<ul><li><a href=\"#_1\">猿创征文｜【深度学习前沿应用】文本生成</a></li><li><a href=\"#_26\">前言</a></li><li><ul><li><ul><li><a href=\"#_28\">什么是文本生成?</a></li></ul>\n</li></ul>\n</li><li><a href=\"#_40\">一、数据加载及预处理</a></li><li><ul><li><a href=\"#_44\">(一)、数据加载</a></li><li><a href=\"#_116\">(二)、构建词表</a></li><li><a href=\"#_149\">(三)、创建指定数据格式</a></li></ul>\n</li><li><a href=\"#_185\">二、模型配置</a></li><li><ul><li><a href=\"#_189\">(一)、定义网络超参数</a></li><li><a href=\"#_204\">(二)、定义编码器</a></li><li><a href=\"#_228\">(三)、定义解码器</a></li></ul>\n</li><li><a href=\"#_251\">三、模型训练</a></li><li><a href=\"#_300\">四、模型预测</a></li><li><a href=\"#_347\">总结</a></li></ul>\n</div>\n<p></p>\n<hr/>\n<h1><a id=\"_26\"></a>前言</h1>\n<h3><a id=\"_28\"></a>什么是文本生成?</h3>\n<p>在自然语言处理领域，文本生成任务是指根据给定的输入，自动生成对应的输出，典型的任务包含：机器翻译、智能问答等。文本生成任务在注意力机制提出之后取得了显著的效果，尤其是在2018年基于多头注意力机制的Transformer(原理如下图1所示)在机器翻译领域取得当时最优效果时，基于Transformer的文本生成任务也进入了新的繁荣时期。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\b7bddf6829844b31828d6232f0d374e0.png\"/></p>\n<p><code>本实验的目的是演示如何使用经典的Transformer实现英-中机器翻译，实验平台为百度AI Studio，实验环境为Python3.7，Paddle2.0。</code></p>\n<hr/>\n<h1><a id=\"_40\"></a>一、数据加载及预处理</h1>\n<hr/>\n<h2><a id=\"_44\"></a>(一)、数据加载</h2>\n<p>本实验选用开源的小型英-中翻译CMN数据集，该数据集中包含样本总数24360条，均为短文本，部分数据展示如下图2所示：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\12d83998c7254b7ab48f9ef05521ecca.png\"/></p>\n<p>不同于图像处理，在处理自然语言时，需要指定文本的长度，便于进行批量计算，因此，在数据预处理阶段，应该先统计数据集中文本的长度，然后指定一个恰当的值，进行统一处理。</p>\n<hr/>\n<ol><li>导入相关包</li></ol>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">import</span> paddle\n<span class=\"token keyword\">import</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n<span class=\"token keyword\">import</span> re\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>paddle<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># cpu/gpu环境选择，在 paddle.set_device() 输入对应运行设备。</span>\n<span class=\"token comment\"># device = paddle.set_device('gpu')</span>\n</code></pre>\n<hr/>\n<ol start=\"2\"><li>统计数据集中句子的长度等信息</li></ol>\n<pre><code class=\"prism language-python\"><span class=\"token comment\"># 统计数据集中句子的长度等信息</span>\nlines <span class=\"token operator\">=</span>  <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data/data78721/cmn.txt'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span>encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>lines<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndatas <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ndic_en <span class=\"token operator\">=</span> <span class=\"token punctuation\">{<!-- --></span><span class=\"token punctuation\">}</span>\ndic_cn <span class=\"token operator\">=</span> <span class=\"token punctuation\">{<!-- --></span><span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> lines<span class=\"token punctuation\">:</span>\n    ll <span class=\"token operator\">=</span> line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">)</span><span class=\"token operator\">&lt;</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">continue</span>\n    datas<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># print(ll[0])</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> dic_en<span class=\"token punctuation\">:</span>\n        dic_en<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        dic_en<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> dic_cn<span class=\"token punctuation\">:</span>\n        dic_cn<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        dic_cn<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ll<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span><span class=\"token number\">1</span>\nkeys_en <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>dic_en<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nkeys_en<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncount <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token comment\"># print('英文长度统计：')</span>\n<span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> keys_en<span class=\"token punctuation\">:</span>\n    count <span class=\"token operator\">+=</span> dic_en<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># print(k,dic_en[k],count/len(lines))</span>\n\nkeys_cn <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>dic_cn<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nkeys_cn<span class=\"token punctuation\">.</span>sort<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncount <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n<span class=\"token comment\"># print('中文长度统计：')</span>\n<span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> keys_cn<span class=\"token punctuation\">:</span>\n    count <span class=\"token operator\">+=</span> dic_cn<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># print(k,dic_cn[k],count/len(lines))</span>\n \nen_length <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\ncn_length <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\n</code></pre>\n<hr/>\n<h2><a id=\"_116\"></a>(二)、构建词表</h2>\n<p>对于中英文，需要分别构建词表，进行词向量学习，除此之外，还需要在每个词表中加入开始符号、结束符合以及填充符号：</p>\n<pre><code class=\"prism language-python\"><span class=\"token comment\"># 构建中英文词表</span>\nen_vocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">{<!-- --></span><span class=\"token punctuation\">}</span>\ncn_vocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">{<!-- --></span><span class=\"token punctuation\">}</span>\n\nen_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;pad&gt;'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> en_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;bos&gt;'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> en_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span>\ncn_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;pad&gt;'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cn_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;bos&gt;'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cn_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span>\nen_idx<span class=\"token punctuation\">,</span> cn_idx <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span>\n<span class=\"token keyword\">for</span> en<span class=\"token punctuation\">,</span> cn <span class=\"token keyword\">in</span> datas<span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># print(en,cn)</span>\n    <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> en<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> w <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> en_vocab<span class=\"token punctuation\">:</span>\n            en_vocab<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> en_idx\n            en_idx <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> cn<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> w <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> cn_vocab<span class=\"token punctuation\">:</span>\n            cn_vocab<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> cn_idx\n            cn_idx <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>en_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>cn_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">'''\n英文词表长度：6057\n中文词表长度：3533\n'''</span>\n</code></pre>\n<hr/>\n<h2><a id=\"_149\"></a>(三)、创建指定数据格式</h2>\n<p>需要将输入英文与输出中文封装为指定格式，即为编码器端输入添加结束符号并填充至固定长度，为解码器输入添加开始、结束符号并填充至固定长度，解码器端输出的正确答案应该只添加结束符号并且填充至固定长度。</p>\n<pre><code class=\"prism language-python\">padded_en_sents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\npadded_cn_sents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\npadded_cn_label_sents <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> en<span class=\"token punctuation\">,</span> cn <span class=\"token keyword\">in</span> datas<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>en<span class=\"token punctuation\">)</span><span class=\"token operator\">&gt;</span>en_length<span class=\"token punctuation\">:</span>\n        en <span class=\"token operator\">=</span> en<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>en_length<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>cn<span class=\"token punctuation\">)</span><span class=\"token operator\">&gt;</span>cn_length<span class=\"token punctuation\">:</span>\n        cn <span class=\"token operator\">=</span> cn<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>cn_length<span class=\"token punctuation\">]</span>\n    padded_en_sent <span class=\"token operator\">=</span> en <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;pad&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>en_length <span class=\"token operator\">-</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>en<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    padded_en_sent<span class=\"token punctuation\">.</span>reverse<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    padded_cn_sent <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;bos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> cn <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;pad&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>cn_length <span class=\"token operator\">-</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>cn<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    padded_cn_label_sent <span class=\"token operator\">=</span> cn <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;pad&gt;'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>cn_length <span class=\"token operator\">-</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>cn<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    \n    padded_en_sents<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>en_vocab<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> padded_en_sent<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    padded_cn_sents<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>cn_vocab<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> padded_cn_sent<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\n    padded_cn_label_sents<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>cn_vocab<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> padded_cn_label_sent<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntrain_en_sents <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>padded_en_sents<span class=\"token punctuation\">)</span>\ntrain_cn_sents <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>padded_cn_sents<span class=\"token punctuation\">)</span>\ntrain_cn_label_sents <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>padded_cn_label_sents<span class=\"token punctuation\">)</span>\n \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train_en_sents<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train_cn_sents<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>train_cn_label_sents<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n</code></pre>\n<hr/>\n<h1><a id=\"_185\"></a>二、模型配置</h1>\n<hr/>\n<h2><a id=\"_189\"></a>(一)、定义网络超参数</h2>\n<pre><code class=\"prism language-python\">embedding_size <span class=\"token operator\">=</span> <span class=\"token number\">128</span>\nhidden_size <span class=\"token operator\">=</span> <span class=\"token number\">512</span>\nnum_encoder_lstm_layers <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\nen_vocab_size <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>en_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ncn_vocab_size <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>cn_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nepochs <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">16</span>\n</code></pre>\n<hr/>\n<h2><a id=\"_204\"></a>(二)、定义编码器</h2>\n<pre><code class=\"prism language-python\"><span class=\"token comment\"># encoder: simply learn representation of source sentence</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Encoder</span><span class=\"token punctuation\">(</span>paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Layer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>en_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">,</span>num_layers<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>head_number<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>middle_units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Encoder<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>emb <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>en_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"\n        d_model (int) - 输入输出的维度。\n        nhead (int) - 多头注意力机制的Head数量。\n        dim_feedforward (int) - 前馈神经网络中隐藏层的大小。\n        \"\"\"</span>\n        encoder_layer <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>TransformerEncoderLayer<span class=\"token punctuation\">(</span>embedding_size<span class=\"token punctuation\">,</span> head_number<span class=\"token punctuation\">,</span> middle_units<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>encoder <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>TransformerEncoder<span class=\"token punctuation\">(</span>encoder_layer<span class=\"token punctuation\">,</span> num_layers<span class=\"token punctuation\">)</span> \n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>emb<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        en_out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>encoder<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> en_out\n</code></pre>\n<hr/>\n<h2><a id=\"_228\"></a>(三)、定义解码器</h2>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Decoder</span><span class=\"token punctuation\">(</span>paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Layer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>cn_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">,</span>num_layers<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>head_number<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>middle_units<span class=\"token operator\">=</span><span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Decoder<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>emb <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>cn_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">)</span>\n        \n        decoder_layer <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>TransformerDecoderLayer<span class=\"token punctuation\">(</span>embedding_size<span class=\"token punctuation\">,</span> head_number<span class=\"token punctuation\">,</span> middle_units<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>decoder <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>TransformerDecoder<span class=\"token punctuation\">(</span>decoder_layer<span class=\"token punctuation\">,</span> num_layers<span class=\"token punctuation\">)</span> \n   \n        <span class=\"token comment\"># for computing output logits</span>\n        self<span class=\"token punctuation\">.</span>outlinear <span class=\"token operator\">=</span>paddle<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>embedding_size<span class=\"token punctuation\">,</span> cn_vocab_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">,</span>  encoder_outputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>emb<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># dec_input, enc_output,self_attn_mask,  cross_attn_mask</span>\n        de_out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>decoder<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> encoder_outputs<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>outlinear<span class=\"token punctuation\">(</span>de_out<span class=\"token punctuation\">)</span>\n        output <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span>  output\n</code></pre>\n<h1><a id=\"_251\"></a>三、模型训练</h1>\n<pre><code class=\"prism language-python\">encoder <span class=\"token operator\">=</span> Encoder<span class=\"token punctuation\">(</span>en_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">)</span>\ndecoder <span class=\"token operator\">=</span> Decoder<span class=\"token punctuation\">(</span>cn_vocab_size<span class=\"token punctuation\">,</span> embedding_size<span class=\"token punctuation\">)</span>\n\nopt <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>optimizer<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.0001</span><span class=\"token punctuation\">,</span>\n                            parameters<span class=\"token operator\">=</span>encoder<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> decoder<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"epoch:{}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>epoch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># shuffle training data</span>\n    perm <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>permutation<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_en_sents<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    train_en_sents_shuffled <span class=\"token operator\">=</span> train_en_sents<span class=\"token punctuation\">[</span>perm<span class=\"token punctuation\">]</span>\n    train_cn_sents_shuffled <span class=\"token operator\">=</span> train_cn_sents<span class=\"token punctuation\">[</span>perm<span class=\"token punctuation\">]</span>\n    train_cn_label_sents_shuffled <span class=\"token operator\">=</span> train_cn_label_sents<span class=\"token punctuation\">[</span>perm<span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># print(train_en_sents_shuffled.shape[0],train_en_sents_shuffled.shape[1])</span>\n    <span class=\"token keyword\">for</span> iteration <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>train_en_sents_shuffled<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">//</span> batch_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_data <span class=\"token operator\">=</span> train_en_sents_shuffled<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span>iteration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span><span class=\"token punctuation\">(</span>iteration<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        sent <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>to_tensor<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">)</span>\n        en_repr <span class=\"token operator\">=</span> encoder<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span>\n\n        x_cn_data <span class=\"token operator\">=</span> train_cn_sents_shuffled<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span>iteration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span><span class=\"token punctuation\">(</span>iteration<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        x_cn_label_data <span class=\"token operator\">=</span> train_cn_label_sents_shuffled<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span>iteration<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>batch_size<span class=\"token operator\">*</span><span class=\"token punctuation\">(</span>iteration<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n \n        loss <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> \n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span> cn_length <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            cn_word <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>to_tensor<span class=\"token punctuation\">(</span>x_cn_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">:</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            cn_word_label <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>to_tensor<span class=\"token punctuation\">(</span>x_cn_label_data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n            logits <span class=\"token operator\">=</span> decoder<span class=\"token punctuation\">(</span>cn_word<span class=\"token punctuation\">,</span> en_repr<span class=\"token punctuation\">)</span>\n            step_loss <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> cn_word_label<span class=\"token punctuation\">)</span>\n            loss <span class=\"token operator\">+=</span> step_loss\n\n        loss <span class=\"token operator\">=</span> loss <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>cn_length <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>iteration <span class=\"token operator\">%</span> <span class=\"token number\">50</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"iter {}, loss:{}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>iteration<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        opt<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        opt<span class=\"token punctuation\">.</span>clear_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>输出结果如下图3所示：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\cf6b1a3a03bb46caaf8baed37e49d196.png\"/></p>\n<hr/>\n<h1><a id=\"_300\"></a>四、模型预测</h1>\n<pre><code class=\"prism language-python\">encoder<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndecoder<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nnum_of_exampels_to_evaluate <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\n\nindices <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>choice<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_en_sents<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  num_of_exampels_to_evaluate<span class=\"token punctuation\">,</span> replace<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nx_data <span class=\"token operator\">=</span> train_en_sents<span class=\"token punctuation\">[</span>indices<span class=\"token punctuation\">]</span>\nsent <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>to_tensor<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">)</span>\nen_repr <span class=\"token operator\">=</span> encoder<span class=\"token punctuation\">(</span>sent<span class=\"token punctuation\">)</span>\n\nword <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>cn_vocab<span class=\"token punctuation\">[</span><span class=\"token string\">'&lt;bos&gt;'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> num_of_exampels_to_evaluate\n<span class=\"token punctuation\">)</span>\nword <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>to_tensor<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n \n\ndecoded_sent <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>cn_length <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    logits  <span class=\"token operator\">=</span> decoder<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> en_repr<span class=\"token punctuation\">)</span>\n    word <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    decoded_sent<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    word <span class=\"token operator\">=</span> paddle<span class=\"token punctuation\">.</span>unsqueeze<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\nresults <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span>decoded_sent<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_of_exampels_to_evaluate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'---------------------'</span><span class=\"token punctuation\">)</span>\n    en_input <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>datas<span class=\"token punctuation\">[</span>indices<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    ground_truth_translate <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>datas<span class=\"token punctuation\">[</span>indices<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    model_translate <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span>\n    <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> results<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        w <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>cn_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> w <span class=\"token operator\">!=</span> <span class=\"token string\">'&lt;pad&gt;'</span> <span class=\"token keyword\">and</span> w <span class=\"token operator\">!=</span> <span class=\"token string\">'&lt;eos&gt;'</span><span class=\"token punctuation\">:</span>\n            model_translate <span class=\"token operator\">+=</span> w\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>en_input<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"true: {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>ground_truth_translate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"pred: {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>model_translate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n</code></pre>\n<p>输出结果如下图4所示：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\1ea53e6b46ed492cb37a54d8eaa9ff78.png\"/></p>\n<hr/>\n<h1><a id=\"_347\"></a>总结</h1>\n<p>本系列文章内容为根据清华社出版的《机器学习实践》所作的相关笔记和感悟，其中代码均为基于百度飞桨开发，若有任何侵权和不妥之处，请私信于我，定积极配合处理，看到必回！！！</p>\n<p>最后，引用本次活动的一句话，来作为文章的结语～(￣▽￣～)~：</p>\n<p>【<strong>学习的最大理由是想摆脱平庸，早一天就多一份人生的精彩；迟一天就多一天平庸的困扰。</strong>】</p>\n<p>ps：更多精彩内容还请进入<strong>本文专栏</strong>：<a href=\"https://blog.csdn.net/m0_54754302/category_11952567.html\"><strong>人工智能</strong></a>，进行查看，欢迎大家支持与指教啊～(￣▽￣～)~</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\49dab51e37e3453c93bc0191609d7382.jpeg\"/></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 1, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-06 22:19:30", "summary": "猿创征文深度学习前沿应用文本生成在这里插入图片描述作者简介：在校大学生一枚，领域新星创作者，华为云享专家，阿里云专家博主，腾云先锋成员，云曦智划项目总负责人，全国高等学校计算机教学与产业实践资源建设专"}