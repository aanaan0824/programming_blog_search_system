{"blogid": "116765743", "writerAge": "码龄4年", "writerBlogNum": "26", "writerCollect": "911", "writerComment": "531", "writerFan": "140", "writerGrade": "4级", "writerIntegral": "1064", "writerName": "王定邦", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_116765743.jpg", "writerRankTotal": "42887", "writerRankWeekly": "87502", "writerThumb": "147", "writerVisitNum": "113339", "blog_read_count": "22777", "blog_time": "已于 2022-04-16 11:08:28 修改", "blog_title": "pytorch yolo5+Deepsort实现目标检测和跟踪", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-light\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p>yolo是一种运行速度很快的目标检测AI模型，目前最新版本是yolov5，最大可处理1280像素的图像。当我们检测出图像中目标后，把视频分解成多幅图像并逐帧执行时，可看到目标跟踪框随目标移动，看上去很酷吧。但是，如果视频帧中有多个目标，如何知道一帧中的目标和上一帧是同一个对象？这就是目标跟踪的工作，应用多个检测来识别特定目标随时间的变化，实现目标跟踪。<br/> Deepsort是实现目标跟踪的算法，从sort（simple online and realtime tracking）演变而来，其使用卡尔曼滤波器预测所检测对象的运动轨迹，匈牙利算法将它们与新的检测目标相匹配。Deepsort易于使用且运行速度快，成为AI目标检测跟踪之热门算法。</p>\n<h2><a id=\"yolov5DeepSort_4\"></a>yolov5+DeepSort</h2>\n<p>源码在这里：<a href=\"https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\">Github</a></p>\n<p>注：*mikel-brostrom 提供的github代码已经更新，添加了多个REID，因此，用原来的ckpt.t7模型不能直接使用。使用新版yolov5+DeepSort，移步另一篇<a href=\"https://blog.csdn.net/weixin_44238733/article/details/123805195?spm=1001.2014.3001.5501\">博文</a></p>\n<p>这个这个…， mikel大侠过于勤奋地更新github，使本博文过期。下面的博文适用于v3.0，请从mikel github网页的右侧去下载不同的版本。<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\502830f72aa14724b3293fbc2f8180cc.png\"/><br/> 点击“+ 4 releases”可寻找对应的版本。<br/> 此外，REID模型ckpt.t7需要google drive，不方便。需要的朋友可从<a href=\"https://pan.baidu.com/s/1As81D7CBruIpapco87kzlQ?pwd=gchf\">百度网盘</a>下载<br/> 提取码：gchf</p>\n<p>下面是安装和演示过程：</p>\n<p>1 克隆github到本地</p>\n<pre><code class=\"prism language-bash\"><span class=\"token function\">git</span> clone https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\n</code></pre>\n<p>其中，yolo5目录是一个链接，不能直接克隆下来，需要另行下载，并将内容放入yolo5。</p>\n<p>下载yolo5模型权重，放入目录your-dir/yolo5/weights</p>\n<p><a href=\"https://github.com/ultralytics/yolov5/releases\">下载yolo5权重地址 </a></p>\n<p>yolov5网站发布的权重有如下几个<br/> yolov5-P5: yolo5s.pt, yolo5m.pt, yolo5l.pt, yolo5x.pt<br/> yolov5-P6: yolo5s6.pt, yolo5m6.pt, yolo5l6.pt, yolo5x6.pt<br/> yolov5-P5可处理640像素图像，从s到x精度逐渐提升，yolov5-P6可处理1280像素图像，同样，从s到x精度逐渐提升。demo程序track.py默认用yolo5s.pt最简单的权重。</p>\n<p>下载Deepsort模型权重 ckpt.t7，放入目录:<br/> your-dir/deep_sort_pytorch/deep_sort/deep/checkpoint<br/> <a href=\"https://drive.google.com/drive/folders/1xhG0kRH1EX5B9_Iz8gQJb7UNnn_riXi6\">下载地址</a></p>\n<p>2 安装所需的运行环境<br/> 建立一个虚拟环境吧，免得与其他环境冲突</p>\n<pre><code class=\"prism language-bash\">conda create -n deepsort <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.7</span>\n</code></pre>\n<p>激活虚拟环境，安装所需模块</p>\n<pre><code class=\"prism language-bash\">conda activate deepsort\n<span class=\"token builtin class-name\">cd</span> your-dir\npip <span class=\"token function\">install</span> -r requirements.txt\n</code></pre>\n<p>3 运行目标检测跟踪程序，my_demo.mp4为演示视频mp4文件</p>\n<pre><code class=\"prism language-bash\">python track.py --source my_demo.mp4\n</code></pre>\n<p>如果安装一切顺利，则很快看到目标跟踪的演示视频。但事情或许并不一帆风顺，总有几个缺失的模块需要另外安装。于是，可在安装完成后，试运行：</p>\n<pre><code class=\"prism language-bash\">python track.py -h\n</code></pre>\n<p>它会告诉你缺失的模块，用pip逐个安装就好了。<br/> 另外，演示程序track.py给出的目标框灰常粗大。修改track.py中draw_boxes方法，把粗框改成细框，大字符改小字符，这样就美观许多啦：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">draw_boxes</span><span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">,</span> bbox<span class=\"token punctuation\">,</span> identities<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> offset<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> box <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>bbox<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x1<span class=\"token punctuation\">,</span> y1<span class=\"token punctuation\">,</span> x2<span class=\"token punctuation\">,</span> y2 <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> box<span class=\"token punctuation\">]</span>\n        x1 <span class=\"token operator\">+=</span> offset<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n        x2 <span class=\"token operator\">+=</span> offset<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n        y1 <span class=\"token operator\">+=</span> offset<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n        y2 <span class=\"token operator\">+=</span> offset<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n        <span class=\"token comment\"># box text and bar</span>\n        <span class=\"token builtin\">id</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>identities<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> identities <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">else</span> <span class=\"token number\">0</span>\n        color <span class=\"token operator\">=</span> compute_color_for_labels<span class=\"token punctuation\">(</span><span class=\"token builtin\">id</span><span class=\"token punctuation\">)</span>\n        label <span class=\"token operator\">=</span> <span class=\"token string\">'{}{:d}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">id</span><span class=\"token punctuation\">)</span>\n        t_size <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>getTextSize<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_PLAIN<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\">#修改字符，原设置： 2,2</span>\n        cv2<span class=\"token punctuation\">.</span>rectangle<span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">,</span> y1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x2<span class=\"token punctuation\">,</span> y2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> color<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 修改线框为1， 原设置：3</span>\n        cv2<span class=\"token punctuation\">.</span>rectangle<span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">,</span> y1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x1 <span class=\"token operator\">+</span> t_size<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> y1 <span class=\"token operator\">+</span> t_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> color<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        cv2<span class=\"token punctuation\">.</span>putText<span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">,</span> y1 <span class=\"token operator\">+</span>\n                t_size<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_PLAIN<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">255</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#修改 2,.,2</span>\n    <span class=\"token keyword\">return</span> img\n</code></pre>\n<p>说明1，yolo5可检测多种类型的目标，而Deepsort目标跟踪只能跟踪一种类型目标，例如行人类，或小汽车类。所以，跟踪需要把yolo5的目标检测类型数量限制成单个类型检测。coco数据集定义的行人类型数=0，小汽车类型数=2。</p>\n<p>行人跟踪：</p>\n<pre><code class=\"prism language-bash\">python track.py --classes <span class=\"token number\">0</span> --source demo_person.mp4  \n</code></pre>\n<p>小汽车跟踪：</p>\n<pre><code class=\"prism language-bash\">python track.py --classes <span class=\"token number\">2</span> --source demo_car.mp4\n</code></pre>\n<p>说明2，yolo5提供不同检测精度的权重文件，yolo5x.pt比yolo5s.pt精度高。应用跟踪时，当两个目标重叠后再分离，yolo5s.pt会出现标注数改变。举个栗子，目标10和目标20发生重叠后分离，目标10变成了目标15，而目标20不变（目标20遮挡了目标10）。此情况用yolo5x.pt就会好很多，维持目标10不变。</p>\n<p>说明3，yolov5-P5可处理640像素图像，这并不要求输入视频尺寸不得大于640。此时输入视频可以是1920x1080，不会报错，yolov5在处理时将大图像resize到640。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210513211421348.png\"/><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\2021051321151447.png\"/></p>\n<h2><a id=\"yolov5_107\"></a>yolov5训练自己的数据集</h2>\n<p>有关如何用自己的数据集训练yolov5模型，有很多文章可参考，此处只给出要点。训练完成后，用户数据集产生的权重best.pt取代yolov5s.pt，看看跟踪目标的效果如何。<br/> 训练自己数据集的参考在这里：<br/> <a href=\"https://blog.csdn.net/qq_34795071/article/details/106645048\">Pytorch 版YOLOV5训练自己的数据集</a></p>\n<p>DeepSort目录下训练yolov5，自己的数据集。因为是DeepSort跟踪，故yolov5目录建立在DeepSort之下。那么当工作目录是DeepSort时，yolov5下面的某些模块目录需要有所变化。<br/> 数据集：DeepSort\\paper_data，在此目录下建立图片目录train，标注xml目录Annotatiaons，把图片JPG和xml文件分别拷贝进入。<br/> split_train_val.py划分train集和val集，建立ImageSets目录，用txt文件划分train和val，而没有重新建立train目录和val目录。<br/> voc_label.py产生label目录，把原来xml文件转成label形式的txt文件，这是yolov模型与其他torch模型不同之处。<br/> 配置训练文件，在paper_data下生成custom_yolov5s.yaml文件<br/> custom_yolov5s.yaml中指定训练集和验证集的标签，类型数，类型名称：</p>\n<pre><code class=\"prism language-bash\">train:  ~/DeepSort/paper_data/train.txt  \nval:    ~/DeepSort/paper_data/val.txt  \n<span class=\"token comment\"># number of classes</span>\nnc: <span class=\"token number\">2</span>   <span class=\"token comment\">#训练的类别</span>\n<span class=\"token comment\"># class names</span>\nnames: <span class=\"token punctuation\">[</span><span class=\"token string\">'car'</span>, <span class=\"token string\">'person'</span><span class=\"token punctuation\">]</span>\n</code></pre>\n<p>修改模型文件，如yolov5s.yaml文件。通常只修改目标类型，若只有一个目标car，则类型数为1。这与torch模型也不同，torch模型中背景占一个类型，故只有一个目标car的类型数为2，一个背景类型和一个目标类型car。<br/> yolov5模型的配置文件采用yolov5s.yaml，将nc数改为2。<br/> 训练：</p>\n<pre><code class=\"prism language-bash\">python yolov5/train.py --data paper_data/custom_yolov5s.yaml  <span class=\"token punctuation\">\\</span>\n--cfg yolov5/models/yolov5s.yaml --weights <span class=\"token string\">'yolov5/weights/yolov5s.pt'</span> <span class=\"token punctuation\">\\</span>\n--batch-size <span class=\"token number\">16</span> --epochs <span class=\"token number\">100</span>\n</code></pre>\n<p>预训练模型yolov5加载初始权重yolov5s.pt，训练完成后在工作目录DeepSort下产生runs目录，保存weight（exp5）和tensorboard运行参数。可用tensorboard观看可视化结果:</p>\n<pre><code class=\"prism language-bash\">tensorboard --logdir<span class=\"token operator\">=</span>runs\n</code></pre>\n<p>经过epoch=100训练，产生只有两个类“car”和“person”的权重，runs/train/exp5/weights/best.pt，其类型“car”的数字为0，person为1。将best.pt用作yolov5推理而加载的模型权重，classes参数与yolov5原来定义的类型不同，要特别注意，否则无法检测出目标类型。</p>\n<p>因此，用yolov5+DeepSort运行目标跟踪时，classes参数需选择0或1，对应car目标或行人目标，weights用自己的best.pt。</p>\n<pre><code class=\"prism language-bash\">python track.py --classes <span class=\"token number\">0</span> --source demo_car.mp4  --weights <span class=\"token string\">'runs/train/exp5/weights/best.pt'</span>\n</code></pre>\n<h2><a id=\"yolov5faster_rcnn_resnet50_fpn_152\"></a>yolov5和faster rcnn resnet50 fpn比较</h2>\n<p>pytorch目标检测提供了预训练模型faster rcnn resnet50 fpn，博主试图用faster rcnn替代yolov5实现目标检测和跟踪，结果得不偿失，未敢尝试Deepsort。<br/> 1 yolov5可以定义限制性类型，比如“行人”，“小汽车”等，限定为单个类型，用于跟踪，而不需要重新训练。 faster rcnn resnet50也可以限定检测类型数量，但需要重新训练。<br/> 2 速度，yolov5明显速度优于faster rcnn，且消耗GPU资源少。用faster rcnn，还没有用到deepsort，只看逐帧检测，速度比 yolov5+deepsort逐帧目标跟踪还要慢，且GPU用尽全力达95%，很快温升达到80度。两者处理1280x736图像，使用yolov5x.pt，GPU占用65%，温升只有60度。<br/> 3 启用voc2007-2008数据集，提取car类型，共549幅图片，取出480幅训练，64幅测试。<br/> yolov5：<br/> batch = 16， GPU占用 4320GB, 99%; batch = 32, GPU占用 7240GB, 99%<br/> batch = 16, epoch=100, 耗时10min。</p>\n<p>faster rcnn resnet50 fpn:<br/> batch = 2， GPU占用6112GB， 95%<br/> epoch = 32, 耗时25min</p>\n<p>显然，yolov5训练过程很快，比faster rcnn resnet50 fpn快很多。<br/> 本人单机GPU rtx2060supper 8GB，属简陋型，对resnet50实在力不从心，而yolov5却可以应付。</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-04-16 11:08:28", "summary": "是一种运行速度很快的目标检测模型，目前最新版本是，最大可处理像素的图像。当我们检测出图像中目标后，把视频分解成多幅图像并逐帧执行时，可看到目标跟踪框随目标移动，看上去很酷吧。但是，如果视频帧中有多个目"}