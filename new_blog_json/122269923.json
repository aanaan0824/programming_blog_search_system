{"blogid": "122269923", "writerAge": "码龄1年", "writerBlogNum": "12", "writerCollect": "113", "writerComment": "36", "writerFan": "69", "writerGrade": "2级", "writerIntegral": "200", "writerName": "清忖灬", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_122269923.jpg", "writerRankTotal": "67344", "writerRankWeekly": "960653", "writerThumb": "36", "writerVisitNum": "15624", "blog_read_count": "6526", "blog_time": "于 2022-01-01 20:05:36 发布", "blog_title": "Python爬虫 自动爬取图片并保存", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p><strong>一、准备工作</strong></p>\n<p style=\"text-align:center;\"></p>\n<p style=\"text-align:center;\">用python来实现对百度图片的爬取并保存，以情绪图片为例，百度搜索可得到下图所示<img alt=\"\" src=\"..\\..\\static\\image\\6cbe405122f94743a5d4bd7b62810198.png\"/></p>\n<p>f12打开源码</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"..\\..\\static\\image\\74e4025aa13843bda3c3eb0f32f79beb.png\"/></p>\n<p>在此处可以看到这次我们要爬取的图片的基本信息是在img - scr中</p>\n<p><strong>二、代码实现</strong></p>\n<p>这次的爬取主要用了如下的第三方库</p>\n<pre><code class=\"language-python\">import re\nimport time\nimport requests\nfrom bs4 import BeautifulSoup\nimport os</code></pre>\n<p></p>\n<p>简单构思可以分为三个小部分</p>\n<p>1.获取网页内容</p>\n<p>2.解析网页</p>\n<p>3.保存图片至相应位置</p>\n<p>下面来看第一部分：获取网页内容</p>\n<pre><code class=\"language-python\">baseurl = 'https://cn.bing.com/images/search?q=%E6%83%85%E7%BB%AA%E5%9B%BE%E7%89%87&amp;qpvt=%e6%83%85%e7%bb%aa%e5%9b%be%e7%89%87&amp;form=IGRE&amp;first=1&amp;cw=418&amp;ch=652&amp;tsc=ImageBasicHover'\nhead = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36 Edg/92.0.902.67\"}\n    response = requests.get(baseurl, headers=head)  # 获取网页信息\n    html = response.text  # 将网页信息转化为text形式</code></pre>\n<p>是不是so easy</p>\n<p>第二部分解析网页才是大头</p>\n<p>来看代码</p>\n<pre><code class=\"language-python\">Img = re.compile(r'img.*src=\"(.*?)\"')  # 正则表达式匹配图片\nsoup = BeautifulSoup(html, \"html.parser\")  # BeautifulSoup解析html\n    #i = 0  # 计数器初始值\n    data = []  # 存储图片超链接的列表\n    for item in soup.find_all('img', src=\"\"):  # soup.find_all对网页中的img—src进行迭代\n        item = str(item)  # 转换为str类型\n        Picture = re.findall(Img, item)  # 结合re正则表达式和BeautifulSoup, 仅返回超链接\n        for b in Picture:\n            data.append(b)\n            #i = i + 1\n            return data[-1]\n\n    # print(i)</code></pre>\n<p>这里就运用到了BeautifulSoup以及re正则表达式的相关知识，需要有一定的基础哦</p>\n<p>下面就是第三部分：保存图片</p>\n<pre><code class=\"language-python\">    for m in getdata(\n            baseurl='https://cn.bing.com/images/search?q=%E6%83%85%E7%BB%AA%E5%9B%BE%E7%89%87&amp;qpvt=%e6%83%85%e7%bb%aa%e5%9b%be%e7%89%87&amp;form=IGRE&amp;first=1&amp;cw=418&amp;ch=652&amp;tsc=ImageBasicHover'):\n        resp = requests.get(m)  #获取网页信息\n        byte = resp.content  # 转化为content二进制\n        print(os.getcwd()) # os库中输出当前的路径\n        i = i + 1 # 递增\n        # img_path = os.path.join(m)\n        with open(\"path{}.jpg\".format(i), \"wb\") as f: # 文件写入\n            f.write(byte)\n            time.sleep(0.5) # 每隔0.5秒下载一张图片放入D://情绪图片测试\n        print(\"第{}张图片爬取成功!\".format(i))</code></pre>\n<p>各行代码的解释已经给大家写在注释中啦，不明白的地方可以直接私信或评论哦~</p>\n<p>下面是完整的代码</p>\n<pre><code class=\"language-python\">import re\nimport time\nimport requests\nfrom bs4 import BeautifulSoup\nimport os\n\n\n\n# m = 'https://tse2-mm.cn.bing.net/th/id/OIP-C.uihwmxDdgfK4FlCIXx-3jgHaPc?w=115&amp;amp;h=183&amp;amp;c=7&amp;amp;r=0&amp;amp;o=5&amp;amp;pid=1.7'\n'''\nresp = requests.get(m)\nbyte = resp.content\nprint(os.getcwd())\nimg_path = os.path.join(m)\n'''\ndef main():\n    baseurl = 'https://cn.bing.com/images/search?q=%E6%83%85%E7%BB%AA%E5%9B%BE%E7%89%87&amp;qpvt=%e6%83%85%e7%bb%aa%e5%9b%be%e7%89%87&amp;form=IGRE&amp;first=1&amp;cw=418&amp;ch=652&amp;tsc=ImageBasicHover'\n    datalist = getdata(baseurl)\n\n\ndef getdata(baseurl):\n    Img = re.compile(r'img.*src=\"(.*?)\"')  # 正则表达式匹配图片\n    datalist = []\n    head = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36 Edg/92.0.902.67\"}\n    response = requests.get(baseurl, headers=head)  # 获取网页信息\n    html = response.text  # 将网页信息转化为text形式\n    soup = BeautifulSoup(html, \"html.parser\")  # BeautifulSoup解析html\n    # i = 0  # 计数器初始值\n    data = []  # 存储图片超链接的列表\n    for item in soup.find_all('img', src=\"\"):  # soup.find_all对网页中的img—src进行迭代\n        item = str(item)  # 转换为str类型\n        Picture = re.findall(Img, item)  # 结合re正则表达式和BeautifulSoup, 仅返回超链接\n        for b in Picture:  # 遍历列表，取最后一次结果\n            data.append(b)\n            # i = i + 1\n            datalist.append(data[-1])\n    return datalist  # 返回一个包含超链接的新列表\n    # print(i)\n\n'''\nwith open(\"img_path.jpg\",\"wb\") as f:\n    f.write(byte)\n'''\n\nif __name__ == '__main__':\n    os.chdir(\"D://情绪图片测试\")\n\n    main()\n    i = 0  # 图片名递增\n    for m in getdata(\n            baseurl='https://cn.bing.com/images/search?q=%E6%83%85%E7%BB%AA%E5%9B%BE%E7%89%87&amp;qpvt=%e6%83%85%e7%bb%aa%e5%9b%be%e7%89%87&amp;form=IGRE&amp;first=1&amp;cw=418&amp;ch=652&amp;tsc=ImageBasicHover'):\n        resp = requests.get(m)  #获取网页信息\n        byte = resp.content  # 转化为content二进制\n        print(os.getcwd()) # os库中输出当前的路径\n        i = i + 1 # 递增\n        # img_path = os.path.join(m)\n        with open(\"path{}.jpg\".format(i), \"wb\") as f: # 文件写入\n            f.write(byte)\n            time.sleep(0.5) # 每隔0.5秒下载一张图片放入D://情绪图片测试\n        print(\"第{}张图片爬取成功!\".format(i))</code></pre>\n<p>最后的运行截图</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"..\\..\\static\\image\\8e28ec966f74486a90d84f73a88b88c5.png\"/></p>\n<p> 三、总结</p>\n<p>这次仅仅是保存了29张图片，在爬取其他网页的时候，用的方法都是大同小异，最主要还是根据网页的内容灵活变换，观察它的源码。另外有部分网站可能会有反爬措施，爬的时候要注意哦~如果还有不懂的地方，欢迎留言私信</p>\n</div>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-01-01 20:05:36", "summary": "一、准备工作用来实现对百度图片的爬取并保存，以情绪图片为例，百度搜索可得到下图所示打开源码在此处可以看到这次我们要爬取的图片的基本信息是在中二、代码实现这次的爬取主要用了如下的第三方库简单构思可以分为"}