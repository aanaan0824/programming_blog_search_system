{"blogid": "126742914", "writerAge": "码龄2年", "writerBlogNum": "43", "writerCollect": "0", "writerComment": "0", "writerFan": "1", "writerGrade": "3级", "writerIntegral": "512", "writerName": "籽麟网络", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126742914.jpg", "writerRankTotal": "72103", "writerRankWeekly": "15033", "writerThumb": "0", "writerVisitNum": "2359", "blog_read_count": "10", "blog_time": "于 2022-09-07 12:01:10 发布", "blog_title": "zookeeper的ZAB协议的原理以及底层源码实现超级详解", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p>zookeeper的ZAB协议的原理以及实现<br/> 一，zookeeper的ZAB协议<br/> 1，ZAB概述<br/> 二，ZAB协议流程的源码实现<br/> 1，客户端建立连接<br/> 2，客户端写数据<br/> 3，服务端接收数据<br/> 4，服务端主结点处理数据<br/> 5，主结点同步数据到从结点(ZAB协议)<br/> 5.1，发送这个propose（第一阶段）<br/> 5.2，Ack确认机制<br/> 5.3，commit提交(第二阶段)<br/> 6，服务端走完最后两个链条结点<br/> 7，服务端给客户端反馈<br/> 8，客户端接收反馈<br/> 三，总结<br/> 1，ZAB的消息广播总结<br/> 2，zookeeper的脑分裂问题<br/> 一，zookeeper的ZAB协议 1，ZAB概述<br/> ZAB：zookeeper atomic broadcast(zookeeper原子广播协议)<br/> ZAB协议主要包括这个 原子广播 和 崩溃恢复</p>\n<p>原子广播<br/> 就是说集群的主结点leader用来写，其他follow从结点只用来读。在主结点写完会将数据同步到从结点，只要写入成功的从结点的数量超过一半，那么这个数据就同步成功。这个主结点同步到从结点可能会有一定的延迟，因此这个zookeeper主要是为了保证这个数据的最终一致性，也可以叫为顺序一致性。</p>\n<p>崩溃恢复<br/> 如果在主结点刚把数据写完，这个主结点挂了，那么这个集群就会重新选举新的leader。选leader的规则就是先比较zxid事务id，再比较这个机器对应的myid，谁大谁被选为leader。</p>\n<p>二，ZAB协议流程的源码实现<br/> 需要下载zookeeper源码，可以参考上一篇：https://blog.csdn.net/zhenghuishengq/article/details/126673923?spm=1001.2014.3001.5502</p>\n<p>1，客户端建立连接<br/> 1，先创建一个zookeeper对象</p>\n<p>ZooKeeper zooKeeper=new ZooKeeper(…);<br/> 这个zookeeper的构造方法可能如下，里面会有很多参数，里面主要是会对创建一个connection的连接。</p>\n<p>public ZooKeeper(<br/> String connectString,<br/> int sessionTimeout,<br/> Watcher watcher,<br/> long sessionId,<br/> byte[] sessionPasswd,<br/> boolean canBeReadOnly,<br/> HostProvider hostProvider,<br/> ZKClientConfig clientConfig) throws IOException{\n <br/> //增加一个监听机制<br/> validateWatcher(watcher);<br/> this.clientConfig = clientConfig != null ? clientConfig : new ZKClientConfig();<br/> ConnectStringParser connectStringParser = new ConnectStringParser(connectString);<br/> this.hostProvider = hostProvider;<br/> //建立一个ClientCnxn连接，会和这个服务端建立连接<br/> cnxn = new ClientCnxn(<br/> connectStringParser.getChrootPath(),<br/> hostProvider,<br/> sessionTimeout,<br/> this.clientConfig,<br/> watcher,<br/> getClientCnxnSocket(),<br/> sessionId,<br/> sessionPasswd,<br/> canBeReadOnly);<br/> //开始连接<br/> cnxn.start();<br/> }<br/> 2，然后进入这个开始连接的start方法，这个方法里面主要是会去开启两个线程，一个线程主要用来连接服务端，一个线程主要用来响应连接后的事件</p>\n<p>public void start() {\n </p>\n<pre><code>sendThread.start();\neventThread.start();\n</code></pre>\n<p>}<br/> 开启这个了线程之后，主要是查看这个线程的run方法。<br/> 接下来看第一个 sendThread 线程的run方法，主要如下，用于连接这个服务端，主要是基于nio和netty两种方式实现这个连接。在连接成功之后，会通过这个nio轮询的方式监听里面的读写事件的发生，并对这个事件进行处理</p>\n<p>@Override<br/> public void run() {\n <br/> while (state.isAlive()) {\n <br/> try {\n <br/> //如果没有建立连接<br/> if (!clientCnxnSocket.isConnected()) {\n <br/> onConnecting(serverAddress);<br/> //建立连接<br/> startConnect(serverAddress);<br/> }<br/> //在建立连接之后，会通过这个nio监听这个读写事件并处理<br/> clientCnxnSocket.doTransport(to, pendingQueue, ClientCnxn.this);<br/> }<br/> }<br/> }</p>\n<p>private void startConnect(InetSocketAddress addr) throws IOException {\n <br/> //基于这个nio或者netty两种方式实现，连接这个客户端<br/> clientCnxnSocket.connect(addr);<br/> }<br/> 接下来看第二个线程 eventThread 的run方法，主要是调用一个watcher的一个监听机制</p>\n<p>@Override<br/> public void run() {\n <br/> while (true) {\n <br/> //从阻塞队列里面获取一个事件对象<br/> Object event = waitingEvents.take();<br/> //处理这个事件<br/> processEvent(event);<br/> }<br/> }</p>\n<p>private void processEvent(Object event) {\n <br/> WatcherSetEventPair pair = (WatcherSetEventPair) event;<br/> //Watcher监听机制，用于事件回调<br/> watcher.process(pair.event);<br/> }<br/> 2，客户端写数据<br/> 3，建立连接成功之后，就可以开始写数据的操作，主要是通过这个create的这个方法实现</p>\n<p>zooKeeper.create(“/myconfig”, bytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);<br/> 这个create的方法具体如下，就是会将这个发送的数据以及存放的路径做一个封装</p>\n<p>public String create(<br/> final String path,<br/> byte[] data,<br/> List acl,<br/> CreateMode createMode) throws KeeperException, InterruptedException {\n <br/> //会将传进来的数据和路径封装到一个request里面<br/> request.setData(data);<br/> request.setFlags(createMode.toFlag());<br/> request.setPath(serverPath);<br/> //通过这个连接对象实现这个客户端向服务端发送数据<br/> ReplyHeader r = cnxn.submitRequest(h, request, response, null);<br/> }<br/> <br/> 发送数据的具体实现如下，会对这个传来的数据进行一个打包的操作，在数据打包之后，会将这个数据存放到一个阻塞队列里面</p>\n<p>public ReplyHeader submitRequest(…){\n <br/> //对这个传过来的数据进行一个打包操作<br/> Packet packet = queuePacket(h,r,request,response,null,null,null,null,<br/> watchRegistration,watchDeregistration);</p>\n<pre><code>waitForPacketFinish(r, packet);\n</code></pre>\n<p>}<br/> public Packet queuePacket(){\n <br/> synhronized (outgoingQueue) {\n <br/> if (!state.isAlive() || closing) {\n <br/> conLossPacket(packet);<br/> } else {\n <br/> if (h.getType() == OpCode.closeSession) {\n <br/> closing = true;<br/> }<br/> //将打包的数据存放到一个阻塞队列里面<br/> outgoingQueue.add(packet);<br/> }<br/> //唤醒被阻塞的selector，然后向这个管道写入一个数据，<br/> //这样就可以触发前面的sendThread线程，并触发里面的写事件，将数据写入到服务端<br/> sendThread.getClientCnxnSocket().packetAdded();<br/> }<br/> }<br/> 最终会通过这个Socket的write写入事件，将这个序列化后的数据存放到buffer里面，然后通过这个SocketChannel的write方法将数据写入到服务端。数据主要是通过这个outgoingQueue队列，以异步的方式将这个信息发送到服务端。</p>\n<p>3，服务端接收数据<br/> 4，服务端这边主要是在这个 ServerCnxnFactory 类下面的 createFactory 方法里面来构建与客户端的连接，这个服务端接收数据主要是通过主结点和这个客户端进行一个交互</p>\n<p>public abstract class ServerCnxnFactory {\n <br/> static public ServerCnxnFactory createFactory() throws IOException {\n <br/> //这里主要是选择nio的方式或者选择netty的方式建立一个连接<br/> String serverCnxnFactoryName =<br/> System.getProperty(ZOOKEEPER_SERVER_CNXN_FACTORY);<br/> if (serverCnxnFactoryName == null) {\n <br/> serverCnxnFactoryName = NIOServerCnxnFactory.class.getName();<br/> }<br/> try {\n <br/> //然后通过这个反射的方式找到对应的server，如使用的netty连接就会找nettyServer<br/> ServerCnxnFactory serverCnxnFactory = (ServerCnxnFactory) Class.forName(serverCnxnFactoryName)<br/> .getDeclaredConstructor().newInstance();</p>\n<pre><code>        return serverCnxnFactory;\n    }\n}\n</code></pre>\n<p>}<br/> 5，接下来主要查看这个 NettyServerCnxnFactory 类的这个构造方法，底层主要是一些netty的一些实现逻辑。主要用来实现数据的传输</p>\n<p>NettyServerCnxnFactory() {\n <br/> EventLoopGroup bossGroup = NettyUtils.newNioOrEpollEventLoopGroup(<br/> NettyUtils.getClientReachableLocalInetAddressCount());<br/> EventLoopGroup workerGroup = NettyUtils.newNioOrEpollEventLoopGroup();<br/> ServerBootstrap bootstrap = new ServerBootstrap()<br/> .group(bossGroup, workerGroup)<br/> .channel(NettyUtils.nioOrEpollServerSocketChannel())<br/> // parent channel options<br/> .option(ChannelOption.SO_REUSEADDR, true)<br/> // child channels options<br/> .childOption(ChannelOption.TCP_NODELAY, true)<br/> .childOption(ChannelOption.SO_LINGER, -1)<br/> .childHandler(new ChannelInitializer() {\n <br/> @Override<br/> protected void initChannel(SocketChannel ch) throws Exception {\n <br/> ChannelPipeline pipeline = ch.pipeline();<br/> if (secure) {\n <br/> initSSL(pipeline, false);<br/> } else if (shouldUsePortUnification) {\n <br/> initSSL(pipeline, true);<br/> }<br/> pipeline.addLast(“servercnxnfactory”, channelHandler);<br/> }<br/> });</p>\n<p>this.bootstrap = configureBootstrapAllocator(bootstrap);<br/> this.bootstrap.validate();</p>\n<p>}<br/> <br/> 6，在建立好连接之后，服务端这边会通过这个channelRead 这个方法来读取通道的信息，就是客户端发过来的信息。</p>\n<p>@Override<br/> public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n <br/> try {\n <br/> if (LOG.isTraceEnabled()) {\n <br/> LOG.trace(“message received called {}”, msg);<br/> }<br/> try {\n <br/> if (LOG.isDebugEnabled()) {\n <br/> LOG.debug(“New message {} from {}”, msg, ctx.channel());<br/> }<br/> //服务端的连接对象<br/> NettyServerCnxn cnxn = ctx.channel().attr(CONNECTION_ATTRIBUTE).get();<br/> if (cnxn == null) {\n </p>\n<pre><code>        } else {&lt;!-- --&gt;\n            //处理客户端传过来的数据\n            cnxn.processMessage((ByteBuf) msg);\n        }\n    } catch (Exception ex) {&lt;!-- --&gt;\n        LOG.error(\"Unexpected exception in receive\", ex);\n        throw ex;\n    }\n} finally {&lt;!-- --&gt;\n    ReferenceCountUtil.release(msg);\n}\n</code></pre>\n<p>}</p>\n<p>//处理这个客户端传过来的数据<br/> void processMessage(ByteBuf buf){\n <br/> receiveMessage(buf);<br/> }<br/> 7，接下来就是正式的接收这个发送过来的数据，并对这个数据进行处理</p>\n<p>private void receiveMessage(ByteBuf message) {\n <br/> //读取message，将数据读取到服务端的byteBuffer里面<br/> message.readBytes(bb);<br/> //处理这个打包好的数据<br/> zks.processPacket(this, bb);<br/> }<br/> 接下来进入这个processPacket 这个方法，主要是用来解析打包的数据。并且在服务端中，又会将这个数据进行一个打包，封装到一个request的一个阻塞队列里面，最后将这个打包的数据进行提交</p>\n<p>public void processPacket(ServerCnxn cnxn, ByteBuffer incomingBuffer) throws IOException {\n <br/> //二进制流接收数据<br/> InputStream bais = new ByteBufferInputStream(incomingBuffer);<br/> BinaryInputArchive bia = BinaryInputArchive.getArchive(bais);<br/> //将传送过来的序列化的数据进行一个反序列化<br/> RequestHeader h = new RequestHeader();<br/> h.deserialize(bia, “header”);</p>\n<pre><code>//最后将客户端传过来的数据又封装到一个request的对象里面\nRequest si = new Request(cnxn, cnxn.getSessionId(), h.getXid(),\nh.getType(), incomingBuffer, cnxn.getAuthInfo());\nsi.setOwner(ServerCnxn.me);\nsetLocalSessionFlag(si);\n//提交这个数据\nsubmitRequest(si);\n</code></pre>\n<p>}<br/> 4，服务端主结点处理数据<br/> 8，就是进入上面的这个 submitRequest 的提交数据的这个方法，里面主要是通过一个processRequest的这个方法来进行处理这些数据</p>\n<p>public void submitRequest(Request si) {\n <br/> firstProcessor.processRequest(si);<br/> }<br/> 9，这个firstProcessor的处理器主要是在 LeaderZooKeeperServer 类下面的这个 setupRequestProcessors 的这个方法初始化的。服务端这边主要会初始化这个Processor的一个链条，底层主要是通过这个责任链的方式实现。责任链主要是为了分工合作，模块解耦</p>\n<p>@Override<br/> protected void setupRequestProcessors() {\n <br/> RequestProcessor finalProcessor = new FinalRequestProcessor(this);<br/> //将上一个processor放入下一个processor，开始构建一个责任链的一个链条<br/> RequestProcessor toBeAppliedProcessor = new Leader.ToBeAppliedRequestProcessor(finalProcessor, getLeader());<br/> commitProcessor = new CommitProcessor(toBeAppliedProcessor,<br/> Long.toString(getServerId()), false,<br/> getZooKeeperServerListener());<br/> commitProcessor.start();<br/> ProposalRequestProcessor proposalProcessor = new ProposalRequestProcessor(this,<br/> commitProcessor);<br/> proposalProcessor.initialize();<br/> prepRequestProcessor = new PrepRequestProcessor(this, proposalProcessor);<br/> //获取队列的数据，并对数据进行读取<br/> prepRequestProcessor.start();<br/> firstProcessor = new LeaderRequestProcessor(this, prepRequestProcessor);<br/> setupContainerManager();<br/> }<br/> 这个链条如下<br/> 10，在执行这个链条的过程中，会通过这个prepRequestProcessor这个线程来读取加在服务端队列的里面的消息，接下来主要就是查看这个线程里面的run方法。这个结点其主要是为了填充这个zxid，就是事务id</p>\n<p>@Override<br/> public void run() {\n <br/> try{\n <br/> Request request = submittedRequests.take();<br/> //通过这个方法进行最终的处理<br/> pRequest(request);<br/> }<br/> }<br/> 在这个pRequest方法里面，会比较之前客户端传过来的命令，比如说create，delete命令等，那么服务端就会执行具体的操作。</p>\n<p>protected void pRequest(Request request) throws RequestProcessorException {\n <br/> try {\n <br/> switch (request.type) {\n <br/> case OpCode.createContainer:<br/> case OpCode.create:<br/> case OpCode.create2:<br/> CreateRequest create2Request = new CreateRequest();<br/> //创建命令的具体逻辑<br/> pRequest2Txn(request.type, zks.getNextZxid(), request, create2Request, true);<br/> break;<br/> case OpCode.createTTL:<br/> CreateTTLRequest createTtlRequest = new CreateTTLRequest();<br/> pRequest2Txn(request.type, zks.getNextZxid(), request, createTtlRequest, true);<br/> break;<br/> case OpCode.deleteContainer:<br/> case OpCode.delete:<br/> DeleteRequest deleteRequest = new DeleteRequest();<br/> pRequest2Txn(request.type, zks.getNextZxid(), request, deleteRequest, true);<br/> break;<br/> case OpCode.setData:<br/> SetDataRequest setDataRequest = new SetDataRequest();<br/> pRequest2Txn(request.type, zks.getNextZxid(), request, setDataRequest, true);<br/> break;<br/> …<br/> }<br/> 接下来就是主要查看一下这个创建命令，主要是通过这个 pRequest2Txn 方法实现，并且里面的这个参数zxid，是一个automic的一个原子类型，不存在这个线程安全问题。获取的命令越新，那么这个zxid的值就越大。 每从这个内存队列里面获取一条消息，那么这个zxid的值就会加1</p>\n<p>protected void pRequest2Txn(int type, long zxid, Request request,<br/> Record record, boolean deserialize)<br/> throws KeeperException, IOException, RequestProcessorException{\n <br/> //将这个zxid填充回request<br/> request.zxid = zks.getZxid();<br/> //由下一个process处理<br/> nextProcessor.processRequest(request);<br/> }<br/> 5，主结点同步数据到从结点(ZAB协议)<br/> 5.1，发送这个propose（第一阶段）<br/> 11，完成了这个链条中的第二个环节之后，就进入第三个环节，即ProposalRequestProcessor的这个结点。这一环节只要是为了同步数据到从结点，并且将数据同步到从结点之后，会将这个数据在本地磁盘里面保存一份<br/> 文章转自：<a href=\"http://www.dxzl8.com/it/1055075.html\">zookeeper的ZAB协议的原理以及底层源码实现超级详解_云平台-答学网</a></p>\n<p>作者：<a href=\"http://www.dxzl8.com/\">答学网</a>，转载请注明原文链接：http://www.dxzl8.com/</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Others", "cpp": 0, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-07 12:01:10", "summary": "的协议的原理以及实现一，的协议，概述二，协议流程的源码实现，客户端建立连接，客户端写数据，服务端接收数据，服务端主结点处理数据，主结点同步数据到从结点协议，发送这个第一阶段，确认机制，提交第二阶段，服"}