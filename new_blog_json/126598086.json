{"blogid": "126598086", "writerAge": "ç é¾„55å¤©", "writerBlogNum": "119", "writerCollect": "201", "writerComment": "19", "writerFan": "99", "writerGrade": "4çº§", "writerIntegral": "1274", "writerName": "Mr_DC_IT", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126598086.jpg", "writerRankTotal": "15794", "writerRankWeekly": "1121", "writerThumb": "36", "writerVisitNum": "22582", "blog_read_count": "614", "blog_time": "äºÂ 2022-08-30 10:38:19Â å‘å¸ƒ", "blog_title": "ã€æ¯•ä¸šè®¾è®¡ã€‘æ·±åº¦å­¦ä¹ äººè„¸æ€§åˆ«è¯†åˆ«ç³»ç»Ÿï¼ˆå¹´é¾„è¯†åˆ«ï¼‰- python OpenCV", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>æ–‡ç« ç›®å½•</h3>\n<ul><li><a href=\"#0__7\">0 å‰è¨€</a></li><li><a href=\"#1__31\">1 è¯¾é¢˜æè¿°</a></li><li><ul><li><ul><li><ul><li><a href=\"#_34\">è¯¾é¢˜æ„ä¹‰</a></li></ul>\n</li></ul>\n</li></ul>\n</li><li><a href=\"#2__38\">2 å®ç°æ•ˆæœ</a></li><li><a href=\"#3__53\">3 ç®—æ³•å®ç°åŸç†</a></li><li><ul><li><a href=\"#31__54\">3.1 æ•°æ®é›†</a></li><li><a href=\"#32__63\">3.2 æ·±åº¦å­¦ä¹ è¯†åˆ«ç®—æ³•</a></li><li><a href=\"#33__75\">3.3 ç‰¹å¾æå–ä¸»å¹²ç½‘ç»œ</a></li><li><a href=\"#34__85\">3.4 æ€»ä½“å®ç°æµç¨‹</a></li></ul>\n</li><li><a href=\"#4__89\">4 å…·ä½“å®ç°</a></li><li><ul><li><a href=\"#41__91\">4.1 é¢„è®­ç»ƒæ•°æ®æ ¼å¼</a></li><li><a href=\"#42__97\">4.2 éƒ¨åˆ†å®ç°ä»£ç </a></li></ul>\n</li></ul>\n</div>\n<p></p>\n<hr color=\"#000000\" size='1\"'/>\n<h1><a id=\"0__7\"></a>0 å‰è¨€</h1>\n<p>ğŸ”¥ Hiï¼Œå¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯ä¸¹æˆå­¦é•¿çš„æ¯•è®¾ç³»åˆ—æ–‡ç« ï¼</p>\n<p>ğŸ”¥ å¯¹æ¯•è®¾æœ‰ä»»ä½•ç–‘é—®éƒ½å¯ä»¥é—®å­¦é•¿å“¦!</p>\n<p>è¿™ä¸¤å¹´å¼€å§‹ï¼Œå„ä¸ªå­¦æ ¡å¯¹æ¯•è®¾çš„è¦æ±‚è¶Šæ¥è¶Šé«˜ï¼Œéš¾åº¦ä¹Ÿè¶Šæ¥è¶Šå¤§â€¦ æ¯•ä¸šè®¾è®¡è€—è´¹æ—¶é—´ï¼Œè€—è´¹ç²¾åŠ›ï¼Œç”šè‡³æœ‰äº›é¢˜ç›®å³ä½¿æ˜¯ä¸“ä¸šçš„è€å¸ˆæˆ–è€…ç¡•å£«ç”Ÿä¹Ÿéœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œæ‰€ä»¥ä¸€æ—¦å‘ç°é—®é¢˜ï¼Œä¸€å®šè¦æå‰å‡†å¤‡ï¼Œé¿å…åˆ°åé¢æªæ‰‹ä¸åŠï¼Œè‰è‰äº†äº‹ã€‚</p>\n<p>ä¸ºäº†å¤§å®¶èƒ½å¤Ÿé¡ºåˆ©ä»¥åŠæœ€å°‘çš„ç²¾åŠ›é€šè¿‡æ¯•è®¾ï¼Œå­¦é•¿åˆ†äº«ä¼˜è´¨æ¯•ä¸šè®¾è®¡é¡¹ç›®ï¼Œä»Šå¤©è¦åˆ†äº«çš„æ–°é¡¹ç›®æ˜¯</p>\n<p>ğŸš© <strong>åŸºäºæ·±åº¦å­¦ä¹ çš„äººè„¸æ€§åˆ«å¹´é¾„è¯†åˆ«ç³»ç»Ÿ</strong></p>\n<p>ğŸ¥‡å­¦é•¿è¿™é‡Œç»™ä¸€ä¸ªé¢˜ç›®ç»¼åˆè¯„åˆ†(æ¯é¡¹æ»¡åˆ†5åˆ†)</p>\n<ul><li>éš¾åº¦ç³»æ•°ï¼š4åˆ†</li><li>å·¥ä½œé‡ï¼š4åˆ†</li><li>åˆ›æ–°ç‚¹ï¼š3åˆ†</li></ul>\n<p>ğŸ§¿ <strong>é€‰é¢˜æŒ‡å¯¼, é¡¹ç›®åˆ†äº«ï¼š</strong></p>\n<p><a href=\"https://blog.csdn.net/Mr_DC_IT/article/details/126460477\">https://blog.csdn.net/Mr_DC_IT/article/details/126460477</a></p>\n<h1><a id=\"1__31\"></a>1 è¯¾é¢˜æè¿°</h1>\n<p>éšç€å¤§æ•°æ®ä¸äººå·¥æ™ºèƒ½é€æ¸èµ°å…¥äººä»¬çš„ç”Ÿæ´»ï¼Œè®¡ç®—æœºè§†è§‰åº”ç”¨è¶Šå‘å¹¿æ³›ã€‚å¦‚åŒ»ç–—å½±åƒè¯†åˆ«ã€æ— äººé©¾é©¶è½¦è½½è§†è§‰ã€é€šç”¨ç‰©ä½“è¯†åˆ«ã€è‡ªç„¶åœºæ™¯ä¸‹çš„æ–‡æœ¬è¯†åˆ«ç­‰ï¼Œæ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œäººè„¸ç ”ç©¶æ–¹å‘å¯ä»¥åˆ†ä¸ºäººè„¸æ£€æµ‹ã€èº«ä»½è¯†åˆ«ã€æ€§åˆ«è¯†åˆ«ã€å¹´é¾„é¢„æµ‹ã€ç§æ—è¯†åˆ«ã€è¡¨æƒ…è¯†åˆ«ç­‰ã€‚è¿‘å¹´æ¥ï¼Œäººè„¸èº«ä»½è¯†åˆ«æŠ€æœ¯å‘å±•è¿…çŒ›ï¼Œåœ¨ç”Ÿæ´»åº”ç”¨ä¸­å–å¾—äº†è¾ƒå¥½çš„æ•ˆæœï¼Œä¹Ÿé€æ¸è¶‹äºæˆç†Ÿï¼Œè€Œå¹´é¾„è¯†åˆ«ä¸æ€§åˆ«é¢„æµ‹ï¼Œä»ç„¶æ˜¯ç”Ÿç‰©ç‰¹å¾è¯†åˆ«ç ”ç©¶é¢†åŸŸä¸­ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯¾é¢˜ã€‚</p>\n<h4><a id=\"_34\"></a>è¯¾é¢˜æ„ä¹‰</h4>\n<p>ç›¸æ¯”äººè„¸æ€§åˆ«å±æ€§è€Œè¨€ï¼Œäººè„¸å¹´é¾„å±æ€§çš„ç ”ç©¶æ›´å¯Œæœ‰æŒ‘æˆ˜æ€§ã€‚ä¸»è¦æœ‰ä¸¤ç‚¹åŸå› ï¼Œé¦–å…ˆæ¯ä¸ªäººçš„å¹´é¾„ä¼šéšç€èº«ä½“å¥åº·çŠ¶å†µã€çš®è‚¤ä¿å…»æƒ…å†µè€Œè¡¨ç°å¾—æœ‰æ‰€ä¸åŒï¼Œå³ä¾¿æ˜¯åœ¨åŒä¸€å¹´ï¼Œè¡¨ç°å¹´é¾„ä¼šéšç€ä¸ªäººçŠ¶æ€çš„ä¸åŒè€Œæ”¹å˜ï¼Œäººç±»è¯†åˆ«å°šä¸”å…·æœ‰è¾ƒé«˜éš¾åº¦ã€‚å…¶æ¬¡ï¼Œå¯ç”¨çš„äººè„¸å¹´é¾„ä¼°è®¡æ•°æ®é›†æ¯”è¾ƒå°‘ï¼Œä¸åŒå¹´é¾„çš„æ•°æ®æ ‡ç­¾æ”¶é›†ä¸æ˜“ï¼Œç°æœ‰å¤§å¤šæ•°çš„å¹´é¾„æ•°æ®é›†éƒ½æ˜¯åœ¨ä¸åŒçš„å¤æ‚ç¯å¢ƒä¸‹çš„ç…§ç‰‡ã€äººè„¸å›¾ç‰‡å­˜åœ¨å…‰ç…§å˜åŒ–è¾ƒå¤æ‚ã€éƒ¨åˆ†é®æŒ¡ã€å›¾åƒæ¨¡ç³Šã€å§¿æ€æ—‹è½¬è§’åº¦è¾ƒå¤§ç­‰ä¸€ç³»åˆ—é—®é¢˜ï¼Œå¯¹äººè„¸æ¨¡å‹çš„é²æ£’æ€§äº§ç”Ÿäº†è¾ƒå¤§çš„å½±å“ã€‚</p>\n<h1><a id=\"2__38\"></a>2 å®ç°æ•ˆæœ</h1>\n<p>è¿™é‡ŒåºŸè¯ä¸å¤šè¯´ï¼Œå…ˆæ”¾ä¸Šå¤§å®¶æœ€å…³å¿ƒçš„å®ç°æ•ˆæœï¼š</p>\n<p><strong>è¾“å…¥å›¾ç‰‡ï¼š</strong><br/> <img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127170119225.png\"/></p>\n<p><strong>è¯†åˆ«ç»“æœï¼š</strong></p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\2021012717021326.png\"/></p>\n<p><strong>æˆ–è€…å®æ—¶æ£€æµ‹</strong><br/> <img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127170509361.png\"/><br/> <img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127170517634.png\"/></p>\n<h1><a id=\"3__53\"></a>3 ç®—æ³•å®ç°åŸç†</h1>\n<h2><a id=\"31__54\"></a>3.1 æ•°æ®é›†</h2>\n<p>å­¦é•¿æ”¶é›†çš„æ•°æ®é›†ï¼š<br/> è¯¥äººè„¸æ•°æ®åº“çš„å›¾ç‰‡æ¥æºäºäº’è”ç½‘çš„çˆ¬å–ï¼Œè€Œéç ”ç©¶æœºæ„æ•´ç†ï¼Œä¸€å…±å«æœ‰13000å¤šå¼ äººè„¸å›¾åƒï¼Œåœ¨è¿™ä¸ªæ•°æ®é›†ä¸­å¤§çº¦æœ‰1860å¼ å›¾ç‰‡æ˜¯æˆå¯¹å‡ºç°çš„ï¼Œå³åŒä¸€ä¸ªäººçš„2å¼ ä¸åŒç…§ç‰‡ï¼Œæœ‰åŠ©äºäººè„¸è¯†åˆ«ç®—æ³•çš„ç ”ç©¶ï¼Œå›¾åƒæ ‡ç­¾ä¸­æ ‡æœ‰äººçš„èº«ä»½ä¿¡æ¯ï¼Œäººè„¸åæ ‡ï¼Œå…³é”®ç‚¹ä¿¡æ¯ï¼Œå¯ç”¨äºäººè„¸æ£€æµ‹å’Œäººè„¸è¯†åˆ«çš„ç ”ç©¶ï¼Œæ­¤æ•°æ®é›†æ˜¯å¯¹äººè„¸ç®—æ³•æ•ˆæœéªŒè¯çš„æƒå¨æ•°æ®é›†.</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127170941102.png\"/><br/> è¯¥æ•°æ®é›†åŒ…å«çš„äººè„¸èŒƒå›´æ¯”è¾ƒå…¨é¢ï¼Œæ¬§äºšäººç§éƒ½æœ‰ã€‚</p>\n<h2><a id=\"32__63\"></a>3.2 æ·±åº¦å­¦ä¹ è¯†åˆ«ç®—æ³•</h2>\n<p>å·ç§¯ç¥ç»ç½‘ç»œæ˜¯å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œè€Œåœ¨CNNå‡ºç°ä¹‹å‰ï¼Œå›¾åƒéœ€è¦å¤„ç†çš„æ•°æ®é‡è¿‡å¤§ï¼Œå¯¼è‡´æˆæœ¬å¾ˆé«˜ï¼Œæ•ˆç‡å¾ˆä½ï¼Œå›¾åƒåœ¨æ•°å­—åŒ–çš„è¿‡ç¨‹ä¸­å¾ˆéš¾ä¿ç•™åŸæœ‰çš„ç‰¹å¾ï¼Œå¯¼è‡´å›¾åƒå¤„ç†çš„å‡†ç¡®ç‡ä¸é«˜ã€‚CNNçš„å‡ºç°ä½¿å¾—æå–ç‰¹å¾çš„èƒ½åŠ›å˜å¾—æ›´å¼ºï¼Œä¸ºæ›´å¤šä¼˜ç§€ç½‘ç»œçš„ç ”ç©¶æä¾›äº†æœ‰åŠ›çš„æ”¯æ’‘ã€‚CNNçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘è§†è§‰ç¥ç»ç³»ç»Ÿï¼Œæ„é€ å¤šä¸ªç¥ç»å…ƒå¹¶å»ºç«‹å½¼æ­¤ä¹‹é—´çš„è”ç³»ã€‚ä¸åŒçš„ç¥ç»å…ƒè¿›è¡Œåˆ†å·¥ï¼Œæµ…å±‚ç¥ç»å…ƒå¤„ç†ä½çº¬åº¦å›¾åƒç‰¹å¾ï¼Œæ·±å±‚ç¥ç»å…ƒå¤„ç†å›¾åƒé«˜çº§ç‰¹å¾ã€è¯­ä¹‰ä¿¡æ¯ç­‰ï¼ŒCNNçš„ç½‘ç»œç»“æ„ä¸»è¦ç”±å·ç§¯å±‚ã€BNå±‚ã€æ¿€æ´»å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚ã€æŸå¤±å‡½æ•°å±‚æ„æˆï¼Œå¤šä¸ªå±‚ååŒå·¥ä½œå®ç°äº†ç‰¹å¾æå–çš„åŠŸèƒ½ï¼Œå¹¶é€šè¿‡ç‰¹æœ‰çš„ç½‘ç»œç»“æ„é™ä½å‚æ•°çš„æ•°é‡çº§ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæœ€ç»ˆå¾—åˆ°è¾“å‡ºç»“æœ.</p>\n<p>CNNä¼ æ‰¿äº†å¤šå±‚æ„ŸçŸ¥æœºçš„æ€æƒ³ï¼Œå¹¶å—åˆ°äº†ç”Ÿç‰©ç¥ç»ç§‘å­¦çš„å¯å‘ï¼Œé€šè¿‡å·ç§¯çš„è¿ç®—æ¨¡æ‹Ÿäººç±»è§†è§‰çš®å±‚çš„â€œæ„Ÿå—é‡â€ã€‚ä¸åŒäºä¼ ç»Ÿçš„å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå·ç§¯è¿ç®—å¯¹å›¾åƒçš„åŒºåŸŸå€¼è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œæœ€ç»ˆä»¥ç¥ç»å…ƒçš„å½¢å¼è¿›è¡Œè¾“å‡ºã€‚å‰é¦ˆç¥ç»ç½‘ç»œå¯¹æ¯ä¸€ä¸ªè¾“å…¥çš„ä¿¡å·è¿›è¡ŒåŠ æƒæ±‚å’Œï¼š</p>\n<ul><li>ï¼ˆaï¼‰å›¾æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œçš„è¿æ¥æ–¹å¼</li><li>ï¼ˆbï¼‰å›¾æ˜¯CNNçš„è¿æ¥æ–¹å¼ã€‚</li></ul>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171342897.png\"/><br/> <strong>cnnæ¡†æ¶å¦‚ä¸‹ï¼š</strong><br/> <img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171406802.png\"/></p>\n<h2><a id=\"33__75\"></a>3.3 ç‰¹å¾æå–ä¸»å¹²ç½‘ç»œ</h2>\n<p>åœ¨æ·±åº¦å­¦ä¹ ç®—æ³•ç ”ç©¶ä¸­ï¼Œé€šç”¨ä¸»å¹²ç‰¹å¾æå–ç½‘ç»œç»“åˆç‰¹å®šä»»åŠ¡ç½‘ç»œå·²ç»æˆä¸ºä¸€ç§æ ‡å‡†çš„è®¾è®¡æ¨¡å¼ã€‚ç‰¹å¾æå–å¯¹äºåˆ†ç±»ã€è¯†åˆ«ã€åˆ†å‰²ç­‰ä»»åŠ¡éƒ½æ˜¯è‡³å…³é‡è¦çš„éƒ¨åˆ†ã€‚ä¸‹é¢ä»‹ç»æœ¬æ–‡ç ”ç©¶ä¸­ç”¨åˆ°çš„ä¸»å¹²ç¥ç»ç½‘ç»œã€‚</p>\n<p><strong>ResNetç½‘ç»œ</strong><br/> ResNetæ˜¯ILSVRC-2015çš„å›¾åƒåˆ†ç±»ä»»åŠ¡å† å†›ï¼Œä¹Ÿæ˜¯CVPR2016çš„æœ€ä½³è®ºæ–‡ï¼Œç›®å‰åº”ç”¨ååˆ†å¹¿æ³›ï¼ŒResNetçš„é‡è¦æ€§åœ¨äºå°†ç½‘ç»œçš„è®­ç»ƒæ·±åº¦å»¶ä¼¸åˆ°äº†æ•°ç™¾å±‚ï¼Œè€Œä¸”å–å¾—äº†éå¸¸å¥½çš„æ•ˆæœã€‚åœ¨ResNetå‡ºç°ä¹‹å‰ï¼Œç½‘ç»œç»“æ„ä¸€èˆ¬åœ¨20å±‚å·¦å³ï¼Œå¯¹äºä¸€èˆ¬æƒ…å†µï¼Œç½‘ç»œç»“æ„è¶Šæ·±ï¼Œæ¨¡å‹æ•ˆæœå°±ä¼šè¶Šå¥½ï¼Œä½†æ˜¯ç ”ç©¶äººå‘˜å‘ç°åŠ æ·±ç½‘ç»œåè€Œä¼šä½¿ç»“æœå˜å·®ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171743942.png\"/></p>\n<p>äººè„¸ç‰¹å¾æå–æˆ‘è¿™é‡Œé€‰ç”¨ResNetï¼Œç½‘ç»œç»“æ„å¦‚ä¸‹ï¼š<br/> <img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171830823.png\"/></p>\n<h2><a id=\"34__85\"></a>3.4 æ€»ä½“å®ç°æµç¨‹</h2>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127172202894.png\"/></p>\n<h1><a id=\"4__89\"></a>4 å…·ä½“å®ç°</h1>\n<h2><a id=\"41__91\"></a>4.1 é¢„è®­ç»ƒæ•°æ®æ ¼å¼</h2>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171937980.png\"/></p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" src=\"..\\..\\static\\image\\20210127171943192.png\"/></p>\n<h2><a id=\"42__97\"></a>4.2 éƒ¨åˆ†å®ç°ä»£ç </h2>\n<p>è®­ç»ƒéƒ¨åˆ†ä»£ç ï¼š</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> absolute_import\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> division\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> print_function\n\n<span class=\"token keyword\">from</span> six<span class=\"token punctuation\">.</span>moves <span class=\"token keyword\">import</span> <span class=\"token builtin\">xrange</span>\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> data <span class=\"token keyword\">import</span> distorted_inputs\n<span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> select_model\n<span class=\"token keyword\">import</span> json\n<span class=\"token keyword\">import</span> re\n\n\nLAMBDA <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span>\nMOM <span class=\"token operator\">=</span> <span class=\"token number\">0.9</span>\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'pre_checkpoint_path'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token triple-quoted-string string\">\"\"\"If specified, restore this pretrained model \"\"\"</span>\n                           <span class=\"token triple-quoted-string string\">\"\"\"before beginning any training.\"\"\"</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'train_dir'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'/home/dpressel/dev/work/AgeGenderDeepLearning/Folds/tf/test_fold_is_0'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Training directory'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_boolean<span class=\"token punctuation\">(</span><span class=\"token string\">'log_device_placement'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token triple-quoted-string string\">\"\"\"Whether to log device placement.\"\"\"</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'num_preprocess_threads'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of preprocessing threads'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'optim'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Momentum'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Optimizer'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'image_size'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">227</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Image size'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'eta'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Learning rate'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'pdrop'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Dropout probability'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'max_steps'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40000</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Number of iterations'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'steps_per_decay'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of steps before learning rate decay'</span><span class=\"token punctuation\">)</span>\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'eta_decay_rate'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Learning rate decay'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of epochs'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Batch size'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'checkpoint'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'checkpoint'</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Checkpoint name'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'model_type'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'default'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Type of convnet'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'pre_model'</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">''</span><span class=\"token punctuation\">,</span><span class=\"token comment\">#'./inception_v3.ckpt',</span>\n                           <span class=\"token string\">'checkpoint file'</span><span class=\"token punctuation\">)</span>\nFLAGS <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>FLAGS\n\n<span class=\"token comment\"># Every 5k steps cut learning rate in half</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">exponential_staircase_decay</span><span class=\"token punctuation\">(</span>at_step<span class=\"token operator\">=</span><span class=\"token number\">10000</span><span class=\"token punctuation\">,</span> decay_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'decay [%f] every [%d] steps'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>decay_rate<span class=\"token punctuation\">,</span> at_step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_decay</span><span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>exponential_decay<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">,</span>\n                                          at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">,</span> staircase<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> _decay\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">optimizer</span><span class=\"token punctuation\">(</span>optim<span class=\"token punctuation\">,</span> eta<span class=\"token punctuation\">,</span> loss_fn<span class=\"token punctuation\">,</span> at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    global_step <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> trainable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    optz <span class=\"token operator\">=</span> optim\n    <span class=\"token keyword\">if</span> optim <span class=\"token operator\">==</span> <span class=\"token string\">'Adadelta'</span><span class=\"token punctuation\">:</span>\n        optz <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> lr<span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>AdadeltaOptimizer<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> <span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">)</span>\n        lr_decay_fn <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n    <span class=\"token keyword\">elif</span> optim <span class=\"token operator\">==</span> <span class=\"token string\">'Momentum'</span><span class=\"token punctuation\">:</span>\n        optz <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> lr<span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>MomentumOptimizer<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> MOM<span class=\"token punctuation\">)</span>\n        lr_decay_fn <span class=\"token operator\">=</span> exponential_staircase_decay<span class=\"token punctuation\">(</span>at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>contrib<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>optimize_loss<span class=\"token punctuation\">(</span>loss_fn<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">,</span> eta<span class=\"token punctuation\">,</span> optz<span class=\"token punctuation\">,</span> clip_gradients<span class=\"token operator\">=</span><span class=\"token number\">4.</span><span class=\"token punctuation\">,</span> learning_rate_decay_fn<span class=\"token operator\">=</span>lr_decay_fn<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">loss</span><span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">)</span>\n    cross_entropy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>sparse_softmax_cross_entropy_with_logits<span class=\"token punctuation\">(</span>\n        logits<span class=\"token operator\">=</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token operator\">=</span>labels<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'cross_entropy_per_example'</span><span class=\"token punctuation\">)</span>\n    cross_entropy_mean <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'cross_entropy'</span><span class=\"token punctuation\">)</span>\n    tf<span class=\"token punctuation\">.</span>add_to_collection<span class=\"token punctuation\">(</span><span class=\"token string\">'losses'</span><span class=\"token punctuation\">,</span> cross_entropy_mean<span class=\"token punctuation\">)</span>\n    losses <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span><span class=\"token string\">'losses'</span><span class=\"token punctuation\">)</span>\n    regularization_losses <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>GraphKeys<span class=\"token punctuation\">.</span>REGULARIZATION_LOSSES<span class=\"token punctuation\">)</span>\n    total_loss <span class=\"token operator\">=</span> cross_entropy_mean <span class=\"token operator\">+</span> LAMBDA <span class=\"token operator\">*</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>regularization_losses<span class=\"token punctuation\">)</span>\n    tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span><span class=\"token string\">'tl (raw)'</span><span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#total_loss = tf.add_n(losses + regularization_losses, name='total_loss')</span>\n    loss_averages <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>ExponentialMovingAverage<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'avg'</span><span class=\"token punctuation\">)</span>\n    loss_averages_op <span class=\"token operator\">=</span> loss_averages<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>losses <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> losses <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>op<span class=\"token punctuation\">.</span>name <span class=\"token operator\">+</span> <span class=\"token string\">' (raw)'</span><span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">)</span>\n        tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>op<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span> loss_averages<span class=\"token punctuation\">.</span>average<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>control_dependencies<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>loss_averages_op<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        total_loss <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>identity<span class=\"token punctuation\">(</span>total_loss<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> total_loss\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>argv<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>Graph<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>as_default<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        model_fn <span class=\"token operator\">=</span> select_model<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>model_type<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Open the metadata file and figure out nlabels, and size of epoch</span>\n        input_file <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> <span class=\"token string\">'md.json'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            md <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n\n        images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> distorted_inputs<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>image_size<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>num_preprocess_threads<span class=\"token punctuation\">)</span>\n        logits <span class=\"token operator\">=</span> model_fn<span class=\"token punctuation\">(</span>md<span class=\"token punctuation\">[</span><span class=\"token string\">'nlabels'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> images<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span>FLAGS<span class=\"token punctuation\">.</span>pdrop<span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        total_loss <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span>\n\n        train_op <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>eta<span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>steps_per_decay<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>eta_decay_rate<span class=\"token punctuation\">)</span>\n        saver <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        summary_op <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>merge_all<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        sess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span>config<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>ConfigProto<span class=\"token punctuation\">(</span>\n            log_device_placement<span class=\"token operator\">=</span>FLAGS<span class=\"token punctuation\">.</span>log_device_placement<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>session<span class=\"token operator\">=</span>sess<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># This is total hackland, it only works to fine-tune iv3</span>\n        <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>pre_model<span class=\"token punctuation\">:</span>\n            inception_variables <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>GraphKeys<span class=\"token punctuation\">.</span>VARIABLES<span class=\"token punctuation\">,</span> scope<span class=\"token operator\">=</span><span class=\"token string\">\"InceptionV3\"</span><span class=\"token punctuation\">)</span>\n            restorer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span>inception_variables<span class=\"token punctuation\">)</span>\n            restorer<span class=\"token punctuation\">.</span>restore<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>pre_model<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>Exists<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Trying to restore checkpoint from %s'</span> <span class=\"token operator\">%</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span>\n                restorer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>latest_checkpoint<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'%s: Pre-trained model restored from %s'</span> <span class=\"token operator\">%</span>\n                      <span class=\"token punctuation\">(</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n        run_dir <span class=\"token operator\">=</span> <span class=\"token string\">'%s/run-%d'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        checkpoint_path <span class=\"token operator\">=</span> <span class=\"token string\">'%s/%s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>checkpoint<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>Exists<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Creating %s'</span> <span class=\"token operator\">%</span> run_dir<span class=\"token punctuation\">)</span>\n            tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>MakeDirs<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>write_graph<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">.</span>graph_def<span class=\"token punctuation\">,</span> run_dir<span class=\"token punctuation\">,</span> <span class=\"token string\">'model.pb'</span><span class=\"token punctuation\">,</span> as_text<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>start_queue_runners<span class=\"token punctuation\">(</span>sess<span class=\"token operator\">=</span>sess<span class=\"token punctuation\">)</span>\n\n\n        summary_writer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>FileWriter<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">)</span>\n        steps_per_train_epoch <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>md<span class=\"token punctuation\">[</span><span class=\"token string\">'train_counts'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> FLAGS<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">)</span>\n        num_steps <span class=\"token operator\">=</span> FLAGS<span class=\"token punctuation\">.</span>max_steps <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>epochs <span class=\"token operator\">&lt;</span> <span class=\"token number\">1</span> <span class=\"token keyword\">else</span> FLAGS<span class=\"token punctuation\">.</span>epochs <span class=\"token operator\">*</span> steps_per_train_epoch\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Requested number of steps [%d]'</span> <span class=\"token operator\">%</span> num_steps<span class=\"token punctuation\">)</span>\n\n        \n        <span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">xrange</span><span class=\"token punctuation\">(</span>num_steps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            _<span class=\"token punctuation\">,</span> loss_value <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train_op<span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n\n            <span class=\"token keyword\">assert</span> <span class=\"token keyword\">not</span> np<span class=\"token punctuation\">.</span>isnan<span class=\"token punctuation\">(</span>loss_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Model diverged with loss = NaN'</span>\n\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">10</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                num_examples_per_step <span class=\"token operator\">=</span> FLAGS<span class=\"token punctuation\">.</span>batch_size\n                examples_per_sec <span class=\"token operator\">=</span> num_examples_per_step <span class=\"token operator\">/</span> duration\n                sec_per_batch <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>duration<span class=\"token punctuation\">)</span>\n                \n                format_str <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'%s: step %d, loss = %.3f (%.1f examples/sec; %.3f '</span> <span class=\"token string\">'sec/batch)'</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>format_str <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> loss_value<span class=\"token punctuation\">,</span>\n                                    examples_per_sec<span class=\"token punctuation\">,</span> sec_per_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Loss only actually evaluated every 100 steps?</span>\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                summary_str <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>summary_op<span class=\"token punctuation\">)</span>\n                summary_writer<span class=\"token punctuation\">.</span>add_summary<span class=\"token punctuation\">(</span>summary_str<span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">)</span>\n                \n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">1000</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> <span class=\"token punctuation\">(</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> num_steps<span class=\"token punctuation\">:</span>\n                saver<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> checkpoint_path<span class=\"token punctuation\">,</span> global_step<span class=\"token operator\">=</span>step<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    tf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<br/>\n<p>ğŸ§¿ <strong>é€‰é¢˜æŒ‡å¯¼, é¡¹ç›®åˆ†äº«ï¼š</strong></p>\n<p><a href=\"https://blog.csdn.net/Mr_DC_IT/article/details/126460477\">https://blog.csdn.net/Mr_DC_IT/article/details/126460477</a></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-08-30 10:38:19", "summary": "æ–‡ç« ç›®å½•å‰è¨€è¯¾é¢˜æè¿°è¯¾é¢˜æ„ä¹‰å®ç°æ•ˆæœç®—æ³•å®ç°åŸç†æ•°æ®é›†æ·±åº¦å­¦ä¹ è¯†åˆ«ç®—æ³•ç‰¹å¾æå–ä¸»å¹²ç½‘ç»œæ€»ä½“å®ç°æµç¨‹å…·ä½“å®ç°é¢„è®­ç»ƒæ•°æ®æ ¼å¼éƒ¨åˆ†å®ç°ä»£ç å‰è¨€ï¼Œå¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯ä¸¹æˆå­¦é•¿çš„æ¯•è®¾ç³»åˆ—æ–‡ç« ï¼å¯¹æ¯•è®¾æœ‰ä»»ä½•ç–‘é—®éƒ½å¯ä»¥é—®"}