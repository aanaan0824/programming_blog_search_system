{"blogid": "126598086", "writerAge": "码龄55天", "writerBlogNum": "119", "writerCollect": "201", "writerComment": "19", "writerFan": "99", "writerGrade": "4级", "writerIntegral": "1274", "writerName": "Mr_DC_IT", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126598086.jpg", "writerRankTotal": "15794", "writerRankWeekly": "1121", "writerThumb": "36", "writerVisitNum": "22582", "blog_read_count": "614", "blog_time": "于 2022-08-30 10:38:19 发布", "blog_title": "【毕业设计】深度学习人脸性别识别系统（年龄识别）- python OpenCV", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>文章目录</h3>\n<ul><li><a href=\"#0__7\">0 前言</a></li><li><a href=\"#1__31\">1 课题描述</a></li><li><ul><li><ul><li><ul><li><a href=\"#_34\">课题意义</a></li></ul>\n</li></ul>\n</li></ul>\n</li><li><a href=\"#2__38\">2 实现效果</a></li><li><a href=\"#3__53\">3 算法实现原理</a></li><li><ul><li><a href=\"#31__54\">3.1 数据集</a></li><li><a href=\"#32__63\">3.2 深度学习识别算法</a></li><li><a href=\"#33__75\">3.3 特征提取主干网络</a></li><li><a href=\"#34__85\">3.4 总体实现流程</a></li></ul>\n</li><li><a href=\"#4__89\">4 具体实现</a></li><li><ul><li><a href=\"#41__91\">4.1 预训练数据格式</a></li><li><a href=\"#42__97\">4.2 部分实现代码</a></li></ul>\n</li></ul>\n</div>\n<p></p>\n<hr color=\"#000000\" size='1\"'/>\n<h1><a id=\"0__7\"></a>0 前言</h1>\n<p>🔥 Hi，大家好，这里是丹成学长的毕设系列文章！</p>\n<p>🔥 对毕设有任何疑问都可以问学长哦!</p>\n<p>这两年开始，各个学校对毕设的要求越来越高，难度也越来越大… 毕业设计耗费时间，耗费精力，甚至有些题目即使是专业的老师或者硕士生也需要很长时间，所以一旦发现问题，一定要提前准备，避免到后面措手不及，草草了事。</p>\n<p>为了大家能够顺利以及最少的精力通过毕设，学长分享优质毕业设计项目，今天要分享的新项目是</p>\n<p>🚩 <strong>基于深度学习的人脸性别年龄识别系统</strong></p>\n<p>🥇学长这里给一个题目综合评分(每项满分5分)</p>\n<ul><li>难度系数：4分</li><li>工作量：4分</li><li>创新点：3分</li></ul>\n<p>🧿 <strong>选题指导, 项目分享：</strong></p>\n<p><a href=\"https://blog.csdn.net/Mr_DC_IT/article/details/126460477\">https://blog.csdn.net/Mr_DC_IT/article/details/126460477</a></p>\n<h1><a id=\"1__31\"></a>1 课题描述</h1>\n<p>随着大数据与人工智能逐渐走入人们的生活，计算机视觉应用越发广泛。如医疗影像识别、无人驾驶车载视觉、通用物体识别、自然场景下的文本识别等，根据不同的应用场景，人脸研究方向可以分为人脸检测、身份识别、性别识别、年龄预测、种族识别、表情识别等。近年来，人脸身份识别技术发展迅猛，在生活应用中取得了较好的效果，也逐渐趋于成熟，而年龄识别与性别预测，仍然是生物特征识别研究领域中一项具有挑战性的课题。</p>\n<h4><a id=\"_34\"></a>课题意义</h4>\n<p>相比人脸性别属性而言，人脸年龄属性的研究更富有挑战性。主要有两点原因，首先每个人的年龄会随着身体健康状况、皮肤保养情况而表现得有所不同，即便是在同一年，表现年龄会随着个人状态的不同而改变，人类识别尚且具有较高难度。其次，可用的人脸年龄估计数据集比较少，不同年龄的数据标签收集不易，现有大多数的年龄数据集都是在不同的复杂环境下的照片、人脸图片存在光照变化较复杂、部分遮挡、图像模糊、姿态旋转角度较大等一系列问题，对人脸模型的鲁棒性产生了较大的影响。</p>\n<h1><a id=\"2__38\"></a>2 实现效果</h1>\n<p>这里废话不多说，先放上大家最关心的实现效果：</p>\n<p><strong>输入图片：</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127170119225.png\"/></p>\n<p><strong>识别结果：</strong></p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\2021012717021326.png\"/></p>\n<p><strong>或者实时检测</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127170509361.png\"/><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127170517634.png\"/></p>\n<h1><a id=\"3__53\"></a>3 算法实现原理</h1>\n<h2><a id=\"31__54\"></a>3.1 数据集</h2>\n<p>学长收集的数据集：<br/> 该人脸数据库的图片来源于互联网的爬取，而非研究机构整理，一共含有13000多张人脸图像，在这个数据集中大约有1860张图片是成对出现的，即同一个人的2张不同照片，有助于人脸识别算法的研究，图像标签中标有人的身份信息，人脸坐标，关键点信息，可用于人脸检测和人脸识别的研究，此数据集是对人脸算法效果验证的权威数据集.</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127170941102.png\"/><br/> 该数据集包含的人脸范围比较全面，欧亚人种都有。</p>\n<h2><a id=\"32__63\"></a>3.2 深度学习识别算法</h2>\n<p>卷积神经网络是常见的深度学习架构，而在CNN出现之前，图像需要处理的数据量过大，导致成本很高，效率很低，图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高。CNN的出现使得提取特征的能力变得更强，为更多优秀网络的研究提供了有力的支撑。CNN的核心思想是利用神经网络模拟人脑视觉神经系统，构造多个神经元并建立彼此之间的联系。不同的神经元进行分工，浅层神经元处理低纬度图像特征，深层神经元处理图像高级特征、语义信息等，CNN的网络结构主要由卷积层、BN层、激活层、池化层、全连接层、损失函数层构成，多个层协同工作实现了特征提取的功能，并通过特有的网络结构降低参数的数量级，防止过拟合，最终得到输出结果.</p>\n<p>CNN传承了多层感知机的思想，并受到了生物神经科学的启发，通过卷积的运算模拟人类视觉皮层的“感受野”。不同于传统的前馈神经网络，卷积运算对图像的区域值进行加权求和，最终以神经元的形式进行输出。前馈神经网络对每一个输入的信号进行加权求和：</p>\n<ul><li>（a）图是前馈神经网络的连接方式</li><li>（b）图是CNN的连接方式。</li></ul>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171342897.png\"/><br/> <strong>cnn框架如下：</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171406802.png\"/></p>\n<h2><a id=\"33__75\"></a>3.3 特征提取主干网络</h2>\n<p>在深度学习算法研究中，通用主干特征提取网络结合特定任务网络已经成为一种标准的设计模式。特征提取对于分类、识别、分割等任务都是至关重要的部分。下面介绍本文研究中用到的主干神经网络。</p>\n<p><strong>ResNet网络</strong><br/> ResNet是ILSVRC-2015的图像分类任务冠军，也是CVPR2016的最佳论文，目前应用十分广泛，ResNet的重要性在于将网络的训练深度延伸到了数百层，而且取得了非常好的效果。在ResNet出现之前，网络结构一般在20层左右，对于一般情况，网络结构越深，模型效果就会越好，但是研究人员发现加深网络反而会使结果变差。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171743942.png\"/></p>\n<p>人脸特征提取我这里选用ResNet，网络结构如下：<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171830823.png\"/></p>\n<h2><a id=\"34__85\"></a>3.4 总体实现流程</h2>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127172202894.png\"/></p>\n<h1><a id=\"4__89\"></a>4 具体实现</h1>\n<h2><a id=\"41__91\"></a>4.1 预训练数据格式</h2>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171937980.png\"/></p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\20210127171943192.png\"/></p>\n<h2><a id=\"42__97\"></a>4.2 部分实现代码</h2>\n<p>训练部分代码：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> absolute_import\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> division\n<span class=\"token keyword\">from</span> __future__ <span class=\"token keyword\">import</span> print_function\n\n<span class=\"token keyword\">from</span> six<span class=\"token punctuation\">.</span>moves <span class=\"token keyword\">import</span> <span class=\"token builtin\">xrange</span>\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">from</span> data <span class=\"token keyword\">import</span> distorted_inputs\n<span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> select_model\n<span class=\"token keyword\">import</span> json\n<span class=\"token keyword\">import</span> re\n\n\nLAMBDA <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span>\nMOM <span class=\"token operator\">=</span> <span class=\"token number\">0.9</span>\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'pre_checkpoint_path'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token triple-quoted-string string\">\"\"\"If specified, restore this pretrained model \"\"\"</span>\n                           <span class=\"token triple-quoted-string string\">\"\"\"before beginning any training.\"\"\"</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'train_dir'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'/home/dpressel/dev/work/AgeGenderDeepLearning/Folds/tf/test_fold_is_0'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Training directory'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_boolean<span class=\"token punctuation\">(</span><span class=\"token string\">'log_device_placement'</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token triple-quoted-string string\">\"\"\"Whether to log device placement.\"\"\"</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'num_preprocess_threads'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of preprocessing threads'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'optim'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Momentum'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Optimizer'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'image_size'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">227</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Image size'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'eta'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Learning rate'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'pdrop'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Dropout probability'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'max_steps'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40000</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Number of iterations'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'steps_per_decay'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of steps before learning rate decay'</span><span class=\"token punctuation\">)</span>\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_float<span class=\"token punctuation\">(</span><span class=\"token string\">'eta_decay_rate'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Learning rate decay'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Number of epochs'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_integer<span class=\"token punctuation\">(</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">'Batch size'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'checkpoint'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'checkpoint'</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">'Checkpoint name'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'model_type'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'default'</span><span class=\"token punctuation\">,</span>\n                           <span class=\"token string\">'Type of convnet'</span><span class=\"token punctuation\">)</span>\n\ntf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>DEFINE_string<span class=\"token punctuation\">(</span><span class=\"token string\">'pre_model'</span><span class=\"token punctuation\">,</span>\n                            <span class=\"token string\">''</span><span class=\"token punctuation\">,</span><span class=\"token comment\">#'./inception_v3.ckpt',</span>\n                           <span class=\"token string\">'checkpoint file'</span><span class=\"token punctuation\">)</span>\nFLAGS <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>flags<span class=\"token punctuation\">.</span>FLAGS\n\n<span class=\"token comment\"># Every 5k steps cut learning rate in half</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">exponential_staircase_decay</span><span class=\"token punctuation\">(</span>at_step<span class=\"token operator\">=</span><span class=\"token number\">10000</span><span class=\"token punctuation\">,</span> decay_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'decay [%f] every [%d] steps'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>decay_rate<span class=\"token punctuation\">,</span> at_step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_decay</span><span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>exponential_decay<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">,</span>\n                                          at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">,</span> staircase<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> _decay\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">optimizer</span><span class=\"token punctuation\">(</span>optim<span class=\"token punctuation\">,</span> eta<span class=\"token punctuation\">,</span> loss_fn<span class=\"token punctuation\">,</span> at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    global_step <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> trainable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    optz <span class=\"token operator\">=</span> optim\n    <span class=\"token keyword\">if</span> optim <span class=\"token operator\">==</span> <span class=\"token string\">'Adadelta'</span><span class=\"token punctuation\">:</span>\n        optz <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> lr<span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>AdadeltaOptimizer<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> <span class=\"token number\">0.95</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1e-6</span><span class=\"token punctuation\">)</span>\n        lr_decay_fn <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n    <span class=\"token keyword\">elif</span> optim <span class=\"token operator\">==</span> <span class=\"token string\">'Momentum'</span><span class=\"token punctuation\">:</span>\n        optz <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> lr<span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>MomentumOptimizer<span class=\"token punctuation\">(</span>lr<span class=\"token punctuation\">,</span> MOM<span class=\"token punctuation\">)</span>\n        lr_decay_fn <span class=\"token operator\">=</span> exponential_staircase_decay<span class=\"token punctuation\">(</span>at_step<span class=\"token punctuation\">,</span> decay_rate<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>contrib<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>optimize_loss<span class=\"token punctuation\">(</span>loss_fn<span class=\"token punctuation\">,</span> global_step<span class=\"token punctuation\">,</span> eta<span class=\"token punctuation\">,</span> optz<span class=\"token punctuation\">,</span> clip_gradients<span class=\"token operator\">=</span><span class=\"token number\">4.</span><span class=\"token punctuation\">,</span> learning_rate_decay_fn<span class=\"token operator\">=</span>lr_decay_fn<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">loss</span><span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>labels<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">)</span>\n    cross_entropy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>sparse_softmax_cross_entropy_with_logits<span class=\"token punctuation\">(</span>\n        logits<span class=\"token operator\">=</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token operator\">=</span>labels<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'cross_entropy_per_example'</span><span class=\"token punctuation\">)</span>\n    cross_entropy_mean <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'cross_entropy'</span><span class=\"token punctuation\">)</span>\n    tf<span class=\"token punctuation\">.</span>add_to_collection<span class=\"token punctuation\">(</span><span class=\"token string\">'losses'</span><span class=\"token punctuation\">,</span> cross_entropy_mean<span class=\"token punctuation\">)</span>\n    losses <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span><span class=\"token string\">'losses'</span><span class=\"token punctuation\">)</span>\n    regularization_losses <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>GraphKeys<span class=\"token punctuation\">.</span>REGULARIZATION_LOSSES<span class=\"token punctuation\">)</span>\n    total_loss <span class=\"token operator\">=</span> cross_entropy_mean <span class=\"token operator\">+</span> LAMBDA <span class=\"token operator\">*</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>regularization_losses<span class=\"token punctuation\">)</span>\n    tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span><span class=\"token string\">'tl (raw)'</span><span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">#total_loss = tf.add_n(losses + regularization_losses, name='total_loss')</span>\n    loss_averages <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>ExponentialMovingAverage<span class=\"token punctuation\">(</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'avg'</span><span class=\"token punctuation\">)</span>\n    loss_averages_op <span class=\"token operator\">=</span> loss_averages<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span>losses <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> losses <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>op<span class=\"token punctuation\">.</span>name <span class=\"token operator\">+</span> <span class=\"token string\">' (raw)'</span><span class=\"token punctuation\">,</span> l<span class=\"token punctuation\">)</span>\n        tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>scalar<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>op<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span> loss_averages<span class=\"token punctuation\">.</span>average<span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>control_dependencies<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>loss_averages_op<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        total_loss <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>identity<span class=\"token punctuation\">(</span>total_loss<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> total_loss\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>argv<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>Graph<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>as_default<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n        model_fn <span class=\"token operator\">=</span> select_model<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>model_type<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Open the metadata file and figure out nlabels, and size of epoch</span>\n        input_file <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> <span class=\"token string\">'md.json'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>input_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            md <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span>\n\n        images<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> distorted_inputs<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>image_size<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>num_preprocess_threads<span class=\"token punctuation\">)</span>\n        logits <span class=\"token operator\">=</span> model_fn<span class=\"token punctuation\">(</span>md<span class=\"token punctuation\">[</span><span class=\"token string\">'nlabels'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> images<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token operator\">-</span>FLAGS<span class=\"token punctuation\">.</span>pdrop<span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        total_loss <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span>\n\n        train_op <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>eta<span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>steps_per_decay<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>eta_decay_rate<span class=\"token punctuation\">)</span>\n        saver <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        summary_op <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>merge_all<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        sess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span>config<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>ConfigProto<span class=\"token punctuation\">(</span>\n            log_device_placement<span class=\"token operator\">=</span>FLAGS<span class=\"token punctuation\">.</span>log_device_placement<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>session<span class=\"token operator\">=</span>sess<span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># This is total hackland, it only works to fine-tune iv3</span>\n        <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>pre_model<span class=\"token punctuation\">:</span>\n            inception_variables <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>get_collection<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>GraphKeys<span class=\"token punctuation\">.</span>VARIABLES<span class=\"token punctuation\">,</span> scope<span class=\"token operator\">=</span><span class=\"token string\">\"InceptionV3\"</span><span class=\"token punctuation\">)</span>\n            restorer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span>inception_variables<span class=\"token punctuation\">)</span>\n            restorer<span class=\"token punctuation\">.</span>restore<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>pre_model<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>Exists<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Trying to restore checkpoint from %s'</span> <span class=\"token operator\">%</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span>\n                restorer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>latest_checkpoint<span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'%s: Pre-trained model restored from %s'</span> <span class=\"token operator\">%</span>\n                      <span class=\"token punctuation\">(</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>pre_checkpoint_path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n        run_dir <span class=\"token operator\">=</span> <span class=\"token string\">'%s/run-%d'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>FLAGS<span class=\"token punctuation\">.</span>train_dir<span class=\"token punctuation\">,</span> os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        checkpoint_path <span class=\"token operator\">=</span> <span class=\"token string\">'%s/%s'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">,</span> FLAGS<span class=\"token punctuation\">.</span>checkpoint<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>Exists<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">)</span> <span class=\"token keyword\">is</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Creating %s'</span> <span class=\"token operator\">%</span> run_dir<span class=\"token punctuation\">)</span>\n            tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>MakeDirs<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>write_graph<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">.</span>graph_def<span class=\"token punctuation\">,</span> run_dir<span class=\"token punctuation\">,</span> <span class=\"token string\">'model.pb'</span><span class=\"token punctuation\">,</span> as_text<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>start_queue_runners<span class=\"token punctuation\">(</span>sess<span class=\"token operator\">=</span>sess<span class=\"token punctuation\">)</span>\n\n\n        summary_writer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">.</span>FileWriter<span class=\"token punctuation\">(</span>run_dir<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">)</span>\n        steps_per_train_epoch <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>md<span class=\"token punctuation\">[</span><span class=\"token string\">'train_counts'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> FLAGS<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">)</span>\n        num_steps <span class=\"token operator\">=</span> FLAGS<span class=\"token punctuation\">.</span>max_steps <span class=\"token keyword\">if</span> FLAGS<span class=\"token punctuation\">.</span>epochs <span class=\"token operator\">&lt;</span> <span class=\"token number\">1</span> <span class=\"token keyword\">else</span> FLAGS<span class=\"token punctuation\">.</span>epochs <span class=\"token operator\">*</span> steps_per_train_epoch\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Requested number of steps [%d]'</span> <span class=\"token operator\">%</span> num_steps<span class=\"token punctuation\">)</span>\n\n        \n        <span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">xrange</span><span class=\"token punctuation\">(</span>num_steps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            _<span class=\"token punctuation\">,</span> loss_value <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train_op<span class=\"token punctuation\">,</span> total_loss<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            duration <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time\n\n            <span class=\"token keyword\">assert</span> <span class=\"token keyword\">not</span> np<span class=\"token punctuation\">.</span>isnan<span class=\"token punctuation\">(</span>loss_value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Model diverged with loss = NaN'</span>\n\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">10</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                num_examples_per_step <span class=\"token operator\">=</span> FLAGS<span class=\"token punctuation\">.</span>batch_size\n                examples_per_sec <span class=\"token operator\">=</span> num_examples_per_step <span class=\"token operator\">/</span> duration\n                sec_per_batch <span class=\"token operator\">=</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>duration<span class=\"token punctuation\">)</span>\n                \n                format_str <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'%s: step %d, loss = %.3f (%.1f examples/sec; %.3f '</span> <span class=\"token string\">'sec/batch)'</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>format_str <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">,</span> loss_value<span class=\"token punctuation\">,</span>\n                                    examples_per_sec<span class=\"token punctuation\">,</span> sec_per_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\"># Loss only actually evaluated every 100 steps?</span>\n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                summary_str <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>summary_op<span class=\"token punctuation\">)</span>\n                summary_writer<span class=\"token punctuation\">.</span>add_summary<span class=\"token punctuation\">(</span>summary_str<span class=\"token punctuation\">,</span> step<span class=\"token punctuation\">)</span>\n                \n            <span class=\"token keyword\">if</span> step <span class=\"token operator\">%</span> <span class=\"token number\">1000</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span> <span class=\"token keyword\">or</span> <span class=\"token punctuation\">(</span>step <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> num_steps<span class=\"token punctuation\">:</span>\n                saver<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> checkpoint_path<span class=\"token punctuation\">,</span> global_step<span class=\"token operator\">=</span>step<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    tf<span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<br/>\n<p>🧿 <strong>选题指导, 项目分享：</strong></p>\n<p><a href=\"https://blog.csdn.net/Mr_DC_IT/article/details/126460477\">https://blog.csdn.net/Mr_DC_IT/article/details/126460477</a></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-08-30 10:38:19", "summary": "文章目录前言课题描述课题意义实现效果算法实现原理数据集深度学习识别算法特征提取主干网络总体实现流程具体实现预训练数据格式部分实现代码前言，大家好，这里是丹成学长的毕设系列文章！对毕设有任何疑问都可以问"}