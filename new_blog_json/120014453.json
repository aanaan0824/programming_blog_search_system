{"blogid": "120014453", "writerAge": "码龄1年", "writerBlogNum": "30", "writerCollect": "435", "writerComment": "247", "writerFan": "1149", "writerGrade": "4级", "writerIntegral": "1354", "writerName": "小负不负", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_120014453.jpg", "writerRankTotal": "15932", "writerRankWeekly": "24644", "writerThumb": "411", "writerVisitNum": "49426", "blog_read_count": "1575", "blog_time": "于 2021-08-31 16:27:54 发布", "blog_title": "ORB_SLAM2 源码解析 ORB特征提取（二）", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"-toc\" style=\"margin-left:0px;\"></p>\n<p id=\"%E4%B8%80%E3%80%81%E5%90%84%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E5%8F%98%E9%87%8F-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%B8%80%E3%80%81%E5%90%84%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E5%8F%98%E9%87%8F\">一、各成员函数变量</a></p>\n<p id=\"1%E3%80%81%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E7%94%A8%E4%BA%8E%E8%A1%A8%E7%A4%BA%E4%BD%BF%E7%94%A8HARRIS%E5%93%8D%E5%BA%94%E5%80%BC%E8%BF%98%E6%98%AF%E4%BD%BF%E7%94%A8FAST%E5%93%8D%E5%BA%94%E5%80%BC-toc\" style=\"margin-left:40px;\"><a href=\"#1%E3%80%81%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E7%94%A8%E4%BA%8E%E8%A1%A8%E7%A4%BA%E4%BD%BF%E7%94%A8HARRIS%E5%93%8D%E5%BA%94%E5%80%BC%E8%BF%98%E6%98%AF%E4%BD%BF%E7%94%A8FAST%E5%93%8D%E5%BA%94%E5%80%BC\">1、定义一个枚举类型用于表示使用HARRIS响应值还是使用FAST响应值</a></p>\n<p id=\"2%E3%80%81%E4%B8%8B%E9%9D%A2%E7%9A%84%E8%BF%99%E4%BA%9B%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E9%83%BD%E6%98%AF%E7%94%A8%E6%9D%A5%E7%9B%B4%E6%8E%A5%E8%8E%B7%E5%8F%96%E7%B1%BB%E7%9A%84%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E7%9A%84-toc\" style=\"margin-left:40px;\"><a href=\"#2%E3%80%81%E4%B8%8B%E9%9D%A2%E7%9A%84%E8%BF%99%E4%BA%9B%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E9%83%BD%E6%98%AF%E7%94%A8%E6%9D%A5%E7%9B%B4%E6%8E%A5%E8%8E%B7%E5%8F%96%E7%B1%BB%E7%9A%84%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E7%9A%84\">2、内联函数都是用来直接获取类的成员变量的</a></p>\n<p id=\"3%E3%80%81%E4%B8%8B%E9%9D%A2%E8%BF%99%E4%BA%9B%E9%83%BD%E6%98%AF%E4%BF%9D%E6%8A%A4%E6%88%90%E5%91%98-toc\" style=\"margin-left:40px;\"><a href=\"#3%E3%80%81%E4%B8%8B%E9%9D%A2%E8%BF%99%E4%BA%9B%E9%83%BD%E6%98%AF%E4%BF%9D%E6%8A%A4%E6%88%90%E5%91%98\">3、保护成员</a></p>\n<p id=\"%E4%BA%8C%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%20computeOrientation()-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%BA%8C%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%20computeOrientation%28%29\">二、计算特征点的方向 computeOrientation()</a></p>\n<p id=\"2.1%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4-toc\" style=\"margin-left:40px;\"><a href=\"#2.1%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4\">2.1、灰度质心法算法步骤</a></p>\n<p id=\"%C2%A0%20%C2%A01%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%80%E4%B8%AA%E5%8D%8A%E5%BE%84%E4%B8%BA15%E7%9A%84%E8%BF%91%E4%BC%BC%E5%9C%86-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A0%20%C2%A01%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%80%E4%B8%AA%E5%8D%8A%E5%BE%84%E4%B8%BA15%E7%9A%84%E8%BF%91%E4%BC%BC%E5%9C%86\">   1、计算一个半径为15的近似圆</a></p>\n<p id=\"%C2%A02%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E8%A7%92%E5%BA%A6-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A02%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E8%A7%92%E5%BA%A6\"> 2、计算特征点角度</a></p>\n<p id=\"%C2%A03%E3%80%81IC_Angle%20%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A03%E3%80%81IC_Angle%20%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7\"> 3、IC_Angle 计算技巧</a></p>\n<p id=\"%C2%A04%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F-toc\" style=\"margin-left:80px;\"><a href=\"#%C2%A04%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F\"> 4、灰度质心法计算公式</a></p>\n<p id=\"5%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%EF%BC%88computeOrientation%EF%BC%89-toc\" style=\"margin-left:80px;\"><a href=\"#5%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%EF%BC%88computeOrientation%EF%BC%89\">5、计算特征点的方向（computeOrientation）</a></p>\n<p id=\"%E4%B8%89%E3%80%81FAST%E6%8F%8F%E8%BF%B0%E5%AD%90-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%B8%89%E3%80%81FAST%E6%8F%8F%E8%BF%B0%E5%AD%90\">三、FAST描述子</a></p>\n<p id=\"BRIEF%E6%8F%8F%E8%BF%B0%E5%AD%90%E7%94%9F%E6%88%90%E6%AD%A5%E9%AA%A4-toc\" style=\"margin-left:80px;\"><a href=\"#BRIEF%E6%8F%8F%E8%BF%B0%E5%AD%90%E7%94%9F%E6%88%90%E6%AD%A5%E9%AA%A4\">BRIEF描述子生成步骤</a></p>\n<p id=\"%C2%A0%E4%BA%94%E3%80%81%E9%87%91%E5%AD%97%E5%A1%94%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88ORBextractor%3A%3AComputePyramid%EF%BC%89-toc\" style=\"margin-left:0px;\"><a href=\"#%C2%A0%E4%BA%94%E3%80%81%E9%87%91%E5%AD%97%E5%A1%94%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88ORBextractor%3A%3AComputePyramid%EF%BC%89\"> 五、金字塔的计算（ORBextractor::ComputePyramid）</a></p>\n<p id=\"%C2%A0%E5%85%AD%E3%80%81%E6%8F%90%E5%8F%96FAST%E7%89%B9%E5%BE%81%E7%82%B9-toc\" style=\"margin-left:0px;\"><a href=\"#%C2%A0%E5%85%AD%E3%80%81%E6%8F%90%E5%8F%96FAST%E7%89%B9%E5%BE%81%E7%82%B9\"> 六、提取FAST特征点</a></p>\n<p id=\"6.1%E3%80%81%E5%88%86cell%E6%90%9C%E7%B4%A2%E7%89%B9%E5%BE%81%E7%82%B9-toc\" style=\"margin-left:40px;\"><a href=\"#6.1%E3%80%81%E5%88%86cell%E6%90%9C%E7%B4%A2%E7%89%B9%E5%BE%81%E7%82%B9\">6.1、分cell搜索特征点</a></p>\n<p id=\"%C2%A06.2%E3%80%81%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E7%82%B9-toc\" style=\"margin-left:40px;\"><a href=\"#%C2%A06.2%E3%80%81%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E7%82%B9\"> 6.2、提取特征点</a></p>\n<p id=\"6.3%E3%80%81%E5%9B%9B%E5%8F%89%E6%A0%91%E7%AD%9B%E9%80%89%E7%89%B9%E5%BE%81%E7%82%B9%3A%C2%A0DistributeOctTree()-toc\" style=\"margin-left:40px;\"><a href=\"#6.3%E3%80%81%E5%9B%9B%E5%8F%89%E6%A0%91%E7%AD%9B%E9%80%89%E7%89%B9%E5%BE%81%E7%82%B9%3A%C2%A0DistributeOctTree%28%29\">6.3、四叉树筛选特征点: DistributeOctTree()</a></p>\n<p id=\"6.4%E3%80%81%C2%A0%E6%9C%80%E5%90%8E%E8%AE%A1%E7%AE%97%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%E4%BF%A1%E6%81%AF-toc\" style=\"margin-left:40px;\"><a href=\"#6.4%E3%80%81%C2%A0%E6%9C%80%E5%90%8E%E8%AE%A1%E7%AE%97%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%E4%BF%A1%E6%81%AF\">6.4、 最后计算这些特征点的方向信息</a></p>\n<p id=\"%E4%B8%83%E3%80%81%E6%80%BB%E7%BB%93-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%B8%83%E3%80%81%E6%80%BB%E7%BB%93\">七、总结</a></p>\n<hr id=\"hr-toc\"/>\n<h1 id=\"%E4%B8%80%E3%80%81%E5%90%84%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E5%8F%98%E9%87%8F\">一、各成员函数变量</h1>\n<p>       在阅读代码之前我们先来介绍变量的命名规则</p>\n<h2 id=\"1%E3%80%81%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E7%94%A8%E4%BA%8E%E8%A1%A8%E7%A4%BA%E4%BD%BF%E7%94%A8HARRIS%E5%93%8D%E5%BA%94%E5%80%BC%E8%BF%98%E6%98%AF%E4%BD%BF%E7%94%A8FAST%E5%93%8D%E5%BA%94%E5%80%BC\">1、定义一个枚举类型用于表示使用HARRIS响应值还是使用FAST响应值</h2>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td> <pre><span style=\"color:#fe2c24;\">nfeatures</span></pre> </td><td> <pre>指定要提取出来的特征点数目</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">scaleFactor</span></pre> </td><td> <pre> 图像金字塔的缩放系数</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">nlevels</span></pre> </td><td> <pre> 指定需要提取特征点的图像金字塔层</pre> </td></tr><tr><td> <p><span style=\"color:#fe2c24;\"> iniThFAST</span></p> </td><td> <pre>初始的默认FAST响应值阈值\n</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\"> minThFAST  </span></pre> </td><td> <pre> 较小的FAST响应值阈值</pre> </td></tr></tbody></table>\n<h2 id=\"2%E3%80%81%E4%B8%8B%E9%9D%A2%E7%9A%84%E8%BF%99%E4%BA%9B%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E9%83%BD%E6%98%AF%E7%94%A8%E6%9D%A5%E7%9B%B4%E6%8E%A5%E8%8E%B7%E5%8F%96%E7%B1%BB%E7%9A%84%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E7%9A%84\">2、内联函数都是用来直接获取类的成员变量的</h2>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td> <pre><span style=\"color:#fe2c24;\">GetScaleFactor()</span></pre> </td><td> <pre>获取当前提取器所在的图像的缩放因子</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\"> mvScaleFactor</span></pre> </td><td> <pre> 图像金字塔中每个图层相对于底层图像的缩放因子</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">GetInverseScaleFactors()</span></pre> </td><td> <pre>获取上面的那个缩放因子s的倒数</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\"> GetScaleSigmaSquares()</span></pre> </td><td> <pre>获取sigma^2，就是每层图像相对于初始图像缩放因子的平方</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">GetInverseScaleSigmaSquares()</span></pre> </td><td> <pre>获取上面sigma平方的倒数</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\"> mvImagePyramid</span></pre> </td><td> <pre>用来存储图像金字塔的变量，一个元素存储一层图像</pre> </td></tr></tbody></table>\n<h2 id=\"3%E3%80%81%E4%B8%8B%E9%9D%A2%E8%BF%99%E4%BA%9B%E9%83%BD%E6%98%AF%E4%BF%9D%E6%8A%A4%E6%88%90%E5%91%98\">3、保护成员</h2>\n<p>   保护成员就是私有的别人不可以调用</p>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td> <pre><span style=\"color:#fe2c24;\">ComputePyramid</span></pre> </td><td> <pre>计算其图像金字塔</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">ComputeKeyPointsOctTree</span></pre> </td><td> <pre> 以八叉树分配特征点的方式，计算图像金字塔中的特征点</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">vToDistributeKeys </span></pre> </td><td> <pre> 等待分配的特征点</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">mnFeaturesPerLevel</span></pre> </td><td> <pre>分配到每层图像中，要提取的特征点数目</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">umax</span></pre> </td><td> <pre>计算特征点方向的时候，有个圆形的图像区域，这个vector中存储了每行u轴的边界（四分之一，其他部分通过对称获得）</pre> </td></tr></tbody></table>\n<h1 id=\"%E4%BA%8C%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%20computeOrientation()\">二、计算特征点的方向 computeOrientation()</h1>\n<p>        计算特征点的方向是为了使得提取的特征点具有旋转不变性</p>\n<p>        方法是<span style=\"color:#fe2c24;\">灰度质心法</span>：以几何中心和灰度质心的连线作为该特征点方向</p>\n<h2 id=\"2.1%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4\">2.1、灰度质心法算法步骤</h2>\n<h3 id=\"%C2%A0%20%C2%A01%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%80%E4%B8%AA%E5%8D%8A%E5%BE%84%E4%B8%BA15%E7%9A%84%E8%BF%91%E4%BC%BC%E5%9C%86\">   1、计算一个半径为15的近似圆</h3>\n<p><img alt=\"\" height=\"342\" src=\"..\\..\\static\\image\\20210831125311736.png\" width=\"747\"/></p>\n<p>        后面计算的是<strong>特征点主方向</strong>上的描述子,计算过程中要将特征点周围像素旋转到主方向上,因此计算一个半径为<span style=\"color:#fe2c24;\"><code>16</code></span>的圆的近似坐标,用于后面计算描述子时进行旋转操作.</p>\n<p><img alt=\"\" height=\"549\" src=\"..\\..\\static\\image\\20210831125515200.png\" width=\"689\"/></p>\n<p> </p>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td> <pre><span style=\"color:#fe2c24;\">PATCH_SIZE</span></pre> </td><td> <pre>图像块的大小,或者说是直径</pre> </td><td>31</td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">HALF_PATCH_SIZE</span></pre> </td><td> <pre>上面这个大小的一半，或者说是半径</pre> </td><td>15</td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">EDGE_THRESHOLD</span></pre> </td><td> <pre>算法生成的图像边</pre> </td><td>19</td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">u_max</span></pre> </td><td> <pre>图像块的每一行的坐标边界 </pre> </td><td></td></tr><tr><td><span style=\"color:#fe2c24;\">float</span></td><td> <pre>返回特征点的角度，范围为[0,360)角度，精度为0.3°</pre> </td><td></td></tr></tbody></table>\n<pre><code>int vmax = cvFloor(HALF_PATCH_SIZE * sqrt(2.f) / 2 + 1); \t// 45°射线与圆周交点的纵坐标\nint vmin = cvCeil(HALF_PATCH_SIZE * sqrt(2.f) / 2);\t\t\t// 45°射线与圆周交点的纵坐标\n\n// 先计算下半45度的umax\nfor (int v = 0; v &lt;= vmax; ++v) {\n\tumax[v] = cvRound(sqrt(15 * 15 - v * v));\t\n}\n\n// 根据对称性补出上半45度的umax\nfor (int v = HALF_PATCH_SIZE, v0 = 0; v &gt;= vmin; --v) {\n    while (umax[v0] == umax[v0 + 1])\n        ++v0;\n    umax[v] = v0;\n    ++v0;\n}</code></pre>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\20210516232433983.png\"/></p>\n<h3 id=\"%C2%A02%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E8%A7%92%E5%BA%A6\"> 2、计算特征点角度</h3>\n<p>点v 绕 原点旋转θ 角，得到点v’，假设 v点的坐标是(x, y) ，那么可以推导得到 v’点的坐标（x’, y’)</p>\n<p><img alt=\"\" height=\"1056\" src=\"..\\..\\static\\image\\20210831131817218.png\" width=\"1200\"/></p>\n<p> </p>\n<pre><code> float angle = (float)kpt.angle*factorPI;\n\tfloat a = (float)cos(angle), b = (float)sin(angle);\n\n\tconst uchar* center = &amp;img.at&lt;uchar&gt;(cvRound(kpt.pt.y), cvRound(kpt.pt.x));\n\tconst int step = (int)img.step;\n\n    // 旋转公式\n\t// x'= xcos(θ) - ysin(θ)\n    // y'= xsin(θ) + ycos(θ)\n\n#define GET_VALUE(idx) \\\n    center[cvRound(pattern[idx].x*b + pattern[idx].y*a)*step + cvRound(pattern[idx].x*a - pattern[idx].y*b)] </code></pre>\n<h3 id=\"%C2%A03%E3%80%81IC_Angle%20%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7\"> 3、IC_Angle 计算技巧</h3>\n<p>        在一个圆域中算出m10（x坐标）和m01（y坐标），计算步骤是先算出中间红线的m10，然后在平行于 x轴算出m10和m01，一次计算相当于图像中的同个颜色的两个line</p>\n<p><img alt=\"\" height=\"231\" src=\"..\\..\\static\\image\\20210831132335824.png\" width=\"307\"/></p>\n<h3 id=\"%C2%A04%E3%80%81%E7%81%B0%E5%BA%A6%E8%B4%A8%E5%BF%83%E6%B3%95%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F\"> 4、灰度质心法计算公式</h3>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\20210511182847555.png\"/></p>\n<p> </p>\n<pre><code>static float IC_Angle(const Mat&amp; image, Point2f pt,  const vector&lt;int&gt; &amp; u_max)\n{\n\t//图像的矩，前者是按照图像块的y坐标加权，后者是按照图像块的x坐标加权\n    int m_01 = 0, m_10 = 0;\n\t//获得这个特征点所在的图像块的中心点坐标灰度值的指针center\n    const uchar* center = &amp;image.at&lt;uchar&gt; (cvRound(pt.y), cvRound(pt.x));\n    // Treat the center line differently, v=0\n\t//这条v=0中心线的计算需要特殊对待\n    //后面是以中心行为对称轴，成对遍历行数，所以PATCH_SIZE必须是奇数\n    for (int u = -HALF_PATCH_SIZE; u &lt;= HALF_PATCH_SIZE; ++u)\n\t\t//注意这里的center下标u可以是负的！中心水平线上的像素按x坐标（也就是u坐标）加权\n        m_10 += u * center[u];\n    // Go line by line in the circular patch  \n\t//这里的step1表示这个图像一行包含的字节总数。参考[https://blog.csdn.net/qianqing13579/article/details/45318279]\n    int step = (int)image.step1();\n\t//注意这里是以v=0中心线为对称轴，然后对称地每成对的两行之间进行遍历，这样处理加快了计算速度\n    for (int v = 1; v &lt;= HALF_PATCH_SIZE; ++v)\n    {\n        // Proceed over the two lines\n\t\t//本来m_01应该是一列一列地计算的，但是由于对称以及坐标x,y正负的原因，可以一次计算两行\n        int v_sum = 0;\n\t\t// 获取某行像素横坐标的最大范围，注意这里的图像块是圆形的！\n        int d = u_max[v];\n\t\t//在坐标范围内挨个像素遍历，实际是一次遍历2个\n        // 假设每次处理的两个点坐标，中心线下方为(x,y),中心线上方为(x,-y) \n        // 对于某次待处理的两个点：m_10 = Σ x*I(x,y) =  x*I(x,y) + x*I(x,-y) = x*(I(x,y) + I(x,-y))\n        // 对于某次待处理的两个点：m_01 = Σ y*I(x,y) =  y*I(x,y) - y*I(x,-y) = y*(I(x,y) - I(x,-y))\n        for (int u = -d; u &lt;= d; ++u)\n        {\n\t\t\t//得到需要进行加运算和减运算的像素灰度值\n\t\t\t//val_plus：在中心线下方x=u时的的像素灰度值\n            //val_minus：在中心线上方x=u时的像素灰度值\n            int val_plus = center[u + v*step], val_minus = center[u - v*step];\n\t\t\t//在v（y轴）上，2行所有像素灰度值之差\n            v_sum += (val_plus - val_minus);\n\t\t\t//u轴（也就是x轴）方向上用u坐标加权和（u坐标也有正负符号），相当于同时计算两行\n            m_10 += u * (val_plus + val_minus);\n        }\n        //将这一行上的和按照y坐标加权\n        m_01 += v * v_sum;\n    }\n\n    //为了加快速度还使用了fastAtan2()函数，输出为[0,360)角度，精度为0.3°\n    return fastAtan2((float)m_01, (float)m_10);\n}\n\n///乘数因子，一度对应着多少弧度\nconst float factorPI = (float)(CV_PI/180.f);\n</code></pre>\n<h3 id=\"5%E3%80%81%E8%AE%A1%E7%AE%97%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%EF%BC%88computeOrientation%EF%BC%89\">5、计算特征点的方向（<span style=\"color:#fe2c24;\">computeOrientation</span>）</h3>\n<pre><code>static void computeOrientation(const Mat&amp; image, vector&lt;KeyPoint&gt;&amp; keypoints, const vector&lt;int&gt;&amp; umax)\n{\n\t// 遍历所有的特征点\n    for (vector&lt;KeyPoint&gt;::iterator keypoint = keypoints.begin(),\n         keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint)\n    {\n\t\t// 调用IC_Angle 函数计算这个特征点的方向\n        keypoint-&gt;angle = IC_Angle(image, \t\t\t//特征点所在的图层的图像\n\t\t\t\t\t\t\t\t   keypoint-&gt;pt, \t//特征点在这张图像中的坐标\n\t\t\t\t\t\t\t\t   umax);\t\t\t//每个特征点所在图像区块的每行的边界 u_max 组成的vector\n    }\n}</code></pre>\n<h1 id=\"%E4%B8%89%E3%80%81FAST%E6%8F%8F%E8%BF%B0%E5%AD%90\">三、FAST描述子</h1>\n<p>       <span style=\"color:#fe2c24;\"> BRIEF算法</span>的核心思想是在关键点P的周围以一定模式选取N个点对，把这N个点对的比较结果组合起来作为描述子。</p>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\5f2dc86c24eeebad23ee18eecc5b33a7.png\"/></p>\n<h3 id=\"BRIEF%E6%8F%8F%E8%BF%B0%E5%AD%90%E7%94%9F%E6%88%90%E6%AD%A5%E9%AA%A4\"><span style=\"color:#fe2c24;\">BRIEF描述子生成步骤</span></h3>\n<p>1.以关键点P为圆心，以d为半径做圆O。<br/> 2.在圆O内某一模式选取N个点对。这里为方便说明，N=4，实际应用中N可以取512.<br/> 假设当前选取的4个点对如上图所示分别标记为：<br/><img alt=\"\" src=\"..\\..\\static\\image\\42e87657e8817f2cd05de1e3131fd74a.png\"/></p>\n<p> 3.定义操作T</p>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\03a419cf40a46322f3ebbe52e2fef3a5.png\"/></p>\n<p> 4.分别对已选取的点对进行T操作，将得到的结果进行组合。<br/> 假如：</p>\n<p><img alt=\"\" src=\"..\\..\\static\\image\\8a9219172cc297b354c7423f76d45623.png\"/></p>\n<p>原始的<strong>BRIEF描述子没有方向不变性</strong>，通过加入<strong>关键点的方向</strong>来计算描述子，称之为Steer BRIEF，具有较好旋转不变特性</p>\n<p>具体地，在计算的时候需要将这里选取的采样模板中点的<strong>x轴方向旋转到特征点</strong>的方向。</p>\n<p>获得采样点中某个idx所对应的点的<strong>灰度值</strong>,这里旋转前坐标为(x,y), 旋转后坐标(x',y')，他们的变换关系:</p>\n<p><span style=\"color:#fe2c24;\"> x'= xcos(θ) - ysin(θ), y'= xsin(θ) + ycos(θ)</span></p>\n<p>下面表示 y'* step + x'</p>\n<pre><code>#define GET_VALUE(idx) center[cvRound(pattern[idx].x*b + pattern[idx].y*a)*step + cvRound(pattern[idx].x*a - pattern[idx].y*b)]        \n    //brief描述子由32*8位组成\n\t//其中每一位是来自于两个像素点灰度的直接比较，所以每比较出8bit结果，需要16个随机点，这也就是为什么pattern需要+=16的原因\nfor (int i = 0; i &lt; 32; ++i, pattern += 16)\n{\n\t\t\n        int t0, \t//参与比较的第1个特征点的灰度值\n\t\t\tt1,\t\t//参与比较的第2个特征点的灰度值\t\t\n\t\t\tval;\t//描述子这个字节的比较结果，0或1\n\t\t\n        t0 = GET_VALUE(0); t1 = GET_VALUE(1);\n        val = t0 &lt; t1;\t\t\t\t\t\t\t//描述子本字节的bit0\n        t0 = GET_VALUE(2); t1 = GET_VALUE(3);\n        val |= (t0 &lt; t1) &lt;&lt; 1;\t\t\t\t\t//描述子本字节的bit1\n        t0 = GET_VALUE(4); t1 = GET_VALUE(5);\n        val |= (t0 &lt; t1) &lt;&lt; 2;\t                //描述子本字节的bit2\n        t0 = GET_VALUE(6); t1 = GET_VALUE(7);\n        val |= (t0 &lt; t1) &lt;&lt; 3;\t\t\t\t\t//描述子本字节的bit3\n        t0 = GET_VALUE(8); t1 = GET_VALUE(9);\n        val |= (t0 &lt; t1) &lt;&lt; 4;\t\t\t\t\t//描述子本字节的bit4\n        t0 = GET_VALUE(10); t1 = GET_VALUE(11);\n        val |= (t0 &lt; t1) &lt;&lt; 5;\t\t\t\t\t//描述子本字节的bit5\n        t0 = GET_VALUE(12); t1 = GET_VALUE(13);\n        val |= (t0 &lt; t1) &lt;&lt; 6;\t\t\t\t\t//描述子本字节的bit6\n        t0 = GET_VALUE(14); t1 = GET_VALUE(15);\n        val |= (t0 &lt; t1) &lt;&lt; 7;\t\t\t\t\t//描述子本字节的bit7\n\n        //保存当前比较的出来的描述子的这个字节\n        desc[i] = (uchar)val;\n    }\n\n    //为了避免和程序中的其他部分冲突在，在使用完成之后就取消这个宏定义\n    #undef GET_VALUE\n}</code></pre>\n<h1 id=\"%C2%A0%E4%BA%94%E3%80%81%E9%87%91%E5%AD%97%E5%A1%94%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88ORBextractor%3A%3AComputePyramid%EF%BC%89\"> 五、金字塔的计算（<span style=\"color:#fe2c24;\">ORBextractor::ComputePyramid</span>）</h1>\n<p>金字塔是为了实现尺度不变性</p>\n<p><img alt=\"\" height=\"784\" src=\"..\\..\\static\\image\\20210831143011817.png\" width=\"1200\"/></p>\n<p>        具体实现方式如上图所示，当摄像机靠近图像，特征点变大，能提取的特征点变少；当摄像机远离图像时特征点变小，能提取到的特征点变多。我们可以观察到摄像机在正常位置时，第0层的特征点与摄像机往前移动第1层的特征点差不多大，利用这个特性我们可以实现尺度不变性。</p>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td> <pre><span style=\"color:#fe2c24;\">iniThFAST</span></pre> </td><td> <pre>指定初始的FAST特征点提取参数，可以提取出最明显的角点</pre> </td></tr><tr><td> <pre><span style=\"color:#fe2c24;\">minThFAST</span></pre> </td><td> <pre>如果初始阈值没有检测到角点，降低到这个阈值提取出弱一点的角点</pre> </td></tr></tbody></table>\n<p></p>\n<p></p>\n<pre><code>ORBextractor::ORBextractor(int _nfeatures,\t\t//指定要提取的特征点数目\n\t\t\t\t\t\t   float _scaleFactor,\t//指定图像金字塔的缩放系数\n\t\t\t\t\t\t   int _nlevels,\t\t//指定图像金字塔的层数\n\t\t\t\t\t\t   int _iniThFAST,\t\t//指定初始的FAST特征点提取参数，可以提取出最明显的角点\n\t\t\t\t\t\t   int _minThFAST):\t\t//如果初始阈值没有检测到角点，降低到这个阈值提取出弱一点的角点\n    nfeatures(_nfeatures), scaleFactor(_scaleFactor), nlevels(_nlevels),\n    iniThFAST(_iniThFAST), minThFAST(_minThFAST)//设置这些参数\n{\n\t//存储每层图像缩放系数的vector调整为符合图层数目的大小\n    mvScaleFactor.resize(nlevels);  \n\t//存储这个sigma^2，其实就是每层图像相对初始图像缩放因子的平方\n    mvLevelSigma2.resize(nlevels);\n\t//对于初始图像，这两个参数都是1\n    mvScaleFactor[0]=1.0f;\n    mvLevelSigma2[0]=1.0f;</code></pre>\n<p>        函数<span style=\"color:#fe2c24;\">void ORBextractor::ComputePyramid(cv::Mat image)</span>逐层计算图像金字塔,对于每层图像进行以下两步:</p>\n<p>1、先进行图片缩放,缩放到<span style=\"color:#fe2c24;\">mvInvScaleFactor</span>对应尺寸.<br/> 2、在图像外补一圈厚度为19的<span style=\"color:#fe2c24;\">padding</span>(提取FAST特征点需要特征点<span style=\"color:#fe2c24;\">周围半径为3的圆域</span>,计算ORB描述子需要特征点<span style=\"color:#fe2c24;\">周围半径为16的圆域</span>).<br/> 下图表示图像金字塔每层结构:</p>\n<p><span style=\"color:#a5a5a5;\">深灰色</span>为缩放后的原始图像.<br/> 包含<span style=\"color:#1c7331;\">绿色</span>边界在内的矩形用于提取FAST特征点.<br/> 包含<span style=\"color:#f3f3f4;\">浅灰色</span>边界在内的整个矩形用于计算ORB描述子.<br/><img alt=\"\" height=\"809\" src=\"..\\..\\static\\image\\20210831150221624.png\" width=\"1096\"/></p>\n<p> </p>\n<pre><code>//计算这层图像的坐标边界， NOTICE 注意这里是坐标边界，EDGE_THRESHOLD指的应该是可以提取特征点的有效图像边界，后面会一直使用“有效图像边界“这个自创名词\n        const int minBorderX = EDGE_THRESHOLD-3;\t\t\t//这里的3是因为在计算FAST特征点的时候，需要建立一个半径为3的圆\n        const int minBorderY = minBorderX;\t\t\t\t\t//minY的计算就可以直接拷贝上面的计算结果了\n        const int maxBorderX = mvImagePyramid[level].cols-EDGE_THRESHOLD+3;\n        const int maxBorderY = mvImagePyramid[level].rows-EDGE_THRESHOLD+3;\n\n\nvoid ORBextractor::ComputePyramid(cv::Mat image) {\n    for (int level = 0; level &lt; nlevels; ++level) {\n        // 计算缩放+补padding后该层图像的尺寸\n        float scale = mvInvScaleFactor[level];\n        Size sz(cvRound((float)image.cols*scale), cvRound((float)image.rows*scale));\n        Size wholeSize(sz.width + EDGE_THRESHOLD * 2, sz.height + EDGE_THRESHOLD * 2);\n        Mat temp(wholeSize, image.type());\n        \n\t\t// 缩放图像并复制到对应图层并补边\n        mvImagePyramid[level] = temp(Rect(EDGE_THRESHOLD, EDGE_THRESHOLD, sz.width, sz.height));\n        if( level != 0 ) {\n            resize(mvImagePyramid[level-1], mvImagePyramid[level], sz, 0, 0, cv::INTER_LINEAR);\n            copyMakeBorder(mvImagePyramid[level], temp, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, \n                           BORDER_REFLECT_101+BORDER_ISOLATED);            \n        } else {\n            copyMakeBorder(image, temp, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, \n                           BORDER_REFLECT_101);            \n        }\n    }\n}</code></pre>\n<p><strong><span style=\"color:#fe2c24;\"><code>opyMakeBorder</code></span>函数实现了复制和<code>padding</code>填充,其参数<span style=\"color:#fe2c24;\"><code>BORDER_REFLECT_101</code></span>参数指定对padding进行镜像填充</strong></p>\n<p><img alt=\"\" height=\"837\" src=\"..\\..\\static\\image\\20210831150823350.png\" width=\"806\"/></p>\n<h1 id=\"%C2%A0%E5%85%AD%E3%80%81%E6%8F%90%E5%8F%96FAST%E7%89%B9%E5%BE%81%E7%82%B9\"> 六、提取FAST特征点</h1>\n<p><img alt=\"\" height=\"447\" src=\"..\\..\\static\\image\\20210831151219500.png\" width=\"1200\"/></p>\n<h2 id=\"6.1%E3%80%81%E5%88%86cell%E6%90%9C%E7%B4%A2%E7%89%B9%E5%BE%81%E7%82%B9\">6.1、分cell搜索特征点</h2>\n<p>分<span style=\"color:#fe2c24;\"><code>CELL</code></span>搜索特征点,若某<code>CELL</code>内特征点响应值普遍较小的话就降低分数线再搜索一遍.</p>\n<p><code>CELL</code>搜索的示意图如下,每个<code>CELL</code>的大小约为<span style=\"color:#fe2c24;\"><code>30✖30</code></span>,搜索到边上,剩余尺寸不够大的时候,最后一个<code>CELL</code><span style=\"color:#fe2c24;\">有多大就用多大的区域.</span></p>\n<p><img alt=\"\" height=\"728\" src=\"..\\..\\static\\image\\2021083115135662.png\" width=\"1059\"/></p>\n<p>        需要注意的是相邻的<code>CELL</code>之间会有<code>6</code>像素的重叠区域,因为提取<code>FAST</code>特征点需要计算特征点周围半径为<code>3</code>的圆周上的像素点信息,实际上产生特征点的区域比传入的搜索区域小<code>3</code>像素.</p>\n<p><img alt=\"\" height=\"358\" src=\"..\\..\\static\\image\\20210831151446659.png\" width=\"911\"/></p>\n<pre><code>//遍历所有图像\n    for (int level = 0; level &lt; nlevels; ++level)\n    {\n\t\t//计算这层图像的坐标边界， NOTICE 注意这里是坐标边界，EDGE_THRESHOLD指的应该是可以提取特征点的有效图像边界，后面会一直使用“有效图像边界“这个自创名词\n        const int minBorderX = EDGE_THRESHOLD-3;\t\t\t//这里的3是因为在计算FAST特征点的时候，需要建立一个半径为3的圆\n        const int minBorderY = minBorderX;\t\t\t\t\t//minY的计算就可以直接拷贝上面的计算结果了\n        const int maxBorderX = mvImagePyramid[level].cols-EDGE_THRESHOLD+3;\n        const int maxBorderY = mvImagePyramid[level].rows-EDGE_THRESHOLD+3;\n\n\t\t//存储需要进行平均分配的特征点\n        vector&lt;cv::KeyPoint&gt; vToDistributeKeys;\n\t\t//一般地都是过量采集，所以这里预分配的空间大小是nfeatures*10\n        vToDistributeKeys.reserve(nfeatures*10);\n\n\t\t//计算进行特征点提取的图像区域尺寸\n        const float width = (maxBorderX-minBorderX);\n        const float height = (maxBorderY-minBorderY);\n\n\t\t//计算网格在当前层的图像有的行数和列数\n        const int nCols = width/W;\n        const int nRows = height/W;\n\t\t//计算每个图像网格所占的像素行数和列数\n        const int wCell = ceil(width/nCols);\n        const int hCell = ceil(height/nRows);\n\n\t\t//开始遍历图像网格，还是以行开始遍历的\n        for(int i=0; i&lt;nRows; i++)\n        {\n\t\t\t//计算当前网格初始行坐标\n            const float iniY =minBorderY+i*hCell;\n\t\t\t//计算当前网格最大的行坐标，这里的+6=+3+3，即考虑到了多出来3是为了cell边界像素进行FAST特征点提取用\n\t\t\t//前面的EDGE_THRESHOLD指的应该是提取后的特征点所在的边界，所以minBorderY是考虑了计算半径时候的图像边界\n\t\t\t//目测一个图像网格的大小是25*25啊\n            float maxY = iniY+hCell+6;\n\n\t\t\t//如果初始的行坐标就已经超过了有效的图像边界了，这里的“有效图像”是指原始的、可以提取FAST特征点的图像区域\n            if(iniY&gt;=maxBorderY-3)\n\t\t\t\t//那么就跳过这一行\n                continue;\n\t\t\t//如果图像的大小导致不能够正好划分出来整齐的图像网格，那么就要委屈最后一行了\n            if(maxY&gt;maxBorderY)\n                maxY = maxBorderY;\n\n\t\t\t//开始列的遍历\n            for(int j=0; j&lt;nCols; j++)\n            {\n\t\t\t\t//计算初始的列坐标\n                const float iniX =minBorderX+j*wCell;\n\t\t\t\t//计算这列网格的最大列坐标，+6的含义和前面相同\n                float maxX = iniX+wCell+6;\n\t\t\t\t//判断坐标是否在图像中\n\t\t\t\t//如果初始的列坐标就已经超过了有效的图像边界了，这里的“有效图像”是指原始的、可以提取FAST特征点的图像区域。\n                //并且应该同前面行坐标的边界对应，都为-3\n\t\t\t\t//!BUG  正确应该是maxBorderX-3\n                if(iniX&gt;=maxBorderX-6)\n                    continue;\n\t\t\t\t//如果最大坐标越界那么委屈一下\n                if(maxX&gt;maxBorderX)\n                    maxX = maxBorderX;\n</code></pre>\n<pre>这里指的应该是FAST角点可以存在的坐标位置范围，其实就是原始图像的坐标范围\n注意这里没有提前进行+3的操作，而是在后面计算每个网格的区域的时候使用-3的操作来处理FAST角点半径问题\n本质上和前面的思想是一样的</pre>\n<pre><code>//计算这个容许坐标区域的宽度和高度\n        const int W = maxBorderX - minBorderX;\n        const int H = maxBorderY - minBorderY;\n\t\t//同时计算每个图像cell的宽度和高度\n        const int cellW = ceil((float)W/levelCols);\n        const int cellH = ceil((float)H/levelRows);\n\n\t\t//计算本层图像中的总cell个数\n        const int nCells = levelRows*levelCols;\n\t\t//ceil:返回大于或者等于表达式的最小整数，向上取整\n\t\t//这里计算了每个cell中需要提取出来的特征点数量，由于存在小数取整问题，所以都是往多了取整\n        const int nfeaturesCell = ceil((float)nDesiredFeatures/nCells);\n</code></pre>\n<h2 id=\"%C2%A06.2%E3%80%81%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E7%82%B9\"> 6.2、提取特征点</h2>\n<p>FAST提取兴趣点, 自适应阈值 并且这个向量存储这个<span style=\"color:#fe2c24;\">cell中</span>的特征点</p>\n<pre><code>//这个向量存储这个cell中的特征点\nvector&lt;cv::KeyPoint&gt; vKeysCell;\n//调用opencv的库函数来检测FAST角点\nFAST(mvImagePyramid[level].rowRange(iniY,maxY).colRange(iniX,maxX),\t//待检测的图像，这里就是当前遍历到的图像块\n     vKeysCell,\t\t\t//存储角点位置的容器\n     iniThFAST,\t\t\t//检测阈值\n     true);\t\t\t\t//使能非极大值抑制\n\n//如果这个图像块中使用默认的FAST检测阈值没有能够检测到角点\nif(vKeysCell.empty())\n{\n//那么就使用更低的阈值来进行重新检测\n  FAST(mvImagePyramid[level].rowRange(iniY,maxY).colRange(iniX,maxX),\t//待检测的图像\n       vKeysCell,\t\t//存储角点位置的容器\n\t   minThFAST,\t\t//更低的检测阈值\n\t   true);\t\t\t//使能非极大值抑制\n}\n//得到的特征点的坐标，依旧是在当前图层下来讲的\n        keypoints = DistributeOctTree(vToDistributeKeys, \t\t\t//当前图层提取出来的特征点，也即是等待剔除的特征点\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//NOTICE 注意此时特征点所使用的坐标都是在“半径扩充图像”下的\n\t\t\t\t\t\t\t\t\t  minBorderX, maxBorderX,\t\t//当前图层图像的边界，而这里的坐标却都是在“边缘扩充图像”下的\n                                      minBorderY, maxBorderY,\n\t\t\t\t\t\t\t\t\t  mnFeaturesPerLevel[level], \t//希望保留下来的当前层图像的特征点个数\n\t\t\t\t\t\t\t\t\t  level);\t\t\t\t\t\t//当前层图像所在的图层\n//PATCH_SIZE是对于底层的初始图像来说的，现在要根据当前图层的尺度缩放倍数进行缩放得到缩放后的PATCH大小 和特征点的方向计算有关\n        const int scaledPatchSize = PATCH_SIZE*mvScaleFactor[level];\n\n        // Add border to coordinates and scale information\n\t\t//获取剔除过程后保留下来的特征点数目\n        const int nkps = keypoints.size();\n\t\t//然后开始遍历这些特征点，恢复其在当前图层图像坐标系下的坐标\n        for(int i=0; i&lt;nkps ; i++)\n        {\n\t\t\t//对每一个保留下来的特征点，恢复到相对于当前图层“边缘扩充图像下”的坐标系的坐标\n            keypoints[i].pt.x+=minBorderX;\n            keypoints[i].pt.y+=minBorderY;\n\t\t\t//记录特征点来源的图像金字塔图层\n            keypoints[i].octave=level;\n\t\t\t//记录计算方向的patch，缩放后对应的大小， 又被称作为特征点半径\n            keypoints[i].size = scaledPatchSize;\n        }\n    }\n\n    // compute orientations\n    //然后计算这些特征点的方向信息，注意这里还是分层计算的\n    for (int level = 0; level &lt; nlevels; ++level)\n        computeOrientation(mvImagePyramid[level],\t//对应的图层的图像\n\t\t\t\t\t\t   allKeypoints[level], \t//这个图层中提取并保留下来的特征点容器\n\t\t\t\t\t\t   umax);\t\t\t\t\t//以及PATCH的横坐标边界\n}</code></pre>\n<h2 id=\"6.3%E3%80%81%E5%9B%9B%E5%8F%89%E6%A0%91%E7%AD%9B%E9%80%89%E7%89%B9%E5%BE%81%E7%82%B9%3A%C2%A0DistributeOctTree()\">6.3、四叉树筛选特征点<span style=\"color:#fe2c24;\">: <code>DistributeOctTree()</code></span></h2>\n<p><span style=\"color:#000000;font-family:Consolas, Inconsolata, Courier, monospace;font-size:14px;\">将提取器节点分成4个子节点，同时也完成图像区域的划分、特征点归属的划分，以及相关标志位的置位</span></p>\n<p><img alt=\"\" height=\"674\" src=\"..\\..\\static\\image\\20210831152800891.png\" width=\"1186\"/></p>\n<pre><code>void ExtractorNode::DivideNode(ExtractorNode &amp;n1, \t\n\t\t\t\t\t\t\t   ExtractorNode &amp;n2, \n\t\t\t\t\t\t\t   ExtractorNode &amp;n3, \n\t\t\t\t\t\t\t   ExtractorNode &amp;n4)\n{\n\t//得到当前提取器节点所在图像区域的一半长宽，当然结果需要取整\n    const int halfX = ceil(static_cast&lt;float&gt;(UR.x-UL.x)/2);\n    const int halfY = ceil(static_cast&lt;float&gt;(BR.y-UL.y)/2);\n\n    //Define boundaries of childs\n\t//下面的操作大同小异，将一个图像区域再细分成为四个小图像区块\n    //n1 存储左上区域的边界\n    n1.UL = UL;\n    n1.UR = cv::Point2i(UL.x+halfX,UL.y);\n    n1.BL = cv::Point2i(UL.x,UL.y+halfY);\n    n1.BR = cv::Point2i(UL.x+halfX,UL.y+halfY);\n\t//用来存储在该节点对应的图像网格中提取出来的特征点的vector\n    n1.vKeys.reserve(vKeys.size());\n\n    //n2 存储右上区域的边界\n    n2.UL = n1.UR;\n    n2.UR = UR;\n    n2.BL = n1.BR;\n    n2.BR = cv::Point2i(UR.x,UL.y+halfY);\n    n2.vKeys.reserve(vKeys.size());\n\n    //n3 存储左下区域的边界\n    n3.UL = n1.BL;\n    n3.UR = n1.BR;\n    n3.BL = BL;\n    n3.BR = cv::Point2i(n1.BR.x,BL.y);\n    n3.vKeys.reserve(vKeys.size());\n\n    //n4 存储右下区域的边界\n    n4.UL = n3.UR;\n    n4.UR = n2.BR;\n    n4.BL = n3.BR;\n    n4.BR = BR;\n    n4.vKeys.reserve(vKeys.size());\n //Associate points to childs\n\t//遍历当前提取器节点的vkeys中存储的特征点\n    for(size_t i=0;i&lt;vKeys.size();i++)\n    {\n\t\t//获取这个特征点对象\n        const cv::KeyPoint &amp;kp = vKeys[i];\n\t\t//判断这个特征点在当前特征点提取器节点图像的哪个区域，更严格地说是属于那个子图像区块\n\t\t//然后就将这个特征点追加到那个特征点提取器节点的vkeys中\n\t\t//NOTICE BUG REVIEW 这里也是直接进行比较的，但是特征点的坐标是在“半径扩充图像”坐标系下的，而节点区域的坐标则是在“边缘扩充图像”坐标系下的\n        if(kp.pt.x&lt;n1.UR.x)\n        {\n            if(kp.pt.y&lt;n1.BR.y)\n                n1.vKeys.push_back(kp);\n            else\n                n3.vKeys.push_back(kp);\n        }\n        else if(kp.pt.y&lt;n1.BR.y)\n            n2.vKeys.push_back(kp);\n        else\n            n4.vKeys.push_back(kp);\n    }//遍历当前提取器节点的vkeys中存储的特征点\n</code></pre>\n<p>step1.如果图片的宽度比较宽，就先把分成左右w/h份。一般的640×480的图像开始的时候只有一个 node。</p>\n<p>step2.如果node里面的点数&gt;1，把每个node分成四个node，如果node里面的特征点为空，就不要了， 删掉。</p>\n<p>step3.新分的node的点数&gt;1，就再分裂成4个node。如此，一直分裂。</p>\n<p>step4.终止条件为：node的总数量&gt; [公式] ，或者无法再进行分裂。</p>\n<p>step5.然后从每个node里面选择一个质量最好的FAST点</p>\n<p></p>\n<p></p>\n<p><img alt=\"\" height=\"693\" src=\"..\\..\\static\\image\\20210831152303327.png\" width=\"1200\"/></p>\n<p> </p>\n<pre><code> //这里判断是否数目等于1的目的是确定这个节点还能不能再向下进行分裂\n    if(n1.vKeys.size()==1)\n        n1.bNoMore = true;\n    if(n2.vKeys.size()==1)\n        n2.bNoMore = true;\n    if(n3.vKeys.size()==1)\n        n3.bNoMore = true;\n    if(n4.vKeys.size()==1)\n        n4.bNoMore = true;</code></pre>\n<h2 id=\"6.4%E3%80%81%C2%A0%E6%9C%80%E5%90%8E%E8%AE%A1%E7%AE%97%E8%BF%99%E4%BA%9B%E7%89%B9%E5%BE%81%E7%82%B9%E7%9A%84%E6%96%B9%E5%90%91%E4%BF%A1%E6%81%AF\">6.4、 最后计算这些特征点的方向信息</h2>\n<pre><code>//遍历图像金字塔中的每个图层\n    for (int level = 0; level &lt; nlevels; ++level)\n\t\t//计算这个图层所有特征点的方向信息\n        computeOrientation(mvImagePyramid[level],\t//这个图层的图像\n\t\t\t\t\t\t   allKeypoints[level], \t//这个图层的特征点对象vector容器\n\t\t\t\t\t\t   umax);\t\t\t\t\t//patch区域的边界\n}\n\n//注意这是一个不属于任何类的全局静态函数，static修饰符限定其只能够被本文件中的函数调用\n/**\n * @brief 计算某层金字塔图像上特征点的描述子\n * \n * @param[in] image                 某层金字塔图像\n * @param[in] keypoints             特征点vector容器\n * @param[out] descriptors          描述子\n * @param[in] pattern               计算描述子使用的固定随机点集\n */\nstatic void computeDescriptors(const Mat&amp; image, vector&lt;KeyPoint&gt;&amp; keypoints, Mat&amp; descriptors,\n                               const vector&lt;Point&gt;&amp; pattern)\n{\n\t//清空保存描述子信息的容器\n    descriptors = Mat::zeros((int)keypoints.size(), 32, CV_8UC1);\n\n\t//开始遍历特征点\n    for (size_t i = 0; i &lt; keypoints.size(); i++)\n\t\t//计算这个特征点的描述子\n        computeOrbDescriptor(keypoints[i], \t\t\t\t//要计算描述子的特征点\n\t\t\t\t\t\t\t image, \t\t\t\t\t//以及其图像\n\t\t\t\t\t\t\t &amp;pattern[0], \t\t\t\t//随机点集的首地址\n\t\t\t\t\t\t\t descriptors.ptr((int)i));\t//提取出来的描述子的保存位置\n}\n</code></pre>\n<h1 id=\"%E4%B8%83%E3%80%81%E6%80%BB%E7%BB%93\">七、总结</h1>\n<pre><code>void ORBextractor::operator()( InputArray _image, InputArray _mask, vector&lt;KeyPoint&gt;&amp; _keypoints,\n                      OutputArray _descriptors)\n{ \n\t// Step 1 检查图像有效性。如果图像为空，那么就直接返回\n    if(_image.empty())\n        return;\n\n\t//获取图像的大小\n    Mat image = _image.getMat();\n\t//判断图像的格式是否正确，要求是单通道灰度值\n    assert(image.type() == CV_8UC1 );\n\n    // Pre-compute the scale pyramid\n    // Step 2 构建图像金字塔\n    ComputePyramid(image);\n\n    // Step 3 计算图像的特征点，并且将特征点进行均匀化。均匀的特征点可以提高位姿计算精度\n\t// 存储所有的特征点，注意此处为二维的vector，第一维存储的是金字塔的层数，第二维存储的是那一层金字塔图像里提取的所有特征点\n    vector &lt; vector&lt;KeyPoint&gt; &gt; allKeypoints; \n    //使用四叉树的方式计算每层图像的特征点并进行分配\n    ComputeKeyPointsOctTree(allKeypoints);\n\n\t//使用传统的方法提取并平均分配图像的特征点，作者并未使用\n    //ComputeKeyPointsOld(allKeypoints);\n\n\t\n\t// Step 4 拷贝图像描述子到新的矩阵descriptors\n    Mat descriptors;\n\n\t//统计整个图像金字塔中的特征点\n    int nkeypoints = 0;\n\t//开始遍历每层图像金字塔，并且累加每层的特征点个数\n    for (int level = 0; level &lt; nlevels; ++level)\n        nkeypoints += (int)allKeypoints[level].size();\n\t\n\t//如果本图像金字塔中没有任何的特征点\n    if( nkeypoints == 0 )\n\t\t//通过调用cv::mat类的.realse方法，强制清空矩阵的引用计数，这样就可以强制释放矩阵的数据了\n\t\t//参考[https://blog.csdn.net/giantchen547792075/article/details/9107877]\n        _descriptors.release();\n    else\n    {\n\t\t//如果图像金字塔中有特征点，那么就创建这个存储描述子的矩阵，注意这个矩阵是存储整个图像金字塔中特征点的描述子的\n        _descriptors.create(nkeypoints,\t\t//矩阵的行数，对应为特征点的总个数\n\t\t\t\t\t\t\t32, \t\t\t//矩阵的列数，对应为使用32*8=256位描述子\n\t\t\t\t\t\t\tCV_8U);\t\t\t//矩阵元素的格式\n\t\t//获取这个描述子的矩阵信息\n\t\t// ?为什么不是直接在参数_descriptors上对矩阵内容进行修改，而是重新新建了一个变量，复制矩阵后，在这个新建变量的基础上进行修改？\n        descriptors = _descriptors.getMat();\n    }\n\n    //清空用作返回特征点提取结果的vector容器\n    _keypoints.clear();\n\t//并预分配正确大小的空间\n    _keypoints.reserve(nkeypoints);\n\n\t//因为遍历是一层一层进行的，但是描述子那个矩阵是存储整个图像金字塔中特征点的描述子，所以在这里设置了Offset变量来保存“寻址”时的偏移量，\n\t//辅助进行在总描述子mat中的定位\n    int offset = 0;\n\t//开始遍历每一层图像\n    for (int level = 0; level &lt; nlevels; ++level)\n    {\n\t\t//获取在allKeypoints中当前层特征点容器的句柄\n        vector&lt;KeyPoint&gt;&amp; keypoints = allKeypoints[level];\n\t\t//本层的特征点数\n        int nkeypointsLevel = (int)keypoints.size();\n\n\t\t//如果特征点数目为0，跳出本次循环，继续下一层金字塔\n        if(nkeypointsLevel==0)\n            continue;\n\n        // preprocess the resized image \n        //  Step 5 对图像进行高斯模糊\n\t\t// 深拷贝当前金字塔所在层级的图像\n        Mat workingMat = mvImagePyramid[level].clone();\n\n\t\t// 注意：提取特征点的时候，使用的是清晰的原图像；这里计算描述子的时候，为了避免图像噪声的影响，使用了高斯模糊\n        GaussianBlur(workingMat, \t\t//源图像\n\t\t\t\t\t workingMat, \t\t//输出图像\n\t\t\t\t\t Size(7, 7), \t\t//高斯滤波器kernel大小，必须为正的奇数\n\t\t\t\t\t 2, \t\t\t\t//高斯滤波在x方向的标准差\n\t\t\t\t\t 2, \t\t\t\t//高斯滤波在y方向的标准差\n\t\t\t\t\t BORDER_REFLECT_101);//边缘拓展点插值类型\n\n        // Compute the descriptors 计算描述子\n\t\t// desc存储当前图层的描述子\n        Mat desc = descriptors.rowRange(offset, offset + nkeypointsLevel);\n\t\t// Step 6 计算高斯模糊后图像的描述子\n        computeDescriptors(workingMat, \t//高斯模糊之后的图层图像\n\t\t\t\t\t\t   keypoints, \t//当前图层中的特征点集合\n\t\t\t\t\t\t   desc, \t\t//存储计算之后的描述子\n\t\t\t\t\t\t   pattern);\t//随机采样模板\n\n\t\t// 更新偏移量的值 \n        offset += nkeypointsLevel;\n\n        // Scale keypoint coordinates\n\t\t// Step 6 对非第0层图像中的特征点的坐标恢复到第0层图像（原图像）的坐标系下\n        // ? 得到所有层特征点在第0层里的坐标放到_keypoints里面\n\t\t// 对于第0层的图像特征点，他们的坐标就不需要再进行恢复了\n        if (level != 0)\n        {\n\t\t\t// 获取当前图层上的缩放系数\n            float scale = mvScaleFactor[level];\n            // 遍历本层所有的特征点\n            for (vector&lt;KeyPoint&gt;::iterator keypoint = keypoints.begin(),\n                 keypointEnd = keypoints.end(); keypoint != keypointEnd; ++keypoint)\n\t\t\t\t// 特征点本身直接乘缩放倍数就可以了\n                keypoint-&gt;pt *= scale;\n        }\n        \n        // And add the keypoints to the output\n        // 将keypoints中内容插入到_keypoints 的末尾\n        // keypoint其实是对allkeypoints中每层图像中特征点的引用，这样allkeypoints中的所有特征点在这里被转存到输出的_keypoints\n        _keypoints.insert(_keypoints.end(), keypoints.begin(), keypoints.end());\n    }\n}\n\n</code></pre>\n<p>参考文献：</p>\n<p>ORB_SLAM2源码解析</p>\n</div>\n</div>", "first_tag": "Others", "cpp": 0, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2021-08-31 16:27:54", "summary": "目录一、各成员函数变量、定义一个枚举类型用于表示使用响应值还是使用响应值、内联函数都是用来直接获取类的成员变量的、保护成员二、计算特征点的方向、灰度质心法算法步骤、计算一个半径为的近似圆、计算特征点角"}