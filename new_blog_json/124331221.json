{"blogid": "124331221", "writerAge": "码龄14年", "writerBlogNum": "179", "writerCollect": "752", "writerComment": "226", "writerFan": "7282", "writerGrade": "5级", "writerIntegral": "2656", "writerName": "扫地的小何尚", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_124331221.jpg", "writerRankTotal": "6784", "writerRankWeekly": "749", "writerThumb": "474", "writerVisitNum": "212452", "blog_read_count": "9255", "blog_time": "已于 2022-05-26 14:21:10 修改", "blog_title": "最新CUDA环境配置(Win10 + CUDA 11.6 + VS2019)", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-light\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h1><a id=\"CUDAWin10__CUDA_116__VS2019_0\"></a>最新CUDA环境配置(Win10 + CUDA 11.6 + VS2019)</h1>\n<p>本篇博客根据NVIDIA 官方文档所述, 并根据自己实践得出. 供各位需要的朋友参考.</p>\n<h2><a id=\"1_4\"></a>1.前言</h2>\n<p>本篇文章的软件环境为:</p>\n<ul><li>Windows 10</li><li>CUDA 11.6</li><li>VS2019</li></ul>\n<p>CUDA是目前做人工智能, 深度学习等方向的必备工具库. 由CUDA衍生出的加速工具很多, 如: cuDNN, TensorRT, cuBLAS等HPC加速库, 或者涉及最新的元宇宙概念中的Omniverse等.</p>\n<p>在很多时候, 非常多的NVIDIA加速库的底层加速方案都是CUDA. 我们可能在绝大多数时候不会直接利用CUDA写代码, 但是了解CUDA如何运转或者基本概念一定能让你如虎添翼.</p>\n<p>如果大家感兴趣也可以查看本人翻译的官方的CUDA编程手册,希望能帮到大家.<br/> <a href=\"https://blog.csdn.net/kunhe0512/category_11774233.html\">https://blog.csdn.net/kunhe0512/category_11774233.html</a></p>\n<h2><a id=\"2VS_2019_17\"></a>2.VS 2019</h2>\n<p>对于VS, 我用的其实极少. 本人从一开始就被老板带进了Vim + Makefile的环境. 这里简单提一下.</p>\n<p>目前我用的是VS2019, 大家可以根据自己需要下载所需版本, 下面是链接地址.<br/> <a href=\"https://visualstudio.microsoft.com/zh-hans/vs/\">https://visualstudio.microsoft.com/zh-hans/vs/</a></p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\089c67cf98604249ab3e2d08bda60203.png\"/></p>\n<p>这里需要重点提的是, 尽量把使用C++的桌面开发选择上.后续在用CMake的时候会比较方便.</p>\n<h2><a id=\"3CUDA_29\"></a>3.CUDA下载</h2>\n<p><strong>CUDA官方安装教程:</strong> <a href=\"https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html\">https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html</a></p>\n<p><strong>CUDA Toolkit的下载:</strong> <a href=\"https://developer.nvidia.com/cuda-downloads\">https://developer.nvidia.com/cuda-downloads</a></p>\n<p>点击上述下载页面之后, 你会看到:<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\ef4455fc7e68404f9351b8446ded5bf2.png\"/></p>\n<p>你需要自己选择你的操作系统, 系统架构, 系统版本 和 安装方式.</p>\n<p>选择完成之后, 点击 <strong>Download(2.5 GB)</strong> 的按钮,就可以下载了.</p>\n<p>当然, 如果你想安装历史版本(更早期的版本), 那么也可以点击下面的<a href=\"https://developer.nvidia.com/cuda-toolkit-archive\">Archive of Previous CUDA Releases</a>来下载, 操作方法同上.</p>\n<p>下载好之后, 你就可以看到以下图标:</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\4587dc2356e7487aa6a5ae0660f38591.png\"/></p>\n<h2><a id=\"4_50\"></a>4.安装配置</h2>\n<p>双击你下载的CUDA Toolkit, 你就会看到工具包的解压路径(推荐默认).</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\cfdfa02e7d534a5faba4f4e0afd33539.png\"/></p>\n<p>解压完毕之后, 就开始安装了, 接下来点击同意并继续:<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\d5a4cd2ac3a04de69ba9081f763cd892.png\"/></p>\n<p>接下来设置安装选项, 这里推荐点击自定义(特别是第一次安装):</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\1ab10017f72e477ca6ab28e4b05865ba.png\"/></p>\n<p>然后将能选的都选上, 很多东西可能你一开始用不上(比如nsight系统), 但是当你做的越来越多, 涉及的越来越深的时候就可能会用到.<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\ad9c48d1570a429d81f62200349e942c.png\"/></p>\n<p>然后选择安装路径, 这里也推荐默认, 毕竟是底层的调用库</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\2121664f9ba948e988fc607234107579.png\"/></p>\n<p>接下来就不用你在操作了, 直到CUDA Toolkit 安装完毕.</p>\n<h2><a id=\"5_77\"></a>5.环境变量</h2>\n<p>右键点击我的电脑(此电脑) --&gt; 属性 --&gt; 高级系统设置 --&gt; 环境变量, 查看CUDA路径是否已经在系统中, 如果没有记得添加上.</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\837dd9eb32c948068e702490c60d3461.png\"/></p>\n<h2><a id=\"6CUDA_83\"></a>6.测试CUDA安装是否成功</h2>\n<p>利用(Win + R)–&gt;cmd, 打开系统终端命令行, 输入</p>\n<pre><code>nvcc -V\n</code></pre>\n<p>如果你看到如下结果, 证明你的CUDA已经安装完毕.<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\ba965185ecda4fe2b2be14f1949c94e4.png\"/></p>\n<h2><a id=\"7Visual_Studio_2019_CUDA_93\"></a>7.利用Visual Studio 2019 进行CUDA程序开发</h2>\n<p>打开已经安装好的VS 2019, 选择创建新项目:<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\b05be6490c564322acefd265a635f3f1.png\"/></p>\n<p>选择CUDA 11.xx Runtime, 这里的xx代表你的版本.</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\5f25b932318c47e9a450a3b469bfdd31.png\"/></p>\n<p>给你的CUDA程序起个名字: <em><strong>Matrix_transpose</strong></em><br/> 这里的名字随便起的, 因为我后面要写一个矩阵转置的示例,所以才用Matrix_transpose这个名字</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\563e886a0180428e8ebc3b41e8cb168c.png\"/></p>\n<p>创建之后, 你会发现里面已经有了一些代码, 那个是向量相加的示例. 你不用管他, 把kernel.cu中的代码删掉, 就可以开始你自己的开发了.</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\5f6da1e78d6148ec9c5934b8bc43f29f.png\"/></p>\n<p>你可以尝试输入一下代码, 完成一个矩阵转置的实例:</p>\n<pre><code class=\"prism language-C++\">#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include \"error.cuh\"\n\n#define TILE_DIM 32   //Don't ask me why I don't set these two values to one\n#define BLOCK_SIZE 32\n#define N 3001 // for huanhuan, you know that!\n\n__managed__ int input_M[N * N];      //input matrix &amp; GPU result\nint cpu_result[N * N];   //CPU result\n\n\n//in-place matrix transpose\n__global__ void ip_transpose(int* data)\n{\n    __shared__ int tile_s[TILE_DIM ][TILE_DIM + 1];\n    __shared__ int tile_d[TILE_DIM ][TILE_DIM + 1];\n\n    int x = blockIdx.x * TILE_DIM + threadIdx.x;\n    int y = blockIdx.y * TILE_DIM + threadIdx.y;\n\n    //Threads in the triangle below\n    if (blockIdx.y &gt; blockIdx.x) {\n        int dx = blockIdx.y * TILE_DIM + threadIdx.x;\n        int dy = blockIdx.x * TILE_DIM + threadIdx.y;\n        if (x &lt; N &amp;&amp; y &lt; N)\n        {\n            tile_s[threadIdx.y][threadIdx.x] = data[(y)*N + x];\n        }\n        if (dx &lt; N &amp;&amp; dy &lt; N)\n        {\n            tile_d[threadIdx.y][threadIdx.x] = data[(dy)*N + dx];\n        }\n\n        __syncthreads();\n        if (dx &lt; N &amp;&amp; dy &lt; N)\n        {\n            data[(dy)*N + dx] = tile_s[threadIdx.x][threadIdx.y];\n        }\n        if (x &lt; N &amp;&amp; y &lt; N)\n        {\n            data[(y)*N + x] = tile_d[threadIdx.x][threadIdx.y];\n        }\n    }\n    else if (blockIdx.y == blockIdx.x)//Threads on the diagonal\n    {\n        if (x &lt; N &amp;&amp; y &lt; N)\n        {\n            tile_s[threadIdx.y][threadIdx.x] = data[(y)*N + x];\n        }\n        __syncthreads();\n        if (x &lt; N &amp;&amp; y &lt; N)\n        {\n            data[(y)*N + x] = tile_s[threadIdx.x][threadIdx.y];\n        }\n    }\n}\n\nvoid cpu_transpose(int* A, int* B)\n{\n    for (int j = 0; j &lt; N; j++)\n    {\n        for (int i = 0; i &lt; N; i++)\n        {\n            B[i * N + j] = A[j * N + i];\n        }\n    }\n}\n\nint main(int argc, char const* argv[])\n{\n\n    cudaEvent_t start, stop_gpu;\n    CHECK(cudaEventCreate(&amp;start));\n    CHECK(cudaEventCreate(&amp;stop_gpu));\n\n\n    for (int i = 0; i &lt; N; ++i) {\n        for (int j = 0; j &lt; N; ++j) {\n            input_M[i * N + j] = rand() % 1000;\n        }\n    }\n    cpu_transpose(input_M, cpu_result);\n\n    CHECK(cudaEventRecord(start));\n    unsigned int grid_rows = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n    unsigned int grid_cols = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n    dim3 dimGrid(grid_cols, grid_rows);\n    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n    ip_transpose &lt;&lt; &lt;dimGrid, dimBlock &gt;&gt; &gt; (input_M);\n    CHECK(cudaDeviceSynchronize());\n    CHECK(cudaEventRecord(stop_gpu));\n    CHECK(cudaEventSynchronize(stop_gpu));\n\n    float elapsed_time_gpu;\n    CHECK(cudaEventElapsedTime(&amp;elapsed_time_gpu, start, stop_gpu));\n    printf(\"Time_GPU = %g ms.\\n\", elapsed_time_gpu);\n\n    CHECK(cudaEventDestroy(start));\n    CHECK(cudaEventDestroy(stop_gpu));\n\n    int ok = 1;\n    for (int i = 0; i &lt; N; ++i)\n    {\n        for (int j = 0; j &lt; N; ++j)\n        {\n            if (fabs(input_M[i * N + j] - cpu_result[i * N + j]) &gt; (1.0e-10))\n            {\n                ok = 0;\n            }\n        }\n    }\n\n\n    if (ok)\n    {\n        printf(\"Pass!!!\\n\");\n    }\n    else\n    {\n        printf(\"Error!!!\\n\");\n    }\n\n    return 0;\n}\n</code></pre>\n<p>点击运行之后, 你就可以看到如下结果:</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\a51bfe6fb507474a9e84c137fc11ecf5.png\"/></p>\n<p>OK, 到这里你就完成了CUDA环境的搭建, 并且写了第一个CUDA程序</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "C++", "cpp": 1, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-05-26 14:21:10", "summary": "最新环境配置本篇博客根据官方文档所述并根据自己实践得出供各位需要的朋友参考前言本篇文章的软件环境为是目前做人工智能深度学习等方向的必备工具库由衍生出的加速工具很多如等加速库或者涉及最新的元宇宙概念中的"}