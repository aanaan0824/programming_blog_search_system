{"blogid": "126658002", "writerAge": "码龄1年", "writerBlogNum": "66", "writerCollect": "184", "writerComment": "21", "writerFan": "619", "writerGrade": "4级", "writerIntegral": "817", "writerName": "夏天是冰红茶", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126658002.jpg", "writerRankTotal": "22818", "writerRankWeekly": "3917", "writerThumb": "130", "writerVisitNum": "27715", "blog_read_count": "742", "blog_time": "已于 2022-09-02 21:32:09 修改", "blog_title": "Opencv项目实战：05 物体检测", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<h1>1，效果展示</h1>\n<p>为此，我专门还去查了查，怎么将视频转化为gif图，不知不觉中，我又多学会了一项技能。</p>\n<p><img alt=\"c7782e586f2f43d992d9225fce5104c6.gif\" src=\"https://img-blog.csdnimg.cn/c7782e586f2f43d992d9225fce5104c6.gif\"/></p>\n<p>OK!cool，效果很不错，今天需要搭配一些文件，都是可以从官网里找到的，那么我为了方便，专门去学习怎么在GitHub上托管项目，还下载了VScode和Git，我太难受了，如果不是要写博客，我绝对懒得去找教程。谢谢自己！</p>\n<p>那么在此gif图像中，我检测了水瓶（截图时间不够了），鼠标，剪刀，书，手机，牙刷，键盘，电脑等。</p>\n<hr/>\n<h1> 2，项目准备</h1>\n<ul><li> <h3>文件搭建</h3> </li></ul>\n<p>我会在结尾处，提供相关的资源，我们先在项目下新建一个目录，其中包含的文件，如图所示：</p>\n<p><img alt=\"2c55f837ee6e498497945971d855d4ee.png\" src=\"..\\..\\static\\image\\2c55f837ee6e498497945971d855d4ee.png\"/></p>\n<h1> 3，代码的讲解与展示</h1>\n<pre><code class=\"language-python\">import cv2\n\nthres = 0.45 # Threshold to detect object\n\ncap = cv2.VideoCapture(1)\ncap.set(3,640)\ncap.set(4,480)\ncap.set(10,70)\n\nclassNames= []\nclassFile = 'coco.names'\nwith open(classFile,'rt') as f:\n    classNames = f.read().rstrip('\\n').split('\\n')\n    #restrip返回删除尾随空白的字符串副本。如果给定了字符而不是无，则删除字符中的字符。\n\nconfigPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\nweightsPath = 'frozen_inference_graph.pb'\n\nnet = cv2.dnn_DetectionModel(weightsPath,configPath)\nnet.setInputSize(320,320)\nnet.setInputScale(1.0/ 127.5)\nnet.setInputMean((127.5, 127.5, 127.5))\nnet.setInputSwapRB(True)\n\nwhile True:\n    success,img = cap.read()\n    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n    print(classIds,bbox)\n\n    if len(classIds) != 0:\n        for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n            cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n            cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),\n                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n            cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),\n                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n\n    cv2.imshow(\"Output\", img)\n    if cv2.waitKey(1) &amp; 0xFF == 27:\n        break\n    #对于物体的检测</code></pre>\n<blockquote>\n<p> 今天的重点在于讲解代码的思路。</p>\n<ul><li>首先，打开我们的外部摄像头，并且设置窗口的宽，长，亮度，注意不要将窗口的大小超出我们外部摄像头的大小，不然你得到的图像可能就是黑屏。</li><li>其次，在我们的coco.names文件当中，它是每个名词单独一行，所以通过文件操作，将其内容放入一个空列表当中，我们用到了read()，rstrip()，split()函数，不清楚的地方，可以去W3school上查询。</li><li>接着，我们看看在包含了net的代码，它用到了DNN算法，其余的函数都可以在dnn.py文件里面查找到。</li></ul>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td>（1）</td><td>setInputSize(weight,height)weight新输入宽度，height新输入宽度。</td></tr><tr><td>（2）</td><td>setInputScale(1.0/ 127.5)设置帧的缩放因子值，帧值的比例乘数。</td></tr><tr><td style=\"width:50px;\">（3）</td><td>setInputMean((127.5, 127.5, 127.5))简要设置帧的平均值。</td></tr><tr><td>（4）</td><td>setInputSwapRB(True)将帧的标志设置为True。</td></tr></tbody></table>\n<ul><li> 然后，又要用到一个detect()函数，它是属于class DetectionModel(Model)下的函数，在这里confThreshold用于根据置信度筛选框的阈值，我们将其阈值放在了较前面的位置，方便更改，它会返回ClassID结果检测中的类索引，一组对应的置信度，一组边界框。</li><li>除此之外，我们用len(classIds) != 0来代表检测到了物体，然而我们有三个需要遍历的变量或信息，所以我们用到了zip函数，避免了写三个循环，而flatten()函数可以将其中的信息展开，再然后画框，放置文本，在这里需要提两句，在coco.name文件里面，每个名词是从1开始的，而classNames列表是从0开始的，故要在索引处-1，使用round（）函数是因为confidence是小数，会与之前的classNmaes的东西叠加在一起，故此将其看作是百分数，并保留了两位小数。</li><li>最后就是，imshow的展示窗口，以及点击Esc键推出。</li></ul>\n</blockquote>\n<h1> 4，项目优化 </h1>\n<p>我已经将注释写在了代码当中，如有不清楚的地方，可以将其打印出来，进行观察。</p>\n<p>其优化效果——有效的优化了之前检测框闪烁和重叠的现象。</p>\n<pre><code class=\"language-python\">import cv2\nimport numpy as np\n\nthres = 0.45 # Threshold to detect object\n#使用nms,不会像先前那样检测框有重叠和闪烁\nnms_threshold = 0.2  #0.2 已经是较大的抑制效果\n#若设置成1，将没有效果\ncap = cv2.VideoCapture(1)\ncap.set(3,1280)\ncap.set(4,720)\ncap.set(10,150)\n\nclassNames= []\nclassFile = 'coco.names'\nwith open(classFile,'rt') as f:\n    classNames = f.read().rstrip('\\n').split('\\n')\n\n#print(classNames)\nconfigPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\nweightsPath = 'frozen_inference_graph.pb'\n\nnet = cv2.dnn_DetectionModel(weightsPath,configPath)\nnet.setInputSize(320,320)\nnet.setInputScale(1.0/ 127.5)\nnet.setInputMean((127.5, 127.5, 127.5))\nnet.setInputSwapRB(True)\n\nwhile True:\n    success,img = cap.read()\n    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n    bbox = list(bbox)\n    #bbox本身得到的是numpy的数组，将其改为list\n    confs = list(np.array(confs).reshape(1,-1)[0])\n    #将其内容转化为只有一个列表,使用np.array()是因为元组是不能reshape\n    confs = list(map(float,confs))\n    #原本的confs是float32的形式，使用map()函数将float映射在confs上\n    #print(type(confs[0]))\n    #print(confs)\n    indices = cv2.dnn.NMSBoxes(bbox,confs,thres,nms_threshold)\n    #print(indices)\n    for i in indices:\n        i = i[0]\n        #打印（indices）的内容是[[0]]\n        box = bbox[i]\n        x,y,w,h = box[0],box[1],box[2],box[3]\n        cv2.rectangle(img, (x,y),(x+w,h+y), color=(0, 255, 0), thickness=2)\n        cv2.putText(img,classNames[classIds[i][0]-1].upper(),(box[0]+10,box[1]+30),\n                    cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n        #此处需要一个classIds的特殊索引，它就是i,而且已经有了一个[],所以是[i][0]\n\n    cv2.imshow(\"Output\",img)\n    cv2.waitKey(1)\n</code></pre>\n<h1>5，项目资源</h1>\n<p>GitHub:<a class=\"has-card\" href=\"https://github.com/Auorui/Opencv-project-training\" title=\"Auorui/Opencv-project-training: According to the project made by learning murtaza Hassan's videos every day, thank the up Master of station B: a graduate student who knows a little about everything. It is mainly used to learn opencv by myself. On my CSDN blog, I have a detailed picture and text introduction of each project. I will continue to study hard. Welcome to my CSDN blog, where I store my code and some information. CSDN link: https://blog.csdn.net/m0_62919535?type=blog 。 You can check it in my column - opencv project practice. (github.com)\"><span class=\"link-card-box\"><span class=\"link-title\">Auorui/Opencv-project-training: According to the project made by learning murtaza Hassan's videos every day, thank the up Master of station B: a graduate student who knows a little about everything. It is mainly used to learn opencv by myself. On my CSDN blog, I have a detailed picture and text introduction of each project. I will continue to study hard. Welcome to my CSDN blog, where I store my code and some information. CSDN link: https://blog.csdn.net/m0_62919535?type=blog 。 You can check it in my column - opencv project practice. (github.com)</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"..\\..\\static\\image\\icon-default.png\"/>https://github.com/Auorui/Opencv-project-training</span></span></a></p>\n<p> 免费转化为Gif图网站：<a class=\"has-card\" href=\"https://tt0.top/\" title=\"踢踢零工具 - tt0.top\"><span class=\"link-card-box\"><span class=\"link-title\">踢踢零工具 - tt0.top</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"..\\..\\static\\image\\icon-default.png\"/>https://tt0.top/</span></span></a></p>\n<h1>6，项目总结与评价</h1>\n<p>其中的很多算法我也不是很明白，只是使用的思路学会到了，后面将会有人脸检测的项目，应该会用到YOYO算法。希望有人能在这个项目中玩的开心，感谢您的关注与支持！！！</p>\n<p><img alt=\"b11a78f361684ce7919a4f276f6a8191.jpeg\" src=\"..\\..\\static\\image\\b11a78f361684ce7919a4f276f6a8191.jpeg\"/></p>\n<p> </p>\n<p> </p>\n</div>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-02 21:32:09", "summary": "，效果展示为此，我专门还去查了查，怎么将视频转化为图，不知不觉中，我又多学会了一项技能。，效果很不错，今天需要搭配一些文件，都是可以从官网里找到的，那么我为了方便，专门去学习怎么在上托管项目，还下载了"}