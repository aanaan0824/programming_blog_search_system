{"blogid": "123959257", "writerAge": "码龄2年", "writerBlogNum": "16", "writerCollect": "162", "writerComment": "10", "writerFan": "33", "writerGrade": "3级", "writerIntegral": "518", "writerName": "深夜的猫213", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_123959257.jpg", "writerRankTotal": "83946", "writerRankWeekly": "373725", "writerThumb": "52", "writerVisitNum": "71772", "blog_read_count": "9147", "blog_time": "于 2022-04-04 20:23:07 发布", "blog_title": "Spark SQL简介", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h2><a id=\"Spark_SQL_0\"></a>Spark SQL简介</h2>\n<h4><a id=\"Shark_2\"></a>一、从Shark说起</h4>\n<p><strong>1</strong>、在这之前我们要先理解Hive的工作原理：<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\b8f68cabe1f44e34b928699bf82e5cdc.png\"/></p>\n<p>Hive是一个基于Hadoop的数据仓库工具，提供了类似于关系数据库SQL的查询语言——HiveSQL，用户可以通过HiveSQL语句快速实现简单的MapReduce统计，Hive自身可以自动将HiveSQL语句快速转换成MapReduce任务进行运行。</p>\n<p><strong>2</strong>、Shark提供了类似于Hive的功能，与Hive不同的是，Shark把SQL语句转换成Spark作业，而不是MapReduce作业。</p>\n<p><em><strong>可以近似地认为：Shark仅将物理执行计划从MapReduce作业替换成了Spark作业，也就是通过Hive的HiveSQL解析功能，把HiveSQL翻译成Spark上的RDD操作。</strong></em></p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\a85f679fba9f4f95ae9cd6a58445b282.png\"/></p>\n<blockquote>\n<p><strong>Shark的设计导致了两个问题</strong>：<br/> 一、是执行计划优化完全依赖于Hive，不方便添加新的优化策略。</p>\n<p>二、是因为Spark是线程级并行，而MapReduce是进程级并行，因此，Spark在兼容Hive的实现上存在线程安全问题，导致Shark不得不使用另外一套独立维护的打了补丁的Hive源码分支。</p>\n</blockquote>\n<p><strong>3</strong>、Spark SQL架构如下：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\14072c01a4734c15b2e6e19276ebd569.png\"/></p>\n<p>Spark SQL在Hive兼容层面仅依赖HiveQL解析、Hive元数据，<strong>也就是说，从HQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由Catalyst（函数式关系查询优化框架）负责。</strong></p>\n<p><strong>Spark SQL增加了DataFrame（即带有Schema信息的RDD）</strong>，使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以是Hive、HDFS、Cassandra等外部数据源，还可以是JSON格式的数据。<br/> Spark SQL目前支持Scala、Java、Python三种语言，支持SQL-92规范。</p>\n<h4><a id=\"DataFrame_34\"></a>二、DataFrame概述</h4>\n<p><strong>1</strong>、DataFrame的推出，让Spark具备了处理大规模结构化数据的能力，不仅比原有的RDD转化方式更加简单易用，而且获得了更高的计算性能。<br/> Spark能够轻松实现从MySQL到DataFrame的转化，并且支持SQL查询。</p>\n<p><strong>RDD是分布式的 Java对象的集合，但是，对象内部结构对于RDD而言却是不可知的。</strong><br/> <strong>DataFrame是一种以RDD为基础的分布式数据集，提供了详细的结构信息。</strong><br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\f725e7ddf8e8418dab306919b51d0e91.png\"/><br/> 从Spark2.0以上版本开始，Spark使用全新的SparkSession接口替代Spark1.6中的SQLContext及HiveContext接口来实现其对数据加载、转换、处理等功能。SparkSession实现了SQLContext及HiveContext所有功能。</p>\n<p><strong>SparkSession支持从不同的数据源加载数据，并把数据转换DataFrame，并且支持把DataFrame转换成SQLContext自身中的表，然后使用SQL语句来操作数据</strong>。SparkSession亦提供了HiveQL以及其他依赖于Hive的功能的支持。</p>\n<p>在编写独立应用程序时，可以通过如下语句创建一个SparkSession对象</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext<span class=\"token punctuation\">,</span>SparkConf\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> SparkSession\nspark <span class=\"token operator\">=</span> SparkSession<span class=\"token punctuation\">.</span>builder<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">(</span>conf <span class=\"token operator\">=</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>getOrCreate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p><strong>实际上，在启动进入pyspark以后，pyspark就默认提供了一个SparkContext对象（名称为sc）和一个SparkSession对象（名称为spark）</strong></p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\ad522fa0f42540beaaad809ed655edcc.png\"/></p>\n<p><strong>2</strong>、从不同类型的文件中加载数据创建DataFrame</p>\n<pre><code class=\"prism language-python\"><span class=\"token comment\">#从不同类型的文件中加载数据创建DataFrame</span>\ndf1 <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.txt\"</span><span class=\"token punctuation\">)</span>\ndf1<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf2 <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.json\"</span><span class=\"token punctuation\">)</span>\ndf2<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf1_1 <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.txt\"</span><span class=\"token punctuation\">)</span>\ndf1_1<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf2_1 <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.json\"</span><span class=\"token punctuation\">)</span>\ndf2_1<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>结果：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\9fac9377e77d4e47b197dbea5cc1c430.png\"/><br/> <strong>3</strong>、DataFrame的保存</p>\n<pre><code class=\"prism language-python\"><span class=\"token comment\">#DataFrame的保存</span>\n<span class=\"token comment\">#例：把上面名称为df1的文件保存到不同格式文件中</span>\ndf1<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">(</span><span class=\"token string\">\"df1.txt\"</span><span class=\"token punctuation\">)</span>\ndf1<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">(</span><span class=\"token string\">\"df1.json\"</span><span class=\"token punctuation\">)</span>\ndf1<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"df1.txt\"</span><span class=\"token punctuation\">)</span>\ndf1<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"df1.json\"</span><span class=\"token punctuation\">)</span>\ndf2<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token string\">\"name\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"age\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"json\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/df2.json\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#选取指定的列保存</span>\n</code></pre>\n<p><strong>另一种存储方式Parquet。详细见下面链接。</strong></p>\n<p><a href=\"http://t.csdn.cn/wQIZA\">很详细的Parquet存储讲解</a></p>\n<p><strong>当把该数据保存到一个文本文件中会新生成一个名称为df1.json的目录（不是文件）和一个名称df1.txt的目录（不是文件）</strong></p>\n<p>如果再次读取json或text文件生成DataFrame，可以直接用这个目录名称，不需要使用part-00000-093d3250-a36a-4ca4-affc-5144b2a2759a-c000.txt文件（当然，使用这个文件也可以）。<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\c475610b4a504bc3a6277735c54dfbee.png\"/></p>\n<h4><a id=\"DataFrame_103\"></a>三、DataFrame的常用操作</h4>\n<blockquote>\n<ul><li>printSchema()</li></ul>\n<p>打印出DataFrame的模式（Schema）信息。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\1422cfab53104c5388acc04a9d6a4d36.png\"/></p>\n<blockquote>\n<ul><li>select()</li></ul>\n<p>从DataFrame中选取部分列的数据。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\f083b32c33da4875ab6da647c3e0ff73.png\"/></p>\n<blockquote>\n<ul><li>filter()</li></ul>\n<p>实现条件查询，找到满足条件要求的记录。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\3c523f1847bc41f7ba7aba892de399ce.png\"/></p>\n<blockquote>\n<ul><li>groupBy()</li></ul>\n<p>用于对记录进行分组。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\c26b8c579ca6451996626fa6e4ddc97c.png\"/></p>\n<blockquote>\n<ul><li>sort()</li></ul>\n<p>用于对记录进行排序。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\a4d4ac92ca074232abf8558c974ddbe7.png\"/></p>\n<h4><a id=\"RDDDataFrame_144\"></a>四、从RDD转换得到DataFrame</h4>\n<p>Spark提供了如下<em><strong>两种</strong></em>方法实现从RDD转换得到DataFrame</p>\n<p><strong>1.利用反射机制推断RDD模式</strong></p>\n<blockquote>\n<p>利用反射机制来推断包含特定类型对象的RDD的模式（Schema），适用于数据结构已知时的RDD转换。</p>\n</blockquote>\n<p>例：现在要把people.txt加载到内存中生成一个DataFrame，并查询其中的数据：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> Row\npeople <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.txt\"</span><span class=\"token punctuation\">)</span>      <span class=\"token comment\">#生成RDD文件</span>\npeople1 <span class=\"token operator\">=</span> people<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span>x<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span>Row<span class=\"token punctuation\">(</span>name<span class=\"token operator\">=</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>age<span class=\"token operator\">=</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\">#得到新的RDD，每个元素都是Row对象</span>\nschemaPeople <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>createDataFrame<span class=\"token punctuation\">(</span>people1<span class=\"token punctuation\">)</span>         <span class=\"token comment\">#转换成DataFrame</span>\nschemaPeople<span class=\"token punctuation\">.</span>createOrReplaceTempView<span class=\"token punctuation\">(</span><span class=\"token string\">\"people\"</span><span class=\"token punctuation\">)</span>      <span class=\"token comment\">#注册为临时表,临时表名字为people</span>\npersonsDF <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">(</span><span class=\"token string\">\"select name,age from people where age&gt;20\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">#SQL语句查询</span>\npersonsRDD <span class=\"token operator\">=</span> personsDF<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span><span class=\"token string\">\"Name: \"</span><span class=\"token operator\">+</span>x<span class=\"token punctuation\">.</span>name<span class=\"token operator\">+</span><span class=\"token string\">\",\"</span><span class=\"token operator\">+</span><span class=\"token string\">\"Age \"</span><span class=\"token operator\">+</span>x<span class=\"token punctuation\">.</span>age<span class=\"token punctuation\">)</span>   <span class=\"token comment\">#格式化输出</span>\npersonsRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>结果：</p>\n<pre><code class=\"prism language-python\"><span class=\"token punctuation\">[</span><span class=\"token string\">'Name: Michael,Age 40'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Name: Andy,Age 30'</span><span class=\"token punctuation\">]</span>\n</code></pre>\n<p><strong>2.使用编程方式定义RDD模式</strong></p>\n<blockquote>\n<p>使用编程接口构造一个模式（Schema），并将其应用在已知的RDD上，适用于数据结构未知时的RDD转换。</p>\n</blockquote>\n<p><img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\27697948ae1e4eb1a3c407feb596f25f.png\"/></p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>types <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n<span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> Row\n<span class=\"token comment\">#下面生成“表头”</span>\nschemaString <span class=\"token operator\">=</span> <span class=\"token string\">\"name age\"</span>\nfields <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>StructField<span class=\"token punctuation\">(</span>field_name<span class=\"token punctuation\">,</span> StringType<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> field_name <span class=\"token keyword\">in</span> schemaString<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\nschema <span class=\"token operator\">=</span> StructType<span class=\"token punctuation\">(</span>fields<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#下面生成“表中的记录”</span>\nlines <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"file:///home/hadoop/program1/people.txt\"</span><span class=\"token punctuation\">)</span>\nparts <span class=\"token operator\">=</span> lines<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\npeople <span class=\"token operator\">=</span> parts<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> Row<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#下面把“表头”和“表中的记录”拼装在一起</span>\nschemaPeople <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>createDataFrame<span class=\"token punctuation\">(</span>people<span class=\"token punctuation\">,</span> schema<span class=\"token punctuation\">)</span>\nschemaPeople<span class=\"token punctuation\">.</span>createOrReplaceTempView<span class=\"token punctuation\">(</span><span class=\"token string\">\"people\"</span><span class=\"token punctuation\">)</span>\nresults <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">(</span><span class=\"token string\">\"select name,age from people\"</span><span class=\"token punctuation\">)</span>\nresults<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>结果</p>\n<pre><code class=\"prism language-python\"><span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span>\n<span class=\"token operator\">|</span>   name<span class=\"token operator\">|</span>age<span class=\"token operator\">|</span>\n<span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span>\n<span class=\"token operator\">|</span>Michael<span class=\"token operator\">|</span> <span class=\"token number\">40</span><span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span>   Andy<span class=\"token operator\">|</span> <span class=\"token number\">30</span><span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> Justin<span class=\"token operator\">|</span> <span class=\"token number\">19</span><span class=\"token operator\">|</span>\n<span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">+</span>\n</code></pre>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "SQL", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 1, "sql": 1, "php": 0, "time": "2022-04-04 20:23:07", "summary": "简介一、从说起、在这之前我们要先理解的工作原理：在这里插入图片描述是一个基于的数据仓库工具，提供了类似于关系数据库的查询语言，用户可以通过语句快速实现简单的统计，自身可以自动将语句快速转换成任务进行运"}