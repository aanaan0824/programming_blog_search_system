{"blogid": "124960923", "writerAge": "码龄5年", "writerBlogNum": "8", "writerCollect": "12", "writerComment": "3", "writerFan": "10", "writerGrade": "2级", "writerIntegral": "152", "writerName": "Raymond-Shen", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_124960923.jpg", "writerRankTotal": "88579", "writerRankWeekly": "243259", "writerThumb": "7", "writerVisitNum": "18836", "blog_read_count": "798", "blog_time": "已于 2022-07-18 10:22:26 修改", "blog_title": "OpenRaft实操分享（撮合引擎场景）", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<p>由于工作需要，一直对原子多播应用有非常浓厚的兴趣。通过一段时间的技术选型。我们非常幸运的得到了databend社群的热心支持。我也想通过我们的实际工作，对Openraft的未来应用尽一些微薄之力。</p>\n<p></p>\n<p></p>\n<p>我的实践的上一篇文章反应了我们的选型过程，有兴趣的人可以看一下。</p>\n<p><a class=\"has-card\" href=\"https://blog.csdn.net/weixin_41308834/article/details/124375789?spm=1001.2014.3001.5501\" title=\"Raft in Rust (原子多播+撮合引擎）_Raymond-Shen的博客-CSDN博客\"><span class=\"link-card-box\"><span class=\"link-title\">Raft in Rust (原子多播+撮合引擎）_Raymond-Shen的博客-CSDN博客</span><span class=\"link-desc\">前言Raft作为一个分布式协同算法，这是原子多播的一个非常重要的视线。今天也得到了广泛的应用。当前情况下，我们为了更好的实现一个快速的撮合引擎，我们进一步探索原子多播在交易系统中的应用。Rust是现代编译执行语言的代表，可以达到可以比肩C语言的执行效率。所以，我们必然要考虑如何在Rust里面应用Raft协议。已有项目tikv/raft-rshttps://github.com/tikv/raft-rshttps://github.com/tikv/raft-rsraft-rs/exampl.</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"https://g.csdnimg.cn/static/logo/favicon32.ico\"/>https://blog.csdn.net/weixin_41308834/article/details/124375789?spm=1001.2014.3001.5501</span></span></a>这篇文章更多的是想说明我们在使用OpenRaft的实际问题，并且通过我们的实现，揭秘OpenRaft的一些机制。</p>\n<h1>代码仓库</h1>\n<p>大家在使用OpenRaft的时候，我相信很多人都查看了手册：</p>\n<p><a class=\"has-card\" href=\"https://datafuselabs.github.io/openraft/getting-started.html\" title=\"Getting Started - openraft\"><span class=\"link-card-box\"><span class=\"link-title\">Getting Started - openraft</span><span class=\"link-desc\">The openraft user guide.</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"https://datafuselabs.github.io/openraft/favicon.svg\"/>https://datafuselabs.github.io/openraft/getting-started.html</span></span></a>当然，这是一个非常优秀的手册。我们从这个手册里，会学习到如何使用OpenRaft实现自己的应用。而且，<a href=\"https://github.com/daexample-raft-kv\" title=\"openraft/example-raft-kv\">openraft/example-raft-kv</a>这个例子确实能够很好的说明如何实现一个简单的应用。但是，这个例子是使用的内存来做持久化实现。当然内存不会真正做持久化，所以很容易在节点退出后，丢失状态。而我们真正需要的示例是一个能够持久化的例子。</p>\n<p>另外一个实例就是</p>\n<p><a class=\"has-card\" href=\"https://github.com/datafuselabs/databend/tree/main/metasrv\" title=\"databend/metasrv at main · datafuselabs/databend · GitHub\"><span class=\"link-card-box\"><span class=\"link-title\">databend/metasrv at main · datafuselabs/databend · GitHub</span><span class=\"link-desc\">A modern Elasticity and Performance cloud data warehouse, activate your object storage for real-time analytics. - databend/metasrv at main · datafuselabs/databend</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"..\\..\\static\\image\\fluidicon.png\"/>https://github.com/datafuselabs/databend/tree/main/metasrv</span></span></a>而这个示例里面，我们可以看到一个完整的 metadata 存储服务的实现。实际上，metasrv本身是一个类似于etcd的kv存储。存储整个databend集群的metadata。这个示例里面，metasrv使用了sled作为底层存储。sled寄存储log，有存储 statemachine 的状态。这个例子，statemachine所有的更新都直接在sled存储里通过sled的事物完成了。所以，对于如何存储snapshot这个问题，我们并不太容易看清楚。所以snapshot的产生和传递主要是在节点间同步的时候使用。</p>\n<p> 这里，大家可以看到我们开放的源代码。虽然这个示例是基于 example-raft-kv 示例，没有达到 metasrv的生产强度。但是我们还是非常全面的表现出了 openraft 对 log, snapshot 处理的行为和能力。</p>\n<p><a class=\"has-card\" href=\"https://github.com/raymondshe/matchengine-raft\" title=\"GitHub - raymondshe/matchengine-raft\"><span class=\"link-card-box\"><span class=\"link-title\">GitHub - raymondshe/matchengine-raft</span><span class=\"link-desc\">Contribute to raymondshe/matchengine-raft development by creating an account on GitHub.</span><span class=\"link-link\"><img alt=\"\" class=\"link-link-icon\" src=\"..\\..\\static\\image\\fluidicon.png\"/>https://github.com/raymondshe/matchengine-raft</span></span></a></p>\n<h1>应用场景</h1>\n<p>和metasrv的场景不同。我们需要我们的statemachine尽量在内存里面更新，尽量少落盘。虽然sled本地落盘的速度也很快，但是内存操作的速度会更快。所以，我们基本上就是这样进行操作的。</p>\n<p style=\"text-align:center;\"><img alt=\"\" src=\"..\\..\\static\\image\\518a00225c3c4bc2b7a466dc4cae47ef.png\"/></p>\n<p style=\"text-align:center;\"> <a href=\"https://excalidraw.com/#json=kSzwFGNGr_WNjytPO65RN,CjvsM4m_3efHnSIGK37Sow\" title=\"总体设计图\">总体设计图</a> </p>\n<p>所以在这个图里面，大家可以看到日志是通过sled进行存储的。而这些日志由于通过Raft协议，实际上他们在每台机器上的顺序是一致的。所以，不同的matchengine-raft实例，在相同的日志流情况下，对状态机的操作就是一致的。所以，不管我们从哪一个日志开始写snapshot，通过加载snapshot并且回放后续的日志，我们都可以恢复到最新状态。</p>\n<p>按照设计图中显示，当前StateMachine的状态是处理了第9个日志里的消息。这时候，系统保存了所有的消息到Sled。并且在第3个消息的时候落盘了一次snapshot，并且在低6个消息的时候落盘了一次snapshot。如果这台机器当机，我们是可以从编号为3的snapshot恢复状态机，并且继续处理3,4,5,6,7,8,9这6条消息来恢复当前状态。当然，我们也可以从编号为6的snapshot恢复状态机，并且继续处理7,8,9这3条消息来恢复当前状态。</p>\n<p>当然我们可以选择多少个消息进行一次落盘。当然落盘的次数越多越可靠，但是性能影响比较大。好在snapshot的生成和落盘是异步的方式做的。</p>\n<p>有兴趣的朋友可以看一下akka的 <a class=\"link-info\" href=\"https://doc.akka.io/docs/akka/current/typed/index-persistence.html\" title=\"EventSroucing\">EventSroucing</a> 模式。这种模式和Raft单节点非常相像。不同的是OpenRaft强调多实例一致性，而Akka 则提供了非常多的方式来存储 Log( Journal )和 Snapshot.</p>\n<h1>实现细节</h1>\n<p> 谈到实现细节。我们还是回到官方文档 <a class=\"link-info\" href=\"https://datafuselabs.github.io/openraft/getting-started.html\" title=\"geting-started\">geting-started</a> 来。我们也按照这个文档的顺序进行说明。</p>\n<p></p>\n<p>Raft对于从应用开发着的角度，我们可以简化到下面的这张图里。Raft的分布式共识就是要保证驱动状态机的指令能够在 Log 里被一致的复制到各个节点里。</p>\n<p class=\"img-center\"><img alt=\"\" src=\"..\\..\\static\\image\\20c6bccdfa1099a0095763f8b145a7e9.png\"/></p>\n<p>Raft有两个重要的组成部分：</p>\n<ul><li>如何一致的在节点之间复制日志。</li><li>并且在状态机里面如何消费这些日志。</li></ul>\n<p>基于OpenRaft 实现我们自己的 Raft 应用其实并不复杂，只需要一下三部分：</p>\n<ul><li>定义好客户端的请求和应答</li><li>实现好存储 RaftStore 来持久化状态</li><li>实现一个网络层，来保证 Raft 节点之间能相互传递消息。</li></ul>\n<p>好，那我们就开始吧：</p>\n<h2>1. 定义好客户端的请求和应答</h2>\n<p>请求有可能是客户端发出的驱动 Raft 状态机的数据，而应答则是 Raft 状态机会打给客户端的数据。</p>\n<p>请求和应答需要实现 AppData 和 AppDataResponse 这里，我们的实现如下：</p>\n<pre><code class=\"language-rust\">#[derive(Serialize, Deserialize, Debug, Clone)]\npub enum ExampleRequest {\n    Set { key: String, value: String },\n    Place { order: Order },\n    Cancel { order: Order}\n}\n\n#[derive(Serialize, Deserialize, Debug, Clone)]\npub struct ExampleResponse {\n    pub value: Option&lt;String&gt;,\n}\n</code></pre>\n<p>这两个类型完全是应用相关的，而且和RaftStrage的状态机实现相关。</p>\n<blockquote>\n<ol><li>这里，Set是 example-raft-kv 原示例就有的命令。</li><li>大家也注意到了，命令都是对状态机有驱动的命令。也就是会对状态机状态造成改变的命令。如果我们需要取状态机内部数据的值返回给客户端。我们大可不必定义到这里。</li></ol>\n</blockquote>\n<h2> 2. 实现 RaftStorage</h2>\n<p>这是整个项目非常关键的一部分。</p>\n<p>只要实现好 trait RaftStorage，我们就把数据存储和消费的行为定义好。RaftStoreage可以包装一个像 <a href=\"https://docs.rs/rocksdb/latest/rocksdb/\" title=\"RocksDB\">RocksDB</a>, <a class=\"link-info\" href=\"https://github.com/spacejam/sled\" title=\"Sled\">Sled</a> 的本地 KV 存储或者远端的 SQL DB。</p>\n<p><code>RaftStorage</code> 定义了下面一些API</p>\n<ul><li> <p>读写Raft状态，比方说 term，vote (term：任期，vote：投票结果）</p> <pre><code class=\"language-rust\">fn save_vote(vote:&amp;Vote) \nfn read_vote() -&gt; Result&lt;Option&lt;Vote&gt;&gt;</code></pre> </li><li> <p>读写日志</p> <pre><code class=\"language-rust\">fn get_log_state() -&gt; Result&lt;LogState&gt; \nfn try_get_log_entries(range) -&gt; Result&lt;Vec&lt;Entry&gt;&gt; \nfn append_to_log(entries) \nfn delete_conflict_logs_since(since:LogId) \nfn purge_logs_upto(upto:LogId)</code></pre> </li><li> <p>将日志的内容应用到状态机</p> <pre><code class=\"language-rust\">fn last_applied_state() -&gt; Result&lt;(Option&lt;LogId&gt;, Option&lt;EffectiveMembership&gt;)&gt; \nfn apply_to_state_machine(entries) -&gt; Result&lt;Vec&lt;AppResponse&gt;&gt;</code></pre> </li><li> <p>创建和安装快照（snapshot） </p> <pre><code class=\"language-rust\">fn build_snapshot() -&gt; Result&lt;Snapshot&gt; \nfn get_current_snapshot() -&gt; Result&lt;Option&lt;Snapshot&gt;&gt; \nfn begin_receiving_snapshot() -&gt; Result&lt;Box&lt;SnapshotData&gt;&gt; \nfn install_snapshot(meta, snapshot)</code></pre> </li></ul>\n<p>在 <a href=\"https://github.com/datafuselabs/openraft/blob/main/example-raft-kv/src/store/mod.rs\" title=\"ExampleStore\">ExampleStore</a>，这些内存化存储行为是非常明确简单的。而我们不是要真正落盘了吗？那我们就看一下 matchengine-rust 是怎么实现的。</p>\n<p>这里是 <a href=\"https://github.com/raymondshe/matchengine-raft/tree/master/src/store\" title=\"matchengine-raft/src/store\">matchengine-raft/src/store</a></p>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px;\"><tbody><tr><td style=\"width:100px;\"><strong>接口</strong></td><td style=\"width:398px;\"><strong>实现方式</strong></td></tr><tr><td style=\"width:100px;\">Raft状态</td><td style=\"width:398px;\">sled存储，使用专门的key来读写raft状态。</td></tr><tr><td style=\"width:100px;\">日志</td><td style=\"width:398px;\">sled存储，使用 log_index 来唯一标识一个 Log Entity</td></tr><tr><td style=\"width:100px;\">应用状态机</td><td style=\"width:398px;\">状态机里面一部分是业务数据，但是一部分是raft的数据。业务数据主要是订单薄。    </td></tr><tr><td style=\"width:100px;\">快照</td><td style=\"width:398px;\">快照完全是通过文件进行存储的，而且文件的名字就保留了快照的全部meta信息。</td></tr></tbody></table>\n<p>我们说明一些设计要点</p>\n<h3>ExampleStore的数据</h3>\n<p>ExchangeStore 里面主要是包含下面的成员变量。</p>\n<pre><code class=\"language-rust\">#[derive(Debug)]\npub struct ExampleStore {\n    last_purged_log_id: RwLock&lt;Option&lt;LogId&lt;ExampleNodeId&gt;&gt;&gt;,\n\n    /// The Raft log.\n    pub log: sled::Tree,//RwLock&lt;BTreeMap&lt;u64, Entry&lt;StorageRaftTypeConfig&gt;&gt;&gt;,\n\n    /// The Raft state machine.\n    pub state_machine: RwLock&lt;ExampleStateMachine&gt;,\n\n    /// The current granted vote.\n    vote: sled::Tree,\n\n    snapshot_idx: Arc&lt;Mutex&lt;u64&gt;&gt;,\n\n    current_snapshot: RwLock&lt;Option&lt;ExampleSnapshot&gt;&gt;,\n\n    config : Config,\n\n    pub node_id: ExampleNodeId,\n}\n</code></pre>\n<p>帮助我们落盘的成员主要是 log, vote。而需要产生snapshot进行落盘的所有内容都在 state_machine.</p>\n<p>1. last_purged_log_id： 这是最后删除的日志ID。删除日志本身可以节约存储，但是，对我们来讲，我了保证数据存储的安全。在删除日志之前，我们必须有这条日志index大的snapshot产生。否则，我们就没有办法通过snapshot来恢复数据。</p>\n<p>2.  log: 这是一个 sled::Tree，也就是一个map。如果看着部分代码的话，我们就可以清楚的明白log对象的结构。key是一个log_id_index的 Big Endian 的字节片段。value是通过serd_json进行序列化的内容。</p>\n<pre><code class=\"language-rust\">    #[tracing::instrument(level = \"trace\", skip(self, entries))]\n    async fn append_to_log(\n        &amp;mut self,\n        entries: &amp;[&amp;Entry&lt;ExampleTypeConfig&gt;],\n    ) -&gt; Result&lt;(), StorageError&lt;ExampleNodeId&gt;&gt; {\n        let log = &amp;self.log;\n        for entry in entries {\n            log.insert(entry.log_id.index.to_be_bytes(), IVec::from(serde_json::to_vec(&amp;*entry).unwrap())).unwrap();\n        }\n        Ok(())\n    }\n</code></pre>\n<p>3. state_machine: 这里就是通过日志驱动的所有状态的集合。</p>\n<pre><code class=\"language-rust\">#[derive(Serialize, Deserialize, Debug, Default, Clone)]\npub struct ExampleStateMachine {\n    pub last_applied_log: Option&lt;LogId&lt;ExampleNodeId&gt;&gt;,\n\n    // TODO: it should not be Option.\n    pub last_membership: EffectiveMembership&lt;ExampleNodeId&gt;,\n\n    /// Application data.\n    pub data: BTreeMap&lt;String, String&gt;,\n\n    // ** Orderbook\n    pub orderbook: OrderBook,\n}\n</code></pre>\n<p> StateMachine里面最重要的数据就是 orderbook这部分就是撮合引擎里面重要的订单表。存放买方和卖方的未成交订单信息。这是主要的业务逻辑。 data 这部分是原来例子中的kv存储。我们还在这里没有删除。</p>\n<p>这里last_applied_log, last_menbership 这些状态和业务逻辑没有太大关系。所以，如果您要实现自己的StateMachine。还是尽量和例子保持一致。主要是因为这两个状态是通过apply_to_state_machine这个接口更新。也正好需要持久化。如果需要进一步隐藏raft的细节，我们还是建议openraft能将这两个状态进一步进行隐藏封装。</p>\n<p>对state_machine的落盘操作主要集中在这里：<a href=\"https://github.com/raymondshe/matchengine-raft/blob/master/src/store/store.rs\" title=\"store/store.rs\">store/store.rs</a>。有兴趣的可以看一下。这里面比较有意思的问题是orderbook本身无法被默认的serde_json序列化/反序列化。所以我们才在 <a href=\"https://github.com/raymondshe/matchengine-raft/blob/master/src/matchengine/mod.rs\" title=\"matchengine/mod.rs\">matchengine/mod.rs</a> 加了这段代码：</p>\n<pre><code class=\"language-rust\">pub mod vectorize {\n    use serde::{Deserialize, Deserializer, Serialize, Serializer};\n    use std::iter::FromIterator;\n\n    pub fn serialize&lt;'a, T, K, V, S&gt;(target: T, ser: S) -&gt; Result&lt;S::Ok, S::Error&gt;\n    where\n        S: Serializer,\n        T: IntoIterator&lt;Item = (&amp;'a K, &amp;'a V)&gt;,\n        K: Serialize + 'a,\n        V: Serialize + 'a,\n    {\n        let container: Vec&lt;_&gt; = target.into_iter().collect();\n        serde::Serialize::serialize(&amp;container, ser)\n    }\n\n    pub fn deserialize&lt;'de, T, K, V, D&gt;(des: D) -&gt; Result&lt;T, D::Error&gt;\n    where\n        D: Deserializer&lt;'de&gt;,\n        T: FromIterator&lt;(K, V)&gt;,\n        K: Deserialize&lt;'de&gt;,\n        V: Deserialize&lt;'de&gt;,\n    {\n        let container: Vec&lt;_&gt; = serde::Deserialize::deserialize(des)?;\n        Ok(T::from_iter(container.into_iter()))\n    }\n}\n\n/// main OrderBook structure\n#[derive(Clone, Default, Serialize, Deserialize, Debug)]\npub struct OrderBook {\n    #[serde(with = \"vectorize\")]\n    pub bids: BTreeMap&lt;BidKey, Order&gt;,\n    #[serde(with = \"vectorize\")]\n    pub asks: BTreeMap&lt;AskKey, Order&gt;,\n    pub sequance: u64,\n}</code></pre>\n<p>4. vote: 就是对最后一次vote的存储。具体请看, 铁这段代码倒不是因为这段代码有多重要，只是由于代码比较简单，看可以少些一些说明：</p>\n<pre><code class=\"language-rust\">    #[tracing::instrument(level = \"trace\", skip(self))]\n    async fn save_vote(&amp;mut self, vote: &amp;Vote&lt;ExampleNodeId&gt;) -&gt; Result&lt;(), StorageError&lt;ExampleNodeId&gt;&gt; {\n        self.vote.insert(b\"vote\", IVec::from(serde_json::to_vec(vote).unwrap())).unwrap();\n        Ok(())\n    }\n\n    async fn read_vote(&amp;mut self) -&gt; Result&lt;Option&lt;Vote&lt;ExampleNodeId&gt;&gt;, StorageError&lt;ExampleNodeId&gt;&gt; {\n        let value = self.vote.get(b\"vote\").unwrap();\n        match value {\n            None =&gt; {Ok(None)},\n            Some(val) =&gt;  {Ok(Some(serde_json::from_slice::&lt;Vote&lt;ExampleNodeId&gt;&gt;(&amp;*val).unwrap()))}\n        }\n    }\n</code></pre>\n<p>但是这儿确实有个小坑，之前我没有注意到vote需要持久化，开始调试的时候产生了很多问题。知道找到openraft作者 Zhang Yanpo才解决。也是出发我想开源这个 openraft 文件持久化实现的诱因吧。感谢 Zhang Yanpo, 好样的。</p>\n<p>5. 其他的成员变量其实没什么太好说的了。和原例子一样。</p>\n<h3>对日志和快照的控制</h3>\n<p>日志，快照相互配合，我们可以很好的持久化状态，并且恢复最新状态。多久写一次快照，保存多少日志。在这里我们使用了下面的代码。</p>\n<pre><code class=\"language-rust\">let mut config = Config::default().validate().unwrap();\n    config.snapshot_policy = SnapshotPolicy::LogsSinceLast(500);\n    config.max_applied_log_to_keep = 20000;\n    config.install_snapshot_timeout = 400;\n    </code></pre>\n<p>强烈建议大家看一下 <a href=\"https://docs.rs/openraft/latest/openraft/config/struct.Config.html\" title=\"Config in openraft::config - Rust\">Config in openraft::config - Rust</a></p>\n<p>重点看 snapshot_policy, 代码里可以清楚的标识，我们需要500次log写一次快照。也就是 openraft会调用 build_snapshot 函数创建snapshot。原示例里，snapshot只是在内存里保存在 current_snapshot 变量里。而我们需要真实的落盘。请注意这段代码的 self.write_snapshot()</p>\n<pre><code class=\"language-rust\">#[async_trait]\nimpl RaftSnapshotBuilder&lt;ExampleTypeConfig, Cursor&lt;Vec&lt;u8&gt;&gt;&gt; for Arc&lt;ExampleStore&gt; {\n    #[tracing::instrument(level = \"trace\", skip(self))]\n    async fn build_snapshot(\n        &amp;mut self,\n    ) -&gt; Result&lt;Snapshot&lt;ExampleTypeConfig, Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, StorageError&lt;ExampleNodeId&gt;&gt; {\n        let (data, last_applied_log);\n\n        {\n            // Serialize the data of the state machine.\n            let state_machine = self.state_machine.read().await;\n            data = serde_json::to_vec(&amp;*state_machine)\n                .map_err(|e| StorageIOError::new(ErrorSubject::StateMachine, ErrorVerb::Read, AnyError::new(&amp;e)))?;\n\n            last_applied_log = state_machine.last_applied_log;\n        }\n\n        let last_applied_log = match last_applied_log {\n            None =&gt; {\n                panic!(\"can not compact empty state machine\");\n            }\n            Some(x) =&gt; x,\n        };\n\n        let snapshot_idx = {\n            let mut l = self.snapshot_idx.lock().unwrap();\n            *l += 1;\n            *l\n        };\n\n        let snapshot_id = format!(\n            \"{}-{}-{}\",\n            last_applied_log.leader_id, last_applied_log.index, snapshot_idx\n        );\n\n        let meta = SnapshotMeta {\n            last_log_id: last_applied_log,\n            snapshot_id,\n        };\n\n        let snapshot = ExampleSnapshot {\n            meta: meta.clone(),\n            data: data.clone(),\n        };\n\n        {\n            let mut current_snapshot = self.current_snapshot.write().await;\n            *current_snapshot = Some(snapshot);\n        }\n\n        self.write_snapshot().await.unwrap();\n\n        Ok(Snapshot {\n            meta,\n            snapshot: Box::new(Cursor::new(data)),\n        })\n    }\n}</code></pre>\n<p>这下我们有了snapshot，当然snapshot一方面可以用来在节点之间同步状态。另一方面就是在启动的时候恢复状态。而 openraft 的实现非常好。实际上恢复状态只需要回复到最新的snapshot就行。只要本地日志完备，openraft 会帮助你调用 apply_to_statemachine 来恢复到最新状态。所以我们就有了restore函数。</p>\n<pre><code class=\"language-rust\">#[async_trait]\nimpl Restore for Arc&lt;ExampleStore&gt; {\n    #[tracing::instrument(level = \"trace\", skip(self))]\n    async fn restore(&amp;mut self) {\n        tracing::debug!(\"restore\");\n        let log = &amp;self.log;\n\n        let first = log.iter().rev()\n        .next()\n        .map(|res| res.unwrap()).map(|(_, val)|\n            serde_json::from_slice::&lt;Entry&lt;ExampleTypeConfig&gt;&gt;(&amp;*val).unwrap().log_id);\n\n        match first {\n            Some(x) =&gt; {\n                tracing::debug!(\"restore: first log id = {:?}\", x);\n                let mut ld = self.last_purged_log_id.write().await;\n                *ld = Some(x);\n            },\n            None =&gt; {}\n        }\n\n        let snapshot = self.get_current_snapshot().await.unwrap();\n\n        match snapshot {\n            Some (ss) =&gt; {self.install_snapshot(&amp;ss.meta, ss.snapshot).await.unwrap();},\n            None =&gt; {}\n        }\n    }\n}\n</code></pre>\n<p>大家注意一下snapshot的操作。当然，在这里，我们也恢复了last_purged_log_id。</p>\n<p>当然store这个函数会在ExampleStore刚刚构建的时候调用。</p>\n<pre><code class=\"language-rust\">\n    // Create a instance of where the Raft data will be stored.\n    let es = ExampleStore::open_create(node_id);\n    \n    //es.load_latest_snapshot().await.unwrap();\n\n    let mut store = Arc::new(es);\n    \n    store.restore().await;</code></pre>\n<h3 id=\"how-do-i-impl-raftstorage-correctly\">如何确定RaftStorage是对的</h3>\n<p>请查阅 <a href=\"https://github.com/datafuselabs/openraft/blob/main/memstore/src/test.rs\" title=\"Test suite for RaftStorage\">Test suite for RaftStorage</a>, 如果通过这个测试，一般来讲，OpenRaft就可以使用他了。</p>\n<pre><code class=\"language-rust\">#[test] \npub fn test_mem_store() -&gt; anyhow::Result&lt;()&gt; { openraft::testing::Suite::test_all(MemStore::new) }</code></pre>\n<h3 id=\"race-condition-about-raftstorage\">RaftStorage的竞争状态</h3>\n<p>在我们的设计里，在一个时刻，最多有一个线程会写状态，但是，会有多个线程来进行读取。比方说，可能有多个复制任务在同时度日志和存储。</p>\n<h3>实现必须保证数据持久性</h3>\n<p>调用者会假设所有的写操作都被持久化了。而且Raft的纠错机制也是依赖于可靠的存储。</p>\n<p></p>\n<h2>3. 实现 RaftNetwork</h2>\n<p>为了节点之间对日志能够有共识，我们需要能够让节点之间进行通讯。trait <code>RaftNetwork就定义了数据传输的需求。</code>RaftNetwork的实现可以是考虑调用远端的Raft节点的服务</p>\n<pre><code class=\"language-rust\">pub trait RaftNetwork&lt;D&gt;: Send + Sync + 'static where D: AppData { \n    async fn send_append_entries(&amp;self, target: NodeId, node:Option&lt;Node&gt;, rpc: AppendEntriesRequest&lt;D&gt;) -&gt; Result&lt;AppendEntriesResponse&gt;; \n    async fn send_install_snapshot( &amp;self, target: NodeId, node:Option&lt;Node&gt;, rpc: InstallSnapshotRequest,) -&gt; Result&lt;InstallSnapshotResponse&gt;; \n    async fn send_vote(&amp;self, target: NodeId, node:Option&lt;Node&gt;, rpc: VoteRequest) -&gt; Result&lt;VoteResponse&gt;; \n}</code></pre>\n<p><a href=\"https://github.com/datafuselabs/openraft/blob/main/example-raft-kv/src/network/raft_network_impl.rs\" title=\"ExampleNetwork\">ExampleNetwork</a> 显示了如何调用传输消息。每一个Raft节点都应该提供有这样一个RPC服务。当节点收到raft rpc，服务会吧请求传递给raft实例，并且通过<a href=\"https://github.com/datafuselabs/openraft/blob/main/example-raft-kv/src/network/raft.rs\" title=\"raft-server-endpoint\">raft-server-endpoint</a>返回应答。</p>\n<p>在实际情况下可能使用 <a href=\"https://github.com/hyperium/tonic\" title=\"Tonic gRPC\">Tonic gRPC</a>是一个更好的选择。 <a href=\"https://github.com/datafuselabs/databend/blob/6603392a958ba8593b1f4b01410bebedd484c6a9/metasrv/src/network.rs#L89\" title=\"databend-meta\">databend-meta</a> 里有一个非常好的参考实现。</p>\n<p>在我们的 matchengen-raft 实现里，我们解决了原示例中大量重连的问题。</p>\n<p>1. 维护一个可服用量的client</p>\n<p>这段代码在：<a href=\"https://github.com/raymondshe/matchengine-raft/blob/master/src/network/raft_network_impl.rs\" title=\"network/raft_network_impl.rs\">network/raft_network_impl.rs</a></p>\n<pre><code class=\"language-rust\">     let clients = Arc::get_mut(&amp;mut self.clients).unwrap();\n\n     let client = clients.entry(url.clone()).or_insert(reqwest::Client::new());\n</code></pre>\n<p>2. 在服务器端引入keep_alive</p>\n<p>这段代码在：<a href=\"https://github.com/raymondshe/matchengine-raft/blob/master/src/lib.rs\" title=\"lib.rs\">lib.rs</a></p>\n<pre><code class=\"language-rust\">    // Start the actix-web server.\n    let server = HttpServer::new(move || {\n        App::new()\n            .wrap(Logger::default())\n            .wrap(Logger::new(\"%a %{User-Agent}i\"))\n            .wrap(middleware::Compress::default())\n            .app_data(app.clone())\n            // raft internal RPC\n            .service(raft::append)\n            .service(raft::snapshot)\n            .service(raft::vote)\n            // admin API\n            .service(management::init)\n            .service(management::add_learner)\n            .service(management::change_membership)\n            .service(management::metrics)\n            // application API\n            .service(api::write)\n            .service(api::read)\n            .service(api::consistent_read)\n    }).keep_alive(Duration::from_secs(5));\n</code></pre>\n<p>这样的改动确实是对性能有一些提升。但是真的需要更快的话，我们使用grpc，甚至使用 reliable multicast，比方说 <a href=\"https://datatracker.ietf.org/doc/html/rfc3208\" title=\"pgm\">pgm</a>。</p>\n<h2>4. 启动集群</h2>\n<p>由于我们保留了之前的 key/value 实现。所以之前的脚本应该还是能够工作的。而且之前的key/value 有了真正的存储。</p>\n<p>为了能够运行集群：</p>\n<p></p>\n<ul><li>启动三个没有初始化的raft节点;</li><li>初始化其中一台raft节点；</li><li>把其他的raft节点加入到这个集群里;</li><li>更新raft成员配置。</li></ul>\n<p><a href=\"https://github.com/datafuselabs/openraft/tree/main/example-raft-kv\" title=\"example-raft-kv\">example-raft-kv</a> 的readme文档里面把这些步骤都介绍的比较清楚了。</p>\n<p>下面两个测试脚本是非常有用的：</p>\n<ul><li> <p><a href=\"https://github.com/datafuselabs/openraft/blob/main/example-raft-kv/test-cluster.sh\" title=\"test-cluster.sh\">test-cluster.sh</a> 这个脚本可以简练的掩饰如何用curl和raft集群进行交互。在脚本里，您可以看到所有http请求和应答。</p> </li><li> <p><a href=\"https://github.com/datafuselabs/openraft/blob/main/example-raft-kv/tests/cluster/test_cluster.rs\" title=\"test_cluster.rs\">test_cluster.rs</a> 这个rust程序显示了怎么使用ExampleClient操作集群，发送请求和接受应答。</p> </li></ul>\n<blockquote>\n<p>这里我们要强调的是，在初始化raft集群的时候。我们需要上述的过程。如果集群已经被初始化，并且我们已经持久化了相应的状态 （menbership, vote, log) 以后，再某些节点退出并且重新加入，我们就不需要再过多干预了。</p>\n<p>在使用metasrv启动meta service的时候，我也遇到了相同的情况。所以还是要先启动一个single node以保证这个节点作为种子节点被合理初始化了。</p>\n<p><a href=\"https://databend.rs/doc/manage/metasrv/metasrv-deploy\" title=\"Deploy a Databend Meta Service Cluster | Databend\">Deploy a Databend Meta Service Cluster | Databend</a></p>\n</blockquote>\n<p>为了更好的启动管理集群，我们在项目里添加了 <a class=\"link-info\" href=\"https://github.com/raymondshe/matchengine-raft/blob/master/test.sh\" title=\"test.sh\">test.sh</a>。用法如下：</p>\n<pre><code class=\"language-bash\">./test.sh &lt;command&gt; &lt;node_id&gt;</code></pre>\n<p>我们可以在不同阶段调用不同的命令。大家有兴趣的话可以看一下代码。这部分是主程序部分，包含了我们实现的所有命令。</p>\n<pre><code class=\"language-bash\">echo \"Run command $1\"\ncase $1 in\n\"place-order\")\n    place_order $2\n    ;;\n\"metrics\")\n    get_metrics $2\n    ;;\n\n\"kill-node\")\n    kill_node $2\n    ;;\n\"kill\")\n    kill\n    ;;\n\"start-node\")\n    start_node $2\n    ;;\n\"get-seq\")\n    rpc 2100$2/read  '\"orderbook_sequance\"'\n    ;;\n\"build-cluster\")\n    build_cluster $2\n    ;;\n\"change-membership\")\n\tchange_membership $2\n    ;;\n\n\"clean\")\n    clean\n    ;;\n  *)\n    \"Nothing is done!\"\n    ;;\nesac</code></pre>\n<h1>未来的工作</h1>\n<p>当前我们实现的matchengine-raft只是为了示例怎么通过raft应用到撮合引擎这样一个对性能，稳定性，高可用要求都非常苛刻的应用场景。通过 raft 集群来完成撮合引擎的分布式管理。我们相信真正把这个玩具撮合引擎推向产品环境，我们还是需要进行很多工作：</p>\n<ol><li>优化序列化方案，serd_json固然好，但是通过字符串进行编解码还是差点儿意思。至少用到bson或者更好的用 protobuf, avro等，提高编解码速度，传输和存储的开销。</li><li>优化RaftNetwork, 在可以使用multi-cast的情况下使用pgm，如果不行，可以使用grpc。</li><li>撮合结果的分发。这部分在很多情况下依赖消息队列中间件比较好。</li><li>增加更多的撮合算法。这部分完全是业务需求，和openraft无关。我们就不在这个文章里讨论了。</li><li>完善测试和客户端的调用。</li><li>完善压测程序，准备进一步调优。</li></ol>\n<h1>结论</h1>\n<p>通过这个简单的小项目，我们：</p>\n<ol><li>实现了一个简单的玩具撮合引擎。</li><li>验证了OpenRaft在功能上对撮合引擎场景的支持能力。</li><li>给OpenRaft提供了一个基于 sled KV存储的日志存储的参考实现。</li><li>给OpenRaft提供了一个基于本地文件的快照存储的参考实现。</li></ol>\n<p>给大家透露一个小秘密，SAP也在使用OpenRaft来构建关键应用。大家想想，都用到Raft协议了，一定是非常重要的应用。</p>\n<p>对于 databend 社群的帮助，我表示由衷的感谢。作为一个长期工作在软件行业一线的老程序猿，看到中国开源软件开始在基础构建发力，由衷的感到欣慰。也希望中国开源社群越来越好，越来越强大，走向软件行业的顶端。</p>\n</div>\n</div>", "first_tag": "SQL", "cpp": 0, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 1, "php": 0, "time": "2022-07-18 10:22:26", "summary": "由于工作需要，一直对原子多播应用有非常浓厚的兴趣。通过一段时间的技术选型。我们非常幸运的得到了社群的热心支持。我也想通过我们的实际工作，对的未来应用尽一些微薄之力。我的实践的上一篇文章反应了我们的选型"}