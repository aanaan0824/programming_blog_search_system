{"blogid": "126665854", "writerAge": "码龄1年", "writerBlogNum": "407", "writerCollect": "121", "writerComment": "16", "writerFan": "5191", "writerGrade": "5级", "writerIntegral": "4357", "writerName": "web17886480312", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126665854.jpg", "writerRankTotal": "4540", "writerRankWeekly": "1496", "writerThumb": "30", "writerVisitNum": "153795", "blog_read_count": "128", "blog_time": "于 2022-09-02 16:24:46 发布", "blog_title": "Hadoop和Spark的对比", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p>Hadoop</p>\n<p>Spark</p>\n<p>场景</p>\n<p>大数据数据集的批处理</p>\n<p>迭代计算、流计算</p>\n<p>编程范式</p>\n<p>Map+Reduce API较低层，适应性差</p>\n<p>RDD组成DAG有向无环图，API顶层，方便使用</p>\n<p>存储</p>\n<p>中间结果在磁盘，延迟大</p>\n<p>RDD结果在内存，延迟小</p>\n<p>运行方式</p>\n<p>Task以进程方式维护，启动任务慢</p>\n<p>Task以线程方式维护，启动快</p>\n<h2><a id=\"1__30\"></a>1. 原理比较</h2>\n<p>Hadoop和Spark都是并行计算，</p>\n<p><strong>Hadoop</strong>一个作业称为一个Job，Job里面分为Map Task和Reduce Task阶段，每个Task都在自己的<strong>进程</strong>中运行，当Task结束时，<strong>进程</strong>也会随之结束；<br/> 好处在于进程之间是互相独立的，每个task独享进程资源，没有互相干扰，监控方便，<br/> 但是问题在于<strong>task之间不方便共享数据，执行效率比较低</strong>。比如多个map task读取不同数据源文件需要将数据源加载到每个map task中，造成重复加载和浪费内存。</p>\n<p><strong>Spark</strong>的任务称为application，一个SparkContext对应一个application；<br/> application中存在多个job，每触发一次行动算子就会产生一个job；<br/> 每个job中有多个stage，stage是shuffle过程中DAGScheduler通过RDD之间的依赖关系划分job而来的，stage数量=宽依赖（shuffle）数量+1 （默认有一个ResultStage）；<br/> 每个stage里面有多个task，组成taskset，由TaskScheduler分发到各个executor中执行；<br/> executor的生命周期是和application一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。<br/> Spark基于<strong>线程</strong>的方式计算是为了数据共享和提高执行效率，<br/> Spark采用了线程的最小的执行单位，但缺点是线程之间会有资源竞争。</p>\n<h2><a id=\"2__47\"></a>2. 应用场景</h2>\n<p><strong>Hadoop MapReduce</strong> 其设计初衷是<strong>一次性数据计算</strong>（一个job中 只有一次map和reduce），并不是为了满足循环迭代式数据流处理，因此在多并行运行的数据可复用场景（如：机器学习、图挖掘算法、交互式数据挖掘算法）中存在诸多计算效率等问题(使用磁盘交互，进度非常慢)。</p>\n<p><strong>Spark</strong> 应运而生，Spark 就是在传统的MapReduce 计算框架的基础上，利用其计算过程的优化，从而大大加快了数据分析、挖掘的运行和读写速度，并将计算单元缩小到更适合并行计算和重复使用的<strong>RDD</strong> 计算模型。<br/> <strong>Spark</strong>将job的结果放到了<strong>内存</strong>当中，为下一次计算提供了更加便利的处理方式，所以Spark做迭代效率更高。</p>\n<p><strong>Hadoop</strong>适合处理静态数据，对于迭代式流式数据的处理能力差；<br/> <strong>Spark</strong>通过在内存中缓存处理的数据，提高了处理流式数据和迭代式数据的性能；</p>\n<h2><a id=\"3__58\"></a>3. 处理速度</h2>\n<p><strong>Hadoop</strong>是磁盘级计算，<strong>计算时需要在磁盘中读取数据</strong>；其采用的是MapReduce的逻辑，把数据进行切片计算用这种方式来处理大量的离线数据.；</p>\n<p><strong>Spark</strong>它会在内存中以接近“实时”的时间完成所有的数据分析。Spark的批处理速度比MapReduce快近10倍，【内存中】的数据分析速度则快近100倍。</p>\n<h2><a id=\"4__65\"></a>4. 启动速度</h2>\n<p>Spark Task 的启动时间快。Spark 采用 fork 线程的方式，而 Hadoop 采用创建新的进程的方式。</p>\n<h2><a id=\"5__70\"></a>5. 中间结果存储</h2>\n<p><strong>Hadoop</strong>中 ，中间结果存放在<strong>HDFS</strong>中，每次MR都需要刷写-调用<br/> <strong>Spark</strong>中间结果存放优先存放在<strong>内存</strong>中，内存不够再存放在磁盘中，不放入HDFS，避免了大量的IO和刷写读取操作；</p>\n<h2><a id=\"6__76\"></a>6. 根本差异</h2>\n<p>Spark 和Hadoop 的根本差异是多个作业之间的数据通信问题 : Spark 多个作业之间数据通信是基于<strong>内存</strong>，而 Hadoop 是基于<strong>磁盘</strong>。<br/> <img alt=\"在这里插入图片描述\" src=\"..\\..\\static\\image\\e60b0e09393f48658ae4a0ba6a4fcec5.png\"/></p>\n<p>Spark 只有在 shuffle 的时候将数据写入磁盘，而 Hadoop 中多个 MR 作业之间的数据交互都要依赖于磁盘交互</p>\n<h2><a id=\"SparkHadoop__84\"></a>Spark能否代替Hadoop ？</h2>\n<p>但是Spark 是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致 Job 执行失败，此时，MapReduce 其实是一个更好的选择，所以 Spark 并不能完全替代 MR</p>\n<p>参考：https://blog.csdn.net/weixin_42058550/article/details/121951509</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Others", "cpp": 0, "csharp": 0, "python": 0, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-02 16:24:46", "summary": "场景大数据数据集的批处理迭代计算、流计算编程范式较低层，适应性差组成有向无环图，顶层，方便使用存储中间结果在磁盘，延迟大结果在内存，延迟小运行方式以进程方式维护，启动任务慢以线程方式维护，启动快原理比"}