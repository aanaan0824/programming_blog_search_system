{"blogid": "126464870", "writerAge": "码龄1年", "writerBlogNum": "79", "writerCollect": "3725", "writerComment": "3286", "writerFan": "5894", "writerGrade": "7级", "writerIntegral": "9793", "writerName": "knighthood2001", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126464870.jpg", "writerRankTotal": "1343", "writerRankWeekly": "41", "writerThumb": "3239", "writerVisitNum": "158303", "blog_read_count": "1100", "blog_time": "于 2022-08-23 06:00:00 发布", "blog_title": "【tensorflow】制作自己的数据集", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"htmledit_views\" id=\"content_views\">\n<blockquote>\n<p>  🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝🔝</p>\n<p><strong>🥰 博客首页：<strong><a href=\"https://blog.csdn.net/knighthood2001?type=blog\" title=\"knighthood2001\">knighthood2001</a></strong></strong></p>\n<p><strong>😗 欢迎点赞👍评论🗨️</strong></p>\n<p><strong>❤️ 热爱python，期待与大家一同进步成长！！❤️</strong></p>\n<p><strong>👀<strong><a href=\"https://www.nowcoder.com/link/pc_csdncpt_knight_python\" title=\"给大家推荐一款很火爆的刷题、面试求职网站\">给大家推荐一款很火爆的刷题、面试求职网站</a></strong>👀</strong></p>\n<p><strong>跟我一起来巩固基础和刷题吧</strong></p>\n</blockquote>\n<p id=\"main-toc\"><strong>目录</strong></p>\n<p id=\"%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D-toc\" style=\"margin-left:0px;\"><strong><a href=\"#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">数据集的基本介绍</span></span></a></strong></p>\n<p id=\"tensorflow%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86-toc\" style=\"margin-left:0px;\"><strong><a href=\"#tensorflow%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">tensorflow中的数据集</span></span></a></strong></p>\n<p id=\"%E4%BB%80%E4%B9%88%E6%98%AFTFDS-toc\" style=\"margin-left:0px;\"><strong><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFTFDS\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">什么是TFDS</span></span></a></strong></p>\n<p id=\"%E5%AE%89%E8%A3%85TFDS-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E5%AE%89%E8%A3%85TFDS\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">安装TFDS</span></span></a></strong></p>\n<p id=\"%E7%94%A8TFDS%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E7%94%A8TFDS%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">用TFDS加载数据集</span></span></a></strong></p>\n<p id=\"%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%B0%86%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%88%B6%E4%BD%9C%E6%88%90%E5%86%85%E5%AD%98%E5%AF%B9%E8%B1%A1%E6%95%B0%E6%8D%AE%E9%9B%86-toc\" style=\"margin-left:0px;\"><strong><a href=\"#%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%B0%86%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%88%B6%E4%BD%9C%E6%88%90%E5%86%85%E5%AD%98%E5%AF%B9%E8%B1%A1%E6%95%B0%E6%8D%AE%E9%9B%86\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">实例：将模拟数据制作成内存对象数据集</span></span></a></strong></p>\n<p id=\"%E2%91%A0%E7%94%9F%E6%88%90%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E2%91%A0%E7%94%9F%E6%88%90%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">①生成模拟数据</span></span></a></strong></p>\n<p id=\"%E2%91%A1%E5%AE%9A%E4%B9%89%E5%8D%A0%E4%BD%8D%E7%AC%A6-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E2%91%A1%E5%AE%9A%E4%B9%89%E5%8D%A0%E4%BD%8D%E7%AC%A6\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">②定义占位符</span></span></a></strong></p>\n<p id=\"%E2%91%A2%E5%BB%BA%E7%AB%8Bsession%E4%BC%9A%E8%AF%9D%EF%BC%8C%E8%8E%B7%E5%8F%96%E5%B9%B6%E6%98%BE%E7%A4%BA%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E3%80%82-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E2%91%A2%E5%BB%BA%E7%AB%8Bsession%E4%BC%9A%E8%AF%9D%EF%BC%8C%E8%8E%B7%E5%8F%96%E5%B9%B6%E6%98%BE%E7%A4%BA%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E3%80%82\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">③建立session会话，获取并显示模拟数据。</span></span></a></strong></p>\n<p id=\"%E2%91%A3%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E2%91%A3%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">④模拟数据可视化</span></span></a></strong></p>\n<p id=\"%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C-toc\" style=\"margin-left:40px;\"><strong><a href=\"#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">运行结果</span></span></a></strong></p>\n<p id=\"%E6%94%B9%E8%BF%9B%EF%BC%9A%E5%88%9B%E5%BB%BA%E5%B8%A6%E6%9C%89%E8%BF%AD%E4%BB%A3%E5%80%BC%E5%B9%B6%E6%94%AF%E6%8C%81%E4%B9%B1%E5%BA%8F%E5%8A%9F%E8%83%BD%E7%9A%84%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0-toc\" style=\"margin-left:0px;\"><strong><a href=\"#%E6%94%B9%E8%BF%9B%EF%BC%9A%E5%88%9B%E5%BB%BA%E5%B8%A6%E6%9C%89%E8%BF%AD%E4%BB%A3%E5%80%BC%E5%B9%B6%E6%94%AF%E6%8C%81%E4%B9%B1%E5%BA%8F%E5%8A%9F%E8%83%BD%E7%9A%84%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0\"><span style=\"color:#1c7331;\"><span style=\"background-color:#fefcd8;\">改进：创建带有迭代值并支持乱序功能的模拟数据集 </span></span></a></strong></p>\n<hr id=\"hr-toc\"/>\n<p></p>\n<h1 id=\"%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D\"><strong>数据集的基本介绍</strong></h1>\n<p>        数据集是样本的集合，在深度学习中，数据集用于模型训练。再用tensorflow框架开发深度学习模型之前，需要为模型准备好数据集。在训练模型环节，程序需要从数据集中不断地将数据输入模型，模型通过对注入数据的计算来学习特征。</p>\n<h1 id=\"tensorflow%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86\"><strong>tensorflow中的数据集</strong></h1>\n<p><span style=\"color:#ff9900;\">tensorflow中有4种数据集格式</span></p>\n<p><strong>        <span style=\"background-color:#e7fafa;\">内存对象数据集：</span></strong>直接用字典变量feed_dict，通过注入模式向模型中输入数据。<span style=\"color:#956fe7;\"><strong>该数据集适用于少量的数据集输入。</strong></span></p>\n<p><strong>        <span style=\"background-color:#e7fafa;\">TFRecord数据集：</span></strong>用队列式管道（tfrecord）向模型输入数据。<span style=\"color:#956fe7;\"><strong>该数据集适用大量的数据集输入。</strong></span></p>\n<p><strong>        <span style=\"background-color:#e7fafa;\">Dataset数据集：</span></strong>通过性能更高的输入管道（tf.data）向模型输入数据。该数据集适用于tensorflow1.4之后的版本。</p>\n<p><strong>        <span style=\"background-color:#e7fafa;\">tf.keras接口数据集：</span></strong>支持tf.keras语法的数据集接口。该数据集适用于tensorflow1.4之后的版本。</p>\n<h1 id=\"%E4%BB%80%E4%B9%88%E6%98%AFTFDS\"><strong>什么是TFDS</strong></h1>\n<p>        TFDS是tensorflow中的数据集集合模块，该模块将常用的数据及封装起来，实现自动下载与统一的调用接口，为开发模型提供了便利。</p>\n<h2 id=\"%E5%AE%89%E8%A3%85TFDS\"><strong>安装TFDS</strong></h2>\n<p>要求：tensorflow版本在1.12及以上。安装命令如下：</p>\n<pre><code class=\"language-python\">pip install tensorflow-datasets</code></pre>\n<h2 id=\"%E7%94%A8TFDS%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86\"><strong>用TFDS加载数据集</strong></h2>\n<p><strong>这里以minst数据集为例</strong></p>\n<pre><code class=\"language-python\">import tensorflow_datasets as tfds\nprint(tfds.list_builders())\nds_train, ds_test = tfds.load(name='mnist', split=[\"train\", \"test\"])\nds_train = ds_train.shuffle(1000).batch(128).prefetch(10)\nfor features in ds_train.take(1):\n    image, label = features[\"image\"], [\"label\"]</code></pre>\n<p>重要结果如下：</p>\n<pre><code class=\"language-python\">Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\mnist\\3.0.1...\n\nDataset mnist downloaded and prepared to ~\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.</code></pre>\n<h1 id=\"%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%B0%86%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%88%B6%E4%BD%9C%E6%88%90%E5%86%85%E5%AD%98%E5%AF%B9%E8%B1%A1%E6%95%B0%E6%8D%AE%E9%9B%86\"><strong>实例：将模拟数据制作成内存对象数据集</strong></h1>\n<p>        本实例将用内存中的模拟数据来制作成数据集，生成的数据集被直接存放在python内存对象中，这样做的好处--<span style=\"color:#1c7331;\"><strong>数据集的制作可以独立于任何框架</strong></span>。</p>\n<p>        本实例将生成一个模拟y≈2x的数据集，并通过静态图的方式显示出来。</p>\n<blockquote>\n<p><strong>步骤如下：</strong></p>\n<p><strong>①生成模拟数据</strong></p>\n<p><strong>②定义占位符</strong></p>\n<p><strong>③建立session会话，获取并显示模拟数据。</strong></p>\n<p><strong>④模拟数据可视化</strong></p>\n</blockquote>\n<h2 id=\"%E2%91%A0%E7%94%9F%E6%88%90%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE\"><strong>①生成模拟数据</strong></h2>\n<p>        在样本制作过程中，最忌讳的是一次性将数据都放入内存中，如果数据量很大，这样容易造成内存用尽，即使是模拟数据，也不建议将数据全部生成以后一次性放入内存中，一般做法是：</p>\n<p><span style=\"background-color:#ffd900;\">Ⅰ创建一个模拟数据生成器，</span></p>\n<p><span style=\"background-color:#ffd900;\">Ⅱ每次只生成指定批次的样本</span></p>\n<p>这样就在迭代过程中，就可以用“随用随制作”的方法来获取样本数据。</p>\n<p>        下面定义GenerateData函数来生成模拟数据，并将GenerateData函数的返回值设为以生成器方式返回。这种做法<strong>使内存被占用的最少</strong>。</p>\n<pre><code class=\"language-python\">import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntf.compat.v1.disable_v2_behavior()\n\n#在内存中生成模拟数据\ndef GenerateData(batchsize = 100):\n    train_X = np.linspace(-1, 1, batchsize)   #train_X为-1到1之间连续的100个浮点数\n    train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3 # y=2x，但是加入了噪声\n    yield train_X, train_Y       #以生成器的方式返回</code></pre>\n<p>        <span style=\"color:#fe2c24;\"><strong>函数使用yield，使得函数以生成器的方式返回数据。生成器对象只生成一次，过后便会自动销毁，可以省略大量的内存。</strong></span></p>\n<h2 id=\"%E2%91%A1%E5%AE%9A%E4%B9%89%E5%8D%A0%E4%BD%8D%E7%AC%A6\"><strong>②定义占位符</strong></h2>\n<pre><code class=\"language-python\">#定义网络模型结构部分，这里只有占位符张量\nXinput = tf.compat.v1.placeholder(\"float\", (None))\nYinput = tf.compat.v1.placeholder(\"float\", (None))</code></pre>\n<p><span style=\"color:#fe2c24;\"><strong>注意：</strong></span>在正常的模型开发中，这个环节应该是定义占位符和网络结构，在训练模型时，系统会将数据集的输入数据用占位符来代替，并使用静态图的注入机制，将输入数据传入模型进行迭代训练。因为本实例只需要从数据集中获取数据，所以只定义占位符，不需要定义其他网络节点。</p>\n<h2 id=\"%E2%91%A2%E5%BB%BA%E7%AB%8Bsession%E4%BC%9A%E8%AF%9D%EF%BC%8C%E8%8E%B7%E5%8F%96%E5%B9%B6%E6%98%BE%E7%A4%BA%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E3%80%82\"><strong>③建立session会话，获取并显示模拟数据。</strong></h2>\n<p><strong>        首先定义数据集的迭代次数，接着建立会话，在会话中使用两层for循环；第一层是按照迭代次数来循环，第二层是对GenerateData函数返回的生成器对象进行循环，并将数据打印出来。</strong></p>\n<p><strong>        因为GenerateData</strong><strong>函数返回的生成器对象只有一个元素，所以第二层循环也只运行一次。</strong></p>\n<pre><code class=\"language-python\">#建立会话，获取并输出数据\ntraining_epochs = 20  # 定义需要迭代的次数\nwith tf.compat.v1.Session() as sess:  # 建立会话（session）\n    for epoch in range(training_epochs): #迭代数据集20遍\n        for x, y in GenerateData(): #通过for循环打印所有的点\n            xv,yv = sess.run([Xinput,Yinput],feed_dict={Xinput: x, Yinput: y}) #通过静态图注入的方式，传入数据\n\n            print(epoch,\"| x.shape:\",np.shape(xv),\"| x[:3]:\",xv[:3])\n            print(epoch,\"| y.shape:\",np.shape(yv),\"| y[:3]:\",yv[:3])</code></pre>\n<p><span style=\"background-color:#d4e9d5;\">代码开始定义了数据集的迭代次数，这个参数在训练模型中才会用到。</span></p>\n<h2 id=\"%E2%91%A3%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96\"><strong>④模拟数据可视化</strong></h2>\n<pre><code class=\"language-python\">#显示模拟数据点\ntrain_data = list(GenerateData())[0]\nplt.plot(train_data[0], train_data[1], 'ro', label='Original data')\nplt.legend()\nplt.show()</code></pre>\n<h2 id=\"%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C\"><strong>运行结果</strong></h2>\n<p> </p>\n<pre><code class=\"language-python\">...\n17 |x.shape: (100,) |x[:3]: [-1.         -0.97979796 -0.959596  ]\n17 |y.shape: (100,) |y[:3]: [-2.0945473 -2.1236315 -1.6280223]\n18 |x.shape: (100,) |x[:3]: [-1.         -0.97979796 -0.959596  ]\n18 |y.shape: (100,) |y[:3]: [-2.022675  -2.118289  -1.8735064]\n19 |x.shape: (100,) |x[:3]: [-1.         -0.97979796 -0.959596  ]\n19 |y.shape: (100,) |y[:3]: [-2.0080116 -2.5169287 -1.6713679]</code></pre>\n<p>每行数据被|符号划分为3块区域，分别为：迭代次数、数据的形状、前三个元素的值。</p>\n<p>可视化结果如下</p>\n<p><img alt=\"\" height=\"356\" src=\"..\\..\\static\\image\\9fce6539763e4fcc99a61a35629dd711.png\" width=\"475\"/></p>\n<h1 id=\"%E6%94%B9%E8%BF%9B%EF%BC%9A%E5%88%9B%E5%BB%BA%E5%B8%A6%E6%9C%89%E8%BF%AD%E4%BB%A3%E5%80%BC%E5%B9%B6%E6%94%AF%E6%8C%81%E4%B9%B1%E5%BA%8F%E5%8A%9F%E8%83%BD%E7%9A%84%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0\"><strong>改进：创建带有迭代值并支持乱序功能的模拟数据集 </strong></h1>\n<p>优化如下：</p>\n<p><strong>①将数据集与 迭代功能绑定在一起，让代码变得更简洁。</strong></p>\n<p><strong>②对数据集进行乱序排序，让生成的x数据无规则 。</strong></p>\n<p>通过对数据集的乱序，可以消除样本中无用的特征，从而大大提升模型的泛化能力。</p>\n<blockquote>\n<p>注意：</p>\n<p>在乱序操作部分使用的是sklearn.utils库中的shuffle()方法。要使用，首先需要安装，命令如下：</p>\n<pre><code class=\"language-python\">pip install sklearn</code></pre>\n</blockquote>\n<p>改进后全部代码如下： </p>\n<pre><code class=\"language-python\">import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\ntf.compat.v1.disable_v2_behavior()\n\ndef GenerateData(training_epochs,batchsize=100):\n    for i in range(training_epochs):\n        train_X=np.linspace(-1,1,batchsize)\n        train_Y=2*train_X+np.random.randn(*train_X.shape)*0.3\n        yield shuffle(train_X,train_Y),i\n\nXinput=tf.compat.v1.placeholder(\"float\",(None))\nYinput=tf.compat.v1.placeholder(\"float\",(None))\n\ntraining_epochs=20\nwith tf.compat.v1.Session() as sess:\n    for (x,y),ii in GenerateData(training_epochs):\n        xv,yv=sess.run([Xinput,Yinput],feed_dict={Xinput:x,Yinput:y})\n            \n        print(ii,\"|x.shape:\",np.shape(xv),\"|x[:3]:\",xv[:3])\n        print(ii,\"|y.shape:\",np.shape(yv),\"|y[:3]:\",yv[:3])\n            \ntrain_data=list(GenerateData(1))[0]\nplt.plot(train_data[0][0],train_data[0][1],'ro',label='Original data')\nplt.legend()\nplt.show()</code></pre>\n<p>可视化结果图片如下：</p>\n<p><img alt=\"\" height=\"345\" src=\"..\\..\\static\\image\\5543039e3b5140c6945f6258f0b7f197.png\" width=\"460\"/></p>\n<p> </p>\n</div>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-08-23 06:00:00", "summary": "博客首页：欢迎点赞评论热爱，期待与大家一同进步成长！！给大家推荐一款很火爆的刷题、面试求职网站给大家推荐一款很火爆的刷题、面试求职网站跟我一起来巩固基础和刷题吧目录数据集的基本介绍中的数据集什么是安装"}