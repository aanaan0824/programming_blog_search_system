{"blogid": "126411411", "writerAge": "码龄1年", "writerBlogNum": "28", "writerCollect": "733", "writerComment": "913", "writerFan": "2240", "writerGrade": "5级", "writerIntegral": "2892", "writerName": "清风莫追", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126411411.jpg", "writerRankTotal": "6332", "writerRankWeekly": "107", "writerThumb": "817", "writerVisitNum": "26307", "blog_read_count": "843", "blog_time": "已于 2022-08-23 20:33:01 修改", "blog_title": "【深度学习】4-梯度确认时遇bug：写了个糟糕的softmax函数", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-github-gist\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<h1><a id=\"__0\"></a>🚩 前言</h1>\n<blockquote>\n<p>活动地址：<a href=\"https://marketing.csdn.net/p/bdabfb52c5d56532133df2adc1a728fd\">CSDN21天学习挑战赛</a><br/> 🚀 博主主页：<a href=\"https://blog.csdn.net/m0_63238256?spm\">阿阿阿阿锋的主页_CSDN</a><br/> 🌊 <em>希望和大家一起加油，一起进步！</em></p>\n</blockquote>\n<p><em>今天学习《深度学习入门：基于python的理论与实践》时，被<strong>梯度确认</strong>的问题卡了很久。具体过程就不赘述，最终发现是我写的 softmax 函数的问题，导致的数值微分与反向传播求得的梯度总对不上。</em><br/> <em>softmax 问题在于我这里没有考虑好不同维度数据的情况。</em></p>\n<hr/>\n<p></p>\n<div class=\"toc\">\n<h3>文章目录</h3>\n<ul><li><a href=\"#__0\">🚩 前言</a></li><li><a href=\"#1_softmax_12\">1. softmax函数代码</a></li><li><a href=\"#2__23\">2. 不能正确处理批量样本</a></li><li><a href=\"#3__71\">3. 解决方案</a></li></ul>\n</div>\n<p></p>\n<hr/>\n<h1><a id=\"1_softmax_12\"></a>1. softmax函数代码</h1>\n<pre><code class=\"prism language-py\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">softmax</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    a <span class=\"token operator\">-=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\n    exp_a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> exp_a <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>exp_a<span class=\"token punctuation\">)</span>\n</code></pre>\n<h1><a id=\"2__23\"></a>2. 不能正确处理批量样本</h1>\n<p>我们对比一下处理单个样本和批量样本的情况：</p>\n<pre><code class=\"prism language-py\">a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nsoftmax<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> softmax<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span>\n\n</code></pre>\n<pre><code>输出：\n(array([0.09003057, 0.24472847, 0.66524096]),\n array([[0.04501529, 0.12236424, 0.33262048],\n        [0.04501529, 0.12236424, 0.33262048]]))\n</code></pre>\n<p>容易发现，对应的值，<strong>后者的结果都是前者的一半</strong>。问题就在<code>np.sum(exp_a)</code>这里：<br/> 在批量数据（矩阵）情况下，我们本意是每个样本求得一个和值，即按行求和。它却将所有数据相加而仅得到一个和值。</p>\n<p>再验证一下：</p>\n<pre><code class=\"prism language-py\">a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nsoftmax<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> softmax<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span>\n</code></pre>\n<pre><code>输出：\n(array([0.09003057, 0.24472847, 0.66524096]),\n array([[0.03001019, 0.08157616, 0.22174699],\n        [0.03001019, 0.08157616, 0.22174699],\n        [0.03001019, 0.08157616, 0.22174699]]))\n</code></pre>\n<p>可以看到，样本数增加为 3 个时，后者的输出也相应地变成了前者的<strong>三分之一</strong>。此时前者输出的 3 个数和为 1 ，而后者是输出的 9 个数和为 1。</p>\n<p>现在单样本和批量的输出之间还具有倍数关系，如果<strong>每个样本是数据不同</strong>，那么将会更加乱套：</p>\n<pre><code class=\"prism language-py\">a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nsoftmax<span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> softmax<span class=\"token punctuation\">(</span>b<span class=\"token punctuation\">)</span>\n</code></pre>\n<pre><code>输出：\n(array([0.09003057, 0.24472847, 0.66524096]),\n array([[0.00426978, 0.01160646, 0.03154963],\n        [0.08576079, 0.23312201, 0.63369132]]))\n</code></pre>\n<h1><a id=\"3__71\"></a>3. 解决方案</h1>\n<p>分情况处理即可：</p>\n<pre><code class=\"prism language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">softmax</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> x<span class=\"token punctuation\">.</span>ndim <span class=\"token operator\">==</span> <span class=\"token number\">2</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>T\n        x <span class=\"token operator\">=</span> x <span class=\"token operator\">-</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> y<span class=\"token punctuation\">.</span>T \n\n    x <span class=\"token operator\">=</span> x <span class=\"token operator\">-</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> \n    <span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p><code>注：此代码来自前言提到的书本</code><br/> 我们之前分析了，其实就是求和函数的问题，因此我尝试着能不能写得更加简洁和统一些。</p>\n<p>但是我没有成功，因为会遇到一些<strong>细节处理</strong>上的问题，例如批量情况下：最大值 max 也应当是按行求得；<code>np.sum</code>得到的是一维数组，为了最后相除时能够进行广播，进行<strong>转置</strong>是有必要的。</p>\n<p>不过修改代码的尝试倒是加深了我对它的理解。</p>\n<hr/>\n<p><em>感谢阅读</em></p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-08-23 20:33:01", "summary": "前言活动地址：天学习挑战赛博主主页：阿阿阿阿锋的主页希望和大家一起加油，一起进步！今天学习《深度学习入门：基于的理论与实践》时，被梯度确认的问题卡了很久。具体过程就不赘述，最终发现是我写的函数的问题，"}