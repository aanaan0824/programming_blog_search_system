{"blogid": "126698265", "writerAge": "码龄5年", "writerBlogNum": "47", "writerCollect": "3396", "writerComment": "123", "writerFan": "382", "writerGrade": "5级", "writerIntegral": "2891", "writerName": "长浔", "writerProfileAdress": "..\\..\\static\\writer_image\\profile_126698265.jpg", "writerRankTotal": "907777", "writerRankWeekly": "40374", "writerThumb": "521", "writerVisitNum": "584711", "blog_read_count": "11", "blog_time": "于 2022-09-07 12:44:43 发布", "blog_title": "CNN经典架构", "content": "<div class=\"article_content clearfix\" id=\"article_content\">\n<link href=\"../../static/bootstrap/css/csdnstyle.css\" rel=\"stylesheet\"/>\n<div class=\"markdown_views prism-atom-one-dark\" id=\"content_views\">\n<svg style=\"display: none;\" xmlns=\"http://www.w3.org/2000/svg\">\n<path d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" stroke-linecap=\"round\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path>\n</svg>\n<p></p>\n<div class=\"toc\">\n<h3>目录</h3>\n<ul><li><a href=\"#_4\">前言</a></li><li><a href=\"#LeNet_18\">一、LeNet</a></li><li><a href=\"#AlexNet_69\">二、AlexNet</a></li><li><a href=\"#VGGNetVGG16_142\">三、VGGNet（VGG-16）</a></li><li><a href=\"#ResNet_227\">四、ResNet</a></li><li><a href=\"#GoogLeNet_345\">五、GoogLeNet</a></li><li><a href=\"#_484\">总结</a></li></ul>\n</div>\n<p></p>\n<hr/>\n<h1><a id=\"_4\"></a>前言</h1>\n<p>近几年来，我们见证了无数CNN的诞生，本篇文章介绍了CNN的5种经典架构：</p>\n<ul><li>LeNet</li><li>AlexNet</li><li>VGGNet（VGG-16）</li><li>ResNet</li><li>GoogLeNet</li></ul>\n<p>MNIST数据集手写数字识别请移步：<a href=\"https://blog.csdn.net/qq_41664447/article/details/126698428\">PyTorch实现MNIST数据集手写数字识别</a></p>\n<hr/>\n<p><code>以下面案例可供参考</code></p>\n<h1><a id=\"LeNet_18\"></a>一、LeNet</h1>\n<p><img alt=\"LeNet神经网络结构\" src=\"..\\..\\static\\image\\20201007115422578.png\"/><br/> 在 LeNet 中，第一个卷积池化层就像是提取线稿，第二个卷积池化层就像是提取框架，然后放入全连接网络中进行训练，<strong>拟合</strong>出一个函数。</p>\n<p>LeNet模型结构：</p>\n<ul><li>2个<strong>卷积-池化层</strong></li><li>3个<strong>全连接层</strong></li></ul>\n<p>模型代码如下：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">LeNet</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> label_num<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>LeNet<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 卷积层 (1*28*28) -&gt; 6*28*28)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 池化层 (6*28*28) -&gt; (6*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 卷积层 (6*14*14) -&gt; (16*10*10)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 池化层 (16*10*10) -&gt; (16*5*5)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 将卷积池化后的tensor拉成向量</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 16*5*5 -&gt; 120</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">16</span> <span class=\"token operator\">*</span> <span class=\"token number\">5</span> <span class=\"token operator\">*</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">120</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 120 -&gt; 84</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">120</span><span class=\"token punctuation\">,</span> <span class=\"token number\">84</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 84 -&gt; 10</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">84</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n</code></pre>\n<p>运行结果（MNIST数据集手写数字识别结果）：</p>\n<p><img alt=\"LeNet模型准确率变化图\" src=\"..\\..\\static\\image\\bb2e748876694b37b535561b89a1b83c.png\"/><br/> <img alt=\"LeNet模型损失变化图\" src=\"..\\..\\static\\image\\b8052cea29624453ac359f9657e9734f.png\"/></p>\n<h1><a id=\"AlexNet_69\"></a>二、AlexNet</h1>\n<p><img alt=\"AlexNet网络结构\" src=\"..\\..\\static\\image\\d430447fb35a46848890fc6b5cf04032.png\"/></p>\n<p>AlexNet是2012年ImageNet竞赛冠军获得者Hinton和他的学生Alex Krizhevsky设计的。特点是在全连接层的前两层中首次使用了 Dropout 随机失活神经元操作，引入Dropout主要是为了防止过拟合。</p>\n<p>AlexNet模型结构：</p>\n<ul><li>5 层卷积（2<strong>卷积-池化层</strong>+3<strong>卷积层</strong>+1<strong>池化层</strong>）</li><li>3 个<strong>全连接层</strong></li></ul>\n<p>模型代码如下：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">AlexNet</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> label_num<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>AlexNet<span class=\"token punctuation\">,</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 卷积层 (1*28*28) -&gt; (24*28*28)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">24</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 池化层 (24*28*28) -&gt; (24*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>LocalResponseNorm<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 卷积层 (24*14*14) -&gt; (64*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">24</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 池化层 (64*14*14) -&gt; (64*7*7)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>LocalResponseNorm<span class=\"token punctuation\">(</span>size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 卷积层 (64*7*7) -&gt; (96*7*7)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">96</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 卷积层 (96*7*7) -&gt; (96*7*7)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">96</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">96</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 卷积层 (96*7*7) -&gt; (64*7*7)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">96</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 池化层 (64*7*7) -&gt; (64*3*3)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># 将卷积池化后的tensor拉成向量</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># dropout</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 (64*3*3) -&gt; (512)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">64</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># dropout</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 (512) -&gt; (512)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> <span class=\"token number\">512</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># dropout</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># 全连接层 (512) -&gt; (10)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n</code></pre>\n<p>运行结果：<br/> <img alt=\"AlexNet模型准确率变化图\" src=\"..\\..\\static\\image\\91f8edc950ff4d4e80fbcc1b40eadf15.png\"/><br/> <img alt=\"AlexNet模型损失变化图\" src=\"..\\..\\static\\image\\edffc93835e4412c89c62d82f98bc49d.png\"/></p>\n<h1><a id=\"VGGNetVGG16_142\"></a>三、VGGNet（VGG-16）</h1>\n<p><img alt=\"VGGNet模型网络结构\" src=\"..\\..\\static\\image\\75fb782545eb4f619d79c07b12ad1ebc.png\"/></p>\n<p>到现在为止，你可能已经注意到 CNN 开始变得越来越深入。这是因为提高深度神经网络性能最直接的方法是增加它们的大小。Visual Geometry Group (VGG) 的人发明了 VGG-16，它有 13 个卷积层和 3 个全连接层，同时继承了 AlexNet 的 ReLU 传统。该网络在 AlexNet 上堆叠了更多层，并使用了更小的过滤器（2×2 和 3×3）。</p>\n<p>VGGNet模型结构：</p>\n<ul><li>13个卷积层（2个 <strong>卷积(2)-池化</strong> + 3个 <strong>卷积(3)-池化</strong>）</li><li>3个<strong>全连接层</strong></li></ul>\n<p>模型代码如下：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">VGGNet</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> label_num <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>VGGNet<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_4 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_5 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">32</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span> <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_4<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_5<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n</code></pre>\n<p>这里提一下，使用多个3×3卷积堆叠的作用有两个：</p>\n<ol><li>在不影响感受野的前提下减少了参数；</li><li>增加了网络的非线性。</li></ol>\n<p>由于MNIST数据集过于简单，在使用VGGNet<br/> 出来了</p>\n<h1><a id=\"ResNet_227\"></a>四、ResNet</h1>\n<p>从过去的几个 CNN 中，我们只看到设计中的层数越来越多，并获得了更好的性能。但<strong>网络层数达到一定深度的时候，准确率就会达到饱和，然后迅速下降。</strong><br/> 原因是由于当神经网络越来越深的时候，反传回来的梯度之间的相关性会越来越差，最后接近白噪声。</p>\n<p>微软研究院的人用 ResNet 解决了这个问题——使用跳过连接（又名快捷连接，残差），同时构建更深层次的模型。<br/> <img alt=\"ResNet的网络结构\" src=\"..\\..\\static\\image\\20190731144208639.png\"/><br/> ResNet 是批标准化的早期采用者之一（由 Ioffe 和 Szegedy 撰写的批规范论文于 2015 年提交给 ICML）。<br/> 模型结构：</p>\n<ul><li>卷积池化层</li><li>残差层（由多个残差块构成）</li><li>平均池化层</li><li>全连接层</li></ul>\n<p>模型代码如下：</p>\n<pre><code class=\"prism language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BasicBlock</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    multiplier <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>BasicBlock<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>shortcut <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> in_channels <span class=\"token operator\">!=</span> out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier <span class=\"token keyword\">or</span> stride <span class=\"token operator\">!=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>shortcut <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n                torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        residual <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        shortcut <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>shortcut<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>residual <span class=\"token operator\">+</span> shortcut<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Bottleneck</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    multiplier <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Bottleneck<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>out_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>shortcut <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> in_channels <span class=\"token operator\">!=</span> out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier <span class=\"token keyword\">or</span> stride <span class=\"token operator\">!=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>shortcut <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n                torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        resiudual <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv3<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        shortcut <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>shortcut<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>resiudual <span class=\"token operator\">+</span> shortcut<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ResNet</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> layer_num<span class=\"token operator\">=</span><span class=\"token number\">18</span><span class=\"token punctuation\">,</span> label_num<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>ResNet<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>base_channels <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\n        block_type<span class=\"token punctuation\">,</span> block_nums <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>res_net_params<span class=\"token punctuation\">(</span>layer_num<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv_pool_layer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>base_channels<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">7</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>base_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>res_layers <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>res_layer<span class=\"token punctuation\">(</span>block_type<span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> block_nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>res_layer<span class=\"token punctuation\">(</span>block_type<span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> block_nums<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>res_layer<span class=\"token punctuation\">(</span>block_type<span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> block_nums<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>res_layer<span class=\"token punctuation\">(</span>block_type<span class=\"token punctuation\">,</span> <span class=\"token number\">512</span><span class=\"token punctuation\">,</span> block_nums<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># 平均池化，平均池化成1*1</span>\n        self<span class=\"token punctuation\">.</span>avg_pool_layer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc_layer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">512</span> <span class=\"token operator\">*</span> block_type<span class=\"token punctuation\">.</span>multiplier<span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">res_layer</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> block_type<span class=\"token punctuation\">,</span> out_channel<span class=\"token punctuation\">,</span> block_num<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        blocks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>block_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            new_block <span class=\"token operator\">=</span> block_type<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>base_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channel<span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span>stride<span class=\"token punctuation\">)</span>\n            blocks<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>new_block<span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>base_channels <span class=\"token operator\">=</span> out_channel <span class=\"token operator\">*</span> new_block<span class=\"token punctuation\">.</span>multiplier\n        <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>blocks<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">res_net_params</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> layer_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> layer_num <span class=\"token operator\">==</span> <span class=\"token number\">18</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> BasicBlock<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> layer_num <span class=\"token operator\">==</span> <span class=\"token number\">34</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> BasicBlock<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> layer_num <span class=\"token operator\">==</span> <span class=\"token number\">50</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> Bottleneck<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>   \n        <span class=\"token keyword\">if</span> layer_num <span class=\"token operator\">==</span> <span class=\"token number\">101</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> Bottleneck<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">23</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> layer_num <span class=\"token operator\">==</span> <span class=\"token number\">152</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> Bottleneck<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">36</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>res_layers<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>avg_pool_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc_layer<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n</code></pre>\n<h1><a id=\"GoogLeNet_345\"></a>五、GoogLeNet</h1>\n<p>GoogLeNet 最大的特点就是 inception 的设计，主要是为了解决网络训练问题，随着网络深度越来越深，参数也越来越多，这使得网络训练越来越慢，同时也会带来其他副作用：梯度消失/爆炸，过拟合等。<br/> inception 的设计就是为了缓解这些情况。<br/> <img alt=\"GooLeNet网络结构\" src=\"https://img-blog.csdnimg.cn/20210608142304800.PNG\"/><br/> 模型代码如下：</p>\n<pre><code class=\"prism language-python\"><span class=\"token comment\"># GoogLeNet Inception模块</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Inception</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels_1<span class=\"token punctuation\">,</span> out_channels_2_1<span class=\"token punctuation\">,</span> out_channels_2_2<span class=\"token punctuation\">,</span> out_channels_3_1<span class=\"token punctuation\">,</span> out_channels_3_2<span class=\"token punctuation\">,</span> out_channels_4<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Inception<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>branch1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_1<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span> \n        self<span class=\"token punctuation\">.</span>branch2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_2_1<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_2_1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>out_channels_2_1<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_2_2<span class=\"token punctuation\">,</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_2_2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>branch3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_3_1<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_3_1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>out_channels_3_1<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_3_2<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_3_2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>branch4 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span>out_channels_4<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels_4<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x_1 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>branch1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x_2 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>branch2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x_3 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>branch3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x_4 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>branch4<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x_1<span class=\"token punctuation\">,</span> x_2<span class=\"token punctuation\">,</span> x_3<span class=\"token punctuation\">,</span> x_4<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n<span class=\"token comment\"># 辅助分类器</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">AuxClassifier</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> label_num<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>AuxClassifier<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>average_pool <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>AvgPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>softmax <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Softmax<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>average_pool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> x\n<span class=\"token comment\"># GoogLeNet</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">GoogLeNet</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> label_num<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> aux<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>GoogLeNet<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>aux <span class=\"token operator\">=</span> aux\n        self<span class=\"token punctuation\">.</span>conv_pool <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            <span class=\"token comment\"># (1*28*28) -&gt; (8*28*28)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">7</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># (8*28*28) -&gt; (8*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># (8*14*14) -&gt; (8*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># (8*14*14) -&gt; (24*14*14)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">24</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">24</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\"># (24*14*14) -&gt; (24*7*7)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>inceptions_1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">24</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>          <span class=\"token comment\"># inception3a</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">24</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>        <span class=\"token comment\"># inception3b</span>\n            <span class=\"token comment\"># (24*7*7) -&gt; (24*3*3)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>      <span class=\"token comment\"># MaxPool 3*3+2(S)</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">60</span><span class=\"token punctuation\">,</span> <span class=\"token number\">24</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">26</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span>          <span class=\"token comment\"># inception4a</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>aux1 <span class=\"token operator\">=</span> AuxClassifier<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">,</span> dropout<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>inceptions_2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>         <span class=\"token comment\"># inception4b</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>         <span class=\"token comment\"># inception4c</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">18</span><span class=\"token punctuation\">,</span> <span class=\"token number\">36</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>         <span class=\"token comment\"># inception4d</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">66</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>       <span class=\"token comment\"># inception4e</span>\n            <span class=\"token comment\"># (24*3*3) -&gt; (24*1*1)</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>       <span class=\"token comment\"># MaxPool 3*3+2(S)</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>aux2 <span class=\"token operator\">=</span> AuxClassifier<span class=\"token punctuation\">(</span><span class=\"token number\">66</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">,</span> dropout<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>inceptions_3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">104</span><span class=\"token punctuation\">,</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>      <span class=\"token comment\"># inception5a</span>\n            Inception<span class=\"token punctuation\">(</span><span class=\"token number\">104</span><span class=\"token punctuation\">,</span> <span class=\"token number\">48</span><span class=\"token punctuation\">,</span> <span class=\"token number\">24</span><span class=\"token punctuation\">,</span> <span class=\"token number\">48</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">)</span>       <span class=\"token comment\"># inception5b</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>avg_pool <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>AdaptiveAvgPool2d<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>dropout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> label_num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv_pool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        \n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>inceptions_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>training <span class=\"token keyword\">and</span> self<span class=\"token punctuation\">.</span>aux<span class=\"token punctuation\">:</span>\n            x_aux_1 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>aux1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>inceptions_2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>training <span class=\"token keyword\">and</span> self<span class=\"token punctuation\">.</span>aux<span class=\"token punctuation\">:</span>\n            x_aux_2 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>aux2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>inceptions_3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>avg_pool<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>aux<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> x<span class=\"token punctuation\">,</span> x_aux_1<span class=\"token punctuation\">,</span> x_aux_2\n        <span class=\"token keyword\">return</span> x\n</code></pre>\n<hr/>\n<h1><a id=\"_484\"></a>总结</h1>\n<p>以上就是本篇文章介绍的CNN的5种经典架构，欢迎相互学习交流！</p>\n</div>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-22a2fefd3b.css\" rel=\"stylesheet\"/>\n<link href=\"https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-4f8fbf9108.css\" rel=\"stylesheet\"/>\n</div>", "first_tag": "Python", "cpp": 0, "csharp": 0, "python": 1, "javascript": 0, "java": 0, "sql": 0, "php": 0, "time": "2022-09-07 12:44:43", "summary": "目录前言一、二、三、四、五、总结前言近几年来，我们见证了无数的诞生，本篇文章介绍了的种经典架构：数据集手写数字识别请移步：实现数据集手写数字识别以下面案例可供参考一、神经网络结构在中，第一个卷积池化层"}